{"meta":{"title":"Maisyの博客","subtitle":"记录生活中的点点滴滴","description":"人的一生就是一个储蓄的过程，在奋斗的时候储存了希望；在耕耘的时候储存了一粒种子；在旅行的时候储存了风景；在微笑的时候储存了快乐。聪明的人善于储蓄，在漫长而短暂的人生旅途中，学会储蓄每一个闪光的瞬间，然后用它们酿成一杯美好的回忆，在四季的变幻与交替之间，散发浓香，珍藏一生","author":"Maisy","url":"https://pdxblog.top","root":"/"},"pages":[{"title":"tags","date":"2020-01-25T12:57:30.000Z","updated":"2020-01-25T12:58:43.644Z","comments":true,"path":"tags/index.html","permalink":"https://pdxblog.top/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2020-01-24T14:29:44.000Z","updated":"2020-01-24T14:30:26.053Z","comments":true,"path":"categories/index.html","permalink":"https://pdxblog.top/categories/index.html","excerpt":"","text":""},{"title":"热门文章Top 10","date":"2018-10-29T16:54:50.000Z","updated":"2020-05-12T07:55:24.901Z","comments":false,"path":"top/index.html","permalink":"https://pdxblog.top/top/index.html","excerpt":"","text":"var APP_ID = ******; //输入个人LeanCloud账号AppID var APP_KEY = ******; //输入个人LeanCloud账号AppKey AV.init({ appId: APP_ID, appKey: APP_KEY }); var query = new AV.Query('Counter');//表名 query.descending('time'); //结果按阅读次数降序排序 query.limit(10); //最终只返回10条结果 query.find().then( response => { var content = response.reduce( (accum, {attributes}) => { accum += `热度 ${attributes.time} ℃${attributes.title}` return accum; },\"\") document.querySelector(\"#post-rank\").innerHTML = content; }) .catch( error => { console.log(error); }); #post-rank { text-align: center; } #post-rank .prefix { color: #ff4d4f; }"},{"title":"派大星","date":"2020-01-25T13:20:10.000Z","updated":"2020-01-25T13:22:20.493Z","comments":true,"path":"about/index.html","permalink":"https://pdxblog.top/about/index.html","excerpt":"","text":"扎实的专业知识是我最大的财富；认真踏实是我做事的原则；不断超越创新是我追求的目标；"}],"posts":[{"title":"Keepalived+mysql双主来实现MySQL-HA","slug":"Keepalived+mysql双主来实现MySQL-HA","date":"2020-07-10T16:00:00.000Z","updated":"2020-07-11T11:38:10.977Z","comments":true,"path":"Keepalived+mysql双主来实现MySQL-HA.html","link":"","permalink":"https://pdxblog.top/Keepalived+mysql%E5%8F%8C%E4%B8%BB%E6%9D%A5%E5%AE%9E%E7%8E%B0MySQL-HA.html","excerpt":"","text":"¶Keepalived+mysql双主来实现MySQL-HA 生产环境中一台mysql主机存在单点故障，所以我们要确保mysql的高可用性，即两台MySQL服务器如果其中有 一台MySQL服务器挂掉后，另外一台能立马接替其进行工作。 MySQL的高可用方案一般有如下几种：keepalived+双主，MHA，PXC，MMM，Heartbeat+DRBD等，比较常用的是keepalived+双主，MHA和PXC。 本节主要介绍了利用 keepalived 实现 MySQL 数据库的高可用。 Keepalived+mysql双主来实现MySQL-HA，我们必须保证两台MySQL数据库的数据完全一样，基本思路是两台MySQL互为主从关系，通过Keepalived配置虚拟IP，实现当其中的一台MySQL数据库宕机后，应用能够自动切换到另外一台MySQL数据库，保证系统的高可用。 ¶一、实验环境 操作系统 CentOS 7 数据库版本 V5.7 master A地址 192.168.206.130 master B地址 192.168.206.131 安装目录 在线安装 数据目录 /var/lib/mysql 注意下面几点： 1231. 要保证同步服务期间之间的网络联通。即能相互ping通，能使用对方授权信息连接到对方数据库（防火墙开放3306端口）。2. 关闭selinux。3. 同步前，双方数据库中需要同步的数据要保持一致。这样，同步环境实现后，再次更新的数据就会如期同步了。 ¶二、MySQL复制 ¶1、MySQL支持哪些复制 ¶（1）基于语句的复制 在主服务器上执行的sql语句，在从服务器上执行同样的语句。mysql默认采用基于语句的复制，效率比较高。一旦发现没法精确复制时，会自动选择基于行的复制。 ¶（2）基于行的复制 把改变的内容复制过去，而不是把命令在从服务器上执行一遍，从mysql 5.0开始支持。 ¶（3）混合类型的复制 默认采用基于语句的复制，一旦发现基于语句的无法精确复制时，就会采用基于行的复制。 ¶2、MySQL复制解决的问题 数据分布（data distribution） 负载平衡（load balancing） 数据备份（backup），保证数据安全 高可用性与容错行（high availability and failover） 实现读写分离，缓解数据库压力 ¶3、MySQL主从复制原理 master服务器将数据的改变记录二进制binlog日志，当master上的数据发生改变时，则将其改变写入二进制日志中；slave服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变。如果发生改变，则开始一个I/O Thread请求master二进制事件，同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的中继日志中，从节点将启动SQL线程从中继日志 中读取二进制日志，在本地重放，使得其数据和主节点的保持一致，最后I/O Thread和SQL Thread将进入睡眠状态，等待下一次被唤醒。 注意几点： 12345（1）master将操作语句记录到binlog日志中，然后授予slave远程连接的权限（master一定要开启binlog二进制日志功能；通常为了数据安全考虑，slave也开启binlog功能）。（2）-slave开启两个线程：IO线程和SQL线程。其中：IO线程负责读取master的binlog内容到中继日志relay log里；SQL线程负责从relay log日志里读出binlog内容，并更新到slave的数据库里，这样就能保证slave数据和 master数据保持一致了。（3）Mysql复制至少需要两个Mysql的服务，当然Mysql服务可以分布在不同的服务器上，也可以在一台服务器上启动多个服务。（4）Mysql复制最好确保master和slave服务器上的Mysql版本相同（如果不能满足版本一致，那么要保证master主节点的版本低于slave从节点的版本）。（5）master和slave两节点间时间需同步。 ¶4、MySQL复制流程 Mysql复制的流程图如下： 如上图所示： Mysql复制过程的第一部分就是master记录二进制日志。在每个事务更新数据完成之前，master在二日志记录这些改变。MySQL将事务串行的写入二进制日志，即使事务中的语句都是交叉执行的。在事件写入二进制日志完成后，master通知存储引擎提交事务。 第二部分就是slave将master的binary log拷贝到它自己的中继日志。首先，slave开始一个工作线程——I/O线程。I/O线程在master上打开一个普通的连接，然后开始binlog dump process。Binlog dump process从master的二进制日志中读取事件，如果已经跟上master，它会睡眠并等待master产生新的事件。I/O线程将这些事件写入中继日志。 SQL slave thread（SQL从线程）处理该过程的最后一步。SQL线程从中继日志读取事件，并重放其中的事件而更新slave的数据，使其与master中的数据一致。只要该线程与I/O线程保持一致，中继日志通常会位于OS的缓存中，所以中继日志的开销很小。 此外，在master中也有一个工作线程：和其它MySQL的连接一样，slave在master中打开一个连接也会使得master开始一个线程。复制过程有一个很重要的限制——复制在slave上是串行化的，也就是说master上的并行更新操作不能在slave上并行操作。 ¶5、MySQL复制的模式 ¶（1）主从复制 主库授权从库远程连接，读取binlog日志并更新到本地数据库的过程；主库写数据后，从库会自动同步过来（从库跟着主库变）。 ¶（2）主主复制 主从相互授权连接，读取对方binlog日志并更新到本地数据库的过程；只要对方数据改变，自己就跟着改变。 ¶6、MySQL主从复制优点 123（1）在从服务器可以执行查询工作(即我们常说的读功能)，降低主服务器压力;（主库写，从库读，降压）（2）在从主服务器进行备份，避免备份期间影响主服务器服务;（确保数据安全）（3）当主服务器出现问题时，可以切换到从服务器。（提升性能） ¶7、MySQL主从复制工作流程细节 （1）MySQL支持单向、异步复制，复制过程中一个服务器充当主服务器，而一个或多个其它服务器充当从服务器。 MySQL复制基于主服务器在二进制日志中跟踪所有对数据库的更改(更新、删除等等)。因此，要进行复制，必须在主服务器上启用二进制日志。每个从服务器从主服务器接收主服务器上已经记录到其二进制日志的保存的更新。当一个从服务器连接主服务器时，它通知主服务器定位到从服务器在日志中读取的最后一次成功更新的位置。从服务器接收从那时起发生的任何更新，并在本机上执行相同的更新。然后封锁并等待主服务器通知新的更新。从服务器执行备份不会干扰主服务器，在备份过程中主服务器可以继续处理更新。 （2）MySQL使用3个线程来执行复制功能，其中两个线程(Sql线程和IO线程)在从服务器，另外一个线程(IO线程)在主服务器。 当发出START SLAVE时，从服务器创建一个I/O线程，以连接主服务器并让它发送记录在其二进制日志中的语句。主服务器创建一个线程将二进制日志中的内容发送到从服务器。该线程可以即为主服务器上SHOW PROCESSLIST的输出中的Binlog Dump线程。从服务器I/O线程读取主服务器Binlog Dump线程发送的内容并将该数据拷贝到从服务器数据目录中的本地文件中，即中继日志。第3个线程是SQL线程，由从服务器创建，用于读取中继日志并执行日志中包含的更新。在从服务器上，读取和执行更新语句被分成两个独立的任务。当从服务器启动时，其I/O线程可以很快地从主服务器索取所有二进制日志内容，即使SQL线程执行更新的远远滞后。 ¶8、总结 ¶（1）主从数据完成同步的过程 123451）在Slave 服务器上执行sart slave命令开启主从复制开关，开始进行主从复制。2）此时，Slave服务器的IO线程会通过在master上已经授权的复制用户权限请求连接master服务器，并请求从执行binlog日志文件的指定位置（日志文件名和位置就是在配置主从复制服务时执行change master命令指定的）之后开始发送binlog日志内容。3）Master服务器接收到来自Slave服务器的IO线程的请求后，其上负责复制的IO线程会根据Slave服务器的IO线程请求的信息分批读取指定binlog日志文件指定位置之后的binlog日志信息，然后返回给Slave端的IO线程。返回的信息中除了binlog日志内容外，还有在Master服务器端记录的IO线程。返回的信息中除了binlog中的下一个指定更新位置。4）当Slave服务器的IO线程获取到Master服务器上IO线程发送的日志内容、日志文件及位置点后，会将binlog日志内容依次写到Slave端自身的Relay Log（即中继日志）文件（Mysql-relay-bin.xxx）的最末端，并将新的binlog文件名和位置记录到master-info文件中，以便下一次读取master端新binlog日志时能告诉Master服务器从新binlog日志的指定文件及位置开始读取新的binlog日志内容。5）Slave服务器端的SQL线程会实时检测本地Relay Log 中IO线程新增的日志内容，然后及时把Relay LOG 文件中的内容解析成sql语句，并在自身Slave服务器上按解析SQL语句的位置顺序执行应用这样sql语句，并在relay-log.info中记录当前应用中继日志的文件名和位置点。 ¶（2）主从复制条件 12341）开启Binlog功能2）主库要建立账号3）从库要配置master.info（CHANGE MASTER to...相当于配置密码文件和Master的相关信息）4）start slave 开启复制功能 ¶（3）需要了解的 123451）3个线程，主库IO，从库IO和SQL及作用2）master.info（从库）作用3）relay-log 作用4）异步复制5）binlog作用（如果需要级联需要开启Binlog） ¶（4）需要注意的 123451）主从复制是异步的逻辑的SQL语句级的复制2）复制时，主库有一个I/O线程，从库有两个线程，I/O和SQL线程3）实现主从复制的必要条件是主库要开启记录binlog功能4）作为复制的所有Mysql节点的server-id都不能相同5）binlog文件只记录对数据库有更改的SQL语句（来自主库内容的变更），不记录任何查询（select，show）语句 ¶三、配置两台MySQL主从复制 ¶1、主从复制实现过程 ¶（1）master配置 ¶1）配置master数据库的my.cnf文件 在[mysqld]配置区域添加下面内容： 12345678[mysqld] server-id=1 #数据库唯一ID，主从的标识号绝对不能重复。log-bin=mysql-bin #开启bin-log，并指定文件目录和文件名前缀binlog-do-db=liting #需要同步liting数据库。如果是多个同步库，就以此格式另写几行即可。如果不指明对某个具体库同步，就去掉此行，表示同步所有库（除了ignore忽略的库）。binlog-ignore-db=mysql #不同步mysql系统数据库。如果是多个不同步库，就以此格式另写几行；也可以在一行，中间逗号隔开。sync_binlog = 1 #确保binlog日志写入后与硬盘同步binlog_checksum = none #跳过现有的采用checksum的事件，mysql5.6.5以后的版本中binlog_checksum=crc32,而低版本都是binlog_checksum=nonebinlog_format = mixed #bin-log日志文件格式，设置为MIXED可以防止主键重复。 温馨提示： 123456在主服务器上最重要的二进制日志设置是sync_binlog，这使得mysql在每次提交事务的时候把二进制日志的内容同步到磁盘上，即使服务器崩溃也会把事件写入日志中。sync_binlog这个参数是对于MySQL系统来说是至关重要的，他不仅影响到Binlog对MySQL所带来的性能损耗，而且还影响到MySQL中数据的完整性。对于&quot;sync_binlog&quot;参数的各种设置的说明如下：sync_binlog&#x3D;0，当事务提交之后，MySQL不做fsync之类的磁盘同步指令刷新binlog_cache中的信息到磁盘，而让Filesystem自行决定什么时候来做同步，或者cache满了之后才同步到磁盘。sync_binlog&#x3D;n，当每进行n次事务提交之后，MySQL将进行一次fsync之类的磁盘同步指令来将binlog_cache中的数据强制写入磁盘。 在MySQL中系统默认的设置是sync_binlog&#x3D;0，也就是不做任何强制性的磁盘刷新指令，这时候的性能是最好的，但是风险也是最大的。因为一旦系统Crash，在binlog_cache中的所有binlog信息都会被丢失。而当设置为“1”的时候，是最安全但是性能损耗最大的设置。因为当设置为1的时候，即使系统Crash，也最多丢失binlog_cache中未完成的一个事务，对实际数据没有任何实质性影响。 从以往经验和相关测试来看，对于高并发事务的系统来说，“sync_binlog”设置为0和设置为1的系统写入性能差距可能高达5倍甚至更多。 ¶2）保证master与slave数据库一致 导出master数据库多余slave数据库中的数据，然后导入到slave数据库中。保证双方在同步环境实现前的数据一致。 注意：新建环境可忽略此步骤 导出数据库之前先锁定数据库 12# 数据库只读锁定命令，防止导出数据库的时候有数据写入。unlock tables命令解除锁定mysql&gt; flush tables with read lock; 导出master数据库中需要同步的库(master数据库的root用户登陆密码：1234) 1234[root@master ~]# mysqldump -uroot liting -p1234 &gt;/opt/liting.sql# 将导出的sql文件上传到slave机器上[root@master ~]# rsync -e \"ssh -p22\" -avpgolr /opt/liting.sql 192.168.0.104:/opt/ ¶3）设置数据同步权限 123456mysql&gt; grant replication slave,replication client on *.* to repl@&#39;192.168.0.104&#39; identified by &quot;repl123&quot;; #只允许192.168.0.104使用repl，且密码为&quot;repl123&quot;连接主库做数据同步 Query OK, 0 rows affected (0.02 sec) #若要所有网段则设置repl@&#39;%&#39; ；部分网段：repl@&#39;192.168.0.%&#39; mysql&gt; flush privileges; Query OK, 0 rows affected (0.00 sec) 温馨提示： 权限查看方式 12mysql&gt; show grants;mysql&gt; show grants for repl@&#39;192.168.0.104&#39;; ¶4）查看主服务器master状态 注意File与Position项，从服务器需要这两项参数。 1234567mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000007 | 120 | liting | mysql | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) ¶（2）slave配置 下面是slave数据库上的操作： ¶1）设置slave数据库的my.cnf文件 在[mysqld]配置区域添加下面内容： 123456[mysqld]server-id=2 #设置从服务器id，必须于主服务器不同log-bin=mysql-bin #启动MySQ二进制日志系统replicate-do-db=liting #需要同步的数据库名。如果不指明同步哪些库，就去掉这行，表示所有库的同步（除了ignore忽略的库）。replicate-ignore-db=mysql #不同步test数据库slave-skip-errors = all #跳过所有的错误，继续执行复制操作 温馨提示： 当只针对某些库的某张表进行同步时，如下，只同步liting库的haha表和test库的heihei表： 1234replicate-do-db = litingreplicate-wild-do-table = liting.haha ``//``当只同步几个或少数表时，可以这样设置。注意这要跟上面的库指定配合使用；replicate-do-db = testreplicate-wild-do-table = test.heihei ``//``如果同步的库的表比较多时，就不能这样一一指定了，就把这个选项配置去掉，直接根据指定的库进行同步。 ¶2）保证master与slave数据库一致 在slave数据库中导入从master传过来的数据。 123456# 先创建一个liting空库，否则下面导入数据时会报错说此库不存在。mysql&gt; CREATE DATABASE liting CHARACTER SET utf8 COLLATE utf8_general_ci;mysql&gt; use liting;# 导入master中多余的数据。mysql&gt; source &#x2F;opt&#x2F;liting.sql; ¶3）配置主从同步指令 123456789mysql&gt; stop slave; #执行同步前，要先关闭slavemysql&gt; change master to master_host&#x3D;&#39;192.168.0.103&#39;,master_user&#x3D;&#39;repl&#39;,master_password&#x3D;&#39;repl123&#39;,master_log_file&#x3D;&#39;mysql-bin.000007&#39;,master_log_pos&#x3D;120; mysql&gt; start slave;mysql&gt; show slave status \\G;....... Slave_IO_Running: Yes Slave_SQL_Running: Yes...... 如上，当IO和SQL线程的状态均为Yes，则表示主从已实现同步了！ ¶2、测试 下面测试下Mysql主从同步的效果，在master主数据库上写入新数据 12345mysql&gt; use liting;mysql&gt;create table if not exists haha (id int(10) PRIMARY KEY AUTO_INCREMENT,name varchar(50) NOT NULL);Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into huanqiu.haha values(100,&#39;anhui&#39;);Query OK, 1 row affected (0.00 sec) 然后在slave数据库上查看，发现master上新写入的数据已经同步过来了。 1234567mysql&gt; select * from liting.haha;+-----+-----------+| id | name |+-----+-----------+| 100 | anhui |+-----+-----------+1 rows in set(0.00 sec) 至此，主从同步环境已经实现！ ¶四、配置两台MySQL主主复制 根据上面的主从环境部署，master和slave已经实现同步，即在master上写入新数据，自动同步到slave。而从库只能读不能写，一旦从库有写入数据，就会造成主从数据不一致！ 下面就说下Mysql主主复制环境，在slave上更新数据时，master也能自动同步过来。 ¶1、温馨提示 在做主主同步前，提醒下需要特别注意的一个问题： 主主复制和主从复制有一些区别，因为多主中都可以对服务器有写权限，所以设计到自增长重复问题，例如： 出现的问题（多主自增长ID重复） 12341）首先在A和B两个库上创建test表结构;2）停掉A，在B上对数据表test(存在自增长属性的ID字段)执行插入操作，返回插入ID为1;3）然后停掉B，在A上对数据表test(存在自增长属性的ID字段)执行插入操作，返回的插入ID也是1;4）然后同时启动A,B，就会出现主键ID重复 ¶2、解决方法 只要保证两台服务器上的数据库里插入的自增长数据不同就可以了。 如：A插入奇数ID，B插入偶数ID，当然如果服务器多的话，还可以自定义算法，只要不同就可以了。 在下面例子中，在两台主主服务器上加入参数，以实现奇偶插入！ 记住：在做主主同步时需要设置自增长的两个相关配置，如下： 12auto_increment_offset 表示自增长字段从那个数开始，取值范围是1 .. 65535。这个就是序号。如果有n台mysql机器，则从第一台开始分为设1，2...nauto_increment_increment 表示自增长字段每次递增的量，其默认值是1，取值范围是1 .. 65535。如果有n台mysql机器，这个值就设置为n。 在主主同步配置时，两台服务器的自增长参数设置如下： 12auto_increment_increment 增长量都配置为2auto_increment_offset 分别配置为1和2。这是序号，第一台从1开始，第二台就是2，以此类推..... 这样才可以避免两台服务器同时做更新时自增长字段的值之间发生冲突。（针对的是有自增长属性的字段） ¶3、主主同步实现操作过程 ¶（1）master配置 ¶1）配置master数据库的my.cnf文件 在[mysqld]配置区域添加下面内容： 12345678910111213[root@master ~]# vim /etc/my.cnf# server-id = 1 log-bin = mysql-bin binlog-ignore-db = mysql,information_schemasync_binlog = 1binlog_checksum = nonebinlog_format = mixed# auto-increment-increment = 2 # auto-increment-offset = 1 slave-skip-errors = all ¶2）重启MySQL 1[root@master ~]# systemctl restart mysqld ¶3）设置数据同步授权 防火墙开启3306端口 12[root@master ~]# firewall-cmd --zone=public --add-port=3306/tcp --permanent[root@master ~]# firewall-cmd --reload 要确保对方机器能使用下面权限连接到本机mysql。 12345678910111213141516171819202122232425mysql&gt; SHOW VARIABLES LIKE &#39;validate_password%&#39;;+--------------------------------------+--------+| Variable_name | Value |+--------------------------------------+--------+| validate_password_check_user_name | OFF || validate_password_dictionary_file | || validate_password_length | 8 || validate_password_mixed_case_count | 1 || validate_password_number_count | 1 || validate_password_policy | MEDIUM || validate_password_special_char_count | 1 |+--------------------------------------+--------+7 rows in set (0.00 sec)mysql&gt; set global validate_password_policy&#x3D;LOW;Query OK, 0 rows affected (0.00 sec)mysql&gt; set global validate_password_length&#x3D;6;Query OK, 0 rows affected (0.00 sec)mysql&gt; grant replication slave,replication client on *.* to repl@&#39;192.168.206.131&#39; identified by &#39;123456&#39;;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) 最好将库锁住，仅仅允许读，以保证数据一致性；待主主同步环境部署后再解锁；锁住后，就不能往表里写数据，但是重启mysql服务后就会自动解锁！ 1234567891011# 注意该参数设置后，如果自己同步对方数据，同步前一定要记得先解锁！mysql&gt; FLUSH TABLES WITH READ LOCK;Query OK, 0 rows affected (0.00 sec)mysql&gt; show master status;+------------------+----------+--------------+--------------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+--------------------------+-------------------+| mysql-bin.000002 | 613 | | mysql,information_schema | |+------------------+----------+--------------+--------------------------+-------------------+1 row in set (0.00 sec) ¶（2）slave配置 如果是克隆的mysql，需要修改uuid，不能与master的uuid相同。如下所示： 1234[root@slave ~]# vim /var/lib/mysql/auto.cnf[auto]server-uuid=5e007fd8-afb0-11ea-93a9-000c29bfd16d ¶1）配置slave数据库的my.cnf文件 12345678910111213[root@slave ~]# vim /etc/my.cnf#server-id= 2 log-bin = mysql-bin binlog-ignore-db = mysql,information_schemasync_binlog = 1binlog_checksum = nonebinlog_format = mixed#auto-increment-increment = 2 #auto-increment-offset = 2 slave-skip-errors = all ¶2）重启MySQL 1[root@slave ~]# systemctl restart mysqld ¶3）设置数据同步授权 防火墙开启3306端口 12[root@slave ~]# firewall-cmd --zone=public --add-port=3306/tcp --permanent[root@slave ~]# firewall-cmd --reload 要确保对方机器能使用下面权限连接到本机mysql。 同理，slave也要授权给master机器远程同步数据的权限。 123456789101112131415161718192021222324252627282930313233343536mysql&gt; SHOW VARIABLES LIKE &#39;validate_password%&#39;;+--------------------------------------+--------+| Variable_name | Value |+--------------------------------------+--------+| validate_password_check_user_name | OFF || validate_password_dictionary_file | || validate_password_length | 8 || validate_password_mixed_case_count | 1 || validate_password_number_count | 1 || validate_password_policy | MEDIUM || validate_password_special_char_count | 1 |+--------------------------------------+--------+7 rows in set (0.00 sec)mysql&gt; set global validate_password_policy&#x3D;LOW;Query OK, 0 rows affected (0.00 sec)mysql&gt; set global validate_password_length&#x3D;6;Query OK, 0 rows affected (0.00 sec)mysql&gt; grant replication slave,replication client on *.* to repl@&#39;192.168.206.130&#39; identified by &#39;123456&#39;;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.02 sec)mysql&gt; FLUSH TABLES WITH READ LOCK;Query OK, 0 rows affected (0.00 sec)mysql&gt; show master status;+------------------+----------+--------------+--------------------------+------------------ -+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+--------------------------+------------------ -+| mysql-bin.000001 | 613 | | mysql,information_schema | |+------------------+----------+--------------+--------------------------+------------------ -+1 row in set (0.00 sec) ¶4、测试 ¶（1）主主双向同步 ¶1）slave同步master 确保slave上要同步的数据，提前在master上存在，最好双方数据保持一致。 1234567891011121314151617181920212223242526272829#先解锁，将对方数据同步到自己的数据库中mysql&gt; unlock tables;Query OK, 0 rows affected (0.00 sec)mysql&gt; stop slave;Query OK, 0 rows affected (0.00 sec)mysql&gt; change master to master_host&#x3D;&#39;192.168.206.130&#39;,master_user&#x3D;&#39;repl&#39;,master_password&#x3D;&#39;123456&#39;,master_log_file&#x3D;&#39;mysql-bin.000001&#39;,master_log_pos&#x3D;150;Query OK, 0 rows affected, 2 warnings (0.01 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.01 sec)mysql&gt; show slave status \\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.206.130 Master_User: repl ...... Slave_IO_Running: Yes Slave_SQL_Running: Yes ...... Master_Server_Id: 1 Master_UUID: 5e007fd8-afb0-11ea-93a9-000c29bfd16c Master_Info_File: &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;master.info 这样就实现了slave－&gt;master的同步环境。 ¶2）master同步slave 确保slave上要同步的数据，提前在master上存在，最好双方数据保持一致。 1234567891011121314151617181920212223242526mysql&gt; unlock tables;Query OK, 0 rows affected (0.00 sec)mysql&gt; stop slave;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; change master to master_host&#x3D;&#39;192.168.206.131&#39;,master_user&#x3D;&#39;repl&#39;,master_password&#x3D;&#39;123456&#39;,master_log_file&#x3D;&#39;mysql-bin.000001&#39;,master_log_pos&#x3D;150;Query OK, 0 rows affected, 2 warnings (0.05 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.01 sec)mysql&gt; show slave status \\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.206.131 Master_User: repl Master_Port: 3306 ...... Slave_IO_Running: Yes Slave_SQL_Running: Yes ...... Master_UUID: 5e007fd8-afb0-11ea-93a9-000c29bfd16d Master_Info_File: &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;master.info 这样就实现了master－&gt;slave的同步环境。至此，主主双向同步环境已经实现！ ¶（2）主主同步 ¶1）在master上写入新数据 123456789101112131415161718192021mysql&gt; create database student;Query OK, 1 row affected (0.03 sec)mysql&gt; use student;Database changedmysql&gt; create table grade(id int);Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into grade values(1),(2),(3);Query OK, 3 rows affected (0.01 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; select * from grade;+------+| id |+------+| 1 || 2 || 3 |+------+3 rows in set (0.00 sec) ¶2）在slave数据库中查看 发现master新写入的数据已经同步过来了。 1234567891011121314151617181920212223242526mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || student || sys |+--------------------+5 rows in set (0.06 sec)mysql&gt; use student;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; select * from grade;+------+| id |+------+| 1 || 2 || 3 |+------+3 rows in set (0.00 sec) ¶3） 在slave上删除数据 12mysql&gt; delete from grade where id&#x3D;1;Query OK, 1 row affected (0.35 sec) ¶4）在master数据库中查看 12345678mysql&gt; mysql&gt; select * from grade;+------+| id |+------+| 2 || 3 |+------+2 rows in set (0.00 sec) 以上，主主同步实现。 ¶五、Keepalived高可用 高可用：两台业务系统启动着相同的服务，如果有一台故障，另一台自动接管,我们将将这个称之为高可用。 ¶1、Keepalived简介 keepalived是集群管理中保证集群高可用的一个软件解决方案，其功能类似于heartbeat，用来防止单点故障 keepalived是以VRRP协议为实现基础的，VRRP全称Virtual RouterRedundancy Protocol，即虚拟路由冗余协议。 ¶2、Keepalived工作原理 虚拟路由冗余协议，可以认为是实现路由器高可用的协议，即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个master和多个backup，master上面有一个对外提供服务的vip，master会发组播（组播地址为224.0.0.18），当backup收不到vrrp包时就认为master宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master。这样的话就可以保证路由器的高可用了。 ¶3、Keepalived主要模块 keepalived主要有三个模块，分别是core 、check和vrrp。 123(1)core模块为keepalived的核心，负责主进程的启动、维护以及全局配置文件的加载和解析。(2)check负责健康检查，包括常见的各种检查方式。(3)vrrp模块是来实现VRRP协议的。 ¶4、keepalived的安装配置 ¶（1）安装keepalived 在master1和master2上安装软件包keepalived，安装keepalived软件包与服务控制 在编译安装Keepalived之前，必须先安装内核开发包kernel-devel以及openssl-devel、popt-devel等支持库。 在两台master上进行如下操作： ¶1）下载Keepalived 1[root@192 ~]# wget https://www.keepalived.org/software/keepalived-2.0.20.tar.gz ¶2）安装依赖库 1[root@192 ~]# yum -y install kernel-devel openssl-devel popt-devel gcc ¶3）解压 1[root@192 ~]# tar zxf keepalived-2.0.20.tar.gz ¶4）安装 12[root@192 ~]# cd keepalived-2.0.20/[root@192 keepalived-2.0.20]# ./configure --prefix=/ &amp;&amp; make &amp;&amp; make install ¶5）使用keepalived服务 12systemctl enable keepalivedsystemctl start keepalived ¶6）创建防火墙规则 若开启了防火墙，需要关闭防火墙或创建规则。 12345firewall-cmd --direct --permanent --add-rule ipv4 filter OUTPUT 0 --in-interface ens33 --destination 224.0.0.18 --protocol vrrp -j ACCEPTfirewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 --in-interface ens33 --destination 224.0.0.18 --protocol vrrp -j ACCEPTfirewall-cmd --reload ¶（2）修改Keepalived配置文件 ¶1）配置区域 keepalived只有一个配置文件keepalived.conf，里面主要包括以下几个配置区域： 123（1）global_defs：主要是配置故障发生时的通知对象以及机器标识。（2）vrrp_instance：用来定义对外提供服务的VIP区域及其相关属性。（3）virtual_server：虚拟服务器定义 ¶2）配置说明 keepalived.conf文件配置内容如下： vim /etc/keepalived/keepalived.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869! Configuration File for keepalived //!表示注释global_defs &#123; router_id MYSQL-1 //表示运行keepalived服务器的一个标识&#125;vrrp_instance VI_1 &#123; # 指定keepalived的角色, 两台配置此处均是BACKUP,设为BACKUP将根据优先级决定主或从 state BACKUP # 指定HA监测网络的接口 interface ens33 # 虚拟路由标识，这个标识是一个数字(取值在0-255之间,用来区分多个instance的VRRP组播)， # 同一个vrrp实例使用唯一的标识,确保和master2相同，同网内不同集群此项必须不同,否则发生冲突。 virtual_router_id 51 # 用来选举master的，要成为master，该项取值范围是1-255（在此范围之外会被识别成默认值100）, # 此处master2上设置为50 priority 100 # 发VRRP包的时间间隔，即多久进行一次master选举（可以认为是健康查检时间间隔） advert_int 1 # 不抢占，即允许一个priority比较低的节点作为master，即使有priority更高的节点启动 nopreempt # 认证区域，认证类型有PASS和HA（IPSEC），推荐使用PASS（密码只识别前8位） authentication &#123; auth_type PASS auth_pass 1111 &#125; # VIP区域，指定vip地址 virtual_ipaddress &#123; 192.168.206.100 &#125;&#125;# 设置虚拟服务器，需要指定虚拟IP地址和服务端口，IP与端口之间用空格隔开virtual_server 192.168.206.100 3306 &#123; # 设置运行情况检查时间，单位是秒 delay_loop 2 # 设置后端调度算法，这里设置为rr，即轮询算法 lb_algo rr # 设置LVS实现负载均衡的机制，有NAT、TUN、DR三个模式可选 lb_kind DR # 会话保持时间，单位是秒。 # 这个选项对动态网页是非常有用的，为集群系统中的session共享提供了一个很好的解决方案。 # 有了这个会话保持功能，用户的请求会被一直分发到某个服务节点，直到超过这个会话的保持时间。 persistence_timeout 60 # 指定转发协议类型，有TCP和UDP两种 protocol TCP # 配置服务节点1，需要指定real server的真实IP地址和端口，IP与端口之间用空格隔开 # 注：master 2上此处改为192.168.206.130(即master2本机ip) real_server 192.168.206.130 3306 &#123; # 配置服务节点的权值，权值大小用数字表示，数字越大，权值越高， # 设置权值大小为了区分不同性能的服务器 weight 3 # 检测到realserver的mysql服务down后执行的脚本 notify_down /etc/keepalived/bin/mysql.sh TCP_CHECK &#123; # 连接超时时间 connect_timeout 3 # 重连次数 nb_get_retry 3 # 重连间隔时间 delay_before_retry 3 # 健康检查端口 connect_port 3306 &#125; &#125;&#125; ¶3）master1的配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@master1 ~]# vim /etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs &#123; router_id mysql-1&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 51 priority 100 advert_int 1 nopreempt authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.206.100 &#125;&#125;virtual_server 192.168.206.100 3306 &#123; delay_loop 6 lb_algo rr lb_kind DR persistence_timeout 60 protocol TCP real_server 192.168.206.130 3306 &#123; weight 1 notify_down /etc/keepalived/bin/mysql.sh TCP_CHECK &#123; connect_port 3306 connect_timeout 3 retry 3 delay_before_retry 3 &#125; &#125;&#125;[root@master1 ~]# systemctl start keepalived ¶4）master2的配置 将master1配置好的文件复制给master，稍加修改即可 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@master1 ~]# scp /etc/keepalived/keepalived.conf root@192.168.206.131:/etc/keepalived/[root@master2 ~]# vim /etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs &#123; router_id mysql-2 # 此处需要修改&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 51 priority 50 # 此处需要修改 advert_int 1 nopreempt authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.206.100 &#125;&#125;virtual_server 192.168.206.100 3306 &#123; delay_loop 6 lb_algo rr lb_kind DR persistence_timeout 60 protocol TCP real_server 192.168.206.131 3306 &#123; # 修改为本机的ip weight 1 notify_down /etc/keepalived/bin/mysql.sh TCP_CHECK &#123; connect_port 3306 connect_timeout 3 retry 3 delay_before_retry 3 &#125; &#125;&#125;[root@master2 ~]# systemctl start keepalived ¶（3）编写检测脚本 在两台master上进行如下操作： 123456[root@master1 ~]# mkdir /etc/keepalived/bin[root@master1 ~]# vim /etc/keepalived/bin/mysql.sh#!/bin/bashpkill keepalived[root@master1 ~]# chmod +x /etc/keepalived/bin/mysql.sh master1 和master2 上都添加此检测脚本，作用是当 mysql 停止工作时自动关闭本机的keepalived，从而实现将故障机器踢出（因每台机器上keepalived 只添加了本机为 realserver）。 当 mysqld 正常启动起来后，要手动启动 keepalived 服务。 ¶（4）测试 ¶1）测试一 在master1和master2分别执行ip addr show dev ens33命令查看master1和 master2对VIP（群集虚拟IP）的控制权。 master1主的查看结果： master2主的查看结果： 从上图可以看出master1 是主服务器，master2 为备用服务器。 ¶2）测试二 停止MySQL服务，看keepalived健康检查程序是否会触发我们编写的脚本。 停止master1主机的mysql服务 master1主的查看结果： master2主的查看结果： 这说明在主服务上停止MySQL服务，触发了我们编写的脚本，进行自动故障切换。 ¶3）MySQL 远程登录测试 我们找一台安装有MySQL 客户端，然后登录 VIP，看是否能登录。 在登录的两台 MySQL 服务器都要授权允许从远程登录。例如： 12345678910111213141516171819202122232425262728[root@master2 ~]# mysql -uroot -pEnter password:Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 83Server version: 5.7.30-log MySQL Community Server (GPL)Copyright (c) 2000, 2020, Oracle and&#x2F;or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement.mysql&gt; set global validate_password_policy&#x3D;LOW;Query OK, 0 rows affected (0.00 sec)mysql&gt; set global validate_password_length&#x3D;4;Query OK, 0 rows affected (0.00 sec)mysql&gt; grant all on *.* to &#39;root&#39;@&#39;%&#39; identified by &#39;1234&#39;;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)mysql&gt; exitBye 在客户端上测试登录 123[root@master1 ~]# mysql -uroot -p -h 192.168.206.100 -P3306mysql&gt; show variables like &#39;server_id&#39;; 上图显示说明在客户端访问 VIP 地址，由 master1 主机提供响应的，因为 master1 当前是主服务器，将 master1 的 mysql 服务停止，在客户端执行 show variableslike‘server_id’; 123[root@master1 ~]# systemctl stop mysqldmysql&gt; show variables like &#39;server_id&#39;; 上图显示说明在客户端的查询请求是由 master2 主机响应的，故障切换成功。 ¶六、Keepalived使用总结 Keepalived+mysql双主一般来说，中小型规模的时候，采用这种架构是最省事的。 在master节点发生故障后，利用keepalived的高可用机制实现快速切换到备用节点。 在这个方案里，有几个需要注意的地方： 1、采用 keepalived 作为高可用方案时，两个节点最好都设置成 BACKUP模式，避免因为意外情况下（比如 脑裂）相互抢占导致往两个节点写入相同数据而引发冲突； 2、把两个节点的 auto_increment_increment（自增步长）和 auto_increment_offset（自增起始值）设成不同值。其目的是为了避免master 节点意外宕机时，可能会有部分 binlog 未能及时复制到slave上被应用，从而会导致slave新写入数据的自增值和原先master上冲突了，因此一开始就使其错开；当然了，如果有合适的容错机制能解决主从自增ID 冲突的话，也可以不这么做； 3、slave 节点服务器配置不要太差，否则更容易导致复制延迟。作为热备节点的 slave服务器，硬件配置不能低于 master 节点； 4、如果对延迟问题很敏感的话，可考虑使用 MariaDB 分支版本，或者直接上线 MySQL 5.7 最新版本，利用多线程复制的方式可以很大程度降低复制延迟。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/tags/MySQL/"}]},{"title":"MySQL+MMM高可用","slug":"MySQL+MMM高可用","date":"2020-07-10T16:00:00.000Z","updated":"2020-07-11T11:38:10.993Z","comments":true,"path":"MySQL+MMM高可用.html","link":"","permalink":"https://pdxblog.top/MySQL+MMM%E9%AB%98%E5%8F%AF%E7%94%A8.html","excerpt":"","text":"¶MySQL+MMM高可用 ¶一、环境简述 ¶1、工作逻辑图 ¶2、MySQL-MMM优缺点 优点：高可用性，扩展性好，出现故障自动切换，对于主主同步，在同一时间只提供一台数据库写操作，保证的数据的一致性。 缺点：Monitor节点是单点，可以结合Keepalived实现高可用。 ¶3、MySQL-MMM工作原理 MMM(Master-Master replication managerfor Mysql，Mysql主主复制管理器)是一套灵活的脚本程序，基于perl实现，用来对mysql replication进行监控和故障迁移，并能管理mysql Master-Master复制的配置(同一时间只有一个节点是可写的)。 mmm_mond：监控进程，负责所有的监控工作，决定和处理所有节点角色活动。此脚本需要在监管机上运行。 mmm_agentd：运行在每个mysql服务器上的代理进程，完成监控的探针工作和执行简单的远端服务设置。此脚本需要在被监管机上运行。 mmm_control：一个简单的脚本，提供管理mmm_mond进程的命令。 mysql-mmm的监管端会提供多个虚拟IP（VIP），包括一个可写VIP，多个可读VIP，通过监管的管理，这些IP会绑定在可用mysql之上，当某一台mysql宕机时，监管会将VIP迁移至其他mysql。 在整个监管过程中，需要在mysql中添加相关授权用户，以便让mysql可以支持监理机的维护。授权的用户包括一个mmm_monitor用户和一个mmm_agent用户，如果想使用mmm的备份工具则还要添加一个mmm_tools用户。 ¶4、需求描述 操作系统：CentOS 7.8 数据库：MySQL 5.7 MMM：MySQL-MMM 2.2.1 数据库分配： function ip hostname server id monitoring host 192.168.206.120 monitor 无 master 1 192.168.206.121 master1 1 master 2 192.168.206.122 master2 2 slave 1 192.168.206.123 slave1 3 slave 2 192.168.206.124 slave2 4 虚拟IP地址（VIP）： ip role 192.168.0.211 writer 192.168.0.212 reader 192.168.0.213 reader 数据库同步需要的用户： function description privileges monitor user mmm监控用于对mysql服务器进程健康检查 REPLICATION CLIENT agent user mmm代理用来更改只读模式，复制的主服务器等 SUPER, REPLICATION CLIENT, PROCESS replication user 用于复制 REPLICATION SLAVE ¶二、4台服务器安装MySQL并配置 ¶1、通用配置 在这个步骤中，可以先在1台mysql服务器（192.168.206.121）上进行以下配置： 12345678910111213[root@master1 ~]# vi /etc/my.cnf #添加如下[mysqld]binlog-do-db=test #需要记录二进制日志的数据库，多个用逗号隔开binlog-ignore-db=mysql，information_schema #不需要记录二进制日志的数据库，多个用逗号隔开auto_increment_increment=2 #字段一次递增多少auto_increment_offset=1 #自增字段的起始值，值设置不同replicate-do-db=test #同步的数据库，多个写多行replicate-ignore-db = information_schema #不同步的数据库，多个写多行server_id = 1 #每台设置不同log_bin = mysql-binlog_slave_updates #当一个主故障，另一个立即接管sync-binlog=1 #每条自动更新，安全性高，默认是0[root@master1 ~]# systemctl restart mysqld ¶2、修改配置 按照第一台服务器克隆出3台，分别修改以下信息： ¶（1）网卡的IP ¶（2）mysql的UUID 1vim /var/lib/mysql/autoconf ¶（3）my.cnf文件 关于mysql的配置，只需要在master1的基础上修改个别参数的值即可。 ¶1）master2 12auto_increment_offset=2 #自增字段的起始值，值设置不同server_id=2 #每台设置不同 ¶2）slave1和slave2 删除以下2项： 12auto_increment_increment=2 #字段一次递增多少auto_increment_offset=1 #自增字段的起始值，值设置不同 server_id分别设置为3和4 1234# slave1server_id=3 #每台设置不同# slave2server_id=4 #每台设置不同 修改完毕之后别忘了重启mysql服务： 1systemctl restart mysqld ¶三、配置master1和master2主主同步 ¶1、先查看下log bin日志和pos值位置 ¶（1）master1 12[root@master1 ~]# mysql -uroot -pmysql&gt; show master status; ¶（2）master2 12[root@master2 ~]# mysql -uroot -pmysql&gt; show master status; ¶2、配置主主同步 ¶（1）master1配置 12345678mysql&gt; set global validate_password_policy=0;mysql&gt; set global validate_password_length=6;mysql&gt; grant replication slave on *.* to 'repl'@'192.168.206.%' identified by '123456';mysql&gt; flush privileges;mysql&gt; stop slave;mysql&gt; change master to master_host='192.168.206.122',master_user='repl',master_password='123456',master_log_file='mysql-bin.000001',master_log_pos=154;mysql&gt; start slave; ¶（2）master2配置 12345678mysql&gt; set global validate_password_policy=0;mysql&gt; set global validate_password_length=6;mysql&gt; grant replication slave on *.* to 'repl'@'192.168.206.%' identified by '123456';mysql&gt; flush privileges;mysql&gt; stop slave;mysql&gt; change master to master_host='192.168.206.121',master_user='repl',master_password='123456',master_log_file='mysql-bin.000001',master_log_pos=154;mysql&gt; start slave; ¶（3）测试主主同步 主主同步配置完毕，查看同步状态Slave_IO和Slave_SQL是YES说明主主同步成功。 1mysql&gt; show slave status\\G 如果Slave_IO_Running和Slave_SQL_Running都为yes，那么主从就已经配置OK了。 ¶1）在master1上增加数据 1234mysql&gt; create database test;mysql&gt; use test;mysql&gt; create table grade(id int);mysql&gt; insert into grade values(1),(2),(3); ¶2）在master2上查看是否数据同步 可以看到已经成功同步过去，同样在master2插入到grade表数据，也能同步过去。我们的双主就成功了，开始做主从复制。 ¶（4）可能出现的错误 1Last_IO_Error: Got fatal error 1236 from master when reading data from binary log: &#39;Client requested master to start replication from position &gt; file size&#39; 解决方案： 123stop slave;reset slave;start slave; ¶四、配置slave1和slave2做为master1的从库 ¶1、先看下master1状态值 ¶2、配置主从库 ¶（1）在slave1和slave2分别修改权限 1mysql&gt; change master to master_host&#x3D;&#39;192.168.206.121&#39;,master_user&#x3D;&#39;repl&#39;,master_password&#x3D;&#39;123456&#39;,master_log_file&#x3D;&#39;mysql-bin.000001&#39;,master_log_pos&#x3D;759; ¶（2）在slave1和slave2查看结果 如上图所示，说明主从复制成功。但是数据没过来，这是因为主从复制原理只同步配置完后的增删改记录，以前的数据是不能同步的。我们可以把主的数据库备份了，然后在送数据库还原。 ¶3、还原数据库 123456789[root@master1 ~]# mysqldump -uroot -p123456 test &gt; test.sql[root@master1 ~]# scp test.sql root@192.168.206.123:/root/[root@master1 ~]# scp test.sql root@192.168.206.124:/root/[root@slave1 ~]# mysql -uroot -p -e \"create database test;\"[root@slave1 ~]# mysql -uroot -p test &lt;test.sql[root@slave2 ~]# mysql -uroot -p -e \"create database test;\"[root@slave2 ~]# mysql -uroot -p test &lt;test.sql ¶五、MySQL-MMM安装配置 CentOS默认没有mysql-mmm软件包，官方推荐使用epel的网络源，五台都安装epel： 12345wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.reporpm -ivh http://mirrors.ustc.edu.cn/fedora/epel/6/x86_64/epel-release-6-8.noarch.rpmyum -y install perl-* libart_lgpl.x86_64 rrdtool.x86_64 rrdtool-perl.x86_64 ¶1、monitor节点安装 1yum -y install mysql-mmm-monitor ¶2、四台db节点安装 1yum -y install mysql-mmm-agent ¶3、在四台db节点授权monitor访问 1234567891011mysql&gt; set global validate_password_policy=0;mysql&gt; set global validate_password_length=6;# 监听帐号，是MMM监控服务器用来对MySQL服务器做健康检查的mysql&gt; grant replication client on *.* to 'mmm_monitor'@'192.168.206.%' identified by '123456';# 代理帐号，是MMM代理用来变成只读模式和同步master等的mysql&gt; grant super,process,replication client on *.* to 'mmm_agent'@'192.168.206.%' identified by '123456';# 刷新权限mysql&gt; flush privileges; ¶4、修改mmm_common.conf文件（5台相同） ¶（1）配置示例说明 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@monitor ~]# vim /etc/mysql-mmm/mmm_common.confactive_master_role writer #积极的master角色的标示，所有的db服务器要开启read_only参数，对于writer服务器监控代理会自动将read_only属性关闭。&lt;host default&gt; cluster_interface eth0 #群集的网络接口 pid_path /var/run/mysql-mmm/mmm_agentd.pid #pid路径 bin_path /usr/libexec/mysql-mmm/ #可执行文件路径 replication_user replication #复制用户 replication_password 123456 #复制用户密码 agent_user mmm_agent #代理用户 agent_password 123456 #代理用户密码&lt;/host&gt;&lt;host master-db1&gt; #master-db1的host名称 ip 192.168.1.11 #master-db1的ip mode master #角色属性，master代表是主 peer master-db2 #与master-db1对等的服务器的host名，也就是master-db2的服务器host名&lt;/host&gt;&lt;host master-db2&gt; #和master-db1的概念一样 ip 192.168.1.12 mode master peer master-db1&lt;/host&gt;&lt;host slave-db1&gt; #从库的host名,如果存在多个从库可以重复一样的配置 ip 192.168.1.13 #从的ip mode slave #slave的角色属性代表当前host是从&lt;/host&gt;&lt;host slave-db2&gt; #和slave-db1的概念一样 ip 192.168.1.14 mode slave&lt;/host&gt;&lt;role writer&gt; #writer角色配置 hosts master-db1, master-db2 #能进行写操作的服务器的host名，如果不想切换写操作这里可以只配置master,这样也可以避免因为网络延时而进行write的切换，但是一旦master出现故障那么当前的MMM就没有writer了只有对外的read操作。 ips 192.168.1.250 #对外提供的写操作的虚拟IP mode exclusive #exclusive代表只允许存在一个主，也就是只能提供一个写的IP&lt;/role&gt;&lt;role reader&gt; #read角色配置 hosts master-db1, master-db2, slave-db1, slave-db2 #对外提供读操作的服务器的host名,当然这里也可以把master加进来 ips 192.168.1.251, 192.168.1.252, 192.168.1.253, 192.168.1.254 #对外提供读操作的虚拟ip，这三个ip和host不是一一对应的,并且ips也hosts的数目也可以不相同，如果这样配置的话其中一个hosts会分配两个ip mode balanced&lt;/role&gt; ¶（2）实际配置参数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@monitor ~]# mkdir /etc/mysql-mmm[root@monitor ~]# vim /etc/mysql-mmm/mmm_common.confactive_master_role writer&lt;host default&gt; cluster_interface ens33 pid_path /var/run/mysql-mmm/mmm_agentd.pid bin_path /usr/libexec/mysql-mmm replication_user repl replecation_password 123456 agent_user mmm_agent agent_password 123456&lt;host&gt;&lt;host master1&gt; ip 192.168.206.121 mode master peer master2&lt;host&gt;&lt;host master2&gt; ip 192.168.206.122 mode master peer master1&lt;host&gt;&lt;host slave1&gt; ip 192.168.206.123 mode slave&lt;host&gt;&lt;host slave2&gt; ip 192.168.206.124 mode slave&lt;host&gt;&lt;role writer&gt; hosts master1,master2 ips 192.168.206.250 mode exclusive&lt;role&gt;&lt;role reader&gt; hosts master1,master2,slave1,slave2 ips 192.168.206.251, 192.168.206.252, 192.168.206.253, 192.168.206.254 mode balanced&lt;role&gt; ¶（3）通过scp命令传送到其他4台 1234[root@monitor ~]# scp -r /etc/mysql-mmm/ root@192.168.206.121:/etc[root@monitor ~]# scp -r /etc/mysql-mmm/ root@192.168.206.122:/etc[root@monitor ~]# scp -r /etc/mysql-mmm/ root@192.168.206.123:/etc[root@monitor ~]# scp -r /etc/mysql-mmm/ root@192.168.206.124:/etc ¶5、修改4台db代理端mmm_agent.conf文件 在所有的MySQL上修改mmm_agent.conf，只需要修改master-db1这里，是哪台就改成哪台，这里只给出master1的： 1234[root@master2 ~]# vim /etc/mysql-mmm/mmm_agent.confinclude mmm_common.confthis ¶6、修改管理端mmm_mon.conf文件 123456789101112131415161718[root@monitor ~]# vim /etc/mysql-mmm/mmm_mon.confinclude mmm_common.conf&lt;monitor&gt; ip 192.168.206.120 pid_path /var/run/mysql-mmm/mmm_mond.pid bin_path /usr/libexec/mysql-mmm status_path /var/lib/mysql-mmm/mmm_mond.status ping_ips 192.168.206.121.192.168.206.122,192.168.206.123,192.168.206.124 auto_set_online 60 #恢复后自动设置在线的时间&lt;monitor&gt;&lt;host default&gt; monitor_user mmm_monitor monitor_password 123456&lt;host&gt;debug 0 ¶六、启动MySQL-MMM ¶1、db代理端启动 12[root@db1 ~]# /etc/init.d/mysql-mmm-agent start[root@db1 ~]# chkconfigmysql-mmm-agent on ¶2、monitor管理端启动 12[root@monitor ~]# /etc/init.d/mysql-mmm-monitor start[root@monitor ~]# chkconfigmysql-mmm-monitor on","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/tags/MySQL/"}]},{"title":"MySQL基本操作","slug":"MySQL基本操作","date":"2020-07-10T16:00:00.000Z","updated":"2020-07-11T11:38:11.008Z","comments":true,"path":"MySQL基本操作.html","link":"","permalink":"https://pdxblog.top/MySQL%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C.html","excerpt":"","text":"¶MySQL基本操作 ¶一、结构化查询语言 ¶1、SQL SQL的含义是结构化查询语句（Structured Query Languate），是对数据库进行查询和修改操作的语言。 ¶2、T-SQL T-SQL ：Transact-SQL T-SQL是SQL的增强版，对功能进行了扩充：如变量说明、流程控制、功能函数。 ¶3、SQL的组成 名称 解释 命令举例 DML (数据操作语言) 用来操作数据库中所包含的数据 INSERT、UPDATE、DELETE DDL (数据定义语言) 用于创建和删除数据库对象等操作 CREATE、DROP、ALTER DQL (数据查询语言) 用来对数据库中的数据进行查询 SELECT DCL (数据控制语言) 用来控制数据库组件的存取许可、存取权限等 GRANT、COMMIT、ROLLBACK ¶二、MySQL常用数据类型 ¶1、数值类型 数值类型的属性： UNSIGNED 1标识为无符号数 ZEROFILL 1宽度（位数）不足，以0填充 示例： 123456789create database &#96;school&#96;;use &#96;school&#96;;create table &#96;student&#96;( &#96;sid&#96; INT(4) ZEROFILL);# 查看表结构desc student;# 插入数据insert into &#96;student&#96; VALUE(12),(123),(1234); 数据显示如下： 123456789mysql&gt; select * from &#96;student&#96;;+------+| sid |+------+| 0012 || 0123 || 1234 |+------+3 rows in set (0.00 sec) ¶2、字符串类型 ¶3、日期类型 若某日期字段默认值为当前日期，一般设置为TIMESTAMP类型 ¶三、MySQL建库、建表 ¶1、创建数据库 创建数据库是在系统磁盘上划分⼀块区域用于数据的存储和管理，如果管理员在设置权限的时候为用户创建了数据库，则可以直接使用，否则，需要自己创建数据库。 语法格式： 1CREATE DATABASE [IF NOT EXISTS] 数据库名 示例： 12# 创建myschool数据库create database myschool; IF NOT EXISTS：在创建数据库之前进行判断，只有该数据库目前尚不存在时才能执行操作。 此选项可以用来避免数据库已经存在而重复创建的错误。 ¶2、创建表 语法格式： 12345CREATE TABLE [IF NOT EXISTS] 表名 ( 字段1 数据类型 [字段属性|约束][索引][注释], …… 字段n 数据类型 [字段属性|约束][索引][注释])[表类型][表字符集][注释]; 示例： 12345#创建学生表CREATE TABLE &#96;student&#96;（ &#96;studentNo&#96; INT(4) PRIMARY KEY, &#96; name&#96; CHAR(10), ……）; 注意： 1234多字段使用逗号分隔保留字用撇号括起来单行注释：#……多行注释：/*……*/ ¶（1）字段的约束及属性 ¶主键 123CREATE TABLE student（ &#96;studentNo&#96; INT(4) PRIMARY KEY, ……）; ¶注释 123CREATE TABLE test ( &#96;id&#96; int(11) UNSIGNED COMMENT ‘编号’)COMMENT&#x3D;&#39;测试表’ ; ¶设置字符集编码 123CREATE TABLE [IF NOT EXISTS] 表名（ #省略代码）CHARSET &#x3D; 字符集名; ¶（2）在myschool数据库中创建学生表 示例： 12345678910111213use myschool;create table student( &#96;studentNo&#96; int(4) not null comment &#39;学号&#39; primary key, &#96;loginPwd&#96; varchar(20) not null comment &#39;密码&#39;, &#96;studentName&#96; varchar(50) not null comment &#39;姓名&#39;, &#96;sex&#96; char(2) not null default &#39;男&#39; comment &#39;性别&#39;, &#96;gradeID&#96; int(4) unsigned comment &#39;年级编号&#39;, &#96;phone&#96; varchar(50) comment &#39;电话&#39;, &#96;address&#96; varchar(255) default &#39;地址不详&#39; comment &#39;地址&#39;, &#96;bornDate&#96; datetime comment &#39;出生日期&#39;, &#96;email&#96; varchar(50) comment &#39;邮件账号&#39;, &#96;identityCard&#96; varchar(18) comment &#39;身份证号&#39; unique key)charset&#x3D;&#39;utf8&#39; comment&#x3D;&#39;学生表&#39;; ¶3、查看表 （1）查看表是否存在 12use myschool;show tables; （2）查看表定义 语法格式： 123desc 表名;或describe 表名; 示例： 12use myschool;desc &#96;student&#96;; ¶4、删除表 语法格式： 1drop table [if exists] 表名; 示例： 12use myschool;drop table if exists &#96;student&#96;; 在删除表之前，先使用if exists语句验证表是否存在。 ¶5、删除数据库 删除数据库是将已经存在的数据库从磁盘空间上清除，清除之后，数据库中的所有数据也将一起被删除。 删除数据库语句和创建数据库的命令相似，MySQL中删除数据库的基本语法格式为： 1drop database if exists 数据库名; 示例： 1drop database if exists myschool; ¶6、上机练习 （1）myschool数据库中创建科目表(subject) （2）myschool数据库中创建成绩表（result） ¶四、MySQL的存储引擎 ¶1、存储引擎简介 数据库存储引擎是数据库底层软件组件，数据库管理系统（DBMS）使用数据引擎进行创建、查询、更新和删除数据操作。不同的存储引擎提供不同的存储机制、索引技巧、锁定水平等功能。使用不同的存储引擎，还可以获得特定的功能。 现在许多不同的数据库管理系统都支持多种不同的数据引擎。MySQL的核心就是存储引擎。 ¶2、存储引擎的类型 mysql有多种存储引擎，它们分别为： 123456789MyISAMInnoDBMERGEMEMORYEXAMPLEFEDERATEDARCHIVECSVBLACKHOLE ¶3、存储引擎的主要区别 ¶（1）MyISAM 存储引擎特点 1234MySQL 5.5 之前使用 MyISAM 引擎，MySQL 5.5 之后使用 InnoDB 引擎MyISAM 引擎读取速度较快，占用资源相对较少，不支持事务，不支持外键约束，但支持全文索引读写互相阻塞，也就是说读数据的时候你就不能写数据，写数据的时候你就不能读数据MyISAM 引擎只能缓存索引，而不能缓存数据 ¶（2）InnoDB 存储引擎特点 1234事务型数据库的首选引擎，支持事务安全表，支持行锁定和外键，MySQL5.5.5 版本之后，InnoDB作为默认存储引擎具有提交、回滚和崩溃恢复能力的事务安全存储引擎，能处理巨大数据量，性能及效率高，完全支持外键完整性约束具有非常高效的缓存特性，能缓存索引也能缓存数据，对硬件要求比较高使用InnoDB时，将在MySQL数据目录下创建一个名为ibdata1的10MB大小的自动扩展数据⽂文件，以及两个名为 ib_logfile0 和 ib_logfile1 的 5MB ⼤大⼩小的日志⽂文件 ¶（3）Memory 存储引擎特点 123Memory存储引擎将表中的数据存储到内存中，为查询和引用其他表数据提供快速访问Memory存储引擎执行 HASH 和 BTREE 索引，不支持 BLOB 和 TEXT 列，支持AUTO_INCREMENT 列和对可包含 NULL 值得列的索引当不再需要 Memory 表的内容时，要释放被 Memory 表使用的内存，应该执行DELETE FROM 或 TRUNCATE TABLE ，或者删除整个表 ¶4、存储引擎适用场合 ¶（1）MyISAM 适⽤用场景 1234不需要事务支持的业务，例如：转账就不行适用于读数据比较多的业务，不适用于读写频繁的业务并发相对较低、数据修改相对较少的业务硬件资源比较差的机器可以考虑使用 MyISAM 引擎 ¶（2）InnoDB 适⽤用场景 123需要事务⽀持的业务、⾼并发的业务数据更新较为频繁的场景，⽐如：BBS、SNS、微博等数据⼀致性要求较⾼的业务，⽐如：充值转账、银⾏卡转账 ¶（3）总结 使用MyISAM: 不需事务，空间小，以查询访问为主 使用InnoDB: 多删除、更新操作，安全性高，事务处理及并发控制 ¶5、查看当前默认存储引擎 123456789mysql&gt; show variables like &#39;%storage_engine&#39;;+----------------------------------+--------+| Variable_name | Value |+----------------------------------+--------+| default_storage_engine | InnoDB || default_tmp_storage_engine | InnoDB || internal_tmp_disk_storage_engine | InnoDB |+----------------------------------+--------+3 rows in set, 1 warning (0.02 sec) ¶6、修改默认存储引擎 ¶（1）MySQL 5.5 修改my.ini配置文件 1default_storage_engine&#x3D;InnoDB ¶（2）MySQL 5.7 最简单的方法，就是通过命令直接修改表的存储引擎，如下所示： 1alter table 表名 ENGINE &#x3D; 引擎名; 示例： 1ALTER TABLE student ENGINE &#x3D; InnoDB; ¶7、设置表的存储引擎 语法格式： 123CREATE TABLE 表名( #省略代码)ENGINE&#x3D;存储引擎; 示例： 123CREATE TABLE &#96;myisam&#96; ( id INT(4))ENGINE&#x3D;MyISAM; ¶五、MySQL补充知识 在mysql中，每个数据库最多可创建20亿个表，一个表允许定义1024列，每行的最大长度为8092字节（不包括⽂本和图像类型的长度）。 当表中定义有varchar、nvarchar或varbinary类型列时，如果向表中插入的数据行超过8092字节时，将导致语句失败，并产生错误信息。 SQL Server对每个表中行的数量没有直接限制，但它受数据库存储空间的限制。每个数据库的最大空间1048516TB，所以一个表可用的最大空间为1048516TB减去数据库类系统表和其它数据库对象所占用的空间。理论上无限大，就看你硬盘够不够大，大多数情况是你的硬盘不够。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/tags/MySQL/"}]},{"title":"MySQL-MHA高可用方案","slug":"MySQL-MHA高可用方案","date":"2020-07-10T16:00:00.000Z","updated":"2020-07-11T11:38:10.993Z","comments":true,"path":"MySQL-MHA高可用方案.html","link":"","permalink":"https://pdxblog.top/MySQL-MHA%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E6%A1%88.html","excerpt":"","text":"¶MySQL-MHA高可用方案 ¶一、MHA简介 MHA（Master High Availability）目前在MySQL高可用方面是一个相对成熟的解决方案，它由日本DeNA公司youshimaton（现就职于Facebook公司）开发，是一套优秀的作为MySQL高可用性环境下故障切换和主从提升的高可用软件。在MySQL故障切换过程中，MHA能做到在0~30秒之内自动完成数据库的故障切换操作，并且在进行故障切换的过程中，MHA能在最大程度上保证数据的一致性，以达到真正意义上的高可用。 MHA里有两个角色一个是MHA Node（数据节点）另一个是MHA Manager（管理节点）。 MHA Manager可以单独部署在一台独立的机器上管理多个master-slave集群，也可以部署在一台slave节点上。MHA Node运行在每台 MySQL服务器上，MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将最新数据的slave提升为新的master，然后将所有其他的slave重新指向新的master。整个故障转移过程对应用程序完全透明。 在MHA自动故障切换过程中，MHA试图从宕机的主服务器上保存二进制日志，最大程度的保证数据的不丢失，但这并不总是可行的。例如，如果主服务器硬件故障或无法通过ssh访问，MHA没法保存二进制日志，只进行故障转移而丢失了最新的数据。使用MySQL 5.5的半同步复制，可以大大降低数据丢失的风险。MHA可以与半同步复制结合起来。如果只有一个slave已经收到了最新的二进制日志，MHA可以将最新的二进制日志应用于其他所有的slave服务器上，因此可以保证所有节点的数据一致性。 注：从MySQL5.5开始，MySQL以插件的形式支持半同步复制。 如何理解半同步呢？首先我们来看看异步，全同步的概念。 ¶1、异步复制（Asynchronous replication） MySQL默认的复制即是异步的，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，主如果crash掉了，此时主上已经提交的事务可能并没有传到从上，如果此时，强行将从提升为主，可能导致新主上的数据不完整。 ¶2、全同步复制（Fully synchronous replication） 指当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。 ¶3、半同步复制（Semisynchronous replication） 介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到relay log中才返回给客户端。相对于异步复制，半同步复制提高了数据的安全性，同时它也造成了一定程度的延迟，这个延迟最少是一个TCP/IP往返的时间。所以，半同步复制最好在低延时的网络中使用。 ¶4、异步与半同步异同 默认情况下MySQL的复制是异步的，Master上所有的更新操作写入Binlog之后并不确保所有的更新都被复制到Slave之上。异步操作虽然效率高，但是在Master/Slave出现问题的时候，存在很高数据不同步的风险，甚至可能丢失数据。 MySQL5.5引入半同步复制功能的目的是为了保证在master出问题的时候，至少有一台Slave的数据是完整的。在超时的情况下也可以临时转入异步复制，保障业务的正常使用，直到一台salve追赶上之后，继续切换到半同步模式。 ¶5、MHA工作原理 相较于其它HA软件，MHA的目的在于维持MySQL Replication中Master库的高可用性，其最大特点是可以修复多个Slave之间的差异日志，最终使所有Slave保持数据一致，然后从中选择一个充当新的Master，并将其它Slave指向它。 从宕机崩溃的master保存二进制日志事件(binlogevents)。 识别含有最新更新的slave。 应用差异的中继日志(relay log)到其它slave。 应用从master保存的二进制日志事件(binlogevents)。 提升一个slave为新master。 -使其它的slave连接新的master进行复制。 目前MHA主要支持一主多从的架构，要搭建MHA,要求一个复制集群中必须最少有三台数据库服务器，一主二从，即一台充当master，一台充当备用master，另外一台充当从库，因为至少需要三台服务器。 ¶二、搭建实验环境 接下来部署MHA，具体的搭建环境如下： 角色 IP地址 主机名 server id 类型 OS Manager 192.168.206.200 manager 管理节点 centos 7.8 Master 192.168.206.201 maser 1 主MySQL（写入） centos 7.8 CandidateMaster 192.168.206.202 c-master 2 从MySQL（读） centos 7.8 slave 192.168.206.203 slave 3 从MySQL（读） centos 7.8 其中master对外提供写服务，备选master（实际的slave，主机名m3）提供读服务，slave也提供相关的读服务，一旦master宕机，将会把备选master提升为新的master，slave指向新的master，manager作为管理服务器。 ¶三、基础环境准备 ¶1、基础配置 在配置好IP地址和主机名后，检查selinux、防火墙设置，关闭 selinux ，防火墙服务，以便后期主从同步不出错。 注：时间要同步 ¶2、 在4台机器都配置epel源 12345678# 安装epel源yum install -y epel-release# 下载阿里开源镜像的epel源文件wget -O /etc/yum.repos.d/epel-7.repo http://mirrors.aliyun.com/repo/epel-7.repo# 清除系统yum缓存yum clean all# 重新生成新的yum缓存yum makecache ¶3、建立ssh无交互登录环境 ¶（1）Manager主机 12[root@manager ~]# ssh-keygen [root@manager ~]# for i in 1 2 3;do ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.206.20$i;done ¶（2）Candidate master主机 12[root@slave-master ~]# ssh-keygen [root@slave-master ~]# for i in 1 2 3;do ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.206.20$i;done ¶（3）master主机 12[root@master ~]# ssh-keygen [root@master ~]# for i in 1 2 3;do ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.206.20$i;done ¶（4）slave主机 12[root@slave ~]# ssh-keygen [root@slave ~]# for i in 1 2 3;do ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.206.20$i;done ¶4、测试ssh无交互登录 12345678[root@manager ~]# ssh root@192.168.206.201Last login: Tue Jul 7 16:24:46 2020 from 192.168.206.1[root@master ~]# exit登出Connection to 192.168.206.201 closed.[root@manager ~]# # 其它服务器测试省略 ¶5、配置hosts环境 1234567891011121314151617[root@manager ~]# vim /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6# 将4台服务器的ip和对应的主机名添加到下面192.168.206.200 manager192.168.206.201 master192.168.206.202 slave-master192.168.206.203 slave# 每台服务器的hosts文件都一样[root@manager ~]# scp /etc/hosts root@192.168.206.201:/etc/hostshosts 100% 256 139.0KB/s 00:00 [root@manager ~]# scp /etc/hosts root@192.168.206.202:/etc/hostshosts 100% 256 208.7KB/s 00:00 [root@manager ~]# scp /etc/hosts root@192.168.206.203:/etc/hostshosts 100% 256 236.3KB/s 00:00 ¶四、配置mysql半同步复制 为了尽可能的减少主库硬件损坏宕机造成的数据丢失，因此在配置MHA的同时建议配置成MySQL的半同步复制。 注：mysql半同步插件是由谷歌提供，具体位置/usr/local/mysql/lib/plugin/下，一个是master用的semisync_master.so，一个是slave用的semisync_slave.so。 下面我们就来具体配置一下，如果不清楚Plugin的目录，用如下命令查找： 1234567mysql&gt; show variables like &#39;%plugin_dir%&#39;;+---------------+------------------------------+| Variable_name | Value |+---------------+------------------------------+| plugin_dir | &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;lib&#x2F;plugin&#x2F; |+---------------+------------------------------+1 row in set (0.01 sec) ¶1、主从节点安装插件 ¶（1）分别在主从节点上安装相关的插件 master Candicate master slave 在MySQL上安装插件需要数据库支持动态载入，检查是否支持，用如下命令检测： 1234567mysql&gt; show variables like &#39;%have_dynamic%&#39;;+----------------------+-------+| Variable_name | Value |+----------------------+-------+| have_dynamic_loading | YES |+----------------------+-------+1 row in set (0.01 sec) 所有mysql数据库服务器，安装半同步插件(semisync_master.so,semisync_slave.so) 12345mysql&gt; install plugin rpl_semi_sync_master soname &#39;semisync_master.so&#39;;Query OK, 0 rows affected (0.24 sec)mysql&gt; install plugin rpl_semi_sync_slave soname &#39;semisync_slave.so&#39;;Query OK, 0 rows affected (0.03 sec) 其他mysql主机采用同样的方法安装。 ¶（2）检查Plugin是否已正确安装 123mysql&gt; show plugins;或mysql&gt; select plugin_name from information_schema.plugins; ¶（3）查看半同步相关信息 1234567891011121314mysql&gt; show variables like &#39;%rpl_semi_sync%&#39;;+-------------------------------------------+------------+| Variable_name | Value |+-------------------------------------------+------------+| rpl_semi_sync_master_enabled | OFF || rpl_semi_sync_master_timeout | 10000 || rpl_semi_sync_master_trace_level | 32 || rpl_semi_sync_master_wait_for_slave_count | 1 || rpl_semi_sync_master_wait_no_slave | ON || rpl_semi_sync_master_wait_point | AFTER_SYNC || rpl_semi_sync_slave_enabled | OFF || rpl_semi_sync_slave_trace_level | 32 |+-------------------------------------------+------------+8 rows in set (0.00 sec) 上图可以看到半同复制插件已经安装，只是还没有启用，所以是off。 ¶2、修改my.cnf文件 注：若主MYSQL服务器已经存在，只是后期才搭建从MYSQL服务器，在置配数据同步前应先将主 MYSQL服务器的要同步的数据库拷贝到从MYSQL服务器上（如先在主MYSQL上备份数据库，再用备份 在从MYSQL服务器上恢复） ¶（1）master主机 12345678910server-id=1log-bin=mysql-binbinlog_format=mixedlog-bin-index=mysql-bin.indexrpl_semi_sync_master_enabled=1rpl_semi_sync_master_timeout=1000rpl_semi_sync_slave_enabled=1relay_log_purge=0relay-log=relay-binrelay-log-index=slave-relay-bin.index 注： rpl_semi_sync_master_enabled=1 1表是启用，0表示关闭 rpl_semi_sync_master_timeout=10000：毫秒单位 ，该参数主服务器等待确认消息10秒后，不再等待，变为异步方式。 ¶（2）Candidate master主机 12345678910server-id=2log-bin=mysql-binbinlog_format=mixedlog-bin-index=mysql-bin.indexrpl_semi_sync_master_enabled=1rpl_semi_sync_master_timeout=10000rpl_semi_sync_slave_enabled=1relay_log_purge=0relay-log = relay-binrelay-log-index = slave-relay-bin.index 注：relay_log_purge=0，禁止 SQL 线程在执行完一个 relay log 后自动将其删除，对于MHA场景下，对 于某些滞后从库的恢复依赖于其他从库的relay log，因此采取禁用自动删除功能 ¶（3）slave主机 123456server-id=3log-bin=mysql-binrelay-log = relay-binrelay-log-index = slave-relay-bin.indexread_only=1rpl_semi_sync_slave_enabled=1 ¶（4）查看半同步相关信息 在所有服务器上重启mysql服务。 1systemctl restart mysqld 进入mysql，查看半同步相关信息。 1234567891011121314mysql&gt; show variables like &#39;%rpl_semi_sync%&#39;;+-------------------------------------------+------------+| Variable_name | Value |+-------------------------------------------+------------+| rpl_semi_sync_master_enabled | ON || rpl_semi_sync_master_timeout | 1000 || rpl_semi_sync_master_trace_level | 32 || rpl_semi_sync_master_wait_for_slave_count | 1 || rpl_semi_sync_master_wait_no_slave | ON || rpl_semi_sync_master_wait_point | AFTER_SYNC || rpl_semi_sync_slave_enabled | ON || rpl_semi_sync_slave_trace_level | 32 |+-------------------------------------------+------------+8 rows in set (0.01 sec) ¶（5）查看半同步状态 123456789101112131415161718192021mysql&gt; show status like &#39;%rpl_semi_sync%&#39;;+--------------------------------------------+-------+| Variable_name | Value |+--------------------------------------------+-------+| Rpl_semi_sync_master_clients | 0 || Rpl_semi_sync_master_net_avg_wait_time | 0 || Rpl_semi_sync_master_net_wait_time | 0 || Rpl_semi_sync_master_net_waits | 0 || Rpl_semi_sync_master_no_times | 0 || Rpl_semi_sync_master_no_tx | 0 || Rpl_semi_sync_master_status | ON || Rpl_semi_sync_master_timefunc_failures | 0 || Rpl_semi_sync_master_tx_avg_wait_time | 0 || Rpl_semi_sync_master_tx_wait_time | 0 || Rpl_semi_sync_master_tx_waits | 0 || Rpl_semi_sync_master_wait_pos_backtraverse | 0 || Rpl_semi_sync_master_wait_sessions | 0 || Rpl_semi_sync_master_yes_tx | 0 || Rpl_semi_sync_slave_status | OFF |+--------------------------------------------+-------+15 rows in set (0.00 sec) 有几个状态参数值得关注的： 123456rpl_semi_sync_master_status ：显示主服务是异步复制模式还是半同步复制模式rpl_semi_sync_master_clients ：显示有多少个从服务器配置为半同步复制模式rpl_semi_sync_master_yes_tx ：显示从服务器确认成功提交的数量rpl_semi_sync_master_no_tx ：显示从服务器确认不成功提交的数量rpl_semi_sync_master_tx_avg_wait_time ：事务因开启 semi_sync ，平均需要额外等待的时间rpl_semi_sync_master_net_avg_wait_time ：事务进入等待队列后，到网络平均等待时间 ¶3、配置主从同步 ¶（1）master主机 12345678910111213141516mysql&gt; stop slave;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; grant replication slave on *.* to mharep@&#39;192.168.206.%&#39; identified by &#39;123456&#39;;Query OK, 0 rows affected, 1 warning (1.00 sec)mysql&gt; grant all privileges on *.* to manager@&#39;192.168.206.%&#39; identified by &#39;123456&#39;;Query OK, 0 rows affected, 1 warning (0.22 sec)mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000001 | 746 | | | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) 第一条grant命令是创建一个用于主从复制的帐号，在master和candicate master的主机上创建即可。 第二条grant命令是创建MHA管理账号，所有mysql服务器上都需要执行。MHA会在配置文件里要求能远程登录到数据库，所以要进行必要的赋权。 ¶（2）Candidate master主机 1234567891011121314151617181920212223242526272829mysql&gt; stop slave;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; grant replication slave on *.* to mharep@&#39;192.168.206.%&#39; identified by &#39;123456&#39;;Query OK, 0 rows affected, 1 warning (10.01 sec)mysql&gt; grant all privileges on *.* to manager@&#39;192.168.206.%&#39; identified by &#39;123456&#39;;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; change master to master_host&#x3D;&#39;192.168.206.201&#39;,master_port&#x3D;3306,master_user&#x3D;&#39;mharep&#39;,master_password&#x3D;&#39;123456&#39;,master_log_file&#x3D;&#39;mysql-bin.000001&#39;,master_log_pos&#x3D;746;Query OK, 0 rows affected, 2 warnings (0.04 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.00 sec)mysql&gt; show slave status\\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.206.201 Master_User: mharep Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 154 Relay_Log_File: relay-bin.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes 查看从的状态，以下两个值必须为yes，代表从服务器能正常连接主服务器。 12Slave_IO_Running:YesSlave_SQL_Running:Yes ¶（3）slave主机 1234567891011121314151617181920212223242526mysql&gt; stop slave;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; grant all privileges on *.* to manager@&#39;192.168.206.%&#39; identified by &#39;123456&#39;;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; change master to master_host&#x3D;&#39;192.168.206.201&#39;,master_port&#x3D;3306,master_user&#x3D;&#39;mharep&#39;,master_password&#x3D;&#39;123456&#39;,master_log_file&#x3D;&#39;mysql-bin.000001&#39;,master_log_pos&#x3D;746;Query OK, 0 rows affected, 2 warnings (0.03 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.00 sec)mysql&gt; show slave status\\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.206.201 Master_User: mharep Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 154 Relay_Log_File: relay-bin.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes 查看从的状态，以下两个值必须为yes，代表从服务器能正常连接主服务器。 12Slave_IO_Running:YesSlave_SQL_Running:Yes ¶（4）查看master服务器的半同步状态 123456789101112131415161718192021mysql&gt; show status like &#39;%rpl_semi_sync%&#39;;+--------------------------------------------+-------+| Variable_name | Value |+--------------------------------------------+-------+| Rpl_semi_sync_master_clients | 2 || Rpl_semi_sync_master_net_avg_wait_time | 0 || Rpl_semi_sync_master_net_wait_time | 0 || Rpl_semi_sync_master_net_waits | 0 || Rpl_semi_sync_master_no_times | 0 || Rpl_semi_sync_master_no_tx | 0 || Rpl_semi_sync_master_status | ON || Rpl_semi_sync_master_timefunc_failures | 0 || Rpl_semi_sync_master_tx_avg_wait_time | 0 || Rpl_semi_sync_master_tx_wait_time | 0 || Rpl_semi_sync_master_tx_waits | 0 || Rpl_semi_sync_master_wait_pos_backtraverse | 0 || Rpl_semi_sync_master_wait_sessions | 0 || Rpl_semi_sync_master_yes_tx | 0 || Rpl_semi_sync_slave_status | OFF |+--------------------------------------------+-------+15 rows in set (0.01 sec) rpl_semi_sync_master_clients ：显示有2个从服务器配置为半同步复制模式。 ¶五、配置mysql-mha mha包括manager节点和data节点： data节点：包括原有的MySQL复制结构中的主机，至少3台，即1主2从，当masterfailover后，还能保证主从结构；只需安装node包。 manager节点：运行监控脚本，负责monitoring 和 auto-failover；需要安装node包和manager包。 ¶1、 在所有主机上安装mha所依赖的软件包 1yum -y install perl-DBD-MySQL perl-Config-Tiny perl-Log-Dispatch perl-Parallel-ForkManager perl-Config-IniFiles ncftp perl-Params-Validate perl-CPAN perl-Test-Mock-LWP.noarch perl-LWP-Authen-Negotiate.noarch perl-devel perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker ¶2、 安装mha4mysql-node 需要2个管理节点（4台服务器）都安装 1234tar zxvf mha4mysql-node-0.58.tar.gzcd mha4mysql-node-0.58/perl Makefile.PLmake &amp;&amp; make install 在3台数据库节点只要安装mha4mysql-node。 ¶3、安装mha4mysql-manager 1234tar zxvf mha4mysql-manager-0.58.tar.gz cd mha4mysql-manager-0.58/perl Makefile.PLmake &amp;&amp; make install 在管理节点需要mha4mysql-node和mha4mysql-manager都安装。 根据提示输入： 12345[root@manager mha4mysql-manager-0.58]# mkdir /etc/masterha[root@manager mha4mysql-manager-0.58]# mkdir -p /masterha/app1[root@manager mha4mysql-manager-0.58]# mkdir /scripts[root@manager mha4mysql-manager-0.58]# cp samples/conf/* /etc/masterha/[root@manager mha4mysql-manager-0.58]# cp samples/scripts/* /scripts/ ¶4、配置mha 与绝大多数Linux应用程序类似，MHA的正确使用依赖于合理的配置文件。MHA的配置文件与mysql的my.cnf文件配置相似，采取的是param=value的方式来配置。配置文件位于管理节点，通常包括每一个mysql server的主机名、mysql用户名、密码、工作目录等等。 ¶（1）编辑mha配置文件 编辑/etc/masterha/app1.conf，内容如下： 123456789101112131415161718192021222324252627[server default]manager_workdir=/masterha/app1manager_log=/masterha/app1/manager.loguser=managerpassword=123456ssh_user=rootrepl_user=mhareprepl_password=123456ping_interval=1[server1]hostname=192.168.206.201port=3306master_binlog_dir=/usr/local/mysql/datacandidate_master=1[server2]hostname=192.168.206.202port=3306master_binlog_dir=/usr/local/mysql/datacandidate_master=1[server3]hostname=192.168.206.203port=3306master_binlog_dir=/usr/local/mysql/datano_master=1 保存并退出。 ¶（2）配关配置项的解释 12345678910111213141516171819manager_workdir=/masterha/app1 //设置manager的工作目录manager_log=/masterha/app1/manager.log //设置manager的日志 user=manager //设置监控用户managerpassword=123456 //监控用户manager的密码ssh_user=root //ssh连接用户 repl_user=mharep //主从复制用户repl_password=123.abc //主从复制用户密码ping_interval=1 //设置监控主库，发送ping包的时间间隔，默认是3秒，尝试三次没有回应的时候自动进行railovermaster_binlog_dir=/usr/local/mysql/data //设置master 保存binlog的位置，以便MHA可以找到master的日志，我这里的也就是mysql的数据目录 candidate_master=1 //设置为候选master，如果设置该参数以后，发生主从切换以后将会将此从库提升为主库。 ¶（3）SSH 有效性验证 123456789101112131415161718192021[root@manager ~]# masterha_check_ssh --global_conf=/etc/masterha/masterha_default.cnf --conf=/etc/masterha/app1.cnfTue Jul 7 18:53:32 2020 - [info] Reading default configuration from /etc/masterha/masterha_default.cnf..Tue Jul 7 18:53:32 2020 - [info] Reading application default configuration from /etc/masterha/app1.cnf..Tue Jul 7 18:53:32 2020 - [info] Reading server configuration from /etc/masterha/app1.cnf..Tue Jul 7 18:53:32 2020 - [info] Starting SSH connection tests..Tue Jul 7 18:53:34 2020 - [debug] Tue Jul 7 18:53:32 2020 - [debug] Connecting via SSH from root@192.168.206.201(192.168.206.201:22) to root@192.168.206.202(192.168.206.202:22)..Tue Jul 7 18:53:33 2020 - [debug] ok.Tue Jul 7 18:53:33 2020 - [debug] Connecting via SSH from root@192.168.206.201(192.168.206.201:22) to root@192.168.206.203(192.168.206.203:22)..Tue Jul 7 18:53:34 2020 - [debug] ok.Tue Jul 7 18:53:35 2020 - [debug] Tue Jul 7 18:53:32 2020 - [debug] Connecting via SSH from root@192.168.206.202(192.168.206.202:22) to root@192.168.206.201(192.168.206.201:22)..Tue Jul 7 18:53:33 2020 - [debug] ok.Tue Jul 7 18:53:33 2020 - [debug] Connecting via SSH from root@192.168.206.202(192.168.206.202:22) to root@192.168.206.203(192.168.206.203:22)..Tue Jul 7 18:53:34 2020 - [debug] ok.Tue Jul 7 18:53:35 2020 - [debug] Tue Jul 7 18:53:33 2020 - [debug] Connecting via SSH from root@192.168.206.203(192.168.206.203:22) to root@192.168.206.201(192.168.206.201:22)..Tue Jul 7 18:53:34 2020 - [debug] ok.Tue Jul 7 18:53:34 2020 - [debug] Connecting via SSH from root@192.168.206.203(192.168.206.203:22) to root@192.168.206.202(192.168.206.202:22)..Tue Jul 7 18:53:35 2020 - [debug] ok.Tue Jul 7 18:53:35 2020 - [info] All SSH connection tests passed successfully. ¶（4）集群复制的有效性验证 mysql必须都启动 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106[root@manager ~]# masterha_check_ssh --global_conf=/etc/masterha/masterha_default.cnf --conf=/etc/masterha/app1.cnfTue Jul 7 18:53:32 2020 - [info] Reading default configuration from /etc/masterha/masterha_default.cnf..Tue Jul 7 18:53:32 2020 - [info] Reading application default configuration from /etc/masterha/app1.cnf..Tue Jul 7 18:53:32 2020 - [info] Reading server configuration from /etc/masterha/app1.cnf..Tue Jul 7 18:53:32 2020 - [info] Starting SSH connection tests..Tue Jul 7 18:53:34 2020 - [debug] Tue Jul 7 18:53:32 2020 - [debug] Connecting via SSH from root@192.168.206.201(192.168.206.201:22) to root@192.168.206.202(192.168.206.202:22)..Tue Jul 7 18:53:33 2020 - [debug] ok.Tue Jul 7 18:53:33 2020 - [debug] Connecting via SSH from root@192.168.206.201(192.168.206.201:22) to root@192.168.206.203(192.168.206.203:22)..Tue Jul 7 18:53:34 2020 - [debug] ok.Tue Jul 7 18:53:35 2020 - [debug] Tue Jul 7 18:53:32 2020 - [debug] Connecting via SSH from root@192.168.206.202(192.168.206.202:22) to root@192.168.206.201(192.168.206.201:22)..Tue Jul 7 18:53:33 2020 - [debug] ok.Tue Jul 7 18:53:33 2020 - [debug] Connecting via SSH from root@192.168.206.202(192.168.206.202:22) to root@192.168.206.203(192.168.206.203:22)..Tue Jul 7 18:53:34 2020 - [debug] ok.Tue Jul 7 18:53:35 2020 - [debug] Tue Jul 7 18:53:33 2020 - [debug] Connecting via SSH from root@192.168.206.203(192.168.206.203:22) to root@192.168.206.201(192.168.206.201:22)..Tue Jul 7 18:53:34 2020 - [debug] ok.Tue Jul 7 18:53:34 2020 - [debug] Connecting via SSH from root@192.168.206.203(192.168.206.203:22) to root@192.168.206.202(192.168.206.202:22)..Tue Jul 7 18:53:35 2020 - [debug] ok.Tue Jul 7 18:53:35 2020 - [info] All SSH connection tests passed successfully.[root@manager ~]# masterha_check_repl --global_conf=/etc/masterha/masterha_default.cnf --conf=/etc/masterha/app1.cnfTue Jul 7 18:56:57 2020 - [info] Reading default configuration from /etc/masterha/masterha_default.cnf..Tue Jul 7 18:56:58 2020 - [info] Reading application default configuration from /etc/masterha/app1.cnf..Tue Jul 7 18:56:58 2020 - [info] Reading server configuration from /etc/masterha/app1.cnf..Tue Jul 7 18:56:58 2020 - [info] MHA::MasterMonitor version 0.58.Tue Jul 7 18:56:59 2020 - [info] GTID failover mode = 0Tue Jul 7 18:56:59 2020 - [info] Dead Servers:Tue Jul 7 18:56:59 2020 - [info] Alive Servers:Tue Jul 7 18:56:59 2020 - [info] 192.168.206.201(192.168.206.201:3306)Tue Jul 7 18:56:59 2020 - [info] 192.168.206.202(192.168.206.202:3306)Tue Jul 7 18:56:59 2020 - [info] 192.168.206.203(192.168.206.203:3306)Tue Jul 7 18:56:59 2020 - [info] Alive Slaves:Tue Jul 7 18:56:59 2020 - [info] 192.168.206.202(192.168.206.202:3306) Version=5.7.22-log (oldest major version between slaves) log-bin:enabledTue Jul 7 18:56:59 2020 - [info] Replicating from 192.168.206.201(192.168.206.201:3306)Tue Jul 7 18:56:59 2020 - [info] Primary candidate for the new Master (candidate_master is set)Tue Jul 7 18:56:59 2020 - [info] 192.168.206.203(192.168.206.203:3306) Version=5.7.22-log (oldest major version between slaves) log-bin:enabledTue Jul 7 18:56:59 2020 - [info] Replicating from 192.168.206.201(192.168.206.201:3306)Tue Jul 7 18:56:59 2020 - [info] Not candidate for the new Master (no_master is set)Tue Jul 7 18:56:59 2020 - [info] Current Alive Master: 192.168.206.201(192.168.206.201:3306)Tue Jul 7 18:56:59 2020 - [info] Checking slave configurations..Tue Jul 7 18:56:59 2020 - [info] read_only=1 is not set on slave 192.168.206.202(192.168.206.202:3306).Tue Jul 7 18:56:59 2020 - [warning] relay_log_purge=0 is not set on slave 192.168.206.203(192.168.206.203:3306).Tue Jul 7 18:56:59 2020 - [info] Checking replication filtering settings..Tue Jul 7 18:56:59 2020 - [info] binlog_do_db= , binlog_ignore_db= Tue Jul 7 18:56:59 2020 - [info] Replication filtering check ok.Tue Jul 7 18:56:59 2020 - [info] GTID (with auto-pos) is not supportedTue Jul 7 18:56:59 2020 - [info] Starting SSH connection tests..Tue Jul 7 18:57:02 2020 - [info] All SSH connection tests passed successfully.Tue Jul 7 18:57:02 2020 - [info] Checking MHA Node version..Tue Jul 7 18:57:03 2020 - [info] Version check ok.Tue Jul 7 18:57:03 2020 - [info] Checking SSH publickey authentication settings on the current master..Tue Jul 7 18:57:04 2020 - [info] HealthCheck: SSH to 192.168.206.201 is reachable.Tue Jul 7 18:57:04 2020 - [info] Master MHA Node version is 0.58.Tue Jul 7 18:57:04 2020 - [info] Checking recovery script configurations on 192.168.206.201(192.168.206.201:3306)..Tue Jul 7 18:57:04 2020 - [info] Executing command: save_binary_logs --command=test --start_pos=4 --binlog_dir=/usr/local/mysql/data --output_file=/data/log/masterha/save_binary_logs_test --manager_version=0.58 --start_file=mysql-bin.000001 Tue Jul 7 18:57:04 2020 - [info] Connecting to root@192.168.206.201(192.168.206.201:22).. Creating /data/log/masterha if not exists.. Creating directory /data/log/masterha.. done. ok. Checking output directory is accessible or not.. ok. Binlog found at /usr/local/mysql/data, up to mysql-bin.000001Tue Jul 7 18:57:05 2020 - [info] Binlog setting check done.Tue Jul 7 18:57:05 2020 - [info] Checking SSH publickey authentication and checking recovery script configurations on all alive slave servers..Tue Jul 7 18:57:05 2020 - [info] Executing command : apply_diff_relay_logs --command=test --slave_user='manager' --slave_host=192.168.206.202 --slave_ip=192.168.206.202 --slave_port=3306 --workdir=/data/log/masterha --target_version=5.7.22-log --manager_version=0.58 --relay_log_info=/usr/local/mysql/data/relay-log.info --relay_dir=/usr/local/mysql/data/ --slave_pass=xxxTue Jul 7 18:57:05 2020 - [info] Connecting to root@192.168.206.202(192.168.206.202:22).. Creating directory /data/log/masterha.. done. Checking slave recovery environment settings.. Opening /usr/local/mysql/data/relay-log.info ... ok. Relay log found at /usr/local/mysql/data, up to relay-bin.000003 Temporary relay log file is /usr/local/mysql/data/relay-bin.000003 Checking if super_read_only is defined and turned on.. not present or turned off, ignoring. Testing mysql connection and privileges..mysql: [Warning] Using a password on the command line interface can be insecure. done. Testing mysqlbinlog output.. done. Cleaning up test file(s).. done.Tue Jul 7 18:57:06 2020 - [info] Executing command : apply_diff_relay_logs --command=test --slave_user='manager' --slave_host=192.168.206.203 --slave_ip=192.168.206.203 --slave_port=3306 --workdir=/data/log/masterha --target_version=5.7.22-log --manager_version=0.58 --relay_log_info=/usr/local/mysql/data/relay-log.info --relay_dir=/usr/local/mysql/data/ --slave_pass=xxxTue Jul 7 18:57:06 2020 - [info] Connecting to root@192.168.206.203(192.168.206.203:22).. Creating directory /data/log/masterha.. done. Checking slave recovery environment settings.. Opening /usr/local/mysql/data/relay-log.info ... ok. Relay log found at /usr/local/mysql/data, up to relay-bin.000003 Temporary relay log file is /usr/local/mysql/data/relay-bin.000003 Checking if super_read_only is defined and turned on.. not present or turned off, ignoring. Testing mysql connection and privileges..mysql: [Warning] Using a password on the command line interface can be insecure. done. Testing mysqlbinlog output.. done. Cleaning up test file(s).. done.Tue Jul 7 18:57:06 2020 - [info] Slaves settings check done.Tue Jul 7 18:57:06 2020 - [info] 192.168.206.201(192.168.206.201:3306) (current master) +--192.168.206.202(192.168.206.202:3306) +--192.168.206.203(192.168.206.203:3306)Tue Jul 7 18:57:06 2020 - [info] Checking replication health on 192.168.206.202..Tue Jul 7 18:57:06 2020 - [info] ok.Tue Jul 7 18:57:06 2020 - [info] Checking replication health on 192.168.206.203..Tue Jul 7 18:57:06 2020 - [info] ok.Tue Jul 7 18:57:06 2020 - [warning] master_ip_failover_script is not defined.Tue Jul 7 18:57:06 2020 - [warning] shutdown_script is not defined.Tue Jul 7 18:57:06 2020 - [info] Got exit code 0 (Not master dead).MySQL Replication Health is OK. 验证成功的话会自动识别出所有服务器和主从状况。 注：在验证时，若遇到这个错误：Can’t exec “mysqlbinlog” … 解决方法是在所有服务器上执行： 1ln -s /usr/local/mysql/bin/* /usr/local/bin/ ¶（5）启动 manager 123[root@manager ~]# nohup masterha_manager --conf=/etc/masterha/app1.cnf&amp; &gt;/tmp/mha_manager.log &amp;[1] 55707[root@manager ~]# nohup: 忽略输入并把输出追加到\"nohup.out\" 注：在应用Unix/Linux时，我们一般想让某个程序在后台运行，于是我们将常会用 &amp; 在程序结尾来让程 序自动运行。比如我们要运行mysql在后台： /usr/local/mysql/bin/mysqld_safe –user=mysql &amp;。可是 有很多程序并不想mysqld一样，这样我们就需要nohup命令， ¶（6）状态检查 12[root@manager ~]# masterha_check_status --conf=/etc/masterha/app1.cnfapp1 (pid:55707) is running(0:PING_OK), master:192.168.206.201 ¶（7）故障转移验证(自动failover) master dead后，MHA当时已经开启，候选Master库（Slave）会自动failover为Master。 验证的方式是先停掉 master（192.168.206.201），因为之前的配置文件中，把Candicate master(192.168.206.202)作为了候选人，那么就到 slave(192.168.206.203) 上查看 master 的 IP 是否变为了 slave-master 的 IP。 ¶1）停掉 master 在master（192.168.206.201） 上把 mysql 停掉。 ¶2）查看 MHA 日志 上面的配置文件中指定了日志位置为/masterha/app1/manager.log。 123456789101112131415161718[root@manager ~]# cat /masterha/app1/manager.log----- Failover Report -----app1: MySQL Master failover 192.168.206.201(192.168.206.201:3306) to 192.168.206.202(192.168.206.202:3306) succeededMaster 192.168.206.201(192.168.206.201:3306) is down!Check MHA Manager logs at manager:/masterha/app1/manager.log for details.Started automated(non-interactive) failover.The latest slave 192.168.206.202(192.168.206.202:3306) has all relay logs for recovery.Selected 192.168.206.202(192.168.206.202:3306) as a new master.192.168.206.202(192.168.206.202:3306): OK: Applying all logs succeeded.192.168.206.203(192.168.206.203:3306): This host has the latest relay log events.Generating relay diff files from the latest slave succeeded.192.168.206.203(192.168.206.203:3306): OK: Applying all logs succeeded. Slave started, replicating from 192.168.206.202(192.168.206.202:3306)192.168.206.202(192.168.206.202:3306): Resetting slave info succeeded.Master failover to 192.168.206.202(192.168.206.202:3306) completed successfully. 从日志信息中可以看到 master failover 已经成功了，并可以看出故障转移的大体流程 ¶3）检查 slave的复制 登录 slave（192.168.206.203） 的Mysql，查看 slave 状态： 1234567891011121314mysql&gt; show slave status \\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.206.202 Master_User: mharep Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000004 Read_Master_Log_Pos: 154 Relay_Log_File: relay-bin.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000004 Slave_IO_Running: Yes Slave_SQL_Running: Yes 可以看到 master 的 IP 现在为 192.168.206.202，已经切换到和192.168.206.202同步了。 本来是和192.168.206.201同步的，说明 MHA 已经把Candicate master(192.168.206.202) 提升为了新的 master，IO线程和SQL线程也正确运行，MHA搭建成功。 ¶六、MHA Manager端日常主要操作步骤 ¶1、检查是否有下列文件，有则删除。 发生主从切换后，MHAmanager服务会自动停掉，且在manager_workdir（/masterha/app1）目录下面生成文件app1.failover.complete。 1234[root@manager ~]# ll /masterha/app1/总用量 24-rw-r--r--. 1 root root 0 7月 7 19:07 app1.failover.complete-rw-r--r--. 1 root root 22192 7月 7 19:07 manager.log 若要启动MHA，必须先确保无此文件， 如果有这个提示，那么删除此文件。 123[error][/usr/share/perl5/vendor_perl/MHA/MasterFailover.pm, ln298] Last failover was done at 2015/01/09 10:00:47.Current time is too early to do failover again. If you want to do failover, manually remove /masterha/app1/app1.failover.complete and run this script again. ¶2、检查MHA复制检查 需要把master设置成candidate的从服务器 ¶（1）查看candidate的从服务器（192.168.206.202）的二进制日志 1234mysql&gt; show master status\\G*************************** 1. row *************************** File: mysql-bin.000004 Position: 154 ¶（2）将master服务器设置为candidate的从服务器 12345678[root@master ~]# systemctl start mysqld[root@master ~]# mysql -uroot -pmysql&gt; change master to master_host&#x3D;&#39;192.168.206.202&#39;,master_port&#x3D;3306,master_user&#x3D;&#39;mharep&#39;,master_password&#x3D;&#39;123456&#39;,master_log_file&#x3D;&#39;mysql-bin.000004&#39;,master_log_pos&#x3D;154;Query OK, 0 rows affected, 2 warnings (0.00 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.00 sec) 12345678910111213141516171819[root@manager ~]# masterha_check_repl --conf=/etc/masterha/app1.cnf# 省略部分输出信息Tue Jul 7 19:31:44 2020 - [info] Slaves settings check done.Tue Jul 7 19:31:44 2020 - [info] 192.168.206.202(192.168.206.202:3306) (current master) +--192.168.206.201(192.168.206.201:3306) +--192.168.206.203(192.168.206.203:3306)Tue Jul 7 19:31:44 2020 - [info] Checking replication health on 192.168.206.201..Tue Jul 7 19:31:44 2020 - [info] ok.Tue Jul 7 19:31:44 2020 - [info] Checking replication health on 192.168.206.203..Tue Jul 7 19:31:44 2020 - [info] ok.Tue Jul 7 19:31:44 2020 - [warning] master_ip_failover_script is not defined.Tue Jul 7 19:31:44 2020 - [warning] shutdown_script is not defined.Tue Jul 7 19:31:44 2020 - [info] Got exit code 0 (Not master dead).MySQL Replication Health is OK. ¶3、停止MHA 1masterha_stop --conf=/etc/masterha/app1.cnf ¶4、启动MHA 1nohup masterha_manager --conf=/etc/masterha/app1.cnf &amp;&gt;/tmp/mha_manager.log &amp; 当有slave 节点宕掉时，默认是启动不了的，加上 --ignore_fail_on_start 即使有节点宕掉也能启动MHA，如下： 1nohup masterha_manager --conf=/etc/masterha/app1.cnf --ignore_fail_on_start &amp; &gt;/tmp/mha_manager.log &amp; ¶5、检查状态 1masterha_check_status --conf=/etc/masterha /app1.cnf ¶6、检查日志 1tail -f /masterha/app1/manager.log ¶7、主从切换后续工作 ¶（1）重构 重构就是你的主挂了，切换到Candidate master上，Candidate master变成了主 ¶（2）重构的两种方案 1）原主库修复成一个新的slave 主库切换后，把原主库修复成新从库，然后重新执行以上5步。 2）原主库数据文件完整的情况下，可通过以下方式找出最后执行的CHANGE MASTER命令： 12345678910111213141516171819202122232425[root@manager ~]# grep \"CHANGE MASTER TO MASTER\" /masterha/app1/manager.log | tail -1Tue Jul 7 19:07:08 2020 - [info] All other slaves should start replication from here. Statement should be: CHANGE MASTER TO MASTER_HOST='192.168.206.202', MASTER_PORT=3306, MASTER_LOG_FILE='mysql-bin.000004', MASTER_LOG_POS=154, MASTER_USER='mharep', MASTER_PASSWORD='xxx';[root@manager ~]# mysql -uroot -pmysql&gt; CHANGE MASTER TO MASTER_HOST='192.168.206.202', MASTER_PORT=3306, MASTER_LOG_FILE='mysql-bin.000004', MASTER_LOG_POS=154, MASTER_USER='mharep', MASTER_PASSWORD='123456';Query OK, 0 rows affected, 2 warnings (0.01 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.00 sec)mysql&gt; show slave status\\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.18.6 Master_User: mharep Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000002 Read_Master_Log_Pos: 154 Relay_Log_File: relay-bin.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes 3）启动manager 12345[root@manager ~]# nohup masterha_manager --conf=/etc/masterha/app1.cnf&amp; &gt;/tmp/mha_manager.log &amp;[1] 55707[root@manager ~]# masterha_check_status --conf=/etc/masterha/app1.cnfapp1 (pid:55707) is running(0:PING_OK), master:192.168.206.201 注意：如果正常，会显示&quot;PING_OK&quot;，否则会显示&quot;NOT_RUNNING&quot;，这代表MHA监控没有开启。 定期删除中继日志 在配置主从复制中，slave上设置了参数relay_log_purge=0，所以slave节点需要定期删除中 继日志，建议每个slave节点删除中继日志的时间错开。 12corntab -e0 5 * * * /usr/local/bin/purge_relay_logs - -user=root --password=pwd123 --port=3306 --disable_relay_log_purge &gt;&gt; /var/log/purge_relay.log 2&gt;&amp;1 ¶七、配置VIP vip配置可以采用两种方式，一种通过keepalived的方式管理虚拟ip的浮动；另外一种通过脚本方式启动虚拟ip 的方式（即不需要keepalived或者heartbeat类似的软件）。 ¶1、keepalived方式管理虚拟ip ¶（1）keepalived配置 下载软件并在master（192.168.206.201）和备选master（192.168.206.202）上安装软件包keepalived。 在编译安装Keepalived之前，必须先安装内核开发包kernel-devel以及openssl-devel、popt-devel等支持库。 ¶1）下载Keepalived 1wget https://www.keepalived.org/software/keepalived-2.0.20.tar.gz ¶2）安装依赖库 1yum -y install kernel-devel openssl-devel popt-devel gcc ¶3）解压 1tar zxf keepalived-2.0.20.tar.gz ¶4）安装 12cd keepalived-2.0.20/./configure --prefix=/ &amp;&amp; make &amp;&amp; make install ¶5）使用keepalived服务 12systemctl enable keepalivedsystemctl start keepalived ¶6）创建防火墙规则 若开启了防火墙，需要关闭防火墙或创建规则。 12345firewall-cmd --direct --permanent --add-rule ipv4 filter OUTPUT 0 --in-interface ens33 --destination 224.0.0.18 --protocol vrrp -j ACCEPTfirewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 --in-interface ens33 --destination 224.0.0.18 --protocol vrrp -j ACCEPTfirewall-cmd --reload ¶（2）修改Keepalived的配置文件 vim /etc/keepalived/keepalived.conf ¶1）在master上配置 1234567891011121314151617181920212223[root@master ~]# vim /etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs &#123; router_id mysql-1&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 51 priority 100 advert_int 1 nopreempt authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.206.100 &#125;&#125; ¶2）在备选master上配置 123456789101112131415161718192021! Configuration File for keepalivedglobal_defs &#123; router_id mysql-2 # 此处需要修改&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 51 priority 50 # 此处需要修改 advert_int 1 nopreempt authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.206.100 &#125;&#125; ¶3）在master上启动并查看日志 注意：需启动keepalived服务 12345678910111213141516171819[root@master keepalived-2.0.20]# systemctl start keepalived.service [root@master keepalived-2.0.20]# ps -ef | grep keepgdm 1977 1813 0 03:52 ? 00:00:00 /usr/libexec/gsd-housekeepinggdm 59162 58971 0 05:51 ? 00:00:00 /usr/libexec/gsd-housekeepingroot 113268 1 0 14:54 ? 00:00:00 //sbin/keepalived -Droot 113270 113268 1 14:54 ? 00:00:00 //sbin/keepalived -Droot 113292 92137 0 14:55 pts/0 00:00:00 grep --color=auto keep[root@master keepalived-2.0.20]# ip a | grep 1001: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 10002: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 inet 192.168.206.100/32 scope global ens33# 省略部分输出信息[root@master keepalived-2.0.20]# tail -f /var/log/messages # 省略部分输出信息Jul 8 14:57:31 master avahi-daemon[740]: Registering new address record for 192.168.206.100 on ens33.IPv4.Jul 8 14:57:31 master avahi-daemon[740]: Registering new address record for 192.168.206.201 on ens33.IPv4.# 省略部分输出信息 发现已经将虚拟ip 192.168.206.100绑定了网卡ens33上。 ¶4）在备选master上启动并查看日志 在另外一台服务器，候选master上启动keepalived服务，并观察 123456[root@slave-master keepalived-2.0.20]# systemctl start keepalived.service [root@slave-master keepalived-2.0.20]# tail -f /var/log/messages # 省略部分输出信息Jul 8 15:01:16 slave-master Keepalived_vrrp[111159]: Assigned address 192.168.206.202 for interface ens33# 省略部分输出信息 从上面的信息可以看到keepalived已经配置成功。 注意： 上面两台服务器的keepalived都设置为了BACKUP模式，在keepalived中2种模式，分别是master-backup模式和backup-&gt;backup模式。这两种模式有很大区别。 121. 在master-&gt;backup模式下，一旦主库宕机，虚拟ip会自动漂移到从库，当主库修复后，keepalived启动后，还会把虚拟ip抢占过来，即使设置了非抢占模式（nopreempt）抢占ip的动作也会发生。2. 在backup-&gt;backup模式下，当主库宕机后虚拟ip会自动漂移到从库上，当原主库恢复和keepalived服务启动后，并不会抢占新主的虚拟ip，即使是优先级高于从库的优先级别，也不会发生抢占。 为了减少ip漂移次数，通常是把修复好的主库当做新的备库。 ¶（3）MHA引入keepalived MySQL服务进程挂掉时通过MHA 停止keepalived 要想把keepalived服务引入MHA，我们只需要修改切换时触发的脚本文件master_ip_failover即可，在该脚本中添加在master发生宕机时对keepalived的处理。 编辑脚本/scripts/master_ip_failover，修改后如下。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#!/usr/bin/env perluse strict;use warnings FATAL =&gt; 'all';use Getopt::Long;my ( $command, $ssh_user, $orig_master_host, $orig_master_ip, $orig_master_port, $new_master_host, $new_master_ip, $new_master_port, $new_master_user, $new_master_password);my $vip=\"192.168.206.100\";my $ssh_start_vip=\"systemctl start keepalived.service\";my $ssh_stop_vip=\"systemctl stop keepalived.service\";GetOptions( 'command=s' =&gt; \\$command, 'ssh_user=s' =&gt; \\$ssh_user, 'orig_master_host=s' =&gt; \\$orig_master_host, 'orig_master_ip=s' =&gt; \\$orig_master_ip, 'orig_master_port=i' =&gt; \\$orig_master_port, 'new_master_host=s' =&gt; \\$new_master_host, 'new_master_ip=s' =&gt; \\$new_master_ip, 'new_master_port=i' =&gt; \\$new_master_port, 'new_master_user=s' =&gt; \\$new_master_user, 'new_master_password=s' =&gt; \\$new_master_password,);exit &amp;main();sub main &#123; print \"\\n\\nIN SCRIPT TEST====$ssh_stop_vip==$ssh_start_vip===\\n\\n\"; if ( $command eq \"stop\" || $command eq \"stopssh\" ) &#123; my $exit_code = 1; eval &#123; print \"Disabling the VIP on old master: $orig_master_host \\n\"; &amp;stop_vip(); $exit_code = 0; &#125;; if ($@) &#123; warn \"Got Error: $@\\n\"; exit $exit_code; &#125; exit $exit_code; &#125; elsif ( $command eq \"start\" ) &#123; my $exit_code = 10; $exit_code = 0; &#125;; if ($@) &#123; warn $@; exit $exit_code; &#125; exit $exit_code; #'ssh $ssh_user\\@cluster1 \\\" $ssh_start_vip \\\"'; exit 0; &#125; else &#123; &amp;usage(); exit 1; &#125;&#125;sub start_vip()&#123; `ssh $ssh_user\\@$new_master_host \\\" $ssh_start_vip \\\"`;&#125;sub stop_vip()&#123; return 0 unless ($ssh_user); `ssh $ssh_user\\@$new_master_host \\\" $ssh_start_vip \\\"`;&#125; sub usage &#123; print\"Usage: master_ip_failover --command=start|stop|stopssh|status --orig_master_host=host --orig_master_ip=ip --orig_master_port=port --new_master_host=host --new_master_ip=ip --new_master_port=port\\n\";&#125; 现在已经修改这个脚本了，接下来我们在/etc/masterha/app1.cnf 中调用故障切换脚本 停止MHA： 1#masterha_stop --conf=/etc/masterha/app1.cnf 在配置文件/etc/masterha/app1.cnf 中启用下面的参数(在[server default下面添加]) 1master_ip_failover_script=/scripts/master_ip_failover ¶（4）启动MHA： 1#nohup masterha_manager --conf=/etc/masterha/app1.cnf &amp;&gt;/tmp/mha_manager.log &amp; ¶（5）检查状态 12[root@centos1 ~]# masterha_check_status --conf=/etc/masterha/app1.cnfapp1 (pid:12047) is running(0:PING_OK), master:192.168.206.202 再检查集群状态，看是否会报错 12345678910111213141516171819202122[root@centos1 ~]# masterha_check_repl --conf=/etc/masterha/app1.cnfFri Sep 30 23:05:10 2016 - [info] Slaves settings check done.Fri Sep 30 23:05:10 2016 - [info]192.168.1.102(192.168.1.102:3306) (current master)+--192.168.206.202(192.168.206.202:3306)+--192.168.206.203(192.168.206.203:3306)Fri Sep 30 23:05:10 2016 - [info] Checking replication health on 192.168.206.202..Fri Sep 30 23:05:10 2016 - [info] ok.Fri Sep 30 23:05:10 2016 - [info] Checking replication health on 192.168.206.203..Fri Sep 30 23:05:10 2016 - [info] ok.Fri Sep 30 23:05:10 2016 - [info] Checking master_ip_failover_script status:Fri Sep 30 23:05:10 2016 - [info] /scripts/master_ip_failover --command=status --ssh_user=root --orig_master_host=192.168.206.201 --orig_master_ip=192.168.206.201 --orig_master_port=3306Checking the Status of the script.. OKFri Sep 30 23:05:10 2016 - [info] OK.Fri Sep 30 23:05:10 2016 - [warning] shutdown_script is not defined.Fri Sep 30 23:05:10 2016 - [info] Got exit code 0 (Not master dead).MySQL Replication Health is OK. ¶（6）测试 在master上停掉mysql服务 1# systemctl stop mysqld [ OK ] 到slave(192.168.206.202)查看slave的状态： 1234567891011121314mysql&gt; show slave status\\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.206.200 Master_User: mharep Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000004 Read_Master_Log_Pos: 154 Relay_Log_File: relay-bin.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000004 Slave_IO_Running: Yes Slave_SQL_Running: Yes 从上图可以看出slave指向了新的master服务器（192.168.206.200） 查看VIP 1234567891011121314151617181920212223[root@master1 keepalived]# ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group defaultqlen 1000link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00inet 127.0.0.1/8 scope host lovalid_lft forever preferred_lft foreverinet6 ::1/128 scope hostvalid_lft forever preferred_lft forever2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UPgroup default qlen 1000link/ether 00:0c:29:ce:ea:e9 brd ff:ff:ff:ff:ff:ffinet 192.168.206.200/24 brd 192.168.206.255 scope global noprefixroute ens33valid_lft forever preferred_lft foreverinet 192.168.206.100/24 brd 192.168.206.255 scope global secondary ens33:0valid_lft forever preferred_lft foreverinet6 fe80::8afe:8575:3294:65a2/64 scope link tentative noprefixroutedadfailedvalid_lft forever preferred_lft foreverinet6 fe80::1d3d:dd62:8adb:c689/64 scope link tentative noprefixroutedadfailedvalid_lft forever preferred_lft foreverinet6 fe80::77a5:d0c0:a955:c7f3/64 scope link noprefixroutevalid_lft forever preferred_lft forever 从上图可以看到master2(原来的master)释放了VIP，master1(新的master)接管了VIP地址 主从切换后续工作 主库切换后，把原主库修复成新从库，相关操作请参考前面相关操作。 为了防止脑裂发生，推荐生产环境采用脚本的方式来管理虚拟ip，而不是使用keepalived来完成。到此为止，基本MHA集群已经配置完毕 ¶（7）总结 MHA软件由两部分组成，Manager工具包和Node工具包，具体的说明如下。 Manager工具包主要包括以下几个工具： masterha_check_ssh 检查MHA的SSH配置状况 masterha_check_repl 检查MySQL复制状况masterha_manger 启动MHA masterha_check_status 检测当前MHA运行状态masterha_master_monitor 检测master是否宕机 masterha_master_switch 控制故障转移（自动或者手动） masterha_conf_host 添加或删除置的server信息Node工具包（这些工具通常由MHA Manager的脚本触发，无需人为操作）主要包括以下几个工具： save_binary_logs 保存和复制master的二进制日志 apply_diff_relay_logs 识别差异的中继日志事件并将其差异的事件应用于其他的slave filter_mysqlbinlog 去除不必要的ROLLBACK事件（MHA已不再使用这个工具）purge_relay_logs 清除中继日志（不会阻塞SQL线程） ¶（8）mysql必备技能掌握 123456789101112131、MySQL架构:对mysql的架构，整体有个印象，才能不断的加深对mysql的理解和后继的学习。 2、用各种姿势备份MySQL数据库 数据备份是DBA或运维工程师日常工作之一，如果让你来备份，你会用什么方式备份，在时间时间备份，使用什么策略备份 3、mysql主从复制及读写分离 mysql的主从复制及读写分离是DBA必备技能之一 4、MySQL/MariaDB数据库基于SSL实现主从复制 加强主从复制的安全性 5、MySQL高可用 数据的高可用如何保证 6、数据库Sharding的基本思想和切分策略 随着数据量的不断攀升，从性能和可维护的角度，需要进行一些Sharding，也就是数据库的切分，有垂直切分和水平切分 7、MySQL/MariaDB 性能调整和优化技巧 掌握优化思路和技巧，对数据库的不断优化是一项长期工程","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/tags/MySQL/"}]},{"title":"MySQL高级查询","slug":"MySQL高级查询","date":"2020-07-10T16:00:00.000Z","updated":"2020-07-11T11:38:11.008Z","comments":true,"path":"MySQL高级查询.html","link":"","permalink":"https://pdxblog.top/MySQL%E9%AB%98%E7%BA%A7%E6%9F%A5%E8%AF%A2.html","excerpt":"","text":"¶MySQL高级查询 本章将介绍如何修改表结构和数据的增删改查，以及mysql中常用的函数和运算符的使用方法。 ¶一、DDL语句（修改表结构） ¶1、修改表 语法： 1234567891011# 修改表名alter table 旧表名 rename 新表名;# 添加字段alter table 表名 add 字段名 数据类型[属性];# 修改字段alter table 表名 CHANGE 原字段名 新字段名 数据类型[属性];# 删除字段alter table 表名 drop 字段名; 示例： 123456789101112131415161718drop table if exists &#96;ttt&#96;;# 创建表create table &#96;ttt&#96;( &#96;sid&#96; int(4) not null auto_increment primary key, &#96;sname&#96; varchar(20) not null);# 修改表名alter table teacher rename ttt;# 添加字段alter table ttt add &#96;sex&#96; char(2);# 修改字段alter table ttt CHANGE &#96;sex&#96; &#96;gender&#96; char(2);# 删除字段alter table ttt drop gender; ¶2、添加主键 语法： 12alter table 表名 add CONSTRAINT 主键名PRIMARY KEY 表名(主键字段); 如何设置grade表中gradeID字段为主键？ 1234567create table grade( &#96;gradeID&#96; int(4) not null, &#96;gradeName&#96; varchar(20) not null);alter table grade add CONSTRAINT pk_gradePRIMARY KEY grage(&#96;gradeID&#96;); ¶3、添加外键 语法： 12alter table 表名 ADD CONSTRAINT 外键名 FOREIGN KEY（外键字段）REFERENCES 关联表名（关联字段）; 如何将student表的gradeId字段和grade表的gradeId字段建立外键关联？ 123alter table student add CONSTRAINT fk_student_gradeFOREIGN KEY(&#96;gradeID&#96;)REFERENCES &#96;grade&#96;(&#96;gradeID&#96;); ¶4、小结 阅读以下代码，哪些SQL语句可以实现修改表？ 12341）ALTER TABLE mybook RENAME book;2）ALTER TABLE book ADD author varchar(10) NOT NULL;3）ALTER TABLE &#96;book&#96; ADD &#96;pk_book&#96; PRIMARY KEY &#96;book&#96;(&#96;bookId&#96;);4）ALTER TABLE &#96;book&#96; DROP &#96;author &#96;; 除了第3个，其他SQL语句都可以实现修改表。 ¶5、上机练习 ¶（1）创建数据表并实现对表的修改操作 字段名称 字段说明 数据类型 长度 属性 number 序号 INT 4 自增列 name 姓名 VARCHAR 50 非空 sex 性别 CHAR 2 bornDate 出生日期 DATETIME 需求说明： 12345在test数据库中创建person表将表名修改为tb_person删除出生日期字段添加出生日期字段，数据类型为DATE类型修改序号字段名（number）为id，类型为BIGINT类型 ¶（2）添加成绩表主外键 result表需要添加的内容 12主键约束：学号、课程编号和日期构成组合主键外键约束：主表student和从表result通过studentNo字段建立主外键关联 ¶二、DML语句（增删改） ¶1、插入单条数据记录 语法： 1INSERT INTO 表名 [(字段名列表)] VALUES (值列表); 注意： 1234字段名是可选的，如省略则依次插入所有字段多个列表和多个值之间使用逗号分隔值列表和字段名列表一一对应如插入的是表中部分数据，字段名列表必填 示例： 12INSERT INTO &#96;student&#96;(&#96;loginPwd&#96;,&#96;studentName&#96;,&#96;gradeId&#96;,&#96;phone&#96;,&#96;bornDate&#96;)VALUES(&#39;123&#39;,&#39;黄小平&#39;,1,&#39;13956799999&#39;,&#39;1996-5-8&#39;); ¶2、插入多条数据记录 语法： 12INSERT INTO 新表（字段名列表）VALUES(值列表1),(值列表2),……,(值列表n); 示例： 12INSERT INTO &#96;subject&#96;(&#96;subjectName&#96;,&#96;classHour&#96;,&#96;gradeID&#96;)VALUES(&#39;Logic Java&#39;,220,1),(&#39;HTML&#39;,160,1),(&#39;Java OOP&#39;,230,2); 经验： 1为避免表结构发生变化引发的错误，建议插入数据时写明具体字段名！ ¶3、将查询结果插入新表 ¶（1）事先创建新表且与插入数据字段相符 123INSERT INTO 新表（字段1,字段2……） SELECT字段1，字段2……FROM 原表; ¶（2）无需事先创建新表 123CREATE TABLE 新表（SELECT 字段1，字段2……FROM 原表）; （3）练习 编写SQL语句实现从学生表提取姓名、手机号两列数据存储到通讯录表中。 123CREATE TABLE &#96;phoneList&#96;( SELECT &#96;studentName&#96;,&#96;phone&#96; FROM &#96;student&#96;); 注意： 1如新表已存在，将会报错！ ¶4、更新数据记录 语法： 123UPDATE 表名 SET 字段1&#x3D;值1,字段2&#x3D;值2,…,字段n&#x3D;值n [WHERE 条件]; ¶5、删除数据记录 语法： 12DELETE FROM 表名 [WHERE条件];TRUNCATE TABLE 表名; 注意： 1TRUNCATE语句删除后将重置自增列，表结构及其字段、约束、索引保持不变，执行速度比DELETE语句快 ¶6、小结 123MySQL中如何使用一条INSERT语句插入多条数据？MySQL中将查询结果集插入新表的两种方式是什么？两者的区别是什么？删除数据时使用DELETE和TRUNCATE的区别是什么？ ¶三、DQL语句（查询） ¶1、通用查询 语法： 123456SELECT &lt;字段名列表&gt;FROM &lt;表名或视图&gt;[WHERE &lt;查询条件&gt;][GROUP BY &lt;分组的字段名&gt;][HAVING &lt;条件&gt;][ORDER BY &lt;排序的字段名&gt; [ASC 或 DESC]] 示例： 1234SELECT &#96;studentNo&#96;,&#96;studentName&#96;,&#96;phone&#96;,&#96;address&#96;,&#96;bornDate&#96; FROM &#96;student&#96;WHERE &#96;gradeId&#96; &#x3D; 1ORDER BY studentNo; ¶2、LIMIT子句 MySQL查询语句中使用LIMIT子句限制结果集。 语法： 123456SELECT &lt;字段名列表&gt;FROM &lt;表名或视图&gt;[WHERE &lt;查询条件&gt;][GROUP BY &lt;分组的字段名&gt;][ORDER BY &lt;排序的列名&gt; [ASC 或 DESC]][LIMIT [位置偏移量, ]行数]; 示例： 123456SELECT &#96;studentNo&#96;,&#96;studentName&#96;,&#96;phone&#96;,&#96;address&#96;,&#96;bornDate&#96; FROM &#96;student&#96;WHERE &#96;gradeId&#96; &#x3D; 1ORDER BY studentNoLIMIT 4,4 #从第5条开始显示4条 注意： 1使用LIMIT子句时，注意第1条记录的位置是0！ ¶3、常用函数 ¶（1）聚合函数 函数名 作用 count() 返回某字段的行数 avg() 返回某字段的平均值 max() 返回某字段的最大值 min() 返回某字段的最小值 sum() 返回某字段的和 ¶（2）字符串函数 函数名 作用 示例 LENGTH(str) 计算字符串长度 SELECT LENGTH(‘date’); CONCAT(str1,str2,…) 字符串合并 select CONCAT(‘a’,‘b’,‘c’) INSERT(str,pos,len,newstr) 字符串替换 select INSERT(‘old string’,1,3,‘letter’) LOWER(str) 将字符串转换为小写 select LOWER(‘A’) UPPER(str) 将字符串转换为大写 select UPPER(‘a’) LEFT(s,n) 返回字符串 s 开始的最左边 n 个字符 SELECT LEFT(‘hello’,2); RIGHT(s,n) 返回字符串 s 开始的最右边 n 个字符 SELECT RIGHT(‘hello word!’,5); LPAD(s1,len,s2) 返回字符串 s1 ，其左边由字符串 s2填充到 len 字符长度，如果 s1 的长度大于 len ，则返回值被缩短至 len 长度 SELECT RPAD(‘hello’,4,’?’); RPAD(s1,len,s2) 返回字符串 s1 ，其右边由字符串 s2 填充到 len 字符长度，如果 s1 的长度大于 len ，则返回值被缩短至 len 长度 SELECT RPAD(‘hello’,10,’?’); LTRIM(s) 用于删除字符串 s 左侧的空格 SELECT LTRIM(’ book '); RTRIM(s) 用于删除字符串 s 右侧的空格 SELECT RTRIM(’ book '); TRIM(s) 用于删除字符串 s 两侧的空格 SELECT TRIM(’ book '); TRIM(s1 FROM s) 删除指定字符串的函数 SELECT TRIM(‘xy’ FROM ‘xyxyabcxy’); REPEAT(s,n) 用于重复字符串 s ，n 表示重复多少次 SELECT REPEAT(‘mysql’,3); SPACE(n) 用于返回 n 个空格 SELECT SPACE(20); REPLACE(s,s1,s2) 使用字符串 s2 替换字符串 s 中所有的字符串 s1 SELECT REPLACE(‘xxx.mysql.com’, ‘x’, ‘w’); STRCMP(s1,s2) 用于比较字符串 s1 和 s2 的大小，若所有字符串相同则返回 0 ，若第一个字符串大于第二个字符串则返回 1 ，若第一个字符串小于第二个字符串则返回 -1 SELECT STRCMP(‘txt’, ‘txt2’), STRCMP(‘txt’, ‘txt’); SUBSTRING(str,num,len) 获取指定位置的子字符串 select SUBSTRING(‘JavaMysqlOracle’,5,5); MID(s,n,len) 用于获取指定位置的子字符串 SELECT MID(‘breakfast’,5); LOCATE(str1,str) 返回字符串 str1 在字符串 str 中的开始位置 SELECT LOCATE(‘ball’, ‘football’); POSITION(str1 IN str) 返回字符串 str1 在字符串 str 中的开始位置 SELECT POSITION(‘ball’ IN ‘football’); INSTR(str, str1) 返回子字符串 str1 在字符串 str 中的开始位置 SELECT INSTR(‘football’, ‘ball’); REVERSE(s) 将字符串 s 反转 SELECT REVERSE(‘abcd’); ELT(n, s1, s2, s3, …) 返回第 n 个字符串，如果 n超出范围则返回 NULL SELECT ELT(3, ‘a’, ‘b’, ‘c’, ‘d’); FIELD(s, s1, s2, …) 返回字符串 s 在列表 s1, s2, … 中的位置，如果不存在字符串 s 则返回 0 ，如果字符串 s 是 NULL 也返回 0 SELECT FIELD(‘hi’, ‘hihi’, ‘hey’, ‘hi’, ‘bas’); FIND_IN_SET(s1, s2) 返回字符串 s1 在字符串列表 s2中的位置 SELECT FIND_IN_SET(‘hi’, ‘hihi,hey,hi,bas’); ¶（3）时间日期函数 函数名 作用 示例 CURDATE() 获取当前日期 select CURDATE(); CURTIME() 获取当前时间 select CURTIME(); CURRENT_TIMESTAMP() 、.LOCALTIME() 、NOW() 、SYSDATE()CURRENT_TIMESTAMP() 获取当前日期和时间 select NOW(); UNIX_TIMESTAMP() 获取 UNIX 格式的时间戳 SELECT UNIX_TIMESTAMP(); FROM_UNIXTIME() 将 UNIX 格式的时间戳转换为普通格式的时间 SELECT FROM_UNIXTIME(‘1495542689’); UTC_DATE() UTC_DATE() 获取当前 UTC (世界标准时间) 日期值 SELECT UTC_DATE(); UTC_TIME() UTC_TIME() 获取当前 UTC (世界标准时间) 时间值 SELECT UTC_TIME(); YEAR(date) 返回日期date的年份 select YEAR(NOW()); QUARTER(date) 返回日期date为一年中第几季度 select QUARTER(NOW()); MONTH(date) 返回日期date的月份 select MONTH(NOW()); WEEK(date) 返回日期date为一年中第几周 select WEEK(NOW()); DAY(date) 返回日期date的日期 select DAY(NOW()); DAYOFYEAR(date) 返回 date 是一年中的第几天，一年有 365 天 SELECT DAYOFYEAR(‘2017-05-23’); DAYOFMONTH(date) 计算 date 是一个月中的第几天 SELECT DAYOFMONTH(‘2017-05-23’); HOUR(time) 返回日期date的小时 select HOUR(NOW()); MINUTE(time) 返回日期date的分钟 select MINUTE(NOW()); SECOND(time) 返回日期date的秒 select SECOND(NOW()); TIME_TO_SEC(time) 将 time 转换为秒钟，公式为 &quot; 小时3600 + 分钟60 + 秒 &quot; SELECT TIME_TO_SEC(‘23:23:00’); SEC_TO_TIME(time) 将秒值转换为时间格式 SELECT SEC_TO_TIME(‘84180’); DATEDIFF(date1,date2) 返回日期date的date1和date2间隔的天数 select DATEDIFF(NOW(),‘2020-06-07’); ADDDATE(date,n) 计算日期date加上n天以后在日期 select ADDDATE(NOW(),3); DATE_FORMAT(date, format) 格式化日期，即根据 format 指定的格式显示 date 值 SELECT DATE_FORMAT(‘1997-10-04 22:23:00’, ‘%W %M %Y’); TIME_FORMAT(time, format) 格式化时间，即根据 format 指定的格式显示 time 值 SELECT TIME_FORMAT(‘16:00:00’, ‘%H %k %I’); GET_FORMAT() 指定值类型和格式化类型，然后会显示成格式字符串 SELECT DATE_FORMAT(‘2000-10-05 22:23:00’, GET_FORMAT(DATE,‘USA’)); 参考内容： 1234567891011121314151617181920212223242526%d该月日期，数字形式（00..31） %e该月日期，数字形式（0..31） %f微秒（000000...999999） %H以2位数表示24小时（00..23） %h,%I 以2位数表示12小时（01..12） %i分钟，数字形式（00-59） %j一年中的天数（001-366） %k以24小时（0-23） %l以12小时（0..12） %M月份名称（january..December） %m月份数字形式（00..12） %p上午（AM）或下午（PM） %r时间，12小时制（小时hh：分钟mm：秒钟ss后面加AM或PM）%S,%s以2位数形式表示秒（00..59） %T时间，24小时制（小时hh：分钟mm：秒数ss） %U周（00..53），其中周日为每周的第一天 %u周（00..53），其中周一为每周的第一天 %V周（01..53），其中周日为每周的第一天，和%X一起使用 %v周（01..53），其中周一为每周的第一天，和%x一起使用 %W工作日名称（周日..周六）%w一周中的每日（0=周日..6=周六） %X该周的年份，其中周日为每周的第一天；数字形式4位数，和%V同时使用 %x该周的年份，其中周一为每周的第一天；数字形式4位数，和%v同时使用 %Y4位数形式表示年份 %y2位数形式表示年份 %% “%”文字字符 ¶（4）数学函数 函数名 作用 示例 ABS(x) 绝对值函数 SELECT ABS(-2); PI() 返回圆周率的函数 SELECT PI(); SQRT(x) 平方根函数，返回非负数二次方根 SELECT SQRT(9); CEIL(x) 向上取整 SELECT CEIL(2.1); FLOOR(x) 向下取整 SELECT FLOOR(2.5); RAND(x) 返回一个随机浮点值，范围在 0 ~ 1 之间 SELECT RAND(); ROUND(x) 对x进行四舍五入 SELECT ROUND(-1.34); ROUND(x,y) 对x进行四舍五入，并且保留小数点后y位 SELECT ROUND(1.37,1); TRUNCATE(x,y) 对x进行截取，结果保留小数点后y位 SELECT TRUNCATE(1.31,1); POW(x,y) 返回 x 的 y 次方的结果 SELECT POW(2,4); ¶（5）系统信息函数 函数名 作用 示例 VERSION() 获取 MySQL 版本号 SELECT VERSION(); CHARSET(str) 查看字符串 str 的字符集 SELECT CHARSET(‘abc’); COLLATION(str) 查看字符串 str 的字符排列方式 SELECT COLLATION(‘abc’); LAST_INSERT_ID() 获取最后一个自动生成的ID 值 SELECT LAST_INSERT_ID(); USER() 、CURRENT_USER() 、SYSTEM_USER() 返回当前登录的用户及主机名 SELECT USER();SELECT CURRENT_USER();SELECT SYSTEM_USER(); CONNECTION_ID() 查看当前用户的连接数的ID SELECT CONNECTION_ID(); DATABASE()、SCHEMA() 查看当前使用的数据库 SELECT DATABASE();SELECT SCHEMA(); SHOW PROCESSLIST 查看当前用户的连接信息 SHOW PROCESSLIST; CONNECTION_ID()函数的参数 123456781. Id ：用户登录 MySQL 时，系统分配的连接 id2. User ：当前连接的用户3. Host ：显示这个语句是从哪个 IP 的哪个端口上发出的，可以用来追踪出现问题语句的用户4. db ：显示这个进程目前连接的是哪个数据库5. Command ：显示当前连接执行的命令，一般取值为休眠(Sleep)、查询(Query)、连接(Connect)6. Time ：显示这个状态持续的时间，单位是秒7. State ：显示使用当前连接的 SQL 语句的状态8. Info ：显示这个 SQL 语句 ¶（6）条件判断函数 函数 作用 示例 IF() IF(expr, v1, v2) 如果表达式 expr 为 TRUE ，则返回值为 v1 ，否则返回 v2 SELECT IF(1&gt;2, 2, 3); IFNULL() IFNULL(v1, v2) 如果 v1 不为 NULL ，则返回值为 v1 ；如果 v1 为 NULL ，则返回值为 v2 SELECT IFNULL(1,2), IFNULL(NULL,10); CASE expr WHEN v1 THEN r1 [WHEN v2 THEN r2] [ELSE rn] END 如果 expr 等于某个 vn，则返回对应位置 THEN 后面的结果，如果与所有值都不相等，则返回 ELSE 后面的 rn SELECT CASE 2 WHEN 1 THEN ‘one’ WHEN 2 THEN ‘two’ ELSE ‘more’ END; ¶（7）加密/解密函数 函数 作用 示例 PASSWORD(str) 从明文密码 str 计算并返回加密后的密码字符串，当参数为 NULL 时，返回 NULL SELECT PASSWORD(‘newpwd’); MD5(str) 为字符串 str 算出一个 MD5 128 比特校验值 SELECT MD5(‘newpwd’); ENCODE(str, pswd_str) 使用 pswd_str 作为密码，加密 str SELECT ENCODE(‘secret’, ‘newpwd’); DECODE(crypt_str, pswd_str) 使用 pswd_str 作为密码，解密加密字符串 crypt_str SELECT DECODE(ENCODE(‘secret’,‘cry’), ‘cry’); ¶（8）其它函数 函数 作用 示例 FORMAT(x, n) 将数字 x 格式化，并以四舍五入的方式保留小数点后 n 位，结果以字符串的形式返回 SELECT FORMAT(1.23456, 4); CONV() 不同进制数之间的转换 SELECT CONV(‘a’,16,2), # 将16进制的a转换为2进制SELECT CONV(15,10,2), # 将10进制的15转换为2进制SELECT CONV(15,10,8), # 将10进制的15转换为8进制SELECT CONV(15,10,16); # 将10进制的15转换为16进制 INET_ATON(expr) 将网络地址转换为一个代表该地址数值的整数 SELECT INET_ATON(‘192.168.1.1’); GET_LOCK(str, timeout) 使用字符串 str 来得到一个锁，持续时间 timeout 秒1. 若成功得到锁，则返回 12. 若操作超时，则返回 03. 若发生错误，则返回 NULL SELECT GET_LOCK(‘lock1’, 10); RELEASE_LOCAK(str) 用于解开被 GET_LOCK() 获取的，用字符串 str 所命名的锁1. 若锁被解开，则返回 12. 若该线程尚未创建锁，则返回 03. 若命名的锁不存在，则返回 NULL4. 若该锁从未被 GET_LOCK() 的调用获取，或锁已经被提前解开，则该锁不存在 SELECT RELEASE_LOCK(‘lock1’); IS_FREE_LOCK(str) 检查名为 str 的锁是否可以使用1. 若锁可以使用，则返回 12. 若锁正在被使用，则返回 03. 若出现错误，则返回 NULL SELECT IS_FREE_LOCK(‘lock1’); IS_USED_LOCK(str) 检查名为 str 的锁是否正在被使用，若被封锁，则返回使用该锁的客户端的连接标识符，否则返回 NULL SELECT IS_USED_LOCK(‘lock1’); BENCHMARK(count, expr) 用于重复 count 次执行表达式 expr1. 可以用于计算 MySQL 处理表达式的速度2. 可以在 MySQL 客户端内部报告语句执行的时间 SELECT PASSWORD(‘newpwd’);SELECT BENCHMARK( 500000, PASSWORD(‘newpwd’) ); CONVERT(… USING …) 用于改变字符串的默认字符集默认是utf8字符集 SELECT CHARSET(‘abc’);SELECT CHARSET(CONVERT(‘abc’ USING latin1)); CONVERT(x, type) 将一个数据类型的值转换为另一个数据类型的值 SELECT CONVERT(100, CHAR(2)); ¶4、运算符 ¶（1）算术运算符 运算符 作用 示例 + 加法 select 1+2; - 减法 select 1-2; * 乘法 select 2*5; /或DIV 除法 select 9/3; 或 select 9 DIV 3; %或MOD 取余 select 9%2; 或 select 9 MOD 2; ¶（2）比较运算符 SELECT 语句中的条件语句经常要使用比较运算符。 通过这些比较运算符，可以判断表中的哪些记录是符合条件的。比较结果为真，则返回 1，为假则返回 0，比较结果不确定则返回 NULL。 符号 描述 备注 = 等于 &lt;&gt;, != 不等于 &gt; 大于 &lt; 小于 &lt;= 小于等于 &gt;= 大于等于 BETWEEN 在两值之间 &gt;=min&amp;&amp;&lt;=max NOT BETWEEN 不在两值之间 IN 在集合中 NOT IN 不在集合中 &lt;=&gt; 严格比较两个NULL值是否相等 两个操作码均为NULL时，其所得值为1；而当一个操作码为NULL时，其所得值为0 LIKE 模糊匹配 REGEXP 或 RLIKE 正则式匹配 IS NULL 为空 IS NOT NULL 不为空 ¶1）等于 1234567891011121314mysql&gt; select 2&#x3D;3;+-----+| 2&#x3D;3 |+-----+| 0 |+-----+mysql&gt; select NULL &#x3D; NULL;+-------------+| NULL &#x3D; NULL |+-------------+| NULL |+-------------+ ¶2）不等于 123456mysql&gt; select 2&lt;&gt;3;+------+| 2&lt;&gt;3 |+------+| 1 |+------+ ¶3）安全等于 与 = 的区别在于当两个操作码均为 NULL 时，其所得值为 1 而不为 NULL，而当一个操作码为 NULL 时，其所得值为 0而不为 NULL。 12345678910111213141516171819202122mysql&gt; select 2&lt;&#x3D;&gt;3;+-------+| 2&lt;&#x3D;&gt;3 |+-------+| 0 |+-------+mysql&gt; select null&#x3D;null;+-----------+| null&#x3D;null |+-----------+| NULL |+-----------+ mysql&gt; select null&lt;&#x3D;&gt;null;+-------------+| null&lt;&#x3D;&gt;null |+-------------+| 1 |+-------------+ ¶4）小于 123456mysql&gt; select 2&lt;3;+-----+| 2&lt;3 |+-----+| 1 |+-----+ ¶5）小于等于 123456mysql&gt; select 2&lt;&#x3D;3;+------+| 2&lt;&#x3D;3 |+------+| 1 |+------+ ¶6）大于 123456mysql&gt; select 2&gt;3;+-----+| 2&gt;3 |+-----+| 0 |+-----+ ¶7）大于等于 123456mysql&gt; select 2&gt;&#x3D;3;+------+| 2&gt;&#x3D;3 |+------+| 0 |+------+ ¶8）BETWEEN 123456mysql&gt; select 5 between 1 and 10;+--------------------+| 5 between 1 and 10 |+--------------------+| 1 |+--------------------+ ¶9）IN 123456mysql&gt; select 5 in (1,2,3,4,5);+------------------+| 5 in (1,2,3,4,5) |+------------------+| 1 |+------------------+ ¶10）NOT IN 123456mysql&gt; select 5 not in (1,2,3,4,5);+----------------------+| 5 not in (1,2,3,4,5) |+----------------------+| 0 |+----------------------+ ¶11）IS NULL 12345678910111213mysql&gt; select null is NULL;+--------------+| null is NULL |+--------------+| 1 |+--------------+mysql&gt; select &#39;a&#39; is NULL;+-------------+| &#39;a&#39; is NULL |+-------------+| 0 |+-------------+ ¶12）IS NOT NULL 1234567891011121314mysql&gt; select null IS NOT NULL;+------------------+| null IS NOT NULL |+------------------+| 0 |+------------------+ mysql&gt; select &#39;a&#39; IS NOT NULL;+-----------------+| &#39;a&#39; IS NOT NULL |+-----------------+| 1 |+-----------------+ ¶13、LIKE 12345678910111213mysql&gt; select &#39;12345&#39; like &#39;12%&#39;;+--------------------+| &#39;12345&#39; like &#39;12%&#39; |+--------------------+| 1 |+--------------------+mysql&gt; select &#39;12345&#39; like &#39;12_&#39;;+--------------------+| &#39;12345&#39; like &#39;12_&#39; |+--------------------+| 0 |+--------------------+ ¶14、REGEXP 12345678910111213mysql&gt; select &#39;beijing&#39; REGEXP &#39;jing&#39;;+-------------------------+| &#39;beijing&#39; REGEXP &#39;jing&#39; |+-------------------------+| 1 |+-------------------------+mysql&gt; select &#39;beijing&#39; REGEXP &#39;xi&#39;;+-----------------------+| &#39;beijing&#39; REGEXP &#39;xi&#39; |+-----------------------+| 0 |+-----------------------+ ¶（3）逻辑运算符 逻辑运算符用来判断表达式的真假。如果表达式是真，结果返回 1。如果表达式是假，结果返回 0。 运算符号 作用 NOT 或 ! 逻辑非 AND 逻辑与 OR 逻辑或 XOR 逻辑异或 ¶1）与 1234567891011121314mysql&gt; select 2 and 0;+---------+| 2 and 0 |+---------+| 0 |+---------+ mysql&gt; select 2 and 1; +---------+ | 2 and 1 | +---------+ | 1 | +---------+ ¶2）或 123456789101112131415161718192021222324252627mysql&gt; select 2 or 0;+--------+| 2 or 0 |+--------+| 1 |+--------+mysql&gt; select 2 or 1;+--------+| 2 or 1 |+--------+| 1 |+--------+mysql&gt; select 0 or 0;+--------+| 0 or 0 |+--------+| 0 |+--------+mysql&gt; select 1 || 0;+--------+| 1 || 0 |+--------+| 1 |+--------+ ¶3）非 12345678910111213mysql&gt; select not 1;+-------+| not 1 |+-------+| 0 |+-------+mysql&gt; select !0;+----+| !0 |+----+| 1 |+----+ ¶4）异或 当任意一个操作数为NULL时,返回值为NULL，对于非NULL的操作数,如果两个的逻辑真假值相异，则返回结果为1，否则为0。 12345678910111213141516171819202122232425262728293031323334mysql&gt; select 1 xor 1;+---------+| 1 xor 1 |+---------+| 0 |+---------+mysql&gt; select 0 xor 0;+---------+| 0 xor 0 |+---------+| 0 |+---------+mysql&gt; select 1 xor 0;+---------+| 1 xor 0 |+---------+| 1 |+---------+mysql&gt; select null or 1;+-----------+| null or 1 |+-----------+| 1 |+-----------+mysql&gt; select 1 ^ 0;+-------+| 1 ^ 0 |+-------+| 1 |+-------+ ¶（4）位运算符 位运算符是在二进制数上进行计算的运算符。位运算会先将操作数变成二进制数，进行位运算。然后再将计算结果从二进制数变回十进制数。 运算符号 作用 &amp; 按位与 | 按位或 ^ 按位异或 ! 取反 &lt;&lt; 左移 &gt;&gt; 右移 ¶1）按位与 对应的二进制位都为 1 ，则该位的运算结果为 1 ，否则为 0。 123456mysql&gt; select 3&amp;5;+-----+| 3&amp;5 |+-----+| 1 |+-----+ ¶2）按位或 对应的二进制位有一个或两个为 1 ，则该位的运算结果为 1 ，否则为 0。 12345678mysql&gt; SELECT 10 | 15 , 9 | 4 | 2 ;+---------+-----------+| 10 | 15 | 9 | 4 | 2 | # 10的二进制为1010,15的二进制为1111，按位或运算之后结果为1111，即15+---------+-----------+ # 9的二进制为1001,4为0100,2的二进制为0010，按位或运算之后1111| 15 | 15 |+---------+-----------+ ¶3）按位异或 对应的二进制位不相同时，结果为 1，否则为 0。 123456mysql&gt; select 3^5;+-----+| 3^5 |+-----+| 6 |+-----+ ¶4）按位取反 将对应的二进制数逐位反转，即 1 取反后变 0 ，0 取反后变 1。 123456mysql&gt; select ~18446744073709551612;+-----------------------+| ~18446744073709551612 |+-----------------------+| 3 |+-----------------------+ ¶5）按位右移 使指定的二进制位都右移指定的位数，右移指定位之后，右边低位的数值将被移出 并丢弃，左边高位空出的职位用 0 补齐。 123456mysql&gt; select 3&gt;&gt;1;+------+| 3&gt;&gt;1 |+------+| 1 |+------+ ¶6）按位左移 使指定的二进制位都左移指定的位数，左移指定位之后，左边高位的数值将被移出 并丢弃，右边低位空出的位置用 0 补齐。 123456mysql&gt; select 3&lt;&lt;1;+------+| 3&lt;&lt;1 |+------+| 6 |+------+ ¶（5）运算符优先级 最低优先级为： :=。 最高优先级为： !、BINARY、 COLLATE。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/tags/MySQL/"}]},{"title":"XtraBacup备份与恢复","slug":"XtraBacup备份与恢复","date":"2020-07-10T16:00:00.000Z","updated":"2020-07-11T11:38:11.008Z","comments":true,"path":"XtraBacup备份与恢复.html","link":"","permalink":"https://pdxblog.top/XtraBacup%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D.html","excerpt":"","text":"¶XtraBacup备份与恢复 ¶一、XtraBacup简介 MySQL冷备、mysqldump、MySQL热拷贝都无法实现对数据库进行增量备份。在实际生产环境中增量备份是非常实用的，如果数据大于50G或100G，存储空间足够的情况下，可以每天进行完整备份，如果每天产生的数据量较大，需要定制数据备份策略。例如每周实用完整备份，周一到周六实用增量备份。而Percona-Xtrabackup就是为了实现增量备份而出现的一款主流备份工具，XtraBacup有2个工具，分别是xtrabakup、innobakupe。 Percona-xtrabackup是 Percona公司开发的一个用于MySQL数据库物理热备的备份工具，支持MySQL、Percona server和MariaDB，开源免费，是目前较为受欢迎的主流备份工具。xtrabackup只能备份innoDB和xtraDB两种数据引擎的表，而不能备份MyISAM数据表。 ¶二、XtraBacup优点 1234567（1）备份速度快，物理备份可靠（2）备份过程不会打断正在执行的事务（无需锁表）（3）能够基于压缩等功能节约磁盘空间和流量（4）自动备份校验（5）还原速度快（6）可以流传将备份传输到另外一台机器上（7）在不增加服务器负载的情况备份数据 ¶三、Xtrabackup备份原理 ¶1、Xtrabackup备份流程图 12345678（1）innobackupex启动后，会先fork一个进程，用于启动xtrabackup，然后等待xtrabackup备份ibd数据文件；（2）xtrabackup在备份innoDB数据是，有2种线程：redo拷贝线程和ibd数据拷贝线程。xtrabackup进程开始执行后，会启动一个redo拷贝的线程，用于从最新的checkpoint点开始顺序拷贝redo.log；再启动ibd数据拷贝线程，进行拷贝ibd数据。这里是先启动redo拷贝线程的。在此阶段，innobackupex进行处于等待状态（等待文件被创建）（3）xtrabackup拷贝完成ibd数据文件后，会通知innobackupex（通过创建文件），同时xtrabackup进入等待状态（redo线程依旧在拷贝redo.log）（4）innobackupex收到xtrabackup通知后哦，执行FLUSH TABLES WITH READ LOCK（FTWRL），取得一致性位点，然后开始备份非InnoDB文件（如frm、MYD、MYI、CSV、opt、par等格式的文件），在拷贝非InnoDB文件的过程当中，数据库处于全局只读状态。（5）当innobackup拷贝完所有的非InnoDB文件后，会通知xtrabackup，通知完成后，进入等待状态；（6）xtrabackup收到innobackupex备份完成的通知后，会停止redo拷贝线程，然后通知innobackupex，redo.log文件拷贝完成；（7）innobackupex收到redo.log备份完成后，就进行解锁操作，执行：UNLOCK TABLES；（8）最后innbackupex和xtrabackup进程各自释放资源，写备份元数据信息等，innobackupex等xtrabackup子进程结束后退出。 ¶2、XtraBackup的备份原理 在InnoDB内部会维护一个redo日志文件，我们也可以叫做事务日志文件（transaction log，事务日志）。事务日志会存储每一个InnoDB表数据的记录修改。当InnoDB启动时，InnoDB会检查数据文件和事务日志，并执行两个步骤：它应用已经提交的事务日志到数据文件，并将修改过但没有提交的数据进行回滚操作。 XtraBacup在启动时会记住log sequence number（LSN），并且复制所有的数据文件。复制过程需要一些时间，所以这期间如果数据文件有改动，那么将会使数据库处于一个不同的时间点。这时，XtraBacup会运行一个后台进程，用于监视事务日志，并从事务日志复制最新的修改。XtraBacup必须持续的做这个操作，是因为事务日志是会轮转重复的写入，并且事务日志可以被重用。所以XtraBacup自启动开始，就不停的将事务日志中每个数据文件的修改都记录下来。这就是XtraBacup的备份过程。 ¶3、XtraBackup命令行工具 XtraBackup中主要包含两个命令行工具： 12（1）xtrabackup：专用于备份InnoDB和XtraDB引擎的数据，不能备份其他类型的表，也不能备份数据表结构；（2）innobackupex：这是一个perl脚本，在执行过程中会调用xtrabackup命令，这样用该命令既可以实现备份InnoDB，也可以备份MyISAM引擎的对象。 常用选项: 1234567891011121314--host 指定主机--user 指定用户名--password 指定密码--port 指定端口--databases 指定数据库--incremental 创建增量备份--incremental-basedir 指定包含完全备份的目录--incremental-dir 指定包含增量备份的目录 --apply-log 对备份进行预处理操作 一般情况下，在备份完成后，数据尚且不能用于恢复操作，因为备份的数据中可能会包含尚未提交的事务或已经提交但尚未同步至数据文件中的事务。因此，此时数据文件仍处理不一致状态。“准备”的主要作用正是通过回滚未提交的事务及同步已经提交的事务至数据文件也使得数据文件处于一致性状态。--redo-only 不回滚未提交事务--copy-back 恢复备份目录 使用innobackupex备份时，其会调用xtrabackup备份所有的InnoDB表，复制所有关于表结构定义的相关文件(.frm)、以及MyISAM、MERGE、CSV和ARCHIVE表的相关文件，同时还会备份触发器和数据库配置信息相关的文件，这些文件会被保存到一个以时间命名的目录当中。在备份的同时，innobackupex还会在备份目录中创建如下文件： 1234567(1)xtrabackup_checkpoints -- 备份类型(如完全或增量)、备份状态(如是否已经为prepared状态)和LSN(日志序列号)范围信息：每个InnoDB页(通常为16k大小)都会包含一个日志序列号，即LSN，LSN是整个数据库系统的系统版本号，每个页面相关的LSN能够表明此页面最近是如何发生改变的。(2)xtrabackup_binlog_info -- mysql服务器当前正在使用的二进制日志文件及备份这一刻位置二进制日志时间的位置。(3)xtrabackup_binlog_pos_innodb -- 二进制日志文件及用于InnoDB或XtraDB表的二进制日志文件的当前position。(4)xtrabackup_binary -- 备份中用到的xtrabackup的可执行文件；(5)backup-my.cnf -- 备份命令用到的配置选项信息：在使用innobackupex进行备份时，还可以使用--no-timestamp选项来阻止命令自动创建一个以时间命名的目录：如此一来，innobackupex命令将会创建一个BACKUP-DIR目录来存储备份数据。 如果要使用一个最小权限的用户进行备份，则可基于如下命令创建此类用户：如果要使用一个最小权限的用户进行备份，则可基于如下命令创建此类用户： 12345678# 创建用户mysql&gt; CREATE USER &#39;bkpuser&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;123456&#39;;# 回收此用户所有权限mysql&gt; REVOKE ALL PRIVILEGES,GRANT OPTION FROM &#39;bkpuser&#39;;# 授权刷新、锁定表、用户查看服务器状态mysql&gt; GRANT RELOAD,LOCK TABLES,RELICATION CLIENT ON *.* TO &#39;bkpuser&#39;@&#39;localhost&#39;;# 刷新授权表mysql&gt; FLUSH PRIVILEGES; 注意：备份时需启动MySQL,恢复时需关闭MySQL,清空mysql数据目录且不能重新初始化，恢复数据后应该立即进行一次完全备份。 ¶四、XtraBackup安装 下载地址： 1https://www.percona.com/downloads/Percona-XtraBackup-2.4/LATEST/ 可以选择rpm包方式安装，也可以下载源码包编译安装，这里直接采用rpm包的方式进行安装。 123[root@192 ~]# yum install -y percona-xtrabackup-24-2.4.9-1.el7.x86_64.rpm[root@192 ~]# rpm -qa |grep xtrabackuppercona-xtrabackup-24-2.4.9-1.el7.x86_64 ¶五、XtraBackup完全备份与恢复 命令行语法格式： 123456备份：innobackupex --user=DBUSER --password=DBUSERPASS --defaults-file=/etc/my.cnf /path/to/BACKUP-DIR/恢复：innobackupex --apply-log /backups/2018-07-30_11-04-55/innobackupex --copy-back --defaults-file=/etc/my.cnf /backups/2018-07-30_11-04-55/ ¶1、准备(prepare)一个完全备份 一般情况下，在备份完成后，数据尚且不能用于恢复操作，因为备份的数据中可能会包含尚未提交的事务或者已经提交但尚未同步至数据文件中的事务。因此，此时数据文件仍处于不一致状态。&quot;准备&quot;的主要作用正是通过回滚未提交的事务及同步已经提交的事务至数据文件也使用得数据文件处于一致性状态。 innobackupex命令的–apply-log选项可用于实现上述功能，如下面的命令： 1234# innobackupex --apply-log &#x2F;path&#x2F;to&#x2F;BACKUP-DIR如果执行正确，其最后输出的几行信息通常如下：120407 09:01:04 innobackupex: completed OK! 在实现&quot;准备&quot;的过程中，innobackupex通常还可以使用–user-memory选项来指定其可以使用的内存的大小，默认为100M。如果有足够的内存空间可用，可以多划分一些内存给prepare的过程，以提高其完成备份的速度。 ¶2、从一个完全备份中恢复数据 注意：恢复不用启动MySQL innobackupex命令的–copy-back选项用于恢复操作，其通过复制所有数据相关的文件至mysql服务器DATADIR目录中来执行恢复过程。innobackupex通过backup-my.cnf来获取DATADIR目录的相关信息。 1# innobackupex --copy-back &#x2F;path&#x2F;to&#x2F;BACKUP-DIR 当数据恢复至DATADIR目录以后，还需要确保所有的数据文件的属主和属组均为正确的用户，如mysql，否则，在启动mysqld之前还需要事先修改数据文件的属主和属组。如： 1# chown -R mysql.mysql &#x2F;mydata&#x2F;data&#x2F; ¶3、实战练习 ¶（1）准备测试环境 测试环境准备 创建一个测试数据库，并创建一张表输入几行数据： 12345678910111213mysql&gt; create database test2;Query OK, 1 row affected (0.00 sec)mysql&gt; use test2;Database changedmysql&gt; create table yy(id int,name varchar(20));Query OK, 0 rows affected (0.08 sec)mysql&gt; insert into yy values(1,&#39;tomcat1&#39;);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into yy values(2,&#39;tomcat2&#39;);Query OK, 1 row affected (0.00 sec) ¶（2）全量备份 123456789101112131415161718[root@192 ~]# innobackupex --user&#x3D;root --password&#x3D;1234 --host&#x3D;127.0.0.1 &#x2F;backups&#x2F;200628 16:31:18 innobackupex: Starting the backup operationIMPORTANT: Please check that the backup run completes successfully. At the end of a successful backup run innobackupex prints &quot;completed OK!&quot;.200628 16:31:18 version_check Connecting to MySQL server with DSN &#39;dbi:mysql:;mysql_read_default_group&#x3D;xtrabackup;host&#x3D;127.0.0.1&#39; as &#39;root&#39; (using password: YES).200628 16:31:18 version_check Connected to MySQL server# 省略部分输出信息200628 16:31:21 [00] Writing &#x2F;backups&#x2F;2020-06-28_16-31-18&#x2F;backup-my.cnf200628 16:31:21 [00] ...done200628 16:31:21 [00] Writing &#x2F;backups&#x2F;2020-06-28_16-31-18&#x2F;xtrabackup_info200628 16:31:21 [00] ...donextrabackup: Transaction log of lsn (2637610) to (2637619) was copied.200628 16:31:21 completed OK! ¶（3）查看完全备份文件 123456789101112131415[root@192 ~]# ll &#x2F;backups&#x2F;总用量 0drwxr-x---. 6 root root 206 6月 28 16:31 2020-06-28_16-31-18[root@192 ~]# ll &#x2F;backups&#x2F;2020-06-28_16-31-18&#x2F;总用量 12336-rw-r-----. 1 root root 424 6月 28 16:31 backup-my.cnf-rw-r-----. 1 root root 425 6月 28 16:31 ib_buffer_pool-rw-r-----. 1 root root 12582912 6月 28 16:31 ibdata1drwxr-x---. 2 root root 4096 6月 28 16:31 mysqldrwxr-x---. 2 root root 8192 6月 28 16:31 performance_schemadrwxr-x---. 2 root root 8192 6月 28 16:31 sysdrwxr-x---. 2 root root 48 6月 28 16:31 test2-rw-r-----. 1 root root 113 6月 28 16:31 xtrabackup_checkpoints-rw-r-----. 1 root root 435 6月 28 16:31 xtrabackup_info-rw-r-----. 1 root root 2560 6月 28 16:31 xtrabackup_logfile ¶（4）模拟完全恢复 ¶1）完全备份 12345678910111213[root@192 ~]# innobackupex --user=root --password=1234 /backups/200628 20:43:32 innobackupex: Starting the backup operationIMPORTANT: Please check that the backup run completes successfully. At the end of a successful backup run innobackupex prints \"completed OK!\".# 省略部分输出信息200628 20:43:34 [00] Writing /backups/2020-06-28_20-43-32/xtrabackup_info200628 20:43:34 [00] ...donextrabackup: Transaction log of lsn (2630081) to (2630090) was copied.200628 20:43:34 completed OK! ¶2）删除数据库目录下的所有文件 1[root@192 ~]# rm -rf /var/lib/mysql/* ¶3）准备恢复 1234567891011121314[root@192 ~]# innobackupex --apply-log --redo-only /backups/2020-06-28_20-43-32200628 20:48:37 innobackupex: Starting the apply-log operationIMPORTANT: Please check that the apply-log run completes successfully. At the end of a successful apply-log run innobackupex prints \"completed OK!\".# 省略部分输出信息xtrabackup: starting shutdown with innodb_fast_shutdown = 1InnoDB: Starting shutdown...InnoDB: Shutdown completed; log sequence number 2630099InnoDB: Number of pools: 1200628 20:48:39 completed OK! ¶4）完全恢复 1234567891011121314[root@192 ~]# innobackupex --user=root --password=1234 --copy-back /backups/2020-06-28_20-43-32200628 20:52:55 innobackupex: Starting the copy-back operationIMPORTANT: Please check that the copy-back run completes successfully. At the end of a successful copy-back run innobackupex prints \"completed OK!\".# 省略部分输出信息200628 20:52:56 [01] Copying ./ib_buffer_pool to /var/lib/mysql/ib_buffer_pool200628 20:52:56 [01] ...done200628 20:52:56 [01] Copying ./xtrabackup_info to /var/lib/mysql/xtrabackup_info200628 20:52:56 [01] ...done200628 20:52:56 completed OK! ¶5）更改mysql目录属性 1[root@192 ~]# chown -R mysql.mysql /var/lib/mysql/ ¶6）启动mysql 123456789101112131415161718[root@192 ~]# mysql -uroot -p -e \"show databases;\"Enter password: ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)# 如果发生以上错误，查看mysql进程的pid，结束mysql，再启动mysql即可。[root@192 ~]# ps -aux | grep mysqlmysql 77011 0.1 9.0 1319504 169428 ? Sl 19:28 0:07 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pidroot 77053 0.0 0.0 135604 1820 pts/3 S+ 19:30 0:00 mysql -uroot -proot 77193 0.0 0.1 135604 1880 pts/2 S+ 19:37 0:00 mysql -uroot -proot 80486 0.0 0.0 112724 988 pts/4 S+ 20:56 0:00 grep --color=auto mysql[root@192 ~]# kill -9 77011[root@192 ~]# systemctl start mysqld[root@192 ~]# ps -aux | grep mysqlroot 77053 0.0 0.0 135604 1820 pts/3 S+ 19:30 0:00 mysql -uroot -proot 77193 0.0 0.1 135604 1880 pts/2 S+ 19:37 0:00 mysql -uroot -pmysql 80514 30.8 9.0 1122096 168328 ? Sl 20:57 0:01 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pidroot 80558 0.0 0.0 112724 988 pts/4 S+ 20:57 0:00 grep --color=auto mysql ¶7）查看数据是否恢复 12345678910[root@192 ~]# mysql -uroot -p -e \"show databases;\"Enter password: +--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+ ¶六、XtraBacup增量备份与恢复 ¶1、XtraBacup的增量备份原理 使用innobackupex进行增量备份，每个InnoDB的页面都会包含一个LSN信息，每当相关的数据发生改变，相关的页面的LSN就会自动增长。这正是InnoDB表可以进行增量备份的基础，即innobackupex通过备份上次完全备份之后发生改变的页面来实现。 在进行增量备份时，首先要进行一次全量备份，第一次增量备份是基于全备的，之后的增量备份都是基于上一次的增量备份的，以此类推。 要实现第一次增量备份，可以使用下面的命令进行： 123456789101112基于全量备份的增量备份与恢复做一次增量备份（基于当前最新的全量备份）innobackupex --user=root --password=root --defaults-file=/etc/my.cnf --incremental /backups/ --incremental-basedir=/backups/2018-07-30_11-01-371. 准备基于全量innobackupex --user=root --password=root --defaults-file=/etc/my.cnf --apply-log --redo-only /backups/2018-07-30_11-01-372. 准备基于增量innobackupex --user=root --password=root --defaults-file=/etc/my.cnf --apply-log --redo-only /backups/2018-07-30_11-01-37 --incremental-dir=/backups/2018-07-30_13-51-47/3. 恢复innobackupex --copy-back --defaults-file=/etc/my.cnf /opt/2017-01-05_11-04-55/解释：1. 2018-07-30_11-01-37指的是完全备份所在的目录。2. 2018-07-30_13-51-47指定是第一次基于2018-07-30_11-01-37增量备份的目录，其他类似以此类推，即如果有多次增量备份。每一次都要执行如上操作。 需要注意的是，增量备份仅能应用于InnoDB或XtraDB表，对于MyISAM表而言，执行增量备份时其实进行的是完全备份。 “准备”(prepare)增量备份与整理完全备份有着一些不同，尤其要注意的是： 12（1）需要在每个备份 (包括完全和各个增量备份)上，将已经提交的事务进行\"重放\"。\"重放\"之后，所有的备份数据将合并到完全备份上。（2）基于所有的备份将未提交的事务进行\"回滚\" ¶2、实战练习 ¶（1）完全备份 12345[root@192 ~]# innobackupex --user=root --password=1234 --host=127.0.0.1 /backups/[root@192 ~]# ll /backups/总用量 0drwxr-x---. 8 root root 262 6月 28 18:17 2020-06-28_18-17-57 ¶（2）增量备份 ¶1）准备测试环境 12345678910111213141516171819202122mysql&gt; use student;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; create table grade(id int);Query OK, 0 rows affected (0.01 sec)mysql&gt; insert into grade values(1),(2),(3);Query OK, 3 rows affected (0.00 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; select * from grade;+------+| id |+------+| 1 || 2 || 3 |+------+3 rows in set (0.00 sec) ¶2）增量备份 123456[root@192 ~]# innobackupex --user=root --password=1234 --host=127.0.0.1 --incremental /backups/ --incremental-basedir=/backups/2020-06-28_18-17-57[root@192 ~]# ll /backups/总用量 4drwxr-x---. 8 root root 262 6月 28 18:17 2020-06-28_18-17-57drwxr-x---. 8 root root 4096 6月 28 18:18 2020-06-28_18-18-38 ¶（3）查看备份数据 1234567891011121314151617# 查看全量备份的xtrabackup_checkpoints[root@192 ~]# cat /backups/2020-06-28_18-17-57/xtrabackup_checkpoints backup_type = full-backuped #备份类型为全量备份from_lsn = 0 #lsn从0开始to_lsn = 2644619 #lsn到2644619结束last_lsn = 2644628compact = 0recover_binlog_info = 0# 查看增量备份的xtrabackup_checkpoints[root@192 ~]# cat /backups/2020-06-28_18-18-38/xtrabackup_checkpoints backup_type = incremental #备份类型为增量备份from_lsn = 2644619 #lsn从2644619开始to_lsn = 2644628 #lsn到2644628结束last_lsn = 2644628compact = 0recover_binlog_info = 0 ¶（4）数据恢复 ¶1）模拟mysql故障，删除数据目录所有数据 12[root@192 ~]# systemctl stop mysqld[root@192 ~]# rm -rf /var/lib/mysql/* ¶2）合并全备数据目录，确保数据的一致性 123456789[root@192 ~]# innobackupex --apply-log --redo-only /backups/2020-06-28_18-17-57# 省略部分输出信息xtrabackup: starting shutdown with innodb_fast_shutdown = 1InnoDB: Starting shutdown...InnoDB: Shutdown completed; log sequence number 2644637InnoDB: Number of pools: 1200628 20:08:23 completed OK! ¶3）将增量备份数据合并到全备数据目录当中 1234567891011[root@192 ~]# innobackupex --apply-log --redo-only /backups/2020-06-28_18-17-57 --incremental-dir=/backups/2020-06-28_18-18-38# 省略部分输出信息200628 20:10:14 [01] Copying /backups/2020-06-28_18-18-38/2020-06-28_17-43-27/db.opt to ./2020-06-28_17-43-27/db.opt200628 20:10:14 [01] ...done200628 20:10:14 [01] Copying /backups/2020-06-28_18-18-38/2020-06-28_17-44-04/db.opt to ./2020-06-28_17-44-04/db.opt200628 20:10:14 [01] ...done200628 20:10:14 [00] Copying /backups/2020-06-28_18-18-38//xtrabackup_info to ./xtrabackup_info200628 20:10:14 [00] ...done200628 20:10:14 completed OK! ¶4）查看数据备份类型 1234567[root@192 ~]# cat /backups/2020-06-28_18-17-57/xtrabackup_checkpoints backup_type = log-applied #查看到数据备份类型是增加from_lsn = 0 #lsn从0开始to_lsn = 2644619 #lsn结束号为最新的lsnlast_lsn = 2644628compact = 0recover_binlog_info = 0 ¶5）恢复数据 123456789[root@192 ~]# innobackupex --copy-back /backups/2020-06-28_18-17-57# 省略部分输出信息200628 20:14:39 [01] Copying ./ib_buffer_pool to /var/lib/mysql/ib_buffer_pool200628 20:14:39 [01] ...done200628 20:14:39 [01] Copying ./xtrabackup_info to /var/lib/mysql/xtrabackup_info200628 20:14:39 [01] ...done200628 20:14:39 completed OK! ¶6）查看数据库目录 1234567891011[root@192 ~]# ll /var/lib/mysql总用量 12324drwxr-x---. 2 root root 20 6月 28 20:14 2020-06-28_17-43-27drwxr-x---. 2 root root 20 6月 28 20:14 2020-06-28_17-44-04-rw-r-----. 1 root root 425 6月 28 20:14 ib_buffer_pool-rw-r-----. 1 root root 12582912 6月 28 20:14 ibdata1drwxr-x---. 2 root root 4096 6月 28 20:14 mysqldrwxr-x---. 2 root root 8192 6月 28 20:14 performance_schemadrwxr-x---. 2 root root 84 6月 28 20:14 studentdrwxr-x---. 2 root root 8192 6月 28 20:14 sys-rw-r-----. 1 root root 507 6月 28 20:14 xtrabackup_info ¶7）更改数据的属主属组 123456789101112[root@192 ~]# chown -R mysql.mysql /var/lib/mysql/[root@192 ~]# ll /var/lib/mysql总用量 12324drwxr-x---. 2 mysql mysql 20 6月 28 20:14 2020-06-28_17-43-27drwxr-x---. 2 mysql mysql 20 6月 28 20:14 2020-06-28_17-44-04-rw-r-----. 1 mysql mysql 425 6月 28 20:14 ib_buffer_pool-rw-r-----. 1 mysql mysql 12582912 6月 28 20:14 ibdata1drwxr-x---. 2 mysql mysql 4096 6月 28 20:14 mysqldrwxr-x---. 2 mysql mysql 8192 6月 28 20:14 performance_schemadrwxr-x---. 2 mysql mysql 84 6月 28 20:14 studentdrwxr-x---. 2 mysql mysql 8192 6月 28 20:14 sys-rw-r-----. 1 mysql mysql 507 6月 28 20:14 xtrabackup_info ¶8）启动mysql 1234[root@192 ~]# systemctl start mysqld[root@192 ~]# ps -aux | grep mysqldmysql 83275 4.0 9.0 1122096 168576 ? Sl 20:18 0:02 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pidroot 83320 0.0 0.0 112724 988 pts/1 S+ 20:19 0:00 grep --color=auto mysqld ¶9）查看数据是否恢复 1234567891011[root@192 ~]# mysql -uroot -p -e \"show databases;\"Enter password: +------------------------------+| Database |+------------------------------+| information_schema || mysql || performance_schema || student || sys |+------------------------------+ ¶10）总结 1234（1）增量备份需要使用参数--incremental指定需要备份到哪个目录，使用incremental-dir指定全备目录；（2）进行数据备份时，需要使用参数--apply-log redo-only先合并全备数据目录数据，确保全备数据目录数据的一致性；（3）再将增量备份数据使用参数--incremental-dir合并到全备数据当中；（4）最后通过最后的全备数据进行恢复数据，注意，如果有多个增量备份，需要逐一合并到全备数据当中，再进行恢复。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/tags/MySQL/"}]},{"title":"MySQL安装","slug":"mysql安装","date":"2020-07-10T16:00:00.000Z","updated":"2020-07-11T11:38:11.008Z","comments":true,"path":"mysql安装.html","link":"","permalink":"https://pdxblog.top/mysql%E5%AE%89%E8%A3%85.html","excerpt":"","text":"¶MySQL安装 ¶一、yum方式安装MySQL 5.7 CentOS 7之后的版本yum的默认源中使用MariaDB替代原先MySQL，因此安装方式较为以往有一些改变： ¶1、下载mysql的源 1wget http://dev.mysql.com/get/mysql57-community-release-el7-7.noarch.rpm ¶2、安装yum库 1yum localinstall -y mysql57-community-release-el7-7.noarch.rpm ¶3、安装MySQL 1yum install -y mysql-community-server ¶4、启动MySQL服务 12systemctl start mysqldsystemctl status mysqld ¶5、进入mysql并修改默认密码 ¶（1）获取初始化密码 此时MySQL已经开始正常运行，不过MySQL5.7加强了root用户的安全性，因此在第一次安装后会初始化一个随机密码，如果要想进入MySQL还得先找出root用户的密码，通过如下命令可以在日志文件中找出密码： 12[root@localhost ~]# grep \"password\" /var/log/mysqld.log2020-07-02T06:53:24.714760Z 1 [Note] A temporary password is generated for root@localhost: rfH2e?6igi%T ¶（2）登录mysql 1[root@localhost ~]# mysql -uroot -p ¶（3）修改原始密码 输入初始密码，此时不能做任何事情，因为MySQL默认必须修改密码之后才能操作数据库： 12mysql&gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;123456&#39;;ERROR 1819 (HY000): Your password does not satisfy the current policy requirements 这里有个问题，新密码设置的时候如果设置的过于简单会报错，原因是因为MySQL有密码设置的规范，具体是与validate_password_policy的值有关。 MySQL完整的初始密码规则可以通过如下命令查看： 12345678910111213mysql&gt; SHOW VARIABLES LIKE &#39;validate_password%&#39;;+--------------------------------------+-------+| Variable_name | Value |+--------------------------------------+-------+| validate_password_check_user_name | ON || validate_password_dictionary_file | || validate_password_length | 8 || validate_password_mixed_case_count | 1 || validate_password_number_count | 1 || validate_password_policy | LOW || validate_password_special_char_count | 1 |+--------------------------------------+-------+7 rows in set (0.00 sec) 密码的长度是由validate_password_length决定的，而validate_password_length的计算公式是： 1validate_password_length &#x3D; validate_password_number_count + validate_password_special_char_count + (2 * validate_password_mixed_case_count) 通过如下命令修改： 1234set global validate_password_policy&#x3D;0;set global validate_password_length&#x3D;4;ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;123456&#39;; 然后退出后即可用新密码登录。 ¶（4）远程连接授权 1GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;your password&#39; WITH GRANT OPTION; ¶（5）开通端口（默认3306） 1firewall-cmd --add-port=3306/tcp ¶6、禁止yum库自动更新 此时还有一个问题，就是因为安装了Yum Repository，以后每次yum操作都会自动更新，需要把这个卸载掉： 1[root@localhost ~]# yum -y remove mysql57-community-release-el7-7.noarch 此时才算真的完成了。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/tags/MySQL/"}]},{"title":"MySQL自带工具使用介绍","slug":"mysql自带工具使用介绍","date":"2020-07-10T16:00:00.000Z","updated":"2020-07-11T11:38:11.024Z","comments":true,"path":"mysql自带工具使用介绍.html","link":"","permalink":"https://pdxblog.top/mysql%E8%87%AA%E5%B8%A6%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D.html","excerpt":"","text":"¶MySQL自带工具使用介绍 MySQL数据库不仅提供了数据库的服务器端应用程序，同时还提供了大量的客户端工具程序，如mysql， mysqladmin，mysqldump等等 。 ¶1、mysql命令 Mysql命令是用的最多的一个命令工具了，为用户提供一个命令行接口来操作管理MySQL 服务器，可以通过mysql --help来查看其详细使用方法。 选项 作用 说明 -u 指定连接数据库时使用的用户 -p 指定用户的密码 可以-p后面直接写密码，也可以不写，进行交互式输入密码，推荐后者 -h 指定要登录的主机 可选，如果为空，则登录本机 -P 指定要连接的端口 可选，默认是3306 -e 可以通过-e命令直接执行SQL语句，而不用进入数据库 免交互登录数据库执行SQL语句，通常在脚本中使用 -D 指定要登录到哪个库 默认不会登录到库，可以省略此选项，直接写库名 -E 查询到的结果以行来显示 类似于每条SQL语句后面加“\\G” -f 即使出现SQL错误，也强制继续 比如在不登陆数据库执行删除库的操作会有一个交互式的确认操作，可以使用此选项来避免交互式 -X 将查询到的数据导出位xml文件 导出的文件在windows系统中可以使用excel表格打开 -H 将查询到的数据导出位html文件 导出的文件在windows系统中可以使用浏览器打开 –prompt 定制自己的MySQL提示符显示的内容 默认登登录到MySQL后的提示符是“mysql &gt;”，可以使用该选项定制提示符 –tee 将操作数据库所有输入和输出的内容都记录进文件中 在一些较大维护变更的时候，为了方便被查，可以将整个操作过程中的输出信息保存到某个文件中 这里主要介绍一些在运维过程中会用到的相关选项。 ¶（1）-e、-u、-p、-h、-P等选项的使用语法 首先看看“-e, --execute=name”参数，这个参数是告诉mysql，我要执行“-e”后面的某个命令，而不是要通过mysql连接登录到MySQL Server 上面。此参数在我们写一些基本的MySQL 检查和监控的脚本中非常有用，运维mysql时经常在脚本中使用到它。 语法格式： 1mysql -hhostname -Pport -uusername -ppassword -e 相关mysql的sql语句 示例1： 免登录执行sql语句 123456789101112mysql -hlocalhost -P3306 -uroot -p mysql -e &quot;select user,host from user;&quot;Enter password: ****+---------------+-----------+| user | host |+---------------+-----------+| bankMaster | % || bankMaster | 127.0.0.1 || epetadmin | localhost || mysql.session | localhost || mysql.sys | localhost || root | localhost |+---------------+-----------+ 示例2： 通过binlog_cache_use 以及 binlog_cache_disk_use来分析设置的binlog_cache_size是否足够 12345678[root@192 ~]# mysql -uroot -p -e &quot;show status like &#39;binlog_cache%&#39;&quot;Enter password: +-----------------------+-------+| Variable_name | Value |+-----------------------+-------+| Binlog_cache_disk_use | 0 || Binlog_cache_use | 0 |+-----------------------+-------+ 示例3： 通过脚本创建数据库、表及对表进行增、改、删、查操作。 脚本内容如下： 123456789101112131415161718192021222324252627282930313233343536# cat mysql1.sh#!&#x2F;bin&#x2F;bashHOSTNAME&#x3D;&quot;localhost&quot;PORT&#x3D;&quot;3306&quot;USERNAME&#x3D;&quot;root&quot;PASSWORD&#x3D;&quot;1234&quot;DBNAME&#x3D;&quot;test_db&quot;TABLENAME&#x3D;&quot;tb1&quot;#create databasecreate_db_sql&#x3D;&quot;create database if not exists $&#123;DBNAME&#125;&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; -e &quot;$&#123;create_db_sql&#125;&quot;#create tablecreate_table_sql&#x3D;&quot;create table if not exists $&#123;TABLENAME&#125; (name varchar(20),id intdefault 0)&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e &quot;$&#123;create_table_sql&#125;&quot;#insert data to tableinsert_sql&#x3D;&quot;insert into $&#123;TABLENAME&#125; values (&#39;tom&#39;,1)&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e &quot;$&#123;insert_sql&#125;&quot;#select dataselect_sql&#x3D;&quot;select * from $&#123;TABLENAME&#125;&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e &quot;$&#123;select_sql&#125;&quot;#update dataupdate_sql&#x3D;&quot;update $&#123;TABLENAME&#125; set id&#x3D;3&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e &quot;$&#123;update_sql&#125;&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e &quot;$&#123;select_sql&#125;&quot;#delete datadelete_sql&#x3D;&quot;delete from $&#123;TABLENAME&#125;&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e &quot;$&#123;delete_sql&#125;&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e &quot;$&#123;select_sql&#125;&quot; 创建授予test用户可以在指定的源登录 123456789101112[root@192 ~]# mysql -uroot -p -e &quot;grant all on test_db.* to test@&#39;192.168.189.%&#39; identified by &#39;123456&#39;&quot;Enter password: [root@192 ~]# mysql -hlocalhost -P3306 -uroot -p mysql -e &quot;select host,user from user&quot;Enter password: +---------------+---------------+| host | user |+---------------+---------------+| 192.168.189.% | test || localhost | mysql.session || localhost | mysql.sys || localhost | root |+---------------+---------------+ 测试test用户连接mysql服务器 123456789101112131415[root@192 ~]# mysql -utest -p -h192.168.189.129Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 37Server version: 5.7.30 MySQL Community Server (GPL)Copyright (c) 2000, 2020, Oracle and&#x2F;or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement.mysql&gt; ¶（2）-E 如果在连接时候使用了“-E, --vertical”参数，登入之后的所有查询结果都将以纵列显示，效果和我们在一条 query 之后以“\\G”结尾一样。 1234567891011121314151617181920[root@192 ~]# mysql -utest -p -h192.168.189.129 -EEnter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 39Server version: 5.7.30 MySQL Community Server (GPL)Copyright (c) 2000, 2020, Oracle and&#x2F;or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement.mysql&gt; show databases;*************************** 1. row ***************************Database: information_schema*************************** 2. row ***************************Database: test_db2 rows in set (0.00 sec) 123456789101112131415161718192021222324252627282930313233343536373839[root@192 ~]# mysql -utest -p -XEnter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 40Server version: 5.7.30 MySQL Community Server (GPL)Copyright (c) 2000, 2020, Oracle and&#x2F;or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement.mysql&gt; use test_db;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; select * from tb1;&lt;?xml version&#x3D;&quot;1.0&quot;?&gt;&lt;resultset statement&#x3D;&quot;select * from tb1;&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;&gt; &lt;row&gt; &lt;field name&#x3D;&quot;name&quot;&gt;tom&lt;&#x2F;field&gt; &lt;field name&#x3D;&quot;id&quot;&gt;1&lt;&#x2F;field&gt; &lt;&#x2F;row&gt; &lt;row&gt; &lt;field name&#x3D;&quot;name&quot;&gt;tom&lt;&#x2F;field&gt; &lt;field name&#x3D;&quot;id&quot;&gt;2&lt;&#x2F;field&gt; &lt;&#x2F;row&gt; &lt;row&gt; &lt;field name&#x3D;&quot;name&quot;&gt;tom&lt;&#x2F;field&gt; &lt;field name&#x3D;&quot;id&quot;&gt;3&lt;&#x2F;field&gt; &lt;&#x2F;row&gt;&lt;&#x2F;resultset&gt;3 rows in set (0.01 sec) ¶（3）–prompt使用方法 “–prompt=name”参数对于做运维的人来说是一个非常重要的参数选项，其主要功能是定制自己的mysql提示 符的显示内容。 在默认情况下，我们通过mysql登入到数据库之后，mysql的提示符只是一个很简单的内容”mysql&gt;“，没有其他任何附加信息。非常幸运的是mysql通过“–prompt=name”参数给我们提供了自定义提示信息的办法，可以通过配置显示登入的主机地址、登录用户名、当前时间、当前数据库schema，MySQL Server 的一些信息等等。 个人强烈建议将登录主机名、登录用户名和所在的schema 这三项加入提示内容，因为当大家手边管理的MySQL 越来越多，操作越来越频繁的时候，非常容易因为操作的时候没有太在意自己当前所处的环境而造成在错误的环境执行了错误的命令并造成严重后果的情况。如果我们在提示内容中加入了这几项之后，至少可以更方便的提醒自己当前所处环境，以尽量减少犯错误的概率。 个人强烈建议提示符定义： 1&quot;\\\\u@\\\\h : \\\\d \\\\r:\\\\m:\\\\s&gt; &quot; 提示符解释： 1234567\\u 表示用户名\\h 表示主机名，\\d 表示当前数据库（none表示没有在任何库中）\\r小时（12小时制）\\R小时（24小时制）\\m分种\\s秒 显示效果如下： 123456789101112131415161718192021[root@192 ~]# mysql -utest -p --prompt&#x3D;&quot;\\\\u@\\\\h: \\\\d \\\\r:\\\\m:\\\\s&gt; &quot;Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 42Server version: 5.7.30 MySQL Community Server (GPL)Copyright (c) 2000, 2020, Oracle and&#x2F;or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement.test@localhost: (none) 04:52:32&gt; test@localhost: (none) 04:52:55&gt; use test_db;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedtest@localhost: test_db 04:54:38&gt; 上述方式每次连接都要写那些字符进行定制，非常麻烦，可以将其写入配置文件中的clinet字段下，之后再登录就可以省略了。如下所示： 1234567891011121314151617181920[root@192 opt]# vim &#x2F;etc&#x2F;my.cnf[client]prompt&#x3D;&quot;\\\\u@\\\\h: \\\\d \\\\R:\\\\m:\\\\s&gt; &quot;[root@192 opt]# mysql -uroot -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 45Server version: 5.7.30 MySQL Community Server (GPL)Copyright (c) 2000, 2020, Oracle and&#x2F;or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and&#x2F;or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement.root@localhost: (none) 17:07:27&gt; ¶（4）–tee的使用方法 “–tee=name”参数也是对运维人员非常有用的参数选项，用来告诉mysql，将所有输入和输出内容都记录进文 件。在我们一些较大维护变更的时候，为了方便被查，最好是将整个操作过程的所有输入和输出内容都保存下 来。 假如mysql命令行状态下，要进行大量的交互操作，其实可以把这些操作记录在log中进行审计，很简单 mysql -u root -p --tee=/path/xxxx.log 也可以在服务器上的/etc/my.cnf中的[client]加入 tee =/tmp/client_mysql.log即可.。 注：若没有[client]就添加即可，或者在mysql&gt;提示符下执行下面的命令 123456789101112test@localhost: test_db 04:54:38&gt; tee &#x2F;opt&#x2F;tmp.logLogging to file &#39;&#x2F;opt&#x2F;tmp.log&#39;test@localhost: test_db 04:59:27&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || test_db |+--------------------+2 rows in set (0.01 sec)test@localhost: test_db 04:59:54&gt; 查看日志，内容如下： 123456789101112test@localhost: test_db 04:54:38&gt; tee &#x2F;opt&#x2F;tmp.logLogging to file &#39;&#x2F;opt&#x2F;tmp.log&#39;test@localhost: test_db 04:59:27&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || test_db |+--------------------+2 rows in set (0.01 sec)test@localhost: test_db 04:59:54&gt; ¶2、mysqladmin命令 mysqladmin，顾名思义，提供的功能都是与MySQL 管理相关的各种功能。如MySQL Server状态检查，各种统计信息的flush，创建/删除数据库，关闭MySQL Server 等等。mysqladmin所能做的事情，虽然大部分都可以通过mysql连接登录上MySQL Server 之后来完成，但是大部分通过mysqladmin来完成操作会更简单更方便。 mysqladmin后面可以接选项，也可以接命令，这里就不说选项了，主要说一下命令。 ¶（1）ping 监测服务是否正常 1234[root@192 ~]# mysqladmin -utest -p pingEnter password: mysqld is alive[root@192 ~]# ¶（2）status 获取mysql当前状态值 123[root@192 ~]# mysqladmin -utest -p statusEnter password: Uptime: 173569 Threads: 3 Questions: 156 Slow queries: 0 Opens: 128 Flush tables: 1 Open tables: 121 Queries per second avg: 0.000 ¶（3）processlist 获取数据库当前连接信息 1234567[root@192 ~]# mysqladmin -utest -p processlistEnter password: +----+------+-----------+----+---------+------+----------+------------------+| Id | User | Host | db | Command | Time | State | Info |+----+------+-----------+----+---------+------+----------+------------------+| 48 | test | localhost | | Query | 0 | starting | show processlist |+----+------+-----------+----+---------+------+----------+------------------+ ¶（4）获取数据库当前的连接数 12 ¶3、mysqldump 这个工具其功能就是将MySQL Server中的数据以SQL 语句的形式从数据库中dump 成文本文件。mysqldump是做为MySQL 的一种逻辑备份工具。 ¶4、mysqlbinlog mysqlbinlog程序的主要功能就是分析MySQL Server 所产生的二进制日志（也就是binlog）。 通过mysqlbinlog，我们可以解析出binlog中指定时间段或者指定日志起始和结束位置的内容解析成SQL 语句。 ¶5、Mysqlslap性能测试 mysqlslap是mysql自带的基准测试工具,优点:查询数据,语法简单,灵活容易使用.该工具可以模拟多个客户端同时并发的向服务器发出查询更新,给出了性能测试数据而且提供了多种引擎的性能比较.mysqlslap为mysql性能优化前后提供了直观的验证依据,建议系统运维和DBA人员应该掌握一些常见的压力测试工具,才能准确的掌握线上数据库支撑的用户流量上限及其抗压性等问题。 这里解释一下一些常用的选项。 12345678910111213--concurrency代表并发数量，多个可以用逗号隔开。例如：concurrency=50,100,200--engines代表要测试的引擎，可以有多个，用分隔符隔开。 --iterations代表要运行这些测试多少次，即运行多少次后，得到结果。 --auto-generate-sql 代表用系统自己生成的SQL脚本来测试。 --auto-generate-sql-load-type 代表要测试的是读还是写还是两者混合的（read,write,update,mixed）--number-of-queries 代表总共要运行多少次查询。每个客户运行的查询数量可以用查询总数/并发数来计算。比如倒数第二个结果2=200/100。 --debug-info 代表要额外输出CPU以及内存的相关信息（注：只有在MySQL用--with-debug编译时可）。 --number-int-cols 代表测试表中的INTEGER类型的属性有几个。 --number-char-cols代表测试表的char类型字段的数量。 --create-schema 代表自己定义的模式（在MySQL中也就是库即创建测试的数据库）。 --query 代表自己的SQL脚本。 --only-print 如果只想打印看看SQL语句是什么，可以用这个选项。 --csv=name 生产CSV格式数据文件 ¶（1）查看Mysql数据库默认最大连接数 可以看到mysql5.7.13默认是151。注：不同版本默认最大连接数不差别。一般生产环境是不够的。 1234567mysql&gt; show variables like &#39;%max_connections%&#39;;+-----------------+-------+| Variable_name | Value |+-----------------+-------+| max_connections | 151 |+-----------------+-------+1 row in set (0.01 sec) ¶（2）修改MySQL数据库默认最大连接数 ¶方式一： 12345678910mysql&gt; set GLOBAL max_connections &#x3D; 1024;Query OK, 0 rows affected (0.00 sec)mysql&gt; show variables like &#39;%max_connections%&#39;;+-----------------+-------+| Variable_name | Value |+-----------------+-------+| max_connections | 1024 |+-----------------+-------+1 row in set (0.01 sec) ¶方式二： 在my.cnf[mysqld]下添加： 1max_connections&#x3D;1024 重启Mysql，查看修改后的最大连接数。 ¶（3）查看Mysql默认使用的存储引擎 123456789101112131415mysql&gt; show engines;+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+| InnoDB | DEFAULT | Supports transactions, row-level locking, and foreign keys | YES | YES | YES || MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO || BLACKHOLE | YES | &#x2F;dev&#x2F;null storage engine (anything you write to it disappears) | NO | NO | NO || MyISAM | YES | MyISAM storage engine | NO | NO | NO || CSV | YES | CSV storage engine | NO | NO | NO || ARCHIVE | YES | Archive storage engine | NO | NO | NO || PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO || FEDERATED | NO | Federated MySQL storage engine | NULL | NULL | NULL |+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+9 rows in set (0.00 sec) ¶（4）测试 现在我们来看一下具体测试的例子。 ¶1）用自带的SQL脚本来测试 123456789101112131415161718192021222324252627282930313233[root@192 opt]# mysqlslap --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --concurrency&#x3D;100,200 --iterations&#x3D;1 --number-int-cols&#x3D;20 --number-char-cols&#x3D;30 --auto-generate-sql --auto-generate-sql-add-autoincrement --auto-generate-sql-load-type&#x3D;mixed --engine&#x3D;myisam,innodb --number-of-queries&#x3D;2000 -uroot -p1234 --verbosemysqlslap: [Warning] Using a password on the command line interface can be insecure.Benchmark Running for engine myisam Average number of seconds to run all queries: 1.459 seconds Minimum number of seconds to run all queries: 1.459 seconds Maximum number of seconds to run all queries: 1.459 seconds Number of clients running queries: 100 Average number of queries per client: 20Benchmark Running for engine myisam Average number of seconds to run all queries: 1.420 seconds Minimum number of seconds to run all queries: 1.420 seconds Maximum number of seconds to run all queries: 1.420 seconds Number of clients running queries: 200 Average number of queries per client: 10Benchmark Running for engine innodb Average number of seconds to run all queries: 1.352 seconds Minimum number of seconds to run all queries: 1.352 seconds Maximum number of seconds to run all queries: 1.352 seconds Number of clients running queries: 100 Average number of queries per client: 20Benchmark Running for engine innodb Average number of seconds to run all queries: 2.330 seconds Minimum number of seconds to run all queries: 2.330 seconds Maximum number of seconds to run all queries: 2.330 seconds Number of clients running queries: 200 Average number of queries per client: 10 ¶测试说明 1模拟测试两次读写并发，第一次100，第二次200，自动生成SQL脚本，测试表包含20个init字段，30个char字段，每次执行2000查询请求。测试引擎分别是myisam，innodb。 ¶测试结果说明 12Myisam第一次100客户端同时发起增查用1.459/s,第二次200客户端同时发起增查用1.420/sInnodb第一次100客户端同时发起增查用1.352/s,第二次200客户端同时发起增查用2.330/s ¶测试结论 12由此可见MyISAM存储引擎处理性能是最好的，也是最常用的，但不支持事务。InonDB存储引擎提供了事务型数据引擎（ACID），在事务型引擎里使用最多的。具有事务回滚，系统修复等特点。 ¶2）测试结果保存为csv文件 Mysqlslap测试工具生产CSV格式数据文件并转换成图表形式： 1234567[root@192 opt]# mysqlslap --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --concurrency&#x3D;100,200 --iterations&#x3D;1 --number-int-cols&#x3D;20 --number-char-cols&#x3D;30 --auto-generate-sql --auto-generate-sql-add-autoincrement --auto-generate-sql-load-type&#x3D;mixed --engine&#x3D;myisam,innodb --number-of-queries&#x3D;2000 -uroot -p1234 --csv&#x3D;&#x2F;opt&#x2F;mysql.csvmysqlslap: [Warning] Using a password on the command line interface can be insecure.[root@192 opt]# ll总用量 8-rw-r-----. 1 root root 152 6月 18 17:54 mysql.csvdrwxr-xr-x. 2 root root 6 10月 31 2018 rh-rw-r--r--. 1 root root 508 6月 18 17:14 tmp.log 执行结果： 12345[root@192 opt]# cat mysql.csv myisam,mixed,0.952,0.952,0.952,100,20myisam,mixed,0.745,0.745,0.745,200,10innodb,mixed,0.953,0.953,0.953,100,20innodb,mixed,1.945,1.945,1.945,200,10 ¶3）使用自定义sql脚本测试 用我们自己定义的SQL 脚本或语句来测试 首先准备好要测试的数据库表，这里我们编写一个生成表的脚本去完 成脚本内容如下： 12345678910111213141516171819202122232425262728293031[root@192 opt]# vim mysql_test.sh#!&#x2F;bin&#x2F;bashHOSTNAME&#x3D;&quot;localhost&quot;PORT&#x3D;&quot;3306&quot;USERNAME&#x3D;&quot;root&quot;PASSWORD&#x3D;&quot;1234&quot;DBNAME&#x3D;&quot;test1&quot;TABLENAME&#x3D;&quot;tb1&quot;#create databasemysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; -e &quot;drop database if exists $&#123;DBNAME&#125;&quot;create_db_sql&#x3D;&quot;create database if not exists $&#123;DBNAME&#125;&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; -e &quot;$&#123;create_db_sql&#125;&quot;#create tablecreate_table_sql&#x3D;&quot;create table if not exists $&#123;TABLENAME&#125;(stuid int not null primary key,stuname varchar(20) not null,stusex char(1) not null,cardid varchar(20) not null,birthday datetime,entertime datetime,address varchar(100) default null)&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e &quot;$&#123;create_table_sql&#125;&quot;#insert data to tablei&#x3D;1while [ $i -le 2000 ]doinsert_sql&#x3D;&quot;insert into $&#123;TABLENAME&#125; values ($i,&#39;zhangsan&#39;,&#39;1&#39;,&#39;1234567890123456&#39;,&#39;1999-10-10&#39;,&#39;2016-9-3&#39;,&#39;zhongguo beijingshi changpinqu&#39;)&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e &quot;$&#123;insert_sql&#125;&quot;let i++done#select dataselect_sql&#x3D;&quot;select count(*) from $&#123;TABLENAME&#125;&quot;mysql -h $&#123;HOSTNAME&#125; -P $&#123;PORT&#125; -u $&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e &quot;$&#123;select_sql&#125;&quot; 授权脚本x执行权限 1[root@192 opt]# chmod +x mysql_test.sh 执行脚本mysq_test.sh生成mysqlslap工具需要的测试表。 123[root@192 opt]# mysql_test.sh执行mysqlslap工具进行测试[root@192 opt]# mysqlslap --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --concurrency&#x3D;10,20 --iterations&#x3D;1 --create-schema&#x3D;&#39;test1&#39; --query&#x3D;&#39;select * from test1.tb1&#39; --engine&#x3D;myisam,innodb --number-of-queries&#x3D;2000 -uroot -p1234 –verbose 显示结果： 123456789101112131415161718192021222324252627282930313233[root@192 opt]# mysqlslap --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --concurrency&#x3D;10,20 --iterations&#x3D;1 --create-schema&#x3D;&#39;test1&#39; --query&#x3D;&#39;select * from test1.tb1&#39; --engine&#x3D;myisam,innodb --number-of-queries&#x3D;2000 -uroot -p1234 –verbosemysqlslap: [Warning] Using a password on the command line interface can be insecure.Benchmark Running for engine myisam Average number of seconds to run all queries: 3.261 seconds Minimum number of seconds to run all queries: 3.261 seconds Maximum number of seconds to run all queries: 3.261 seconds Number of clients running queries: 10 Average number of queries per client: 200Benchmark Running for engine myisam Average number of seconds to run all queries: 3.010 seconds Minimum number of seconds to run all queries: 3.010 seconds Maximum number of seconds to run all queries: 3.010 seconds Number of clients running queries: 20 Average number of queries per client: 100Benchmark Running for engine innodb Average number of seconds to run all queries: 3.421 seconds Minimum number of seconds to run all queries: 3.421 seconds Maximum number of seconds to run all queries: 3.421 seconds Number of clients running queries: 10 Average number of queries per client: 200Benchmark Running for engine innodb Average number of seconds to run all queries: 3.252 seconds Minimum number of seconds to run all queries: 3.252 seconds Maximum number of seconds to run all queries: 3.252 seconds Number of clients running queries: 20 Average number of queries per client: 100 注：通过mysqlslap工具对mysql server进行压力测试，可以通过–concurrency、–number-of-queries等选项的 值查看每次测试的结果，通过反复测试、优化得出mysql server的最大并发数。 如果mysqlslap工具输出结果为 Segmentation fault (core dumped)基本表示走超出mysql server的负载。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/tags/MySQL/"}]},{"title":"初识MySQL","slug":"初识MySQL","date":"2020-07-10T16:00:00.000Z","updated":"2020-07-11T11:38:11.024Z","comments":true,"path":"初识MySQL.html","link":"","permalink":"https://pdxblog.top/%E5%88%9D%E8%AF%86MySQL.html","excerpt":"","text":"¶初识MySQL ¶一、数据库基础知识 ¶1、什么是数据库 数据库的概念诞⽣生于60年前，随着信息技术和市场的快速发展，数据库技术层出不穷，随着应用的扩展和深入，数据库的数量和规模越来越大，其诞生和发展给计算机信息管理带来了一场巨大的革命。 数据库的发展大致划分为以下几个阶段：⼈⼯管理阶段、文件系统阶段、数据库系统阶段、高级数据库阶段。其种类大概有3种：层次式数据库、网络式数据库和关系式数据库。不同种类的数据库按不同的数据结构来联系和组织。 对于数据库的概念，没有一个完全固定的定义，随着数据库历史的发展，定义的内容也有很大的差异，其中一种比较普遍的观点认为，数据库（DataBase，DB）是一个长期存储在计算机内的、有组织的、有共享的、统一管理的数据集合。它是一个按数据结构来存储和管理数据的计算机软件系统。即数据库包含两层含义：保管数据的“仓库”，以及数据管理的方法和技术。 数据库的特点包括：实现数据共享，减少数据冗余；采用特定的数据类型；具有较⾼的数据独立性；具有统一的数据控制功能。 ¶2、为何需要数据库 存储数据的方法 12345第一种方法：用大脑来记住数据第二种方法：写在纸上第三种方法：写在计算机的内存中第四种方法：写成磁盘文件…… ¶3、数据库能够做什么 1234存储大量数据，方便检索和访问保持数据信息的一致、完整共享和安全通过组合分析，产生新的有用信息 ¶4、数据库和应用程序 应用程序 数据库 作用 响应操作并显示结果、向数据库请求数据 存储数据、检索数据、生成新的数据 要求 美观、操作简单方便 统一、安全、性能等 ¶5、时下流行的数据库 Oracle SqlServer MySQL Oracle公司的产品 针对不同用户群体的多个版本 开放源代码 产品免费、服务收费 易用性好 网站应用广泛 ¶6、数据库的基本概念 在关系数据库中，数据库的表是一系列二维数组的集合，用来存储数据和操作数据的逻辑结构。它是由纵向的列和横向的行组成，行被称为记录，也叫作实体，是组织数据的单位；列被称为字段，每一列表示记录的一个属性，都有相应的描述信息，如数据类型、数据宽度等。 ¶（1）实体 这些客观存在的、可以被描述的事物都是“实体”。 ¶二、MySQL数据库 MySQL是一个开放源代码的数据库管理系统（DBMS），它是由MySQL AB公司开发、发布并支持的。MySQL是一个跨平台的开源关系数据库管理系统，广泛地应用在Internet上的中小型网站公司开发中。 ¶1、MySQL的优势 12345671. 运行速度快。2. 使用成本低：MySQL对多数个人用户来说是免费的。3. 容易使用：与其他大型数据库的设置和管理相比，其复杂程度较低，易于学习。4. 可移植性强：能够工作在众多不同的系统平台上，例如：Windows、Linux、Unix等。5. 支持丰富的接口：提供了用于C、C++、Java、perl、PHP、Ruby、Python等语言的API6. 支持查询语言：MySQL可以利用标准SQL语法和支持ODBC（开放式数据库连接）的应用程序7. 安全性和连续性：十分灵活和安全的权限和密码系统，允许基于主机的验证。连接到服务器器时，所有的密码传输均采用加密形式，从而保证了密码安全。并且由于Mysql是网络化的，因此可以在因特网上的任何地方访问，提高数据共享的效率。 ¶2、MySQL版本 MySQL分为2个不同的版本： 社区版（Community Server） 企业版（Enterprise Server） 免费、开源 收费，不可自由下载 适合普通用户 适合对功能和安全要求高的企业用户 功能和服务更完善它能够以很高的性价比为企业提供数据仓库应⽤，支持ACID事务处理，提供完整的提交、回滚、崩溃恢复和行级锁定功能。 ¶3、MySQL的命名 MySQL的命名机制由3个数字和1个后缀组成，例如mysql-5.5.13. 123第1个数字（5）是主版本号，描述了文件格式，所有版本5的发行版都有相同的文件格式。第2个数字（5）是发行级别，主版本号和发行级别组合在一起便构成了发行序列号第3个数字（13）是在此发行系列的版本号，随每次新发布版本递增，通常选择已经发行的最新版本。 ¶4、MySQL的运行机制 ¶（1）讲解思路 就一个SQL语句，如select * from tablename ，从支持接口进来后，进入连接池后做权限、验证等环节，然后判断是否有缓存，有则直接放回结果，否则进入SQL接口，在查询之前查询优化器进行优化，最后进行解析，查询。并通过存储引擎与文件交互。 然后再介绍MySQL的企业管理服务和工具。 ¶（2）名词解释 支持接口： 不同的编程语言与SQL的交互 连接池： 管理缓冲用户连接，线程处理等需要缓存的需求 SQL接口： 接受用户的SQL命令，并且返回用户需要查询的结果。比如select from就是调用SQL接口 解析器： SQL命令传递到解析器的时候会被解析器验证和解析。解析器是由Lex和YACC实现的，是一个很长的脚本。 123主要功能：1. 将SQL语句分解成数据结构，并将这个结构传递到后续步骤，以后SQL语句的传递和处理就是基于这个结构的；例如将 select * from tablename where 1=1；分解为select、*、from、tablename、where 、1=1，并去解析。2. 如果在分解构成中遇到错误，那么就说明这个SQL语句是不合理的。 查询优化器： SQL语句在查询之前会使用查询优化器对查询进行优化，使用的是“选取-投影-联接”策略进行查询。 1234例： select uid,name from user where gender = 1; a.先根据where 语句进行选取，而不是先将表全部查询出来以后再进行gender过滤 b.先根据uid和name进行属性投影，而不是将属性全部取出以后再进行过滤 将这两个查询条件联接起来生成最终查询结果。 缓存： 如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。 这个缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key缓存，权限缓存等。 存储引擎： 存储引擎是MySql中具体的与文件打交道的子系统。也是Mysql最具有特色的一个地方。 Mysql的存储引擎是插件式的。它根据MySql AB公司提供的文件访问层的一个抽象接口来定制一种文件访问机制（这种访问机制就叫存储引擎）。 现在有很多种存储引擎，各个存储引擎的优势各不一样，最常用的MyISAM、InnoDB、BDB。 MyISAM引擎，它查询速度快，有较好的索引优化和数据压缩技术。但是它不支持事务。 InnoDB支持事务，并且提供行级的锁定，应用也相当广泛。 Mysql也支持自己定制存储引擎，甚至一个库中不同的表使用不同的存储引擎，这些都是允许的。 MySQL5.7默认使用InnoDB存储引擎。 ¶5、MySQL安装与配置 ¶（1）安装步骤（略） ¶（2）基本配置 123端口号：3306默认字符集：utf-8root密码设置 ¶（3）安装目录介绍 1234bin：include：lib：share： ¶（4）命令行连接MySQL ¶1）检查MySQL服务是否启动 方式1：Windows服务 方式2：dos命令 12net start mysql57net stop mysql57 修改了配置文件，必须重启MySQL服务才能生效。 ¶2）连接MySQL 语法格式： 1mysql -h服务器主机地址 -u 用户名 -p 密码 示例： 1mysql -u root -p 方式1：dos命令启动 方式2：MySQL Command Line Client 默认root登录，仅输入密码。 ¶三、MySQL数据库类型 ¶1、系统数据库 安装完MySQL服务器后，MySQL会附带系统数据库，包括： 1234information_schema:主要存储系统中的一些数据库对象信息，如用户表信息、字段信息、权限信息、字符集信息和分区信息等。performance_schema:主要存储数据库服务器性能参数mysql:主要存储系统的用户权限信息test:MySQL数据库管理系统自动创建的测试数据库，任何用户都可以使用 ¶2、用户数据库 用户数据库是用户根据实际需求创建的数据库。本章后面的讲解主要针对用户数据库。 ¶四、数据库基本操作 ¶1、查看数据列表 123456789101112mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sakila || sys || world |+--------------------+6 rows in set (0.36 sec) ¶2、创建数据库 12345678910111213141516mysql&gt; create database test;Query OK, 1 row affected (0.08 sec)mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sakila || sys || test || world |+--------------------+7 rows in set (0.00 sec) ¶3、选择数据库 12mysql&gt; use test;Database changed ¶4、删除数据库 123456789101112131415mysql&gt; drop database test;Query OK, 0 rows affected (0.33 sec)mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sakila || sys || world |+--------------------+6 rows in set (0.00 sec) ¶五、图形化MySQL管理工具 ¶1、Navicat ¶2、PDMan","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/tags/MySQL/"}]},{"title":"Varnish4.0缓存代理配置","slug":"Varnish4.0缓存代理配置","date":"2020-06-30T16:00:00.000Z","updated":"2020-07-01T10:15:32.941Z","comments":true,"path":"Varnish4.0缓存代理配置.html","link":"","permalink":"https://pdxblog.top/Varnish4.0%E7%BC%93%E5%AD%98%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE.html","excerpt":"","text":"¶Varnish4.0缓存代理配置 ¶一、Varnish原理 ¶1、Varnish简介 varnish 缓存是 web 应用加速器，同时也作为 http 反向缓存代理。你可以安装 varnish 在任何http 的前端，同时配置它缓存内容。与传统的 squid 相比，varnish 具有性能更高、速度更快、管理更加方便等诸多优点。有一部分企业已经在生产环境中使用其作为旧版本的 squid的替代方案，以在相同的服务器成本下提供更好的缓存效果，Varnish 更是作为 CDN 缓存服务器的可选服务之一 根据官网的介绍，Varnish 的主要特性如下：https://www.varnish-cache.org/ 缓存位置： 可以使用内存也可以使用磁盘。如果要使用磁盘的话推荐 SSD 做 RAID1 日志存储： 日志也存储在内存中。存储策略：固定大小，循环使用支持虚拟内存的使用 有精确的时间管理机制，即缓存的时间属性控制 状态引擎架构： 在不同的引擎上完成对不同的缓存和代理数据进行处理。可以通过特定的配置语言设计不同的控制语句，以决定数据在不同位置以不同方式缓存，在特定的地方对经过的报文进行特定规则的处理 缓存管理： 以二叉堆格式管理缓存数据，做到数据的及时清理 ¶2、Varnish 与 与 Squid 的对比 相同点： 都是一个反向代理服务器 都是开源软件 ¶Varnish 的优势： 12345678Varnish 的稳定性很高，两者在完成相同负荷的工作时，Squid 服务器发生故障的几率要高于 Varnish，因为使用 Squid 要经常重启Varnish 访问速度更快，因为采用了“Visual Page Cache”技术，所有缓存数据都直接从内存读取，而 squid 是从硬盘读取，因而 Varnish 在访问速度方面会更快Varnish 可以支持更多的并发连接，因为 Varnish 的 TCP 连接释放要比 Squid 快，因而在高并发连接情况下可以支持更多 TCP 连接Varnish 可以通过管理端口，使用正则表达式批量的清除部分缓存，而 Squid 是做不到的；squid 属于是单进程使用单核 CPU，但 Varnish 是通过 fork 形式打开多进程来做处理，所以可以合理的使用所有核来处理相应的请求 ¶Varnish 的劣势： 123varnish 进程一旦 Crash 或者重启，缓存数据都会从内存中完全释放，此时所有请求都会发送到后端服务器，在高并发情况下，会给后端服务器造成很大压力在 varnish 使用中如果单个 url 的请求通过 HA&#x2F;F5 等负载均衡，则每次请求落在不同的varnish 服务器中，造成请求都会被穿透到后端；而且同样的请求在多台服务器上缓存，也会造成 varnish 的缓存的资源浪费，造成性能下降 ¶Varnish 劣势的解决方案 针对劣势一： 在访问量很大的情况下推荐使用 varnish 的内存缓存方式启动，而且后面需要跟多台 squid/nginx 服务器。主要为了防止前面的 varnish 服 务、服务器被重启的情况下，大量请求穿透 varnish，这样 squid/nginx 可以就担当第二层 CACHE，而且也弥补了 varnish 缓存在内存中重启都会释放的问题 针对劣势二： 可以在负载均衡上做 url 哈希，让单个 url 请求固定请求到一台 varnish 服务器上 ¶3、使用 varnish 作为 web 代理缓存的原理 varnish 是一个 http 反向代理的缓存。它从客户端接收请求然后尝试从缓存中获取数据来响应客户端的请求，如果 varnish 不能从缓存中获得数据来响应客户端，它将转发请求到后端（backend servers）,获取响应同时存储，最后交付给客户端 如果 varnish 已经缓存了某个响应，它比你传统的后端服务器的响应要快很多，所以你需要尽可能是更多的请求直接从 varnish 的缓存中获取响应 varnish 决定是缓存内容或者是从后端服务器获取响应。后端服务器能通过 http 响应头中的Cache-Control 来同步 varnish 缓存内容。在某些条件下 varnish 将不缓存内容，最常见的是使用 cookie。当一个被标记有 cookie 的客户端 web 请求，varnish 默认是不缓存。这些众多的varnish 功能特点都是可以通过写 vcl 来改变的 ¶4、 简单架构 Varnish 分为 management 进程和 child 进程 ¶Management 进程： 对子进程进行管理，同时对 VCL 配置进行编译，并应用到不同的状态引擎 ¶Child 进程： 生成线程池，负责对用户请求进行处理，并通过 hash 查找返回用户结果 ¶5、varnish 主要配置部分 varnish 配置主要分为： 后端配置 ACL 配置 probes 配置 directors 配置 核心子程序配置 其中后端配置是必要的，在多台服务器中还会用到 directors 配置，核心子程序配置 ¶后端配置： 即给 varnish 添加反代服务器节点，最少配置一个 ¶ACL 配置： 即给 varnish 添加访问控制列表，可以指定这些列表访问或禁止访问 ¶probes 配置： 即给 varnish 添加探测后端服务器是否正常的规则，方便切换或禁止对应后端服务器 ¶directors 配置： 即给 varnish 添加负载均衡模式管理多个后端服务器 ¶核心子程序配置： 即给 varnish 添加后端服务器切换，请求缓存，访问控制，错误处理等规则 ¶6、VCL 中内置 预设变量： 变量( 也叫 object ） req： The request object，请求到达时可用的变量(客户端发送的请求对象) bereq： The backend request object，向后端主机请求时可用的变量 beresp： The backend response object，从后端主机获取内容时可用的变量(后端响应请求对象) resp： The HTTP response object，对客户端响应时可用的变量(返回给客户端的响应对象) obj： 存储在内存中时对象属性相关的可用的变量(高速缓存对象，缓存后端响应请求内容) 预设变量是系统固定的，请求进入对应的 vcl 子程序后便生成，这些变量可以方便子程序提取，当然也可以自定义一些全局变量 当前时间： ¶now 作用：返回当前时间戳 ¶客户端：（客户端基本信息） 注：原 client.port 已经弃用，如果要取客户端请求端口号使用std.port(client.ip)， importstd;才可以使用 std client.ip：返回客户端 IP 地址 client.identity：用于装载客户端标识码 ¶服务器：（服务器基本信息） 注：原 server.port 已经弃用，如果要取服务器端口号使用std.port(server.ip)，需要 import std;才可以使用 std server.hostname：服务器主机名 server.identity：服务器身份标识 server.ip：返回服务器端 IP 地址 ¶req :（客户端发送的请求对象） 1234567891011121314151617181920212223req：整个 HTTP 请求数据结构req.backend_hint：指定请求后端节点，设置后 bereq.backend 才能获取后端节点配置数据req.can_gzip：客户端是否接受 GZIP 传输编码req.hash_always_miss：是否强制不命中高速缓存，如果设置为 true，则高速缓存不会命中，一直会从后端获取新数据req.hash_ignore_busy：忽略缓存中忙碌的对象，多台缓存时可以避免死锁req.http：对应请求 HTTP 的 headerreq.method：请求类型（如 GET , POST）req.proto：客户端使用的 HTTP 协议版本req.restarts：重新启动次数。默认最大值是 4req.ttl：缓存有剩余时间req.url：请求的 URLreq.xid：唯一 ID ¶bereq：（发送到后端的请求对象，基于 req 对象） 123456789101112131415161718192021222324bereq：（发送到后端的请求对象，基于 req 对象）bereq：整个后端请求后数据结构bereq.backend：所请求后端节点配置bereq.between_bytes_timeout：从后端每接收一个字节之间的等待时间（秒）bereq.connect_timeout：连接后端等待时间（秒），最大等待时间bereq.first_byte_timeout：等待后端第一个字节时间（秒），最大等待时间bereq.http：对应发送到后端 HTTP 的 header 信息bereq.method：发送到后端的请求类型（如：GET , POST）bereq.proto：发送到后端的请求的 HTTP 版本bereq.retries：相同请求重试计数bereq.uncacheable：无缓存这个请求bereq.url：发送到后端请求的 URLbereq.xid：请求唯一 ID ¶beresp：（后端响应请求对象） 123456789101112131415161718192021222324252627beresp：整个后端响应 HTTP 数据结构beresp.backend.ip：后端响应的 IPberesp.backend.name：响应后端配置节点的 nameberesp.do_gunzip：默认为 false 。缓存前解压该对象beresp.do_gzip：默认为 false 。缓存前压缩该对象beresp.grace：设置当前对象缓存过期后可额外宽限时间，用于特殊请求加大缓存时间，当并发量巨大时，不易设置过大否则会堵塞缓存，一般可设置 1m 左右，当 beresp.ttl&#x3D;0s 时该值无效beresp.http：对应的 HTTP 请求 headerberesp.keep：对象缓存后带保持时间beresp.proto：响应的 HTTP 版本beresp.reason：由服务器返回的 HTTP 状态信息beresp.status：由服务器返回的状态码beresp.storage_hint：指定保存的特定存储器beresp.ttl：该对象缓存的剩余时间，指定统一缓存剩余时间。beresp.uncacheable：继承 bereq.uncacheable，是否不缓存 ¶OBJ ：（高速缓存对象，缓存后端响应请求内容） 123456789101112131415obj.grace：该对象额外宽限时间obj.hits：缓存命中次数，计数器从 1 开始，当对象缓存该值为 1，一般可以用于判断是否有缓存，当前该值大于 0 时则为有缓存obj.http：对应 HTTP 的 headerobj.proto：HTTP 版本obj.reason：服务器返回的 HTTP 状态信息obj.status：服务器返回的状态码obj.ttl：该对象缓存剩余时间（秒）obj.uncacheable：不缓存对象 ¶resp :（返回给客户端的响应对象） 123456789resp：整个响应 HTTP 数据结构resp.http：对应 HTTP 的 headerresp.proto：编辑响应的 HTTP 协议版本resp.reason：将要返回的 HTTP 状态信息resq.status：将要返回的 HTTP 状态码 ¶存储 ： 12345storage.&lt;name&gt;.free_space：存储可用空间（字节数）storage.&lt;name&gt;.used_space：存储已经使用空间（字节数）storage.&lt;name&gt;.happy：存储健康状态 ¶7、特定功能性语句 12345678910111213141516171819202122232425262728293031323334353637383940ban(expression)：清除指定对象缓存call(subroutine)：调用子程序，如：call(name)hash_data(input)：生成 hash 键，用于制定 hash 键值生成结构，只能在 vcl_hash 子程序中使用。调用 hash_data(input) 后，即这个 hash 为当前页面的缓存 hash 键值，无需其它获取或操作，如：sub vcl_hash&#123;hash_data(client.ip);return(lookup);&#125;注意：return(lookup); 是默认返回值，所以可以不写new()：创建一个 vcl 对象，只能在 vcl_init 子程序中使用return()：结束当前子程序，并指定继续下一步动作，如：return (ok); 每个子程序可指定的动作均有不同rollback()：恢复 HTTP 头到原来状态，已经弃用，使用 std.rollback() 代替synthetic(STRING)：合成器，用于自定义一个响应内容，比如当请求出错时，可以返回自定义 404 内容，而不只是默认头信息，只能在 vcl_synth 与 vcl_backend_error 子程序中使用，如：sub vcl_synth &#123; //自定义内容 synthetic (&#123;\"&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\"&gt;&lt;html lang=\"zh-cn\"&gt; &lt;head&gt; &lt;meta http-equiv=\"ContentType\"content=\"text/html;charset=utf-8\"/&gt; &lt;title&gt;error&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Error&lt;/h1&gt; &lt;h3&gt;这只是一个测试自定义响应异常内容&lt;/h3&gt; &lt;/body&gt;&lt;/html&gt; \"&#125;); //只交付自定义内容 return(deliver);regsub(str, regex, sub)：使用正则替换第一次出现的字符串，第一个参数为待处理字符串，第二个参数为正则表达式，第三个为替换为字符串regsuball(str, regex, sub)：使用正则替换所有匹配字符串。参数与 regsuball 相同具体变量详见：https://www.varnish-cache.org/docs/4.0/reference/vcl.html#reference-vcl ¶8、return语句 return 语句是终止子程序并返回动作，所有动作都根据不同的 vcl 子程序限定来选用 https://www.varnish-cache.org/docs/4.0/users-guide/vcl-built-in-subs.html 语法：return(action); 常用的动作： 1234567891011121314151617181920212223abandon 放弃处理，并生成一个错误deliver 交付处理fetch 从后端取出响应对象hash 哈希缓存处理lookup 查找缓存对象ok 继续执行pass 进入 pass 非缓存模式pipe 进入 pipe 非缓存模式purge 清除缓存对象，构建响应restart 重新开始retry 重试后端处理synth(status code,reason) 合成返回客户端状态信息 ¶9、varnish 中内置子程序 注：varnish 内置子程序均有自己限定的返回动作 return （动作）; 不同的动作将调用对应下一个子程序 ¶vcl_recv 子程序 1开始处理请求，通过 return (动作); 选择 varnish 处理模式，默认进入 hash 缓存模式（即return(hash);），缓存时间为配置项 default_ttl（默认为 120 秒）过期保持时间 default_grace（默认为 10 秒）。该子程序一般用于模式选择，请求对象缓存及信息修改，后端节点修改，终止请求等操作 可操作对象：（部分或全部值） 读：client，server，req，storage 写：client，req 返回值： synth(status code,reason); 定义响应内容 pass 进入 pass 模式，并进入 vcl_pass 子程序 pipe 进入 pipe 模式，并进入 vcl_pipe 子程序 hash 进入 hash 缓存模式，并进入 vcl_hash 子程序，默认返回值 purge 清除缓存等数据，子程序先从 vcl_hash 再到 vcl_purge ¶vcl_pipe 子程序 1ipe 模式处理，该模式主要用于直接取后端响应内容返回客户端，可定义响应内容返回客户端。该子程序一般用于需要及时且不作处理的后端信息，取出后端响应内容后直接交付到客户端不进入 vcl_deliver 子程序处理 可操作对象：（部分或全部值） 读：client，server，bereq，req，storage 写：client，bereq，req 返回值： synth(status code,reason); 定义响应内容 pipe 继续 pipe 模式，进入后端 vcl_backend_fetch 子程序，默认返回值 ¶vcl_pass 子程序 1pass 模式处理，该模式类似 hash 缓存模式，仅不做缓存处理 可操作对象：（部分或全部值） 读：client，server，req，storage 写：client，req 返回值： synth(status code,reason); 定义响应内容 fetch 继续 pass 模式，进入后端 vcl_backend_fetch 子程序，默认返回值 ¶vcl_hit 子程序 1hash 缓存模式时，存在 hash 缓存时调用，用于缓存处理，可放弃或修改缓存 可操作对象：（部分或全部值） 读：client，server，obj，req，storage 写：client，req 返回值： restart 重启请求 deliver 交付缓存内容，进入 vcl_deliver 子程序处理，默认返回值 synth(status code,reason); 定义响应内容 ¶vcl_miss 子程序 1hash 缓存模式时，不存在 hash 缓存时调用，用于判断性的选择进入后端取响应内容，可以修改为 pass 模式 可操作对象：（部分或全部值） 读：client，server，req，storage 写：client，req 返回值： restart 重启请求 synth(status code,reason); 定义响应内容 pass 切换到 pass 模式，进入 vcl_pass 子程序 fetch 正常取后端内容再缓存，进入 vcl_backend_fetch 子程序，默认返回值 ¶vcl_hash 子程序 1hash缓存模式，生成hash值作为缓存查找键名提取缓存内容，主要用于缓存hash键值处理，可使用 hash_data(string) 指定键值组成结构，可在同一个页面通过 IP 或 cookie 生成不同的缓存键值 可操作对象：（部分或全部值） 读：client，server，req，storage 写：client，req 返回值： lookup 查找缓存对象，存在缓存进入 vcl_hit 子程序，不存在缓存进入 vcl_miss 子程序，当使用了 purge 清理模式时会进入 vcl_purge 子程序，默认返回值 ¶vcl_purge 子程序 1清理模式，当查找到对应的缓存时清除并调用，用于请求方法清除缓存，并报告 可操作对象：（部分或全部值） 读：client，server，req，storage 写：client，req 返回值： synth(status code,reason); 定义响应内容 restart 重启请求 ¶vcl_deliver 子程序 1客户端交付子程序，在 vcl_backend_response 子程序后调用（非 pipe 模式），或 vcl_hit 子程序后调用，可用于追加响应头信息，cookie 等内容 可操作对象：（部分或全部值） 读：client，server，req，resp，obj，storage 写：client，req，resp 返回值： deliver 正常交付后端或缓存响应内容，默认返回值 restart 重启请求 ¶vcl_backend_fetch 子程序 1发送后端请求之前调用，可用于改变请求地址或其它信息，或放弃请求 可操作对象：（部分或全部值） 读：server，bereq，storage 写：bereq 返回值： fetch 正常发送请求到到后端取出响应内容，进入 vcl_backend_response 子程序，默认返回值 abandon 放弃后端请求，并生成一个错误，进入 vcl_backend_error 子程序 ¶vcl_backend_response 子程序 1后端响应后调用，可用于修改缓存时间及缓存相关信息 可操作对象：（部分或全部值） 读：server，bereq，beresp，storage 写：bereq，beresp 返回值： deliver 正常交付后端响应内容，进入 vcl_deliver 子程序，默认返回值 abandon 放弃后端请求，并生成一个错误，进入 vcl_backend_error 子程序 retry 重试后端请求，重试计数器加 1，当超过配置中 max_retries 值时会报错并进入vcl_backend_error 子程序 ¶vcl_backend_error 子程序 1后端处理失败调用，异常页面展示效果处理，可自定义错误响应内容，或修改 beresp.status与 beresp.http.Location 重定向等 可操作对象：（部分或全部值） 读：server，bereq，beresp，storage 写：bereq，beresp 返回值： deliver 只交付 sysnthetic(string) 自定义内容，默认返回后端异常标准错误内容 retry 重试后端请求，重试计数器加 1，当超过配置中 max_retries 值时会报错并进入vcl_backend_error 子程序 ¶vcl_synth 子程序 1自定义响应内容。可以通过 synthetic（）和返回值 synth 调用，这里可以自定义异常显示内容，也可以修改 resp.status 与 resp.http.Location 重定向 可操作对象：（部分或全部值） 读：client，server，req，resp，storage 写：req，resp 返回值： deliver 只交付 sysnthetic(string) 自定义内容，默认返回 sysnth 异常指定状态码与错误内容 restart 重启请求 ¶vcl_init 子程序 1加载 vcl 时最先调用，用于初始化 VMODs，该子程序不参与请求处理，仅在 vcl 加载时调用一次 可操作对象：（部分或全部值） 读：server 写：无 返回值： ok 正常返回，进入 vcl_recv 子程序，默认返回值 ¶vcl_fini 子程序 1卸载当前 vcl 配置时调用，用于清理 VMODs，该子程序不参与请求处理，仅在 vcl 正常丢弃后调用 可操作对象：（部分或全部值） 读：server 写：无 返回值： ok 正常返回，本次 vcl 将释放，默认返回值 varnish 子程序调用流程图，通过大部分子程序的 return 返回值进入下一步行动： ¶10、优雅模式（Garce mode） Varnish 中的请求合并 当几个客户端请求同一个页面的时候，varnish 只发送一个请求到后端服务器，然后让其他几个请求挂起并等待返回结果；获得结果后，其它请求再复制后端的结果发送给客户端；但如果同时有数以千计的请求，那么这个等待队列将变得庞大，这将导致 2 类潜在问题： 惊群问题(thundering herd problem)，即突然释放大量的线程去复制后端返回的结果，将导致负载急速上升；没有用户喜欢等待； 故为了解决这类问题，可以配置 varnish 在缓存对象因超时失效后再保留一段时间，以给那些等待的请求返回过去的文件内容(stale content)，配置案例如下： 12345678910sub vcl_recv &#123;if (! req.backend.healthy) &#123;set req.grace = 5m;&#125; else &#123;set req.grace = 15s;&#125;&#125;sub vcl_fetch &#123;set beresp.grace = 30m;&#125; 以上配置表示 varnish 将会将失效的缓存对象再多保留 30 分钟，此值等于最大的 req.grace值即可 而根据后端主机的健康状况，varnish 可向前端请求分别提供 5 分钟内或 15 秒内的过期内容 ¶二、安装varnish ¶1、安装依赖关系的软件包 1[root@varnish ~]# yum -y install autoconf automake libedit-devel libtool ncurses-devel pcre-devel pkgconfig python-docutils python-sphinx ¶2、安装 varnish 安装包 提取码：h71d varnish 的官方网址为 http://varnish-cache.org，可以在这里下载最新版本的软件 注意：Varnish 网站有时会被墙 解压，进入解压目录编译安装： 12345[root@varinsh ~]# tar zxf varnish-4.0.3.tar.gz [root@varinsh ~]# cd varnish-4.0.3/[root@varinsh varnish-4.0.3]# export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig[root@varinsh varnish-4.0.3]# ./configure &amp;&amp; make &amp;&amp; make install# 不指定安装路径，默认是安装在/usr/local 目录下 注： ./autogen.sh 如果从 Git 库下载的安装包时才需要运行，用于生成 configure 编译文件 复制 vcl 文件（在编译安装目录下），如果安装目录里没有 default.vcl 文件 复制到安装目录的/usr/local/var/varnish/目录下（当然并无必需要求在哪个目录，因为正式启动时还得指定这个文件的目录） 1[root@varinsh varnish-4.0.3]# cp etc/example.vcl /usr/local/var/varnish/default.vcl ¶三、varnish 实例解析 12345varnish 配置基本上是编辑 VCL(Varnish Configuration Language) 文件,varnish 有一套自定义VCL 语法，启动时，会将配置文件编译为 C 语言，再执行varnish 4.0 开始，每个 VCL 文件必须在开始行声明它的版本“vcl 4.0;”块（子程序）由大括号分隔，语句用分号结束。所有的关键字及预设子程序名都是全小写。注释：支持 // 或 # 多行时还可以使用 /* .. */ ¶1、后端服务器地址池配置及后端服务器健康检查 varnish 有&quot;后端&quot;或者&quot;源&quot;服务器的概念。backend server 提供给 varnish 加速的内容。实际上就是给 varnish 添加可供访问的 web 服务器，如果有多台 web 服务器时，可添加多个 backend块 ¶1）后端服务器定义 命令：backend。这个定义为最基本的反向入口定义，用于 varnish 连接对应的服务器，如果没有定义或定义错误则用户无法访问正常页面 语法格式： 123backend name&#123; .attribute = \"value\";&#125; 说明： backend 是定义后端关键字，name 是当前后端节点的别名，多个后端节点时，name 名不能重复，否则覆盖。花括号里面定义当前节点相关的属性（键=值）。除默认节点外其它节点定义后必需有调用，否则 varnish 无法启动。后端是否正常可以通过 std.healthy(backend)判断 支持运算符： = （赋值运算） == （相等比较） ~ （匹配，可以使用正则表达式，或访问控制列表） !~ （不匹配，可以使用正则表达式，或访问控制列表） ！ （非） &amp;&amp; （逻辑与） || （逻辑或） 属性列表： .host=“xxx.xxx.xxx.xxx”; 要转向主机（即后端主机）的 IP 或域名，必填键/值对 .port=“8080”; 主机连接端口号或协议名（HTTP 等），默认 80 .host_header=’’; 请示主机头追加内容 .connect_timeout=1s; 连接后端的超时时间 .first_byte_timeout=5s; 等待从后端返回的第一个字节时间 .between_bytes_timeout=2s; 每接收一个字节之间等待时间 .probe=probe_name; 监控后端主机的状态,指定外部监控 name 或者内部直接添加 .max_connections=200; 设置最大并发连接数，超过这个数后连接就会失败 例：（下面两个例子结果是一样的，但第二个例子中更适用于集群，可以方便批量修改） 123456789101112131415161718backend web&#123; .host=\"192.168.31.83\"; .port=\"80\"; .probe=&#123; # 直接追加监控块.probe 是一个的参数 .url=\"/\"; .timeout=2s; &#125;&#125;或probe web_probe&#123; # 监控必需定义在前面，否则后端调用找不到监控块。 .url=\"/\"; .timeout=2s;&#125;backend web&#123; .host=\"192.168.31.83\"; .port=\"80\"; .probe=web_probe; //调用外部共用监控块&#125; ¶2）监视器的定义 命令：probe 。监控可以循环访问指定的地址，通过响应时间判定服务器是否空闲或正常。这类命令非常适用于集群中某些节点服务器崩溃或负载过重，而禁止访问这台节点服务器。 语法格式： 123probe name&#123; .attribute = \"value\";&#125; 说明： probe 是定义监控关键字，name 是当前监控点的别名，多个监控节点时，name 名不能重复，否则覆盖。花括号里面定义当前节点相关的属性（键=值）。没有必填属性，因为默认值就可以正常执行操作 属性列表： .url=&quot;/&quot;; 指定监控入口 URL 地址，默认为&quot;/&quot; .request=&quot;&quot;; 指定监控请求入口地址，比 .url 优先级高 .expected_response=“200”; 请求响应代码，默认是 200 .timeout=2s; 请求超时时间 .interval=5s; 每次轮询请求间隔时间,默认为 5s .initial=-1; 初始启动时以.window 轮询次数中几次良好后续才能使用这个后端服务器节点，默认为 -1 ，则轮询完 .window 所有次数良好判定为正常 .window=8; 指定多少轮询次数，用于判定服务器正常，默认是 8 .threshold=3; 必须多少次轮询正常才算该后端节点服务器正常,默认是 3 例：创建健康监测，定义健康检查名称为 backend_healthcheck 1234567probe backend_healthcheck &#123; .url = \"/\"; .timeout = 1s; .interval = 5s; .window = 5; .threshold = 3;&#125; 在上面的例子中 varnish 将每 5s 检测后端，超时设为 1s。每个检测将会发送 get /的请求。如果 5 个检测中大于 3 个是成功，varnish 就认为后端是健康的，反之，后端就有问题了 ¶3）集群负载均衡 directors： 123varnish 可以定义多个后端，也可以将几个后端放在一个后端集群里面已达到负载均衡的目的你也可以将几个后端组成一组后端。这个组被叫做 Directors。可以提高性能和弹性 directors 是 varnish 负载均衡模块，使用前必需引入 directors 模块，directors 模块主要包含： round_robin，random，hash，fallback 负载均衡模式 round_robin : 循环依次逐个选择后端服务器 random ： 随机选择后端服务器，可设置每个后端权重增加随机率 hash : 通过散列随机选择对应的后端服务器且保持选择对应关系，下次则直接找对应的后端服务器 Fallback：后备 注意： random，hash 有权重值设置，用于提高随机率。每个后端最好都配置监控器（后端服务器正常监测）以便 directors 自动屏蔽不正常后端而不进入均衡列中。 这些操作需要你载入 VMOD（varnish module），然后在 vcl_init 中调用这个 VMOD 1234567891011121314151617181920212223import directors; # load the directorsbackend web1 &#123; .host = \"192.168.0.10\"; .port = \"80\"; .probe = backend_healthcheck;&#125;backend web2 &#123; .host = \"192.168.0.11\"; .port = \"80\"; .probe = backend_healthcheck;&#125;# 初始化处理sub vcl_init &#123; # 调用 vcl_init 初始化子程序创建后端主机组，即 directors new web_cluster = directors.round_robin(); # 使用 new 关键字创建 drector 对象,使用 round_robin 算法 web_cluster.add_backend(web1); # 添加后端服务器节点 web_cluster.add_backend(web2);&#125;# 开始处理请求sub vcl_recv &#123; # 调用 vcl_recv 子程序，用于接收和处理请求 set req.backend_hint = web_cluster.backend(); # 选取后端&#125; 说明： set 命令是设置变量 unset 命令是删除变量 web_cluster.add_backend( backend , real ); 添加后端服务器节点，backend 为后端配置别名，real 为权重值，随机率计算公式：100 * (当前权重 / 总权重) req.backend_hint 是 varnish 的预定义变量，作用是指定请求后端节点 vcl 对象需要使用 new 关键字创建，所有可创建对象都是内定的，使用前必需 import，所有new 操作只能在 vcl_init 子程序中 扩展：varnish 将不同的 url 发送到不同的后端 server 1234567891011121314151617181920212223242526272829303132333435363738394041import directors; # load the directorsbackend web1 &#123; .host = \"192.168.0.10\"; .port = \"80\"; .probe = backend_healthcheck;&#125;backend web2 &#123; .host = \"192.168.0.11\"; .port = \"80\"; .probe = backend_healthcheck;&#125;backend img1 &#123; .host = \"img1.lnmmp.com\"; .port = \"80\"; .probe = backend_healthcheck;&#125;backend img2 &#123; .host = \"img2.lnmmp.com\"; .port = \"80\"; .probe = backend_healthcheck;&#125;# 初始化处理sub vcl_init &#123; # 调用 vcl_init 初始化子程序创建后端主机组，即 directors new web_cluster = directors.round_robin(); # 使用 new 关键字创建 drector 对象,使用 round_robin 算法 web_cluster.add_backend(web1); # 添加后端服务器节点 web_cluster.add_backend(web2); new img_cluster = directors.random(); img_cluster.add_backend(img1,2); # 添加后端服务器节点，并且设置权重值 img_cluster.add_backend(img2,5);&#125;# 根据不同的访问域名，分发至不同的后端主机组sub vcl_recv &#123; if (req.http.host ~ \"(?i)^(www.)?benet.com$\") &#123; set req.http.host = \"www.benet.com\"; set req.backend_hint = web_cluster.backend(); # 选取后端 &#125; elsif (req.http.host ~ \"(?i)^images.benet.com$\") &#123; set req.backend_hint = img_cluster.backend(); &#125;&#125; 说明：中的 i 就是忽略大小写的意思。(?i)表示开启忽略大小写，而(?-i)表示关闭忽略大小写 ¶4）访问控制列表（ACL） 创建一个地址列表，用于后面的判断，可以是域名或 IP 集合。这个可以用于指定某些地址请求入口，防止恶意请求等 语法格式： 123456acl purgers &#123; \"127.0.0.1\"; \"localhost\"; “192.168.134.0/24” !\"192.168.134.1\";&#125; 说明：acl 是访问列表关键字（必需小写），name 是该列表的别名用于调用，花括号内部是地址集 注意：如果列表中包含了无法解析的主机地址，它会匹配任何地址 如果不想让它匹配可以在前添加一个 ! 符号，如上面 !“192.168.134.1”; 使用 ACL 只需要用 匹配运算符 ~ 或 !~ 如： 123456789sub vcl_recv &#123; if (req.method == \"PURGE\") &#123; # PURGE 请求的处理 if (client.ip ~ purgers) &#123; return(purge); &#125; else &#123; return(synth(403, \"Access denied.\")); &#125; &#125;&#125; ¶5）缓存规则配置 123456789101112131415161718192021222324252627282930sub vcl_recv &#123; # PURGE 请求的处理 if (req.method == \"PURGE\") &#123; if (!client.ip ~ purgers) &#123; return (synth(405, \"Not Allowed.\")); &#125; return (purge); &#125; set req.backend_hint = web.backend(); # 将 php、asp 等动态内容访问请求直接发给后端服务器，不缓存。 if (req.url ~ \"\\.(php|asp|aspx|jsp|do|ashx|shtml)($|\\?)\") &#123; return (pass); &#125; # 将非 GET 和 HEAD 访问请求直接发给后端服务器，不缓存。例如 POST 请求。 if (req.method != \"GET\" &amp;&amp; req.method != \"HEAD\") &#123; return (pass); &#125; # 如果 varnish 看到 header 中有'Authorization'头，它将 pass 请求。 if (req.http.Authorization) &#123; return (pass); &#125; # 带 cookie 首部的 GET 请求也缓存 if (req.url ~ \"\\.(css|js|html|htm|bmp|png|gif|jpg|jpeg|ico|gz|tgz|bz2|tbz|zip|rar|mp3|mp4|ogg|swf|flv)($|\\?)\") &#123; unset req.http.cookie; return (hash); &#125;&#125; 说明：默认情况，varnish 不缓存从后端响应的 http 头中带有 Set-Cookie 的对象。如果客户 端发送的请求带有 Cookie header，varnish 将忽略缓存，直接将请求传递到后端 为发往后端主机的请求添加 X-Forward-For 首部,首次访问增加 X-Forwarded-For 头信息,方 便后端程序获取客户端 ip，而不是 varnish 地址 1234567if (req.restarts == 0) &#123; if (req.http.x-forwarded-for) &#123; # 如果设置过此 header 则要再次附加上用逗号隔开 set req.http.X-Forwarded-For = req.http.X-Forwarded-For + \", \" + client.ip; &#125; else &#123; # 如果只有一层代理的话,就无需设置了 set req.http.X-Forwarded-For = client.ip; &#125;&#125; 说明： X-Forwarded-For 是用来识别通过 HTTP 代理或负载均衡方式连接到 Web 服务器的客户 端最原始的 IP 地址的 HTTP 请求头字段 子程序： 子程序是一种类似 C 的函数，但是程序没有调用参数，子程序以 sub 关键字定义。在 VCL里子程序是用于管理程序 注意：所有 VCL 内置的程序都是以 vcl_ 开头，并已经预置好，在 VCL 文件中只要声明对应的内置子程序，都会在对应的流程中调用 ¶三、varnish 完整配置实例 ¶1、拓扑环境 varnish 192.168.1.20 web01 192.168.1.30 web02 192.168.1.40 配置 web01、web02 做为后端服务器（过程略） 确保 varnish 服务器能正常访问 web01、web02 Varnish 缓存代理服务器配置： ¶2、vcl文件配置内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164[root@varinsh ~]# cat /usr/local/var/varnish/default.vcl vcl 4.0;import directors;import std;probe backend_healthcheck &#123; .url = \"/\"; .timeout = 1s; .interval = 5s; .window = 5; .threshold = 3;&#125;backend web1 &#123; .host = \"192.168.1.30\"; .port = \"80\"; .probe = backend_healthcheck;&#125;backend web2 &#123; .host = \"192.168.1.40\"; .port = \"80\"; .probe = backend_healthcheck;&#125;acl purgers &#123; \"127.0.0.1\"; \"localhost\"; \"192.168.1.0/24\"; !\"192.168.1.40\";&#125;sub vcl_init &#123; new web_cluster = directors.round_robin(); web_cluster.add_backend(web1); web_cluster.add_backend(web2);&#125;sub vcl_recv &#123; set req.backend_hint = web_cluster.backend(); if (req.method == \"PURGE\") &#123; if (!client.ip ~ purgers) &#123; return (synth(405, \"Not Allowed.\")); &#125; return (purge); &#125; if (req.method != \"GET\" &amp;&amp; req.method != \"HEAD\" &amp;&amp; req.method != \"PUT\" &amp;&amp; req.method != \"POST\" &amp;&amp; req.method != \"TRACE\" &amp;&amp; req.method != \"OPTIONS\" &amp;&amp; req.method != \"PATCH\" &amp;&amp; req.method != \"DELETE\") &#123; return (pipe); &#125; if (req.method != \"GET\" &amp;&amp; req.method != \"HEAD\")&#123; return (pass); &#125; if (req.url ~ \"\\.(php|asp|aspx|jsp|do|ashx|shtml)($|\\?)\")&#123; return (pass); &#125; if (req.http.Authorization) &#123; return (pass); &#125; if (req.http.Accept-Encoding) &#123; if (req.url ~ \"\\.(bmp|png|gif|jpg|jpeg|ico|gz|tgz|bz2|tbz|zip|rar|mp3|mp4|ogg|swf|flv)$\")&#123; unset req.http.Accept-Encoding; &#125; elseif (req.http.Accept-Encoding ~ \"gzip\") &#123; set req.http.Accept-Encoding = \"gzip\"; &#125; elseif (req.http.Accept-Encoding ~ \"deflate\") &#123; set req.http.Accept-Encoding = \"deflate\"; &#125; else &#123; unset req.http.Accept-Encoding; &#125; &#125; if (req.url ~ \"\\.(css|js|html|htm|bmp|png|gif|jpg|jpeg|ico|gz|tgz|bz2|tbz|zip|rar|mp3|mp4|ogg|sw f|flv)($|\\?)\") &#123; unset req.http.cookie; return (hash); &#125; if (req.restarts == 0) &#123; if (req.http.X-Forwarded-For) &#123; set req.http.X-Forwarded-For = req.http.X-Forwarded-For + \", \" + client.ip; &#125; else &#123; set req.http.X-Forwarded-For = client.ip; &#125; &#125; return (hash);&#125;sub vcl_hash &#123; hash_data(req.url); if (req.http.host) &#123; hash_data(req.http.host); &#125; else &#123; hash_data(server.ip); &#125; return (lookup);&#125;sub vcl_hit &#123; if (req.method == \"PURGE\") &#123; return (synth(200, \"Purged.\")); &#125; return (deliver);&#125;sub vcl_miss &#123; if (req.method == \"PURGE\") &#123; return (synth(404, \"Purged.\")); &#125; return (fetch);&#125;sub vcl_deliver &#123; if (obj.hits &gt; 0) &#123; set resp.http.X-Cache = \"HIT\"; set resp.http.X-Cache-Hits = obj.hits; &#125; else &#123; set resp.http.X-Cache = \"MISS\"; &#125; unset resp.http.X-Powered-By; unset resp.http.Server; unset resp.http.X-Drupal-Cache; unset resp.http.Via; unset resp.http.Link; unset resp.http.X-Varnish; set resp.http.xx_restarts_count = req.restarts; set resp.http.xx_Age = resp.http.Age; set resp.http.hit_count = obj.hits; unset resp.http.Age; return (deliver);&#125;sub vcl_pass &#123; return (fetch); &#125;sub vcl_backend_response &#123; set beresp.grace = 5m; if (beresp.status == 499 || beresp.status == 404 || beresp.status == 502) &#123; set beresp.uncacheable = true; &#125; if (bereq.url ~ \"\\.(php|jsp)(\\?|$)\") &#123; set beresp.uncacheable = true; &#125; else &#123; if (bereq.url ~ \"\\.(css|js|html|htm|bmp|png|gif|jpg|jpeg|ico)($|\\?)\") &#123; set beresp.ttl = 15m; unset beresp.http.Set-Cookie; &#125; elseif (bereq.url ~ \"\\.(gz|tgz|bz2|tbz|zip|rar|mp3|mp4|ogg|swf|flv)($|\\?)\") &#123; set beresp.ttl = 30m; unset beresp.http.Set-Cookie; &#125; else &#123; set beresp.ttl = 10m; unset beresp.http.Set-Cookie; &#125; &#125; return (deliver);&#125;sub vcl_purge &#123; return (synth(200,\"success\"));&#125;sub vcl_backend_error &#123; if (beresp.status == 500 || beresp.status == 501 || beresp.status == 502 || beresp.status == 503 || beresp.status == 504) &#123; return (retry); &#125;&#125;sub vcl_fini &#123; return (ok);&#125; ¶3、启动varnish 当启动 varnish 时有两个重要的参数你必须设置: 一个是处理 http 请求的 tcp 监听端口,另一个是处理真实请求的后端 server 注：如果你使用操作系统自带的包管理工具安装的 varnish,你将在下面的文件找到启动参数:Red Hat, Centos: /etc/sysconfig/varnish ¶1）’-a’ ‘-a’ 参数定义了 varnish 监听在哪个地址,并用该地址处理 http 请求，你可能想设置这个参数在众所周知的 http 80 端口 例子: -a :80 -a localhost:80 -a 192.168.1.100:8080 -a ‘[fe80::1]:80’ -a ‘0.0.0.0:8080,[::]:8081’ 如果你的 webserver 和 varnish 运行在同一台机器,你必须换一个监听地址 ¶2）’-f’ -f 添加 vcl 文件,-b 定义后端 serve varnish 需要知道从哪里找到这个需要缓存的 http server.你可以用-b 参数指定,或者帮把它放在 vcl 文件中,然后使用-f 参数指定 在启动的时候使用-b 是一个快捷的方式. -b 192.168.1.2:80 注意:如果你指定的是 name,这个 name 必须能解析成一个 IPv4 或者 IPv6 的地址如果你使用-f 参数,你启动的时候可以在-f 指定 vcl 文件 默认的 varnish 使用 100M 的内存来缓存对象,如果你想缓存更多,可以使用-s 参数 注：Varnish 拥有大量的有用的命令行参数，建议查看其帮助 1[root@varinsh ~]# /usr/local/sbin/varnishd -h 启动 varnish 12[root@varinsh ~]# varnishd -f /usr/local/var/varnish/default.vcl -s malloc,200M -a 0.0.0.0:80[root@varinsh ~]# netstat -anput | grep 80tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 13968/varnishd ¶3）访问 现在，varnish 已经启动和运行，你可以通过 varnish 访问您的 Web 应用程序 第一次访问 第二次访问 ¶4）清除缓存再次访问","categories":[{"name":"架构","slug":"架构","permalink":"https://pdxblog.top/categories/%E6%9E%B6%E6%9E%84/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://pdxblog.top/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"Nginx优化与防盗链+单机部署LNMP","slug":"Nginx优化与防盗链+单机部署LNMP","date":"2020-06-12T16:00:00.000Z","updated":"2020-06-13T03:39:56.520Z","comments":true,"path":"Nginx优化与防盗链+单机部署LNMP.html","link":"","permalink":"https://pdxblog.top/Nginx%E4%BC%98%E5%8C%96%E4%B8%8E%E9%98%B2%E7%9B%97%E9%93%BE+%E5%8D%95%E6%9C%BA%E9%83%A8%E7%BD%B2LNMP.html","excerpt":"","text":"¶Nginx优化与防盗链+单机部署LNMP Nginx 是俄罗斯人编写的十分轻量级的 HTTP 服务器,Nginx，它的发音为“engine X”，是一个高性能的 HTTP 和反向代理服务器，同时也是一个 IMAP/POP3/SMTP 代理服务器．Nginx 是由俄罗斯人 Igor Sysoev 为俄罗斯访问量第二的 Rambler.ru 站点开发 Nginx 以事件驱动（epoll）的方式编写，所以有非常好的性能，同时也是一个非常高效的反 向代理、负载平衡。但是 Nginx 并不支持 cgi 方式运行，原因是可以减少因此带来的一些程 序上的漏洞。所以必须使用 FastCGI 方式来执行 PHP 程序 由于 Nginx 本身的一些优点，轻量，开源，易用，越来越多的公司使用 nginx 作为自己公司 的 web 应用服务器，本文详细介绍 nginx 源码安装的同时并对 nginx 进行优化配置 ¶一、Nginx的优化 ¶1、编译安装前的优化 编译前的优化主要是用来修改程序名等等，目的更改源码隐藏软件名称和版本号 ¶（1）安装 zlib-devel、pcre-devel 等依赖包 1[root@nginx ~]# yum -y install gcc gcc-c++ make libtool zlib zlib-devel pcre pcre-devel openssl openssl-devel ¶（2）下载Nginx源码包 1[root@nginx ~]# wget http://nginx.org/download/nginx-1.10.2.tar.gz ¶（3）解压源码包 12[root@nginx ~]# tar zxf nginx-1.10.2.tar.gz [root@nginx ~]# cd nginx-1.10.2/ ¶（4）隐藏软件名称和版本号 12345[root@nginx nginx-1.10.2]# vim src/core/nginx.h# 此行修改的是你想要的版本#define NGINX_VERSION \"1.10.2\" # 第13行# 此行修改的是你想修改的软件名称#define NGINX_VER \"nginx/\" NGINX_VERSION # 第14行 修改上面的信息，即可更改 nginx 显示版本。例如：(curl –I 可看到，请求头和响应头显示) 12#define NGINX_VERSION \"7.0\"#define NGINX_VER \"IIS/\" NGINX_VERSION 修改 HTTP 头信息中的 connection 字段，防止回显具体版本号 拓展： 通用 http 头 ，通用头包含请求和响应消息都支持的头，通用头包含 Cache-Control、 Connection、Date、Pragma、Transfer-Encoding、Upgrade、Via。对通用头的扩展要求通讯双方都支持此扩展，如果存在不支持的通用头，一般将会作为实体头处理。那么也就是说有部分设备，或者是软件，能获取到 connection，部分不能，要隐藏就要彻底！ 12345[root@nginx nginx-1.10.2]# vim src/http/ngx_http_header_filter_module.c# 修改前static char ngx_http_server_string[] = \"Server: nginx\" CRLF; # 第49行# 修改后static char ngx_http_server_string[] = \"Server: IIS\" CRLF; 定义了 http 错误码的返回： 有时候我们页面程序出现错误，Nginx 会代我们返回相应的错误代码，回显的时候，会带上 nginx 和版本号，我们把他隐藏起来 12345678910111213[root@nginx nginx-1.10.2]# vim src/http/ngx_http_special_response.c# 修改前static u_char ngx_http_error_tail[] =\"&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;\" CRLF # 第29行\"&lt;/body&gt;\" CRLF\"&lt;/html&gt;\" CRLF;# 修改后static u_char ngx_http_error_tail[] =\"&lt;hr&gt;&lt;center&gt;IIS&lt;/center&gt;\" CRLF\"&lt;/body&gt;\" CRLF\"&lt;/html&gt;\" CRLF; ¶2、安装nginx ¶（1）添加 nginx 组 创建nginx运行账户nginx并加入到nginx 组，不允许 www 用户直接登录系统 12[root@nginx nginx-1.10.2]# groupadd nginx[root@nginx nginx-1.10.2]# useradd -g nginx nginx -s /sbin/nologin ¶（2）编译安装 1234567[root@nginx nginx-1.10.2]# ./configure --prefix=/usr/local/nginx1.10 \\&gt; --with-http_dav_module --with-http_stub_status_module \\&gt; --with-http_addition_module --with-http_sub_module \\&gt; --with-http_flv_module --with-http_mp4_module --with-pcre \\&gt; --with-http_ssl_module --with-http_gzip_static_module \\&gt; --user=nginx --group=nginx[root@nginx nginx-1.10.2]# make &amp;&amp; make install 相关选项说明： –with-http_dav_module 增加 PUT,DELETE,MKCOL：创建集合，COPY 和 MOVE 方法 –with-http_stub_status_module 获取 Nginx 的状态统计信息 –with-http_addition_module 作为一个输出过滤器，支持不完全缓冲，分部分相应请求 –with-http_sub_module 允许一些其他文本替换 Nginx 相应中的一些文本 –with-http_flv_module 提供支持 flv 视频文件支持 –with-http_mp4_module 提供支持 mp4 视频文件支持，提供伪流媒体服务端支持 –with-http_ssl_module 启用 ngx_http_ssl_module如果 pcre 是通过编译安装的话，例如 123tar zxvf /usr/local/src/pcre-8.36.tar.gz -C /usr/local/src/cd /usr/local/src/pcre-8.36 ./configure &amp;&amp; make &amp;&amp; make install 则–with-pcre=/usr/local/src/pcre-8.36 需要注意，这里指的是源码,用./configure --help | grep pcre 查看帮助 1234[root@nginx nginx-1.10.2]# ln -s /usr/local/nginx1.10/sbin/nginx /usr/local/sbin/[root@nginx nginx-1.10.2]# nginx -tnginx: the configuration file /usr/local/nginx1.10/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx1.10/conf/nginx.conf test is successful ¶（3）启动 nginx 123[root@nginx nginx-1.10.2]# nginx[root@nginx nginx-1.10.2]# netstat -anpt | grep nginxtcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 8303/nginx: master ¶（4）测试是否隐藏了版本和软件名 12345678910[root@nginx ~]# curl -I 127.0.0.1HTTP/1.1 200 OKServer: IIS/7.0Date: Fri, 12 Jun 2020 01:08:48 GMTContent-Type: text/htmlContent-Length: 612Last-Modified: Fri, 12 Jun 2020 00:59:55 GMTConnection: keep-aliveETag: \"5ee2d38b-264\"Accept-Ranges: bytes ¶3、nginx配置项优化 123[root@nginx ~]# ps -ef | grep nginxroot 8303 1 0 09:07 ? 00:00:00 nginx: master process nginxnginx 8304 8303 0 09:07 ? 00:00:00 nginx: worker process 在这里我们还可以看到在查看的时候，work 进程是 nginx 程序用户，但是 master 进程还是 root，其中，master 是监控进程，也叫主进程，work 是工作进程，部分还有 cache 相关进程，关系如图： 可以直接理解为 master 是管理员，work 进程才是为用户提供服务的！ ¶（1）Nginx 运行 工作置 进程个数 一般我们设置 CPU 的核心或者核心数 x2 如果不了解 cpu 的核数，可以 top 命令之后按 1 也可以看出来，也可以查看/proc/cpuinfo 文件 123456789[root@nginx ~]# grep ^processor /proc/cpuinfo | wc -l1[root@nginx ~]# vim /usr/local/nginx1.10/conf/nginx.confworker_processes 2;[root@nginx ~]# nginx -s reload[root@nginx ~]# ps -aux | grep nginx | grep -v greproot 8303 0.0 0.1 46028 1920 ? Ss 09:07 0:00 nginx: master process nginxnginx 10242 0.0 0.2 48540 2072 ? S 09:14 0:00 nginx: worker processnginx 10243 0.0 0.2 48540 2072 ? S 09:14 0:00 nginx: worker process ¶（2）Nginx 运行 CPU 亲和力 比如 4 核配置 12worker_processes 4;worker_cpu_affinity 0001 0010 0100 1000 比如 8 核配置 12worker_processes 8;worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000; worker_processes 最多开启 8 个，8 个以上性能提升不会再提升了，而且稳定性变得更低， 所以 8 个进程够用了 ¶（3）Nginx 最多可以打开文件数 1worker_rlimit_nofile 65535; 这个指令是指当一个 nginx 进程打开的最多文件描述符数目，理论值应该是最多打开文件数 （ulimit -n）与 nginx 进程数相除，但是 nginx 分配请求并不是那么均匀，所以最好与 ulimit -n的值保持一致 注： 文件资源限制的配置可以在/etc/security/limits.conf 设置，针对 root/user 等各个用户或者*代表所有用户来设置。 用户重新登录生效（ulimit -n） 12345[root@nginx ~]# vim /etc/security/limits.conf* soft nofile 65535* hard nofile 65535[root@nginx ~]# ulimit -n65535 ¶（4）Nginx 事件处理模型 12345events &#123; use epoll; worker_connections 65535; multi_accept on;&#125; nginx 采用 epoll 事件模型，处理效率高 work_connections 是单个 worker 进程允许客户端最大连接数，这个数值一般根据服务器性 能和内存来制定，实际最大值就是 worker 进程数乘以 work_connections实际我们填入一个 65535，足够了，这些都算并发值，一个网站的并发达到这么大的数量，也算一个大站了！ multi_accept 告诉 nginx 收到一个新连接通知后接受尽可能多的连接 ¶（5）开启高效传输模式 123456http &#123; include mime.types; default_type application/octet-stream; ...... sendfile on; tcp_nopush on; Include mime.types; 媒体类型, include 只是一个在当前文件中包含另一个文件内容的指令 default_type application/octet-stream; 默认媒体类型足够 sendfile on； 开启高效文件传输模式，sendfile 指令指定 nginx 是否调用 sendfile 函数来 输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘 IO 重负载应用，可设置为off，以平衡磁盘与网络 I/O 处理速度，降低系统的负载 注意：如果图片显示不正常把这个改成 off。 tcp_nopush on； 必须在 sendfile 开启模式才有效，防止网路阻塞，积极的减少网络报文段的数量（告诉 nginx 在一个数据包里发送所有头文件，而不一个接一个的发送。） ¶（6）连接超时时间 主要目的是保护服务器资源，CPU，内存，控制连接数，因为建立连接也是需要消耗资源的 123456789101112keepalive_timeout 65;tcp_nodelay on;client_header_buffer_size 4k;open_file_cache max=102400 inactive=20s;open_file_cache_valid 30s;open_file_cache_min_uses 1;client_header_timeout 15;client_body_timeout 15;reset_timedout_connection on;send_timeout 15;server_tokens off;client_max_body_size 10m; keepalived_timeout 客户端连接保持会话超时时间，超过这个时间，服务器断开这个链接 tcp_nodelay; 也是防止网络阻塞，不过要包涵在 keepalived 参数才有效 client_header_buffer_size 4k; 客户端请求头部的缓冲区大小，这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过 1k，不过由于一般系统分页都要大于 1k，所以这里设置为分页大小。分页大小可以用命令 getconf PAGESIZE 取得 open_file_cache max=102400 inactive=20s; 这个将为打开文件指定缓存，默认是没有启用的，max 指定缓存数量，建议和打开文件 数一致，inactive 是指经过多长时间文件没被请求后删除缓存 open_file_cache_valid 30s; 这个是指多长时间检查一次缓存的有效信息 open_file_cache_min_uses 1; open_file_cache 指令中的 inactive 参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在 inactive 时间内一次没被使用，它将被移除 client_header_timeout 设置请求头的超时时间。我们也可以把这个设置低些，如果超过这个时间没有发送任何数据，nginx 将返回 request time out 的错误 client_body_timeout 设置请求体的超时时间。我们也可以把这个设置低些，超过这个时间没有发送任何数据，和上面一样的错误提示 reset_timeout_connection 告诉 nginx 关闭不响应的客户端连接。这将会释放那个客户端所占有的内存空间 send_timeout 响应客户端超时时间，这个超时时间仅限于两个活动之间的时间，如果超过这个时间，客户端没有任何活动，nginx 关闭连接 server_tokens 并不会让 nginx 执行的速度更快，但它可以关闭在错误页面中的 nginx 版本数字，这样对于安全性是有好处的 client_max_body_size 上传文件大小限制 ¶（7）fastcgi 调优 1234567891011# 接上个位置继续写 fastcgi_connect_timeout 600; fastcgi_send_timeout 600; fastcgi_read_timeout 600; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; fastcgi_temp_path /usr/local/nginx1.10/nginx_tmp; fastcgi_intercept_errors on; fastcgi_cache_path /usr/local/nginx1.10/fastcgi_cache levels=1:2 keys_zone=cache_fastcgi:128m inactive=1d max_size=10g; Cache： 写入缓存区 Buffer： 读取缓存区 Fastcgi 是静态服务和动态服务的一个接口 fastcgi_connect_timeout 600; 指定连接到后端 FastCGI 的超时时间 fastcgi_send_timeout 600; 向 FastCGI 传送请求的超时时间 fastcgi_read_timeout 600; 指定接收 FastCGI 应答的超时时间 fastcgi_buffer_size 64k; 指定读取 FastCGI 应答第一部分需要用多大的缓冲区，默认的缓冲区大小为 fastcgi_buffers 指令中的每块大小，可以将这个值设置更小 fastcgi_buffers 4 64k; 指定本地需要用多少和多大的缓冲区来缓冲 FastCGI 的应答请求，如果 一个 php 脚本所产生的页面大小为 256KB，那么会分配 4 个 64KB 的缓冲区来缓存，如果页面大小大于 256KB，那么大于 256KB 的部分会缓存到 fastcgi_temp_path 指定的路径中，但是这并不是好方法，因为内存中的数据处理速度要快于磁盘。一般这个值应该为站点中 php脚本所产生的页面大小的中间值，如果站点大部分脚本所产生的页面大小为 256KB，那么可以把这个值设置为“8 32K”、“4 64k”等 fastcgi_busy_buffers_size 128k; 建议设置为 fastcgi_buffers 的两倍，繁忙时候的 buffer fastcgi_temp_file_write_size 128k; 在写入 fastcgi_temp_path 时将用多大的数据块，默认值是 fastcgi_buffers 的两倍，该数值设置小时若负载上来时可能报 502 Bad Gateway fastcgi_temp_path 缓存临时目录 fastcgi_intercept_errors on; 这个指令指定是否传递 4xx 和 5xx 错误信息到客户端，或者允许nginx 使用 error_page 处理错误信息 注：静态文件不存在会返回 404 页面，但是 php 页面则返回空白页！！ fastcgi_cache_path /usr/local/nginx1.10/fastcgi_cache levels=1:2 keys_zone=cache_fastcgi:128minactive=1d max_size=10g; fastcgi_cache 缓存目录，可以设置目录层级，比如 1:2 会生成 16*256 个子目录，cache_fastcgi 是这个缓存空间的名字，cache 是用多少内存（这样热门的 内容 nginx 直接放内存，提高访问速度），inactive 表示默认失效时间，如果缓存数据在失效 时间内没有被访问,将被删除，max_size 表示最多用多少硬盘空间 fastcgi_cache cache_fastcgi; 表示开启 FastCGI 缓存并为其指定一个名称。开启缓存非常有用，可以有效降低 CPU 的负载，并且防止 502 的错误放生。cache_fastcgi 为 proxy_cache_path指令创建的缓存区名称 fastcgi_cache_valid 200 302 1h; 用来指定应答代码的缓存时间，实例中的值表示将 200 和302 应答缓存一小时，要和 fastcgi_cache 配合使用 fastcgi_cache_valid 301 1d; 将 301 应答缓存一天 fastcgi_cache_valid any 1m; 将其他应答缓存为 1 分钟 fastcgi_cache_min_uses 1; 该指令用于设置经过多少次请求的相同 URL 将被缓存。fastcgi_cache_key http://$host$request_uri; #该指令用来设置web缓存的Key值,nginx根据Key值 md5 哈希存储.一般根据$host(域名)、$request_uri(请求的路径)等变量组合成proxy_cache_key fastcgi_pass 指定 FastCGI 服务器监听端口与地址，可以是本机或者其它 总结： nginx 的缓存功能有：proxy_cache / fastcgi_cache proxy_cache的作用是缓存后端服务器的内容，可能是任何内容，包括静态的和动态 fastcgi_cache的作用是缓存 fastcgi 生成的内容，很多情况是 php 生成的动态的内容 proxy_cache 缓存减少了 nginx 与后端通信的次数，节省了传输时间和后端宽带 fastcgi_cache缓存减少了nginx与php的通信的次数，更减轻了php和数据库(mysql)的压力 ¶（8）gzip调优 使用 gzip 压缩功能，可能为我们节约带宽，加快传输速度，有更好的体验，也为我们节约 成本，所以说这是一个重点 Nginx 启用压缩功能需要你来 ngx_http_gzip_module 模块，apache 使用的是 mod_deflate一般我们需要压缩的内容有：文本，js，html，css，对于图片，视频，flash 什么的不压缩，同时也要注意，我们使用 gzip 的功能是需要消耗 CPU 的！ 1234567gzip on;gzip_min_length 2k;gzip_buffers 4 32k;gzip_http_version 1.1;gzip_comp_level 6; gzip_types text/plain text/css text/javascript application/json application/javascript application/x-javascript application/xml;gzip_vary on;gzip_proxied any; gzip on; 开启压缩功能 gzip_min_length 1k; 设置允许压缩的页面最小字节数，页面字节数从 header 头的Content-Length 中获取，默认值是 0，不管页面多大都进行压缩，建议设置成大于 1K，如果小与 1K 可能会越压越大 gzip_buffers 4 32k; 压缩缓冲区大小，表示申请4个单位为32K的内存作为压缩结果流缓存，默认值是申请与原始数据大小相同的内存空间来存储 gzip 压缩结果 gzip_http_version 1.1; 压缩版本，用于设置识别 HTTP 协议版本，默认是 1.1，目前大部分浏览器已经支持 GZIP 解压，使用默认即可 gzip_comp_level 6; 压缩比例，用来指定 GZIP 压缩比，1 压缩比最小，处理速度最快，9 压缩比最大，传输速度快，但是处理慢，也比较消耗 CPU 资源 gzip_types text/css text/xml application/javascript; 用来指定压缩的类型，‘text/html’类型总是会被压缩 默认值: gzip_types text/html (默认不对 js/css 文件进行压缩) 压缩类型，匹配 MIME 类型进行压缩 不能用通配符 text/* (无论是否指定)text/html 默认已经压缩 设置哪压缩种文本文件可参考 conf/mime.types gzip_vary on; vary header 支持，改选项可以让前端的缓存服务器缓存经过 GZIP 压缩的页面，例如用 Squid 缓存经过 nginx 压缩的数据 ¶（9）expires 缓存调优 缓存，主要针对于图片，css，js 等元素更改机会比较少的情况下使用，特别是图片，占用 带宽大，我们完全可以设置图片在浏览器本地缓存 365d，css，js，html 可以缓存个 10 来天，这样用户第一次打开加载慢一点，第二次，就非常快了！缓存的时候，我们需要将需要缓存的拓展名列出来， Expires 缓存配置在 server 字段里面 1234567891011location ~* \\.(ico|jpe?g|gif|png|bmp|swf|flv)$ &#123; expires 30d; #log_not_found off; access_log off;&#125;location ~* \\.(js|css)$ &#123; expires 7d; log_not_found off; access_log off;&#125; 注：log_not_found off;是否在 error_log 中记录不存在的错误。默认是 总结： expire 功能优点： expires 可以降低网站购买的带宽，节约成本 同时提升用户访问体验 减轻服务的压力，节约服务器成本，是 web 服务非常重要的功能 expire 功能缺点： 被缓存的页面或数据更新了，用户看到的可能还是旧的内容，反而影响用户体验 解决办法： 第一个缩短缓存时间，例如：1 天，但不彻底，除非更新频率大于 1 天； 第二个对缓存的对象改名 网站不希望被缓存的内容： 网站流量统计工具 更新频繁的文件 ¶（10）防盗链 防止别人直接从你网站引用图片等链接，消耗了你的资源和网络流量，那么我们的解决办法 由几种： 水印，品牌宣传，你的带宽，服务器足够 防火墙，直接控制，前提是你知道 IP 来源 防盗链策略 下面的方法是直接给予 404 的错误提示 123456789location ~* ^.+\\.(jpg|gif|png|swf|flv|wma|wmv|asf|mp3|mmf|zip|rar)$ &#123; valid_referers none blocked 192.168.1.20; if ($invalid_referer) &#123; #return 302 http://192.168.1.20/img/nolink.jpg; return 404; break; &#125; access_log off;&#125; ¶（11）内核参数优化 1234567891011121314151617181920212223242526272829303132333435[root@nginx ~]# vim /etc/sysctl.conffs.file-max = 999999net.ipv4.ip_forward = 0net.ipv4.conf.default.rp_filter = 1net.ipv4.conf.default.accept_source_route = 0kernel.sysrq = 0kernel.core_uses_pid = 1net.ipv4.tcp_syncookies = 1kernel.msgmnb = 65536kernel.msgmax = 65536kernel.shmmax = 68719476736kernel.shmall = 4294967296net.ipv4.tcp_max_tw_buckets = 6000net.ipv4.tcp_sack = 1net.ipv4.tcp_window_scaling = 1net.ipv4.tcp_rmem = 10240 87380 12582912net.ipv4.tcp_wmem = 10240 87380 12582912net.core.wmem_default = 8388608net.core.rmem_default = 8388608net.core.rmem_max = 16777216net.core.wmem_max = 16777216net.core.netdev_max_backlog = 262144net.core.somaxconn = 40960net.ipv4.tcp_max_orphans = 3276800net.ipv4.tcp_max_syn_backlog = 262144net.ipv4.tcp_timestamps = 0net.ipv4.tcp_synack_retries = 1net.ipv4.tcp_syn_retries = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_mem = 94500000 915000000 927000000net.ipv4.tcp_fin_timeout = 1net.ipv4.tcp_keepalive_time = 30net.ipv4.ip_local_port_range = 1024 65000[root@nginx ~]# sysctl -p fs.file-max = 999999 这个参数表示进程（比如一个 worker 进程）可以同时打开的最大句柄数，这个参数直线限制最大并发连接数，需根据实际情况配置 net.ipv4.tcp_max_tw_buckets = 6000 这个参数表示操作系统允许 TIME_WAIT 套接字数量的最大值，如果超过这个数字，TIME_WAIT 套接字将立刻被清除并打印警告信息。该参数默认为 180000，过多的TIME_WAIT 套接字会使 Web 服务器变慢 注：主动关闭连接的服务端会产生 TIME_WAIT 状态的连接 net.ipv4.ip_local_port_range = 1024 65000 允许系统打开的端口范围 net.ipv4.tcp_tw_recycle = 1 启用 timewait 快速回收 net.ipv4.tcp_tw_reuse = 1 开启重用。允许将 TIME-WAIT sockets 重新用于新的 TCP 连接。这对于服务器来说很有意义，因为服务器上总会有大量 TIME-WAIT 状态的连接 net.ipv4.tcp_keepalive_time = 30 这个参数表示当 keepalive 启用时，TCP 发送 keepalive 消息的频度。默认是 2 小时，若将其设置的小一些，可以更快地清理无效的连接 net.ipv4.tcp_syncookies = 1 开启 SYN Cookies，当出现 SYN 等待队列溢出时，启用 cookies 来处理 net.core.somaxconn = 40960 web 应用中 listen 函数的 backlog 默认会给我们内核参数的net.core.somaxconn 限制到 128，而 nginx 定义的 NGX_LISTEN_BACKLOG 默认为 511，所以有必要调整这个值 注： 对于一个 TCP 连接，Server 与 Client 需要通过三次握手来建立网络连接.当三次手成后,我们可以看到端口的状态由 LISTEN 转变为 ESTABLISHED,接着这条链路上就可以开始传送数据了.每一个处于监听(Listen)状态的端口,都有自己的监听队列.监听队列的长度与如somaxconn 参数和使用该端口的程序中 listen()函数有关 somaxconn参数:定义了系统中每一个端口最大的监听队列的长度,这是个全局的参数,默认值为 128，对于一个经常处理新连接的高负载 web 服务环境来说，默认的 128 太小了。大多数环境这个值建议增加到 1024 或者更多。大的侦听队列对防止拒绝服务 DoS 攻击也会有所帮助 net.core.netdev_max_backlog = 262144 每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目 net.ipv4.tcp_max_syn_backlog = 262144 这个参数标示 TCP 三次握手建立阶段接受 SYN 请求队列的最大长度，默认为 1024，将其设置得大一些可以使出现 Nginx 繁忙来不及 accept 新连接的情况时，Linux 不至于丢失客户端发起的连接请求 net.ipv4.tcp_rmem = 10240 87380 12582912 这个参数定义了 TCP 接受缓存（用于 TCP 接受滑动窗口）的最小值、默认值、最大值 net.ipv4.tcp_wmem = 10240 87380 12582912 这个参数定义了 TCP 发送缓存（用于 TCP 发送滑动窗口）的最小值、默认值、最大值 net.core.rmem_default = 6291456 这个参数表示内核套接字接受缓存区默认的大小 net.core.wmem_default = 6291456 这个参数表示内核套接字发送缓存区默认的大小 net.core.rmem_max = 12582912 这个参数表示内核套接字接受缓存区的最大大小 net.core.wmem_max = 12582912 这个参数表示内核套接字发送缓存区的最大大小 net.ipv4.tcp_syncookies = 1 该参数与性能无关，用于解决 TCP 的 SYN 攻击 ¶（12）关于系统连接数的优化： linux 默认值 open files 为 1024】 说明 server 只允许同时打开 1024 个文件】 使用 ulimit -a 可以查看当前系统的所有限制值，使用 ulimit -n 可以查看当前的最大打开文 件数 新装的 linux 默认只有 1024 ，当作负载较大的服务器时，很容易遇到 error: too many openfiles。因此，需要将其改大 在/etc/security/limits.conf 最后增加： 1234* soft nofile 65535* hard nofile 65535* soft noproc 65535* hard noproc 65535 ¶二、部署LNMP 软件连接 提取码：vzsu ¶1、安装php ¶（1）解决依赖关系 1[root@nginx ~]# yum -y install libxml2-devel libcurl-devel openssl-devel bzip2-devel 安装libmcypt 1[root@nginx libmcrypt-2.5.7]# ./configure --prefix=/usr/local/libmcrypt &amp;&amp; make &amp;&amp; make install ¶（2）编译安装php 123456789[root@nginx ~]# tar zxf php-5.6.27.tar.gz [root@nginx ~]# cd php-5.6.27/[root@nginx php-5.6.27]# ./configure --prefix=/usr/local/php5.6 --with-mysql=mysqlnd \\&gt; --with-pdo-mysql=mysqlnd --with-mysqli=mysqlnd --with-openssl --enable-fpm \\&gt; --enable-sockets --enable-sysvshm --enable-mbstring --with-freetype-dir --with-jpeg-dir \\&gt; --with-png-dir --with-zlib --with-libxml-dir=/usr --enable-xml --with-mhash \\&gt; --with-mcrypt=/usr/local/libmcrypt --with-config-file-path=/etc \\&gt; --with-config-file-scan-dir=/etc/php.d --with-bz2 --enable-maintainer-zts[root@nginx php-5.6.27]# make &amp;&amp; make install ¶（3）提供php配置文件 1[root@nginx php-5.6.27]# cp php.ini-production /etc/php.ini ¶（4）为 php-fpm 提供脚本 1234[root@nginx php-5.6.27]# cp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm[root@nginx php-5.6.27]# chmod +x /etc/init.d/php-fpm [root@nginx php-5.6.27]# chkconfig --add php-fpm[root@nginx php-5.6.27]# chkconfig php-fpm on ¶（5）提供 php-fpm 配置文件并编辑 123456789[root@nginx php-5.6.27]# cp /usr/local/php5.6/etc/php-fpm.conf.default /usr/local/php5.6/etc/php-fpm.conf[root@nginx php-5.6.27]# vim /usr/local/php5.6/etc/php-fpm.conf# 修改内容如下pid = run/php-fpm.pidlisten = 0.0.0.0:9000pm.max_children = 50pm.start_servers = 5pm.min_spare_servers = 5pm.max_spare_servers = 35 启动php-fpm服务 12345678[root@nginx php-5.6.27]# service php-fpm startStarting php-fpm done[root@nginx php-5.6.27]# netstat -anpt | grep php-fpmtcp 0 0 0.0.0.0:9000 0.0.0.0:* LISTEN 125567/php-fpm: mas[root@nginx ~]# firewall-cmd --permanent --add-port=9000/tcpsuccess[root@nginx ~]# firewall-cmd --reloadSuccess 在 nginx.conf 文件的 server 中添加下面内容支持 php 12345678910111213141516171819[root@nginx ~]# vim /usr/local/nginx1.10/conf/nginx.conf location / &#123; root html; index index.php index.html index.htm; &#125; location ~ .*\\.(php|php5)?$ &#123; root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; fastcgi_cache cache_fastcgi; fastcgi_cache_valid 200 302 1h; fastcgi_cache_valid 301 1d; fastcgi_cache_valid any 1m; fastcgi_cache_min_uses 1; fastcgi_cache_use_stale error timeout invalid_header http_500; fastcgi_cache_key http://$host$request_uri; &#125; 重载 nginx 服务 1[root@nginx ~]# nginx -s reload 下面是 nginx.conf 的一个完整配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188[root@nginx ~]# cat /usr/local/nginx1.10/conf/nginx.confuser nginx nginx;worker_processes 2;worker_cpu_affinity 01 10;worker_rlimit_nofile 65535;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; use epoll; worker_connections 65535; multi_accept on;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; sendfile on; tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; tcp_nodelay on; client_header_buffer_size 4k; open_file_cache max=102400 inactive=20s; open_file_cache_valid 30s; open_file_cache_min_uses 1; client_header_timeout 15; client_body_timeout 15; reset_timedout_connection on; send_timeout 15; server_tokens off; client_max_body_size 10m; fastcgi_connect_timeout 600; fastcgi_send_timeout 600; fastcgi_read_timeout 600; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; fastcgi_temp_path /usr/local/nginx1.10/nginx_tmp; fastcgi_intercept_errors on; fastcgi_cache_path /usr/local/nginx1.10/fastcgi_cache levels=1:2 keys_zone=cache_fastcgi:128m inactive=1d max_size=10g; gzip on; gzip_min_length 2k; gzip_buffers 4 32k; gzip_http_version 1.1; gzip_comp_level 6; gzip_types text/plain text/css text/javascript application/json application/javascript application/x-javascript application/xml; gzip_vary on; gzip_proxied any; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location ~* ^.+\\.(jpg|gif|png|swf|flv|wma|wmv|asf|mp3|mmf|zip|rar)$ &#123; valid_referers none blocked 192.168.1.20; if ($invalid_referer) &#123; #return 302 http://192.168.1.20/img/nolink.jpg; return 404; break; &#125; access_log off; &#125; location / &#123; root html; index index.php index.html index.htm; &#125; location ~* \\.(ico|jpe?g|gif|png|bmp|swf|flv)$ &#123; expires 30d; #log_not_found off; access_log off; &#125; location ~* \\.(js|css)$ &#123; expires 7d; log_not_found off; access_log off; &#125; location ~ .*\\.(php|php5)?$ &#123; root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; fastcgi_cache cache_fastcgi; fastcgi_cache_valid 200 302 1h; fastcgi_cache_valid 301 1d; fastcgi_cache_valid any 1m; fastcgi_cache_min_uses 1; fastcgi_cache_use_stale error timeout invalid_header http_500; fastcgi_cache_key http://$host$request_uri; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; ¶三、验证、压力测试 ¶1、验证防盗链 使用httpd做为一个测试站点，192.168.1.30，在测试页上做一个超链接，链接 nginx站点的一张图片 12[root@httpd ~]# vim /var/www/html/index.html&lt;a href=\"http://192.168.1.20/11.gif\"&gt;lianjie&lt;/a&gt; Nginx 站点的网页目录结如下 12345678[root@nginx ~]# tree /usr/local/nginx1.10/html//usr/local/nginx1.10/html/├── 11.gif├── 50x.html├── img│ └── nolink.jpg├── index.html└── test.php 在客户端浏览器中输入192.168.1.30 点击页面链接 将return的404关闭，指定跳转文件 12return 302 http://192.168.1.20/img/nolink.jpg; #return 404; 11.gif图片 nolink.jpg图片 根据防盗链的设置，会跳转到nolink.jpg图片 配置已经生效 ¶2、验证gzip功能 用户访问test.php文件，在上图中content-encoding:gzip表明响应给用户的数据是压缩传输 ¶3、压力测试 安装 httpd-tools 软件包 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[root@nginx ~]# yum -y install httpd-tools[root@nginx ~]# ab -c 500 -n 50000 http://192.168.1.20/index.htmlThis is ApacheBench, Version 2.3 &lt;$Revision: 1430300 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking 192.168.1.20 (be patient)Completed 5000 requestsCompleted 10000 requestsCompleted 15000 requestsCompleted 20000 requestsCompleted 25000 requestsCompleted 30000 requestsCompleted 35000 requestsCompleted 40000 requestsCompleted 45000 requestsCompleted 50000 requestsFinished 50000 requestsServer Software: IISServer Hostname: 192.168.1.20Server Port: 80Document Path: /index.htmlDocument Length: 612 bytesConcurrency Level: 500Time taken for tests: 2.544 secondsComplete requests: 50000Failed requests: 0Write errors: 0Total transferred: 41800000 bytesHTML transferred: 30600000 bytesRequests per second: 19657.71 [#/sec] (mean)Time per request: 25.435 [ms] (mean)Time per request: 0.051 [ms] (mean, across all concurrent requests)Transfer rate: 16048.68 [Kbytes/sec] receivedConnection Times (ms) min mean[+/-sd] median maxConnect: 0 10 3.9 10 20Processing: 9 16 4.0 15 29Waiting: 0 8 1.0 8 12Total: 15 25 1.5 25 36Percentage of the requests served within a certain time (ms) 50% 25 66% 26 75% 26 80% 26 90% 27 95% 28 98% 29 99% 30 100% 36 (longest request) 第二次压力测试，比较两次的差异 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@nginx ~]# ab -c 1000 -n 100000 http://192.168.1.20/index.htmlThis is ApacheBench, Version 2.3 &lt;$Revision: 1430300 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking 192.168.1.20 (be patient)Completed 10000 requestsCompleted 20000 requestsCompleted 30000 requestsCompleted 40000 requestsCompleted 50000 requestsCompleted 60000 requestsCompleted 70000 requestsCompleted 80000 requestsCompleted 90000 requestsCompleted 100000 requestsFinished 100000 requestsServer Software: IISServer Hostname: 192.168.1.20Server Port: 80Document Path: /index.htmlDocument Length: 612 bytesConcurrency Level: 1000Time taken for tests: 5.633 secondsComplete requests: 100000Failed requests: 0Write errors: 0Total transferred: 83600000 bytesHTML transferred: 61200000 bytesRequests per second: 17753.07 [#/sec] (mean)Time per request: 56.328 [ms] (mean)Time per request: 0.056 [ms] (mean, across all concurrent requests)Transfer rate: 14493.71 [Kbytes/sec] receivedConnection Times (ms) min mean[+/-sd] median maxConnect: 0 17 8.0 17 44Processing: 9 39 7.9 39 69Waiting: 0 24 5.4 24 48Total: 28 56 5.9 56 101Percentage of the requests served within a certain time (ms) 50% 56 66% 58 75% 59 80% 60 90% 62 95% 64 98% 68 99% 75 100% 101 (longest request) 第一次：Requests per second: 19657.71 [#/sec] (mean) 第二次：Requests per second: 17753.07 [#/sec] (mean) ¶5、xcache加速php ¶（1）安装 xcache 1234567[root@nginx ~]# wget http://xcache.lighttpd.net/pub/Releases/3.2.0/xcache-3.2.0.tar.gz[root@nginx ~]# tar zxf xcache-3.2.0.tar.gz [root@nginx ~]# cd xcache-3.2.0/# 用 phpize 生成 configure 配置文件[root@nginx xcache-3.2.0]# /usr/local/php5.6/bin/phpize[root@nginx xcache-3.2.0]# ./configure --enable-xcache --enable-xcache-coverager --enable-xcache-optimizer --with-php-config=/usr/local/php5.6/bin/php-config[root@nginx xcache-3.2.0]# make &amp;&amp; make install 安装完成之后，出现下面的界面，记住以下路径，后面会用到 1Installing shared extensions: /usr/local/php5.6/lib/php/extensions/no-debug-zts-20131226/ ¶（2）创建 xcache 缓存文件 12[root@nginx xcache-3.2.0]# touch /tmp/xcache[root@nginx xcache-3.2.0]# chmod 777 /tmp/xcache ¶（3）拷贝xcache后台管理程序到网站根目录 1[root@nginx xcache-3.2.0]# cp -r htdocs/ /usr/local/nginx1.10/html/xcache ¶（4）配置 php 支持 xcache 123456789101112131415161718192021222324252627282930[root@nginx ~]# vim /etc/php.ini# 最后一样添加[xcache-common]extension = /usr/local/php5.6/lib/php/extensions/no-debug-zts-20131226/xcache.so# 注意目录[xcache.admin]xcache.admin.enable_auth = Off[xcache]xcache.shm_scheme =\"mmap\"xcache.size=60Mxcache.count =1xcache.slots =8Kxcache.ttl=0xcache.gc_interval =0xcache.var_size=64Mxcache.var_count =1xcache.var_slots =8Kxcache.var_ttl=0xcache.var_maxttl=0xcache.var_gc_interval =300xcache.test =Offxcache.readonly_protection = Offxcache.mmap_path =\"/tmp/xcache\"xcache.coredump_directory =\"\"xcache.cacher =Onxcache.stat=Onxcache.optimizer =Off[xcache.coverager]xcache.coverager =Onxcache.coveragedump_directory =\"\" ¶6、测试 重启php-fpm 123[root@nginx ~]# service php-fpm restartGracefully shutting down php-fpm . doneStarting php-fpm done 浏览器打开网站根目录下面的 xcache 测试对 php 动态页面的压力测试 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[root@nginx ~]# ab -c 1000 -n 100000 http://192.168.1.20/test.phpThis is ApacheBench, Version 2.3 &lt;$Revision: 1430300 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking 192.168.1.20 (be patient)Completed 10000 requestsCompleted 20000 requestsCompleted 30000 requestsCompleted 40000 requestsCompleted 50000 requestsCompleted 60000 requestsCompleted 70000 requestsCompleted 80000 requestsCompleted 90000 requestsCompleted 100000 requestsFinished 100000 requestsServer Software: IISServer Hostname: 192.168.1.20Server Port: 80Document Path: /test.phpDocument Length: 84586 bytesConcurrency Level: 1000Time taken for tests: 9.496 secondsComplete requests: 100000Failed requests: 0Write errors: 0Total transferred: 8476300000 bytesHTML transferred: 8458600000 bytesRequests per second: 10531.17 [#/sec] (mean)Time per request: 94.956 [ms] (mean)Time per request: 0.095 [ms] (mean, across all concurrent requests)Transfer rate: 871732.00 [Kbytes/sec] receivedConnection Times (ms) min mean[+/-sd] median maxConnect: 0 14 7.4 13 58Processing: 13 81 12.3 81 146Waiting: 2 26 9.2 25 79Total: 35 95 11.7 93 165Percentage of the requests served within a certain time (ms) 50% 93 66% 97 75% 100 80% 103 90% 110 95% 114 98% 124 99% 130 100% 165 (longest request) Requests per second: 10531.17 [#/sec] (mean)","categories":[{"name":"架构","slug":"架构","permalink":"https://pdxblog.top/categories/%E6%9E%B6%E6%9E%84/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://pdxblog.top/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"Nginx反向代理缓存服务器构建","slug":"Nginx反向代理缓存服务器构建","date":"2020-06-10T16:00:00.000Z","updated":"2020-06-11T05:32:37.243Z","comments":true,"path":"Nginx反向代理缓存服务器构建.html","link":"","permalink":"https://pdxblog.top/Nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E7%BC%93%E5%AD%98%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9E%84%E5%BB%BA.html","excerpt":"","text":"¶Nginx反向代理缓存服务器构建 代理服务可简单的分为正向代理和反向代理: 正向代理: 用于代理内部网络对 Internet 的连接请求(如 VPN/NAT),客户端指定代理服务器,并将本来要直接发送给目标Web服务器的HTTP请求先发送到代理服务器上, 然后由代理服务 器去访问 Web 服务器, 并将 Web 服务器的 Response 回传给客户端 反向代理: 与正向代理相反,如果局域网向Internet提供资源,并让Internet上的其他用户可以 访问局域网内资源, 也可以设置一个代理服务器, 它提供的服务就是反向代理. 反向代理服 务器接受来自 Internet 的连接,然后将请求转发给内部网络上的服务器,并将 Response 回传给 Internet 上请求连接的客户端 ¶一、nginx 反向代理：Web 服务器的调度器 ¶1、反向代理方式 反向代理（Reverse Proxy）方式是指以代理服务器来接受客户端的连接请求，然后将请 求转发给网络上的 web 服务器（可能是 apache、nginx、tomcat、iis 等），并将从 web 服务 器上得到的结果返回给请求连接的客户端，此时代理服务器对外就表现为一个服务器 从上图可以看出：反向代理服务器代理网站 Web 服务器接收 Http 请求，对请求进行转发。 而且nginx作为反向代理服务器可以根据用户请求的内容把请求转发给后端不同的web服务 器，例如静动分离，再例如在 nginx 上创建多个虚拟主机，这样就成功的做到了在浏览器中 输入不同域名（url）的时候访问后端的不同 web 服务器或 web 群集 ¶2、反向代理的作用 ¶（1）保护网站安全： 任何来自 Internet 的请求都必须先经过代理服务器 ¶（2）通过配置缓存功能加速 Web 请求： 可以缓存真实 Web 服务器上的某些静态资源，减轻真 实 Web 服务器的负载压力 ¶（3）实现负载均衡： 充当负载均衡服务器均衡地分发请求，平衡集群中各个服务器的负载压力 ¶二、什么是 nginx： ¶1、nginx简介 Nginx 是一款轻量级的网页服务器、反向代理器以及电子邮件代理服务器。因它的稳定性、 丰富的功能集、示例配置文件和低系统资源的消耗而闻名。Nginx（发音同 engine x），它是 由俄罗斯程序员 Igor Sysoev 所开发的。起初是供俄国大型的门户网站及搜索引擎 Rambler （俄语：Рамблер）使用。此软件 BSD-like 协议下发行，可以在 UNIX、GNU/Linux、 BSD、Mac OS X、Solaris，以及 Microsoft Windows 等操作系统中运行 ¶2、Nginx 的应用现状： Nginx 已经在俄罗斯最大的门户网站── Rambler Media（www.rambler.ru）上运行，同时俄 罗斯超过 20%的虚拟主机平台采用 Nginx 作为反向代理服务器 在国内，已经有 淘宝、新浪博客、新浪播客、网易新闻、六间房、56.com、Discuz!、水木 社区、豆瓣、YUPOO、海内、迅雷在线 等多家网站使用 Nginx 作为 Web 服务器或反向代 理服务器 ¶3、Nginx 的核心特点： ¶（1）跨平台： Nginx 可以在大多数 OS 编译运行，而且也有 Windows 的版本 ¶（2）配置异常简单： 非常容易上手 ¶（3）非阻塞、高并发连接： 官方测试能够支撑 5 万并发连接，在实际生产环境中跑到 2～3 万并发连接数。（这得益于 Nginx 使用了最新的 epoll 模型） 注： 对于一个 Web 服务器来说，首先看一个请求的基本过程：建立连接—接收数据—发送数据， 在系统底层看来 ：上述过程（建立连接—接收数据—发送数据）在系统底层就是读写事件。 如果采用阻塞调用的方式，当读写事件没有准备好时，那么就只能等待，当前线程被挂起，等事件准备好了，才能进行读写事件。 如果采用非阻塞调用的方式：事件马上返回，告诉你事件还没准备好呢，过会再来吧。过一 会，再来检查一下事件，直到事件准备好了为止，在这期间，你就可以先去做其它事情，然 后再来看看事件好了没。虽然不阻塞了，但你得不时地过来检查一下事件的状态，你可以做 更多的事情了，但带来的开销也是不小的。非阻塞调用指在不能立刻得到结果之前，该调用 不会阻塞当前线程 ¶（4）事件驱动： 通信机制采用 epoll 模型，支持更大的并发连接 阻塞通过不断检查事件的状态来判断是否进行读写操作，这样带来的开销很大，因此就有 了异步非阻塞的事件处理机制。这 种机制让你可以同时监控多个事件，调用他们是非阻塞的， 但可以设置超时时间，在超时时间之内，如果有事件准备好了，就返回。这种机制解决了上 面阻塞调用与非阻塞调用的两个问题。 以 epoll 模型为例： 当事件没有准备好时，就放入 epoll(队列)里面。如果有事件准备好了， 那么就去处理；当事件没有准备好时，才在 epoll 里面等着。这样，我们就可以并发处理大 量的并发了，当然，这里的并发请求，是指未处理完的请求。线程只有一个，所以同时能处 理的请求当然只有一个了，只是在请求之间进行不断地切换而已，切换也是因为异步事件未 准备好，而主动让出的。这里的切换是没有任何代价，你可以理解为循环处理多个准备好的 事件。 多线程方式相比，这种事件处理方式是有很大的优势的，不需要创建线程，每个请求占用的 内存也很少，没有上下文切换， 事件处理非常的轻量级，并发数再多也不会导致无谓的资 源浪费（上下文切换）。对于 apache 服务器，每个请求会独占一个工作线程，当并发数上到 几千时，就同时有几千的线程在处理请求了。这对操作系统来说，是个不小的挑战：因为线 程带来的内存占用非常大，线程的上下文切换带来的 cpu 开销很大，自然性能就上不 去， 从而导致在高并发场景下性能下降严重 总结：通过异步非阻塞的事件处理机制，Nginx 实现由进程循环处理多个准备好的事件，从 而实现高并发和轻量级 ¶（5）Master/Worker 结构： 一个 master 进程，生成一个或多个 worker 进程 注： Master-Worker 设计模式主要包含两个主要组件 Master 和 Worker，Master 维护着 Worker 队列，将请求下发到多个 Worker 并行执行，Worker 主要进行实际逻辑计算，并将结果返回 给 Maste nginx 采用这种进程模型有什么好处？采用独立的进程，可以让互相之间不会影响，一个进 程退出后，其它进程还在工作，服务不会中断，Master 进程则很快重新启动新的 Worker进程。当然，Worker 进程的异常退出，肯定是程序有 bug 了，异常退出，会导致当前 Worker 上的所有请求失败，不过不会影响到所有请求，所以降低了风险 ¶（6）内存消耗小： 处理大并发的请求内存消耗非常小。在 3 万并发连接下，开启的 10 个 Nginx 进程才消耗 150M 内存（15M*10=150M） ¶（7）内置的健康检查功能： 如果 Nginx 代理的后端的某台 Web 服务器宕机了，不会影响 前端访问 ¶（8）节省带宽： 支持 GZIP 压缩，可以添加浏览器本地缓存的 Header 头 ¶（9）稳定性高： 用于反向代理，宕机的概率微乎其微 ¶三、Nginx+apache构筑 Web 服务器集群的负载均衡 nginx 配置反向代理 配置 nginx 作为反向代理和负载均衡，同时利用其缓存功能，将静态页面在 nginx 缓存，以达到降低后端服务器连接数的目的并检查后端 web 服务器的健康状况 ¶1、安装nginx 环境： OS centos7.5 nginx 192.168.1.20 apache1 192.168.1.30 apache2 192.168.1.40 ¶（1）安装 zlib-devel、pcre-devel 等依赖包 1[root@nginx ~]# yum -y install gcc gcc-c++ make libtool zlib zlib-devel pcre pcre-devel opensll openssl-devel 注： 结合 proxy 和 upstream 模块实现后端 web 负载均衡 使用 proxy 模块实现静态文件缓存 结合 nginx 默认自带的 ngx_http_proxy_module 模块和ngx_http_upstream_module 模块实现后端服务器的健康检查，也可以使用第三方模块 nginx_upstream_check_module 使用 nginx-sticky-module 扩展模块实现 Cookie 会话黏贴（保持会话） 使用 ngx_cache_purge 实现更强大的缓存清除功能 上面提到的 2 个模块都属于第三方扩展模块，需要提前下好源码，然后编译时通过–add-moudle=src_path 一起安装 ¶（2）安装nginx 添加nginx组 1[root@nginx ~]# groupadd nginx 创建nginx的运行账户nginx，加入到nginx组中，不允许nginx直接登录系统 1[root@nginx ~]# useradd -g nginx nginx -s /sbin/nologin 所需要的软件包 nginx-1.14.0.tar.gz ngx_cache_purge-2.3.tar.gz nginx-sticky-module.zip 软件链接 提取码：tfax 12345678910111213[root@nginx ~]# tar zxf nginx-1.14.0.tar.gz -C /usr/src/[root@nginx ~]# tar zxf ngx_cache_purge-2.3.tar.gz -C /usr/src/[root@nginx ~]# unzip nginx-sticky-module.zip -d /usr/src/[root@nginx ~]# cd /usr/src/nginx-1.14.0/[root@nginx nginx-1.14.0]# ./configure --prefix=/usr/local/nginx1.14 \\&gt; --user=nginx --group=nginx --with-http_stub_status_module \\&gt; --with-http_realip_module --with-http_ssl_module --with-http_gzip_static_module \\&gt; --http-client-body-temp-path=/var/tmp/nginx/client \\&gt; --http-proxy-temp-path=/var/tmp/nginx/proxy \\&gt; --http-fastcgi-temp-path=/var/tmp/nginx/fcgi --with-pcre --with-http_flv_module \\&gt; --add-module=/usr/src/nginx-sticky-module \\&gt; --add-module=/usr/src/ngx_cache_purge-2.3[root@nginx nginx-1.14.0]# make &amp;&amp; make install 注：nginx 的所有模块必须在编译的时候添加，不能再运行的时候动态加载 相关参数解释： –with-http-stub-status-module： 通过网页监控nginx的状态 –with-http-realip-module： 获取客户端的真实IP地址 –with-http-ssl module： 开启nginx的加密传输功能 –with-httpgzipstaticmodule： 开启压缩功能 –http-client-body-temp-path=/var/tmp/nginx/client： 客户端访问数据临吁存放路径 –with-pcre： 支持正则匹配表达式 –add-module=/usr/src/ngx_cache_purge-2.3： 添加nginx的第三方模块语法为—add-module=第三方模块路径 –with-http flv module： 支持flv视频流 ¶2、优化 nginx 程序的执行路径 12345[root@nginx nginx-1.14.0]# ln -s /usr/local/nginx1.14/sbin/nginx /usr/local/sbin/[root@nginx nginx-1.14.0]# nginx -tnginx: the configuration file /usr/local/nginx1.14/conf/nginx.conf syntax is oknginx: [emerg] mkdir() \"/var/tmp/nginx/client\" failed (2: No such file or directory)nginx: configuration file /usr/local/nginx1.14/conf/nginx.conf test failed 这里会报错，根据提示创建相应的目录即可 12345[root@nginx nginx-1.14.0]# mkdir -p /var/tmp/nginx/client[root@nginx nginx-1.14.0]# chown -R nginx:nginx /var/tmp/nginx/[root@nginx nginx-1.14.0]# nginx -tnginx: the configuration file /usr/local/nginx1.14/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx1.14/conf/nginx.conf test is successful ¶3、编写nginx服务脚本 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364[root@nginx ~]# cat /etc/init.d/nginx #!/bin/bash # chkconfig: 2345 99 20 # description: Nginx Service Control Script PROG=\"/usr/local/nginx1.14/sbin/nginx\"PIDF=\"/usr/local/nginx-1.14/logs/nginx.pid\"case \"$1\" in start) netstat -anplt |grep \":80\" &amp;&gt; /dev/null &amp;&amp; pgrep \"nginx\" &amp;&gt; /dev/null if [ $? -eq 0 ] then echo \"Nginx service already running.\" else $PROG -t &amp;&gt; /dev/null if [ $? -eq 0 ] ; then $PROG echo \"Nginx service start success.\" else $PROG -t fi fi ;; stop) netstat -anplt |grep \":80\" &amp;&gt; /dev/null &amp;&amp; pgrep \"nginx\" &amp;&gt; /dev/nul if [ $? -eq 0 ] then kill -s QUIT $(cat $PIDF) echo \"Nginx service stop success.\" else echo \"Nginx service already stop\" fi ;; restart) $0 stop $0 start ;; status) netstat -anplt |grep \":80\" &amp;&gt; /dev/null &amp;&amp; pgrep \"nginx\" &amp;&gt; /dev/null if [ $? -eq 0 then echo \"Nginx service is running.\" else echo \"Nginx is stop.\" fi ;; reload) netstat -anplt |grep \":80\" &amp;&gt; /dev/null &amp;&amp; pgrep \"nginx\" &amp;&gt; /dev/nul if [ $? -eq 0 ] then $PROG -t &amp;&gt; /dev/null if [ $? -eq 0 ] ; then kill -s HUP $(cat $PIDF) echo \"reload Nginx config success.\" else $PROG -t fi else echo \"Nginx service is not run.\" fi ;; *) echo \"Usage: $0 &#123;start|stop|restart|reload&#125;\" exit 1esac 测试脚本是否能用： 1234567[root@nginx ~]# chmod +x /etc/init.d/nginx [root@nginx ~]# chkconfig --add nginx[root@nginx ~]# chkconfig nginx on[root@nginx ~]# /etc/init.d/nginx startNginx service start success.[root@nginx ~]# netstat -anput | grep 80tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 6162/nginx: master 注：如果你想在已安装好的 nginx 上添加第三方模块，依然需要重新编译，但为了不覆盖你原有的配置，请不要 make install，而是直接拷贝可执行文件： 1234567[root@localhost nginx-1.14.0]#./configure --add-module=…… #你的第三方模块[root@localhost nginx-1.14.0]# make 后不要 make install,改为手动拷贝，先备份[root@localhost nginx-1.14.0]# cp /usr/local/nginx-1.14/sbin/nginx /usr/local/nginx-1.14/sbin/nginx.bak[root@localhost nginx-1.14.0]# cp objs/nginx /usr/local/nginx-1.14/sbin/nginx ¶四、开启nginx网页界面认证 ¶1、安装httpd-tools软件包 1[root@nginx ~]# yum -y install httpd-tools ¶2、使用htppasswd命令生成账号密码 1234[root@nginx ~]# /usr/bin/htpasswd -c /usr/local/nginx1.14/nginx.passwd adminNew password: Re-type new password: Adding password for user admin ¶3、添加配置文件： 1234567[root@nginx ~]# vim /usr/local/nginx1.14/conf/nginx.conf location /auth &#123; root html; index index.html index.htm; auth_basic \"提示语句\"; auth_basic_user_file /usr/local/nginx1.14/nginx.passwd; &#125; ¶4、创建文件夹及网页 123[root@nginx ~]# mkdir /usr/local/nginx1.14/auth[root@nginx ~]# cat /usr/local/nginx1.14/auth/index.htmlThis is a test file! ¶5、重载nginx，访问测试 [root@nginx ~]# nginx -s reload 输入用户名密码就可以访问了 ¶五、配置 nginx 反向代理：反向代理+负载均衡+健康探测 查看 nginx 加载的模块 123456[root@nginx ~]# nginx -Vnginx version: nginx/1.14.0built by gcc 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017TLS SNI support enabledconfigure arguments: --prefix=/usr/local/nginx1.14 --user=nginx --group=nginx --with-http_stub_status_module --with-http_realip_module --with-http_ssl_module --with-http_gzip_static_module --http-client-body-temp-path=/var/tmp/nginx/client --http-proxy-temp-path=/var/tmp/nginx/proxy --http-fastcgi-temp-path=/var/tmp/nginx/fcgi --with-pcre --with-http_flv_module --add-module=/usr/src/nginx-sticky-module --add-module=/usr/src/ngx_cache_purge-2.3 nginx 的所有模块必须在编译的时候添加，不能再运行的时候动态加载 ¶1、nginx-sticky-module 模块： 这个模块的作用是通过 cookie 黏贴的方式将来自同一个客户端（浏览器）的请求发送到同一个后端服务器上处理，这样一定程度上可以解决多个 backend servers 的 session 同步的问题 —— 因为不再需要同步，而 RR 轮询模式必须要运维人员自己考虑 session 同步的实现另外内置的 ip_hash 也可以实现根据客户端 IP 来分发请求，但它很容易造成负载不均衡的情况，而如果 nginx 前面有 CDN 网络或者来自同一局域网的访问，它接收的客户端 IP 是一样的，容易造成负载不均衡现象。nginx-sticky-module 的 cookie 过期时间，默认浏览器关闭就过期 这个模块并不合适不支持 Cookie 或手动禁用了 cookie 的浏览器，此时默认 sticky 就会切换成 RR。它不能与 ip_hash 同时使用 12345upstream backend &#123; server 192.168.31.141:80 weight=1; server 192.168.31.250:80 weight=1; sticky; &#125; 配置起来超级简单，一般来说一个 sticky 指令就够了 相关信息可以查看官方文档 ¶2、load-balance 其它调度方案： 这里顺带介绍一下 nginx 的负载均衡模块支持的其它调度算法： 轮询（默认）： 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某台服务器宕机，故障系统被自动剔除，使用户访问不受影响。Weight 指定轮询权值，Weight 值越大，分配到的访问机率越高，主要用于后端每个服务器性能不均的情况下 ip_hash ： 每个请求按访问 IP 的 hash 结果分配，这样来自同一个 IP 的访客固定访问一个后端服务器，有效解决了动态网页存在的 session 共享问题。当然如果这个节点不可用了，会发到下个节点，而此时没有 session 同步的话就注销掉了 least_conn ： 请求被发送到当前活跃连接最少的 realserver 上。会考虑 weight 的值 url_hash： 此方法按访问 url 的 hash 结果来分配请求，使每个 url 定向到同一个后端服务器，可以进一步提高后端缓存服务器的效率。Nginx 本身是不支持 url_hash 的，如果需要使用这种调度算法，必须安装 Nginx 的 hash 软件包 nginx_upstream_hash fair： 这是比上面两个更加智能的负载均衡算法。此种算法可以依据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。Nginx 本身是不支持 fair 的，如果需要使用这种调度算法，必须下载 Nginx 的upstream_fair 模块 ¶3、负载均衡与健康检查： 严格来说，nginx 自带是没有针对负载均衡后端节点的健康检查的，但是可以通过默认自带的 ngx_http_proxy_module 模块和 ngx_http_upstream_module 模块中的相关指令来完成当后端节点出现故障时，自动切换到下一个节点来提供访问 修改配置文件：（vim /usr/local/nginx-1.14/conf/nginx.config） 123456789101112131415161718# http模块下添加upstream backend &#123; server 192.168.1.30:80 max_fails=2 fail_timeout=10s; server 192.168.1.40:80 max_fails=2 fail_timeout=10s; sticky;&#125;# location模块添加 location / &#123; root html; index index.html index.htm; proxy_pass http://backend; &#125;[root@nginx ~]# nginx -s reload[root@nginx ~]# curl 127.0.0.1apache1[root@nginx ~]# curl 127.0.0.1apache2# 访问nginx服务器，nginx就代理了后端两台apache服务，并进行轮询 weight ： 轮询权值也是可以用在 ip_hash 的，默认值为 1 max_fails ： 允许请求失败的次数，默认为 1。当超过最大次数时，返回proxy_next_upstream 模块定义的错误 fail_timeout ： 有两层含义，一是在 10s 时间内最多容许 2 次失败；二是在经历了 2 次 失败以后，10s 时间内不分配请求到这台服务器 ¶4、nginx的proxy缓存的使用 缓存也就是将 js、css、image 等静态文件从后端服务器缓存到 nginx 指定的缓存目录下，既可以减轻后端服务器负担，也可以加快访问速度，但这样缓存及时清理成为了一个问题，所以需要 ngx_cache_purge 这个模块来在过期时间未到之前，手动清理缓存 proxy 模块中常用的指令是 proxy_pass 和 proxy_cache nginx 的 web 缓存功能的主要是由 proxy_cache、fastcgi_cache 指令集和相关指令集完成， proxy_cache 指令负责反向代理缓存后端服务器的静态内容，fastcgi_cache 主要用来处理 FastCGI 动态进程缓存 在配置文件中添加修改：注：在添加文件前请查看文件中是否有，如果没有再添加 123456789101112131415161718192021222324252627282930313233 log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log logs/access.log main; proxy_buffering on; proxy_temp_path /usr/local/nginx1.14/proxy_temp; proxy_cache_path /usr/local/nginx1.14/proxy_cache levels=1:2 keys_zone=my-cache:100m inactive=600m max_size=2g; location ~/purge(/.*) &#123; allow 127.0.0.1; allow 192.168.1.0/24; deny all; proxy_cache_purge my-cache $host$1$is_args$args; &#125; location / &#123; root html; index index.html index.htm; proxy_pass http://backend; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout invalid_header http_500 http_502 http_504; proxy_cache my-cache; add_header Nginx-Cache $upstream_cache_status; proxy_cache_valid 200 304 301 302 8h; proxy_cache_valid 404 1m; proxy_cache_valid any 1d; proxy_cache_key $host$uri$is_args$args; &#125;[root@nginx ~]# nginx -s reload 相关选项说明： proxy_buffering on： 代理的时候，开启或关闭缓冲后端服务器的响应 当开启缓冲时，nginx 尽可能快地从被代理的服务器接收响应，再将它存入缓冲区中 proxy_temp_path： 缓存临时目录。后端的响应并不直接返回客户端，而是先写到一个临 时文件中，然后被 rename 一下当做缓存放在 proxy_cache_path 。0.8.9 版本以后允许 temp 和 cache 两个目录在不同文件系统上（分区），然而为了减少性能损失还是建议把它们设成 一个文件系统上 proxy_cache_path： 设置缓存目录，目录里的文件名是 cache_key 的 MD5 值。 levels=1:2 keys_zone=my-cache:50m 表示采用 2 级目录结构，第一层目录只有一个字符，是 由levels=1:2设置，总共二层目录，子目录名字由二个字符组成。Web缓存区名称为my-cache， 内存缓存空间大小为 100MB，这个缓冲 zone 可以被多次使用。文件系统上看到的缓存文件 名类似于 /usr/local/nginx1.14/proxy_cache/c/29/b7f54b2df7773722d382f4809d65029c 。 inactive=600 max_size=2g 表示 600 分钟没有被访问的内容自动清除，硬盘最大缓存空间为 2GB，超过这个大学将清除最近最少使用的数据 proxy_cache： 用前面定义的缓存区 my-cache proxy_cache_key： 定义如何生成缓存的键，设置 web 缓存的 key 值，nginx 根据 key 值 md5 哈希存储缓存 proxy_cache_valid： 为不同的响应状态码设置不同的缓存时间，比如 200、302 等正常结果 可以缓存的时间长点，而 404、500 等缓存时间设置短一些，这个时间到了文件就会过期， 而不论是否刚被访问过 add_header： 指令来设置 response header, 语法: add_header name value; $upstream_cache_status： 这个变量来显示缓存的状态，我们可以在配置中添加一个 http 头来显示这一状态 $upstream_cache_status 包含以下几种状态： 123456789MISS 未命中，请求被传送到后端HIT 缓存命中EXPIRED 缓存已经过期请求被传送到后端 UPDATING 正在更新缓存，将使用旧的应答 STALE 后端将得到过期的应答 expires： 在响应头里设置 Expires:或 Cache-Control:max-age，返回给客户端的浏览器缓存失 效时间 ¶5、访问测试 查看这个文件，里面就有了缓存文件 123[root@nginx ~]# ll /usr/local/nginx1.14/proxy_cache/d/a0/总用量 4-rw-------. 1 nginx nginx 622 6月 11 11:22 d5bd6fad23957bb6e6023525d18aba0d 如果在缓存时间之内需要更新被缓存的静态文件怎么办呢，这时候就需要手动来清除缓存了 浏览器访问 192.168.1.20/purge/来清除缓存 备注： purge 是 ngx_cache_pure 模块指令 index.html是要清除的缓存文件 URL 路径 缓存数据已经没有了 12[root@nginx ~]# ll /usr/local/nginx1.14/proxy_cache/d/a0/总用量 0 ¶六、开启gzip压缩输出，减少网络传输 123456789101112131415161718192021 #keepalive_timeout 0; keepalive_timeout 65; gzip on; gzip_comp_level 6; gzip_http_version 1.1; gzip_proxied any; gzip_min_length 1k; gzip_buffers 16 8k; gzip_types text/plain text/css text/javascript application/json application/javascript application/x-javascript application/xml; gzip_vary on; client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 75; proxy_send_timeout 75; proxy_read_timeout 75; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k;[root@nginx ~]# nginx -s reload 相关解释： proxy_busy_buffers_size 64k： 高负荷下缓冲大小（默认大小是 proxy_buffers 指令设置单块缓冲大小的 2 倍） proxy_temp_file_write_size 64k ： 当缓存被代理的服务器响应到临时文件时，这个选项限制每次写临时文件的大小 gzip on : 开启 gzip 压缩输出，减少网络传输 gzip_min_length 1k： 置允许压缩的页面最小字节数，页面字节数从 header 头得 content-length 中进行获取。建议设置成大于 1k 的字节数，小于 1k 可能会越压越大 gzip_buffers 16 8k： 设置系统获取几个单位的缓存用于存储 gzip 的压缩结果数据流。16 8k 代表以8k 为单位，按照原始数据大小以 8k 为单位的16倍申请内存。如果没有设置，默认值是申请跟原始数据相同大小的内存空间去存储 gzip 压缩结果 gzip_http_version 1.1： 用于识别 http 协议的版本，早期的浏览器不支持 Gzip 压缩，用户 就会看到乱码，所以为了支持前期版本加上了这个选项，如果你用了 Nginx 的反向代理并 期望也 启用 Gzip 压缩的话，由于末端通信是 http/1.1，故请设置为 1.1 gzip_comp_level 6： gzip 压缩比，1 压缩比最小处理速度最快，9 压缩比最大但处理速度最 慢(传输快但比较消耗 cpu) gzip_types： 匹配 mime 类型进行压缩，无论是否指定”text/html”类型总是会被压缩的。 默认值: gzip_types text/html (默认不对 js/css 文件进行压缩) 1234567压缩类型，匹配 MIME 类型进行压缩不能用通配符 text&#x2F;*(无论是否指定)text&#x2F;html 默认已经压缩 设置哪压缩种文本文件可参考 conf&#x2F;mime.types gzip_proxied any： Nginx 作为反向代理的时候启用，根据某些请求和应答来决定是否在对 代理请求的应答启用 gzip 压缩，是否压缩取决于请求头中的“Via”字段，指令中可以同时指 定多个不同的参数 意义如下： 1234567891011121314151617off – 关闭所有的代理结果数据的压缩expired – 启用压缩，如果 header 头中包含 “Expires” 头信息no-cache – 启用压缩，如果 header 头中包含 “Cache-Control:no-cache” 头信息no-store – 启用压缩，如果 header 头中包含 “Cache-Control:no-store” 头信息private – 启用压缩，如果 header 头中包含 “Cache-Control:private” 头信息no_last_modified – 启用压缩,如果 header 头中不包含 “Last-Modified” 头信息no_etag – 启用压缩 ,如果 header 头中不包含 “ETag” 头信息auth – 启用压缩 , 如果 header 头中包含 “Authorization” 头信息any – 无条件启用压缩 gzip_vary on： 和 http 头有关系，加个 vary 头，给代理服务器用的，有的浏览器支持压缩， 有的不支持，所以避免浪费不支持的也压缩，所以根据客户端的 HTTP 头来判断，是否需要压缩 将httpd服务的网页制造大点，访问测试： ¶七、开启br压缩 12[root@nginx ~]# tar zxf ngx_brotli.tar.gz -C /usr/src/[root@nginx ~]# cd /usr/src/nginx-1.14.0/ ¶1、使用nginx -V查看编译时的信息 123456[root@nginx nginx-1.14.0]# nginx -Vnginx version: nginx/1.14.0built by gcc 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017TLS SNI support enabledconfigure arguments: --prefix=/usr/local/nginx1.14 --user=nginx --group=nginx --with-http_stub_status_module --with-http_realip_module --with-http_ssl_module --with-http_gzip_static_module --http-client-body-temp-path=/var/tmp/nginx/client --http-proxy-temp-path=/var/tmp/nginx/proxy --http-fastcgi-temp-path=/var/tmp/nginx/fcgi --with-pcre --with-http_flv_module --add-module=/usr/src/nginx-sticky-module --add-module=/usr/src/ngx_cache_purge-2.3 ¶2、进行编译 最后加上--add-module=/usr/src/ngx_brotli即可 12[root@nginx nginx-1.14.0]# ./configure --prefix=/usr/local/nginx1.14 --user=nginx --group=nginx --with-http_stub_status_module --with-http_realip_module --with-http_ssl_module --with-http_gzip_static_module --http-client-body-temp-path=/var/tmp/nginx/client --http-proxy-temp-path=/var/tmp/nginx/proxy --http-fastcgi-temp-path=/var/tmp/nginx/fcgi --with-pcre --with-http_flv_module --add-module=/usr/src/nginx-sticky-module --add-module=/usr/src/ngx_cache_purge-2.3 --add-module=/usr/src/ngx_brotli[root@nginx nginx-1.14.0]# make # 不要make install ¶3、将新的nginx命令文件替换旧的 替换前先做个备份 12[root@nginx nginx-1.14.0]# mv /usr/local/nginx1.14/sbin/nginx /usr/local/nginx1.14/sbin/nginx.bak[root@nginx nginx-1.14.0]# cp objs/nginx /usr/local/nginx1.14/sbin/ ¶4、重启nginx 12[root@nginx nginx-1.14.0]# nginx -s stop[root@nginx nginx-1.14.0]# nginx ¶5、添加配置文件内容 1234567891011[root@nginx ~]# vim /usr/local/nginx1.14/conf/nginx.conf #keepalive_timeout 0; keepalive_timeout 65; brotli on; brotli_types text/plain text/css text/xml application/xml application/json ; brotli_static off; brotli_comp_level 11; brotli_buffers 16 8k; brotli_window 512k; brotli_min_length 20;[root@nginx ~]# nginx -s reload 相关参数解释： brotli_static off; 否允许查找预处理好的、以.br结尾的压缩 件,可inyon off always brotli_comp_level 11; 压缩级别 brotli_buffers 16 8k; 读取缓冲区数量和大小 brotli_window 512k; 滑动窗口大小 brotli_min_length 20; 指定压缩数据的最小字节 ¶6、访问测试 123456789101112[root@nginx ~]# curl -I -H \"Accept-Encoding: gzip, deflate,br\" 127.0.0.1HTTP/1.1 200 OKServer: nginx/1.14.0Date: Thu, 11 Jun 2020 04:01:16 GMTContent-Type: text/html; charset=UTF-8Connection: keep-aliveVary: Accept-EncodingSet-Cookie: route=617ff1b025324ae95a8a4e10c70854c9; Path=/Last-Modified: Thu, 11 Jun 2020 03:46:40 GMTETag: W/\"1cb0-5a7c6cef388ea\"Nginx-Cache: MISSContent-Encoding: br ¶八、nginx完整配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188[root@nginx ~]# cat /usr/local/nginx1.14/conf/nginx.confuser nginx nginx;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream;upstream backend &#123; server 192.168.1.30:80 max_fails=2 fail_timeout=10s; server 192.168.1.40:80 max_fails=2 fail_timeout=10s; sticky;&#125; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log logs/access.log main; proxy_buffering on; proxy_temp_path /usr/local/nginx1.14/proxy_temp; proxy_cache_path /usr/local/nginx1.14/proxy_cache levels=1:2 keys_zone=my-cache:100m inactive=600m max_size=2g; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; brotli on; brotli_types text/plain text/css text/xml application/xml application/json ; brotli_static off; brotli_comp_level 11; brotli_buffers 16 8k; brotli_window 512k; brotli_min_length 20; gzip on; gzip_comp_level 6; gzip_http_version 1.1; gzip_proxied any; gzip_min_length 1k; gzip_buffers 16 8k; gzip_types text/plain text/css text/javascript application/json application/javascript application/x-javascript application/xml; gzip_vary on; client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 75; proxy_send_timeout 75; proxy_read_timeout 75; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; #proxy_buffering on; #proxy_temp_path /usr/local/nginx1.14/proxy_temp; #proxy_cache_path /usr/local/nginx1.14/proxy_cache levels=1:2 keys_zone=my-cache:100m inactive=600m max_size=2g; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location ~/purge(/.*) &#123; allow 127.0.0.1; allow 192.168.1.0/24; deny all; proxy_cache_purge my-cache $host$1$is_args$args; &#125; location / &#123; root html; index index.html index.htm; proxy_pass http://backend; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout invalid_header http_500 http_502 http_504; proxy_cache my-cache; add_header Nginx-Cache $upstream_cache_status; proxy_cache_valid 200 304 301 302 8h; proxy_cache_valid 404 1m; proxy_cache_valid any 1d; proxy_cache_key $host$uri$is_args$args; &#125; location /index.html &#123; root html; index index.html index.htm; &#125; location /auth &#123; root html; index index.html index.htm; auth_basic \"提示语句\"; auth_basic_user_file /usr/local/nginx1.14/nginx.passwd; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; ¶九、扩展知识 nginx 修改版本等信息 ¶1、更改ngnix显示版本 编译前编辑 12345[root@nginx ~]# vim /usr/src/nginx-1.14.0/src/core/nginx.h#define nginx_version#define NGINX_VERSION#define NGINX_VER#define NGINX_VAR 修改上面的信息，即可更改 nginx 显示版本 ¶2、自定义信息 编译前编辑 12345[root@nginx ~]# vim /usr/src/nginx-1.14.0/src/http/ngx_http_special_response.cstatic u_char ngx_http_error_full_tail[] =static u_char ngx_http_error_tail[] =[root@nginx ~]# vim /usr/src/nginx-1.14.0/src/http/ngx_http_header_filter_module.cstatic char ngx_http_server_string[]= 修改上面的信息为你自己的 ¶3、修改nginx版本名称 编译完成后修改/usr/local/nginx1.14/conf/目录下面 fastcgi.conf、fastcgi.conf.default、fastcgi_params、fastcgi_params.default这四个文件里面的版本名称 查看 nginx 版本号 1[root@nginx ~]# nginx -v","categories":[{"name":"架构","slug":"架构","permalink":"https://pdxblog.top/categories/%E6%9E%B6%E6%9E%84/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://pdxblog.top/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"Apache之FCGI模式部署LAMP","slug":"Apache之FCGI模式部署LAMP","date":"2020-06-09T16:00:00.000Z","updated":"2020-06-10T10:56:08.038Z","comments":true,"path":"Apache之FCGI模式部署LAMP.html","link":"","permalink":"https://pdxblog.top/Apache%E4%B9%8BFCGI%E6%A8%A1%E5%BC%8F%E9%83%A8%E7%BD%B2LAMP.html","excerpt":"","text":"¶FCGI模式编译安装 LAMP+xcache php 的工作模式： php 在 lamp 环境下共有三种工作模式：CGI 模式、apache 模块、FastCGI 模式。CGI 模式下 运行 PHP，性能不是很好。作为 apache 的模块方式运行，在以前编译安装 lamp 已 经介绍过了。FastCGI 的方式和 apache 模块的不同点在于：FastCGI 方式 PHP 是一处独立的 进程，所有 PHP 子进程都由 PHP 的一个叫作 php-fpm 的组件负责管理；而 apache 模块化方 式运行的 PHP，则是 apache 负责调用 PHP 完成工作。PHP 的 FastCGI 方式性能要比 apache 模块化方式强很多，今天我们以 FastCGI 方式编译安装 lamp FastCGI 工作机制： 首先客户端发起请求，请求分为 2 种，一种是静态请求它可以直接由 Apache 直接响应返回； 另一种是动态的请求，如其中包含中 php 或者 Perl 这种脚本解释性语言，则由 Apache 服务 器通过 fastcgi 协议调用 php 服务器执行并返回给Apache由 Apache返回解释执行后的结果， 如果这个过程中涉及到对数据的操作，此时 php 服务器还会还会通过 mysql 协议调用 mysql 服务器 编译环境及各软件版本： Linux Web服务器 PHP Mysql数据库 xcache Centos7.5 Httpd-2.4.23 php-5.6.27 Mysql5.7 xcache-3.1.0 本文用到的软件连接 提取码：vzsu 主机规划 至少 3 台主机，操作系统都是 centos7.5.网段在 192.168.1.0/24 网关 192.168.1.250 分配如下： 1台httpd服务器（192.168.1.70） 1台php服务器（192.168.1.50） 1台mysql服务器（192.168.1.40） ¶一、编译安装 LAMP 编译安装 apache(请参考前面 apache 的安装） MySQL直接使用脚本意一键安装 ¶FastCGI 方式安装 php ¶1、解决依赖关系 1[root@phpserver ~]# yum -y install libxml2-devel lzip2-devel libcurl-devel libmcrypt-devel openssl-devel bzip2-devel 安装libmcrypt 123[root@phpserver ~]# tar zxf libmcrypt-2.5.7.tar.gz [root@phpserver ~]# cd libmcrypt-2.5.7/[root@phpserver libmcrypt-2.5.7]# ./configure --prefix=/usr/local/libmcrypt &amp;&amp; make &amp;&amp; make install ¶2、编译安装php 123456789[root@phpserver ~]# tar zxf php-5.6.27.tar.gz[root@phpserver ~]# cd php-5.6.27/[root@phpserver php-5.6.27]# ./configure --prefix=/usr/local/php5.6 --with-mysql=mysqlnd \\&gt; --with-pdo-mysql=mysqlnd --with-mysqli=mysqlnd --with-openssl --enable-fpm \\&gt; --enable-sockets --enable-sysvshm --enable-mbstring --with-freetype-dir --with-jpeg-dir \\&gt; --with-png-dir --with-zlib --with-libxml-dir=/usr --enable-xml --with-mhash \\&gt; --with-mcrypt=/usr/local/libmcrypt --with-config-file-path=/etc \\&gt; --with-config-file-scan-dir=/etc/php.d --with-bz2--enable-maintainer-zts[root@phpserver php-5.6.27]# make &amp;&amp; make install 相关选项解释： 123456789101112131415161718192021222324252627282930313233343536373839404142434445--prefix=/usr/local/php5.6：安装位置--with-mysql=mysqlnd：支持 mysql--with-pdo-mysql=mysqlnd：支持 pdo 模块--with-mysqli=mysqlnd：支持 mysqli 模块注：上面的三选项的作用：数据库与 php 不在一个服务器上，指定此种方式，安装数据库 连接驱动--with-openssl：支持 openssl 模块--enable-fpm：支持 fpm 模式--enable-sockets：启用 socket 支持--enable-sysvshm：启用系统共享内存支持--enable-mbstring：多字节字串、像我们的中文就是多字节字串--with-freetype-dir：支持 freetype、就要装 freetype-devel、跟字体相关的、字体解析工具--with-jpeg-dir--with-png-dir注：上面的二选项的作用：处理 jpeg、png 图片的、php 可以动态生成 jpeg 图片--with-zlib：是个压缩库、在互联网传输时用来压缩传输的--with-libxml-dir=/usr：这个 libxml 是用来解析 xml 的、指定/usr 下--enable-xml：支持 xml 的--with-mhash：支持 mhash--with-mcrypt=/usr/local/libmcrypt：libmcrypt-devel 这个程序包所指定的--with-config-file-path=/etc：指定配置文件的存放路径的--with-config-file-scan-dir=/etc/php.d：配置文件扫描路径--with-bz2：支持 BZip2为了支持 apache 的 worker 或 event 这两个 MPM，编译时使用了--enable-maintainer-zts 选项 如果使用 PHP5.3 以上版本，为了链接 MySQL 数据库，可以指定 mysqlnd，这样在本机就不 需要先安装 MySQL 或 MySQL 开发包了。mysqlnd 从 php 5.3 开始可用，可以编译时绑定到它 （而不用和具体的 MySQL 客户端库绑定形成依赖），但从 PHP 5.4 开始它就是默认设置了 ¶3、提供php配置文件 1[root@phpserver php-5.6.27]# cp php.ini-production /etc/php.ini ¶4、为php-fpm提供脚本 1234[root@phpserver php-5.6.27]# cp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm[root@phpserver php-5.6.27]# chmod +x /etc/init.d/php-fpm [root@phpserver php-5.6.27]# chkconfig --add php-fpm[root@phpserver php-5.6.27]# chkconfig php-fpm on ¶5、提供php-fpm配置文件并编辑 123456789[root@phpserver ~]# cp /usr/local/php5.6/etc/php-fpm.conf.default /usr/local/php5.6/etc/php-fpm.conf[root@phpserver ~]# vim /usr/local/php5.6/etc/php-fpm.conf修改内容如下：pid = run/php-fpm.pidlisten = 192.168.1.50:9000pm.max_children = 50pm.start_servers = 5pm.min_spare_servers = 5pm.max_spare_servers = 35 启动php-fpm 12345678[root@phpserver ~]# service php-fpm startStarting php-fpm done[root@phpserver ~]# netstat -anpt | grep php-fpmtcp 0 0 192.168.1.50:9000 0.0.0.0:* LISTEN 114068/php-fpm: mas[root@phpserver ~]# firewall-cmd --permanent --add-port=9000/tcpsuccess[root@phpserver ~]# firewall-cmd --reloadSuccess 在该主机上新建虚拟主机目录用于存放网页文件 1[root@phpserver ~]# mkdir -p /var/www/benet 至此 php 安装配置完毕，下面配置 apache 通过 fastcgi 协议调用 php ¶6、配置 apache(切换到 apache 主机上操作) 在 Apache2.4 以后已经专门有一个模块针对 FastCGI 的实现，此模块为 mod_proxy_fcgi.so， 它其实是作为 mod_proxy.so 模块的扩充，因此，这两个模块都要加载 12345678[root@apache ~]# vim /usr/local/http-2.4.23/conf/httpd.conf去掉一下注释LoadModule proxy_module modules/mod_proxy.soLoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so[root@apache ~]# apachectl restart[root@apache ~]# apachectl -M | grep proxy proxy_module (shared) proxy_fcgi_module (shared) 建立一个目录作为虚拟主机的家目录 1[root@apache ~]# mkdir -p /var/www/benet 编辑主配置文件 httpd.conf，开启虚拟主机 1234567891011[root@apache ~]# vim /usr/local/http-2.4.23/conf/httpd.conf启用 Include conf/extra/httpd-vhosts.confInclude conf/extra/httpd-vhosts.conf # 去掉注释同时定位 AddType；添加下面两行：让 apache 能识别 php 格式的页面 AddType application/x-httpd-php .php AddType application/x-httpd-php-source .phps并且定位至 DirectoryIndex：支持 php 格式的主页&lt;IfModule dir_module&gt; DirectoryIndex index.php index.html&lt;/IfModule&gt;添加 index.php（最好添加在最前面） 配置虚拟主机支持使用 fcgi 12345678910111213141516171819[root@apache ~]# vim /usr/local/http-2.4.23/conf/extra/httpd-vhosts.conf&lt;VirtualHost *:80&gt; ServerAdmin webmaster@benet.com DocumentRoot \"/var/www/benet\" ServerName www.benet.com ServerAlias benet.com ErrorLog \"logs/benet.com-error_log\" CustomLog \"logs/benet.com-access_log\" common ProxyRequests OffProxyPassMatch ^/(.*\\.php(/.*)?)$ fcgi://192.168.1.50:9000/var/www/benet/$1 #&lt;LocationMatch \"^(.*\\.php(/.*)?)$\"&gt; # ProxyPass fcgi://192.168.1.50:9000/var/www/benet #&lt;/LocationMatch&gt;&lt;Directory \"/var/www/benet\"&gt; Options FollowSymLinks AllowOverride None Require all granted&lt;/Directory&gt;&lt;/VirtualHost&gt; 其中： 123456789101112131415161718192021ProxyRequests off：关闭正向代理ProxyPassMatch：把以.php 结尾的文件请求发送到 php-fpm 进程，php-fpm 至少需要知道运 行的目录和 URI，所以这里直接在 fcgi://192.168.31.141:9000 后指明了这两个参数，其它的 参数的传递已经被 mod_proxy_fcgi.so 进行了封装，不需要手动指定特别注意的是，目录需要与中的 DocumentRoot 后的路径一致ProxyPassMatch只有满足特定正则模式的内容才会匹配并执行此规则，这里的模式是，^/(.*\\.php(/.*)?)$ 从网站（虚拟主机的根目录开始，匹配任何以 .php 结尾，或者在 .php 之后 紧跟一个 / 再跟别的内容的路径^ (caret) 和 $ (dollar)标志要匹配的路径的开始和结束( )括号里的内容可以用 $1 来表示，以方便后面引用它fcgi:// 192.168.1.50:9000 通过 mod_proxy_fcgi 来转发的代理，使用 fastCGI 协议，转到 PHP-FPM 监听的端口/path/to/your/documentroot/非常重要！必须与虚拟主机的路径匹配，且必须是对应 php 文件在操作系统中的绝对路径。 否则会找不到文件$1 可以从原始请求扩展成整个请求路径的变量，这里指代前面( ) 里面匹配的那个路径（uri） 补充： 1Apache httpd 2.4 以前的版本中，要么把 PHP 作为 Apache 的模块运行，要么添加一个第 三方模块支持 PHP-FPM 实现 ¶7、测试 LAMP 环境： 在 mysql 主机上创建用于 php 服务器连接的 mysql 账户 12mysql&gt; grant all on *.* to testuser@&#39;%&#39; identified by &#39;123&#39;;Query OK, 0 rows affected, 1 warning (0.00 sec) 注意防火墙要允许 mysql 连接 在 php 服务器上的/var/www/benet 目录下创建.php 的测试页： 12345678910[root@phpserver ~]# cat /var/www/benet/index.php &lt;?phpphpinfo();?&gt;[root@phpserver ~]# cat /var/www/benet/test1.php &lt;?php$link=mysql_connect('192.168.1.40','testuser','123');if ($link)echo \"connection success......\";mysql_close();?&gt; 测试访问php测试页 看到上面两个测试页说明 apache、php、mysql 之间可以协同工作了 ¶二、压力测试 网站性能压力测试是服务器网站性能调优过程中必不可缺少的一环。只有让服务器处在高压 情况下，才能真正体现出软件、硬件等各种设置不当所暴露出的问题 性能测试工具目前最常见的有以下几种：ab、http_load、webbench、siege。今天我们专门 来介绍 ab ab 是 apache 自带的压力测试工具。ab 非常实用，它不仅可以对 apache 服务器进行网站访 问压力测试，也可以对或其它类型的服务器进行压力测试。比如 nginx、tomcat、IIS 等 下面我们开始介绍有关 ab 命令的使用： ab 的原理 ab 的安装 ab 参数说明 ab 性能指标 ab 实际使用 测试 nginx 性能 ¶1）ab的原理 ab 是 apachebench 命令的缩写 ab 的原理： ab 命令会创建多个并发访问线程，模拟多个访问者同时对某一 URL 地址进行访 问。它的测试目标是基于 URL 的，因此，它既可以用来测试 apache 的负载压力，也可以测 试 nginx、lighthttp、tomcat、IIS 等其它 Web 服务器的压力 ab 命令对发出负载的计算机要求很低，它既不会占用很高 CPU，也不会占用很多内存。但 却会给目标服务器造成巨大的负载，其原理类似 CC 攻击。自己测试使用也需要注意，否则 一次上太多的负载。可能造成目标服务器资源耗完，严重时甚至导致死机 ¶2）ab的安装 ab 的安装非常简单，如果是源码安装 apache 的话，那就更简单了。apache 安装完毕后 ab 命令存放在 apache 安装目录的 bin 目录下。如下： 1&#x2F;usr&#x2F;local&#x2F;http-2.4.23&#x2F;bin&#x2F;ab 如果 apache 是通过 yum 的 RPM 包方式安装的话，ab 命令默认存放在/usr/bin 目录下。如 下： 1which ab 注意：如果不想安装 apache 但是又想使用 ab 命令的话，我们可以直接安装 apache 的工具 包 httpd-tools。如下： 1yum -y install httpd-tools 查看 ab 是否安装成功，可以切换到上述目录下，使用 ab –V 命令进行检测。如下： 1[root@apache ~]# /usr/local/http-2.4.23/bin/ab -V 如果ab -V命令出错，可以export LD_LIBRARY_PATH=&quot;/usr/local/openssl/lib/&quot;，就可以了 12345[root@apache ~]# export LD_LIBRARY_PATH=\"/usr/local/openssl/lib/\"[root@apache ~]# ab -VThis is ApacheBench, Version 2.3 &lt;$Revision: 1748469 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/ ¶3）ab参数说明 有关 ab 命令的使用，我们可以通过帮助命令进行查看。如下： 1[root@apache ~]# ab --help 下面我们对这些参数，进行相关说明。如下： n：在测试会话中所执行的请求个数(即总请求数) -c：一次产生的请求个数（即并发用户数） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[root@apache ~]# ab -c 500 -n 10000 http://192.168.1.70/index.htmlThis is ApacheBench, Version 2.3 &lt;$Revision: 1748469 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking 192.168.1.70 (be patient)Completed 1000 requestsCompleted 2000 requestsCompleted 3000 requestsCompleted 4000 requestsCompleted 5000 requestsCompleted 6000 requestsCompleted 7000 requestsCompleted 8000 requestsCompleted 9000 requestsCompleted 10000 requestsFinished 10000 requestsServer Software: ApacheServer Hostname: 192.168.1.70Server Port: 80Document Path: /index.html Document Length: 208 bytes Concurrency Level: 500 Time taken for tests: 25.787 seconds Complete requests: 10000 Failed requests: 4 (Connect: 0, Receive: 0, Length: 4, Exceptions: 0)Non-2xx responses: 10000Total transferred: 3720000 bytes #HTML transferred: 2080000 bytes Requests per second: 387.80 [#/sec] (mean) Time per request: 1289.329 [ms] (mean) Time per request: 2.579 [ms] (mean, across all concurrent requests) Transfer rate: 140.88 [Kbytes/sec] receivedConnection Times (ms) min mean[+/-sd] median maxConnect: 0 1 31.7 0 3008Processing: 2 302 1687.9 9 25773Waiting: 2 294 1641.2 9 25773Total: 6 303 1689.6 9 25781Percentage of the requests served within a certain time (ms) 50% 9 66% 10 75% 10 80% 10 90% 11 95% 939 98% 6460 99% 12908 100% 25781 (longest request) Document Path: /index.html ： 请求的资源 Document Length: 208 bytes ： 响应数据的正文长度 Concurrency Level: 500 ： 并发个数（并发用户数） Time taken for tests: 25.787 seconds ： 所有这些请求处理完成所花费的时间 Complete requests: 10000 ： 完成请求数 Failed requests: 4 ： 失败的请求数 Total transferred: 3720000 bytes ： 表示所有请求的响应数据长度总和，包括每个 HTTP响应数据的头信息和正文数据的长度。注意这里不包括 HTTP 请求数据的长度，仅仅为 web服务器流向用户 PC 的应用层数据总长度 HTML transferred: 2080000 bytes ： 表示所有请求的响应数据中正文数据的总和，也就是减去了 Total transferred 中 HTTP 响应数据中的头信息的长度 Requests per second: 387.80 [：/sec] (mean) ： 吞吐量-每秒请求数 计算公式：Complete requests/Time taken for tests Time per request: 1289.329 [ms] (mean) ： 用户平均请求等待时间 计算公式：Timetoken for tests/（Complete requests/Concurrency Level） Time per request: 2.579 [ms] (mean, across all concurrent requests) ： 服务器平均请求等待时间 计算公式：Time taken for tests/Complete requests Transfer rate: 140.88 [Kbytes/sec] received 表示这些请求在单位时间内从服务器获取的数据长度 计算公式：Total trnasferred/ Time taken for tests，这个统计很好的说明服务器的处理能力达到极限时，其出口宽带的需求量。（即平均每秒网络上的流量） 1234567891011121314151617Connection Times (ms) min mean[+/-sd] median maxConnect: 0 1 31.7 0 3008Processing: 2 302 1687.9 9 25773Waiting: 2 294 1641.2 9 25773Total: 6 303 1689.6 9 25781Percentage of the requests served within a certain time (ms) 50% 9 66% 10 75% 10 80% 10 90% 11 95% 939 98% 6460 99% 12908 100% 25781 (longest request) 这部分数据用于描述每个请求处理时间的分布情况，比如以上测试，80%的请求处理时间 都不超过 66ms，这个处理时间是指前面的 Time per request，即对于单个用户而言，平均 每个请求的处理时间 ¶4）ab 性能指标 在进行性能测试过程中有几个指标比较重要： ¶1、吞吐率（Requests per second） 服务器并发处理能力的量化描述，单位是 reqs/s，指的是在某个并发用户数下单位时间内处 理的请求数。某个并发用户数下单位时间内能处理的最大请求数，称之为最大吞吐率。 记住：吞吐率是基于并发用户数的。这句话代表了两个含义： a、吞吐率和并发用户数相关 b、不同的并发用户数下，吞吐率一般是不同的 计算公式：总请求数/处理完成这些请求数所花费的时间，即： Request per second=Complete requests/Time taken for tests 必须要说明的是，这个数值表示当前机器的整体性能，值越大越好 ¶2、并发连接数（The number of concurrent connections） 并发连接数指的是某个时刻服务器所接受的请求数目，简单的讲，就是一个会话 ¶3、并发用户数（Concurrency Level） 要注意区分这个概念和并发连接数之间的区别，一个用户可能同时会产生多个会话，也即连 接数 ¶4、用户平均请求等待时间（Time per request） 计算公式：处理完成所有请求数所花费的时间/（总请求数/并发用户数），即： Time per request=Time taken for tests/（Complete requests/Concurrency Level） ¶5、服务器平均请求等待时间（Time per request:across all concurrent requests） 计算公式：处理完成所有请求数所花费的时间/总请求数，即： Time taken for/testsComplete requests 可以看到，它是吞吐率的倒数。同时，它也等于用户平均请求等待时间/并发用户数，即：Time per request/Concurrency Level ¶三、php加速软件Xcache （在 php 主机上完成下面的操作) 说明： php 安装目录：/usr/local/php5.6 php.ini 配置文件路径：/etc/php.ini php 网页根目录：/var/www/benet ¶1、安装xcache 12345678[root@phpserver ~]# wget http://xcache.lighttpd.net/pub/Releases/3.2.0/xcache-3.2.0.tar.gz[root@phpserver ~]# tar zxf xcache-3.2.0.tar.gz [root@phpserver ~]# cd xcache-3.2.0/# 用 phpize 生成 configure 配置文件[root@phpserver xcache-3.2.0]# /usr/local/php5.6/bin/phpize[root@phpserver xcache-3.2.0]# ./configure --enable-xcache --enable-xcache-coverager \\&gt; --enable-xcache-optimizer --with-php-config=/usr/local/php5.6/bin/php-config[root@phpserver xcache-3.2.0]# make &amp;&amp; make install 安装完成后最后出现的目录要记住，后面会用到 1Installing shared extensions: /usr/local/php5.6/lib/php/extensions/no-debug-non-zts-20131226/ ¶2、创建 xcache 缓存文件 12[root@phpserver xcache-3.2.0]# touch /tmp/xcache[root@phpserver xcache-3.2.0]# chmod 777 /tmp/xcache ¶3、拷贝xcache 后台管理程序到网站根目录 1[root@phpserver xcache-3.2.0]# cp -r htdocs/ /var/www/benet/xcache ¶4、配置php支持xcache 1234567891011121314151617181920212223242526272829[root@phpserver ~]# vim /etc/php.ini# 在最后添加以下内容[xcache-common]extension = /usr/local/php5.6/lib/php/extensions/no-debug-non-zts-20131226/xcache.so # 这个路径就是之前保存的路径[xcache.admin]xcache.admin.enable_auth = Off[xcache]xcache.shm_scheme =\"mmap\"xcache.size=60Mxcache.count =1xcache.slots =8Kxcache.ttl=0xcache.gc_interval =0xcache.var_size=64Mxcache.var_count =1xcache.var_slots =8Kxcache.var_ttl=0xcache.var_maxttl=0xcache.var_gc_interval =300xcache.test =Offxcache.readonly_protection = Offxcache.mmap_path =\"/tmp/xcache\"xcache.coredump_directory =\"\"xcache.cacher =Onxcache.stat=Onxcache.optimizer =Off[xcache.coverager]xcache.coverager =Onxcache.coveragedump_directory =\"\" 将 xcache 目录拷贝到 apache 主机的网页文档目录下 1[root@phpserver ~]# scp -r /var/www/benet/xcache/ root@192.168.1.70:/var/www/benet/ ¶5、测试 重启 php-fpm 1[root@phpserver ~]# service php-fpm restart 浏览器打开网站根目录下面的 xcache 192.168.1.70/xcache可以看到如下页面： 至此，Linux 下安装 php 加速软件 Xcache 教程完成 执行 ab 压力测试： 执行第一次压力测试： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@apache ~]# ab -c 100 -n 1000 http://192.168.1.70/index.phpThis is ApacheBench, Version 2.3 &lt;$Revision: 1748469 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking 192.168.1.70 (be patient)Completed 100 requestsCompleted 200 requestsCompleted 300 requestsCompleted 400 requestsCompleted 500 requestsCompleted 600 requestsCompleted 700 requestsCompleted 800 requestsCompleted 900 requestsCompleted 1000 requestsFinished 1000 requestsServer Software: ApacheServer Hostname: 192.168.1.70Server Port: 80Document Path: /index.phpDocument Length: 84474 bytesConcurrency Level: 100Time taken for tests: 1.464 secondsComplete requests: 1000Failed requests: 85 (Connect: 0, Receive: 0, Length: 85, Exceptions: 0)Total transferred: 84719909 bytesHTML transferred: 84473909 bytesRequests per second: 683.19 [#/sec] (mean)Time per request: 146.373 [ms] (mean)Time per request: 1.464 [ms] (mean, across all concurrent requests)Transfer rate: 56523.11 [Kbytes/sec] receivedConnection Times (ms) min mean[+/-sd] median maxConnect: 0 0 0.6 0 2Processing: 23 139 21.1 143 192Waiting: 9 135 20.9 138 157Total: 25 140 20.6 143 192Percentage of the requests served within a certain time (ms) 50% 143 66% 145 75% 147 80% 148 90% 152 95% 157 98% 160 99% 161 100% 192 (longest request) 执行第二次压力测试 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@apache ~]# ab -c 100 -n 1000 http://192.168.1.70/index.phpThis is ApacheBench, Version 2.3 &lt;$Revision: 1748469 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking 192.168.1.70 (be patient)Completed 100 requestsCompleted 200 requestsCompleted 300 requestsCompleted 400 requestsCompleted 500 requestsCompleted 600 requestsCompleted 700 requestsCompleted 800 requestsCompleted 900 requestsCompleted 1000 requestsFinished 1000 requestsServer Software: ApacheServer Hostname: 192.168.1.70Server Port: 80Document Path: /index.phpDocument Length: 84474 bytesConcurrency Level: 100Time taken for tests: 1.510 secondsComplete requests: 1000Failed requests: 101 (Connect: 0, Receive: 0, Length: 101, Exceptions: 0)Total transferred: 84719889 bytesHTML transferred: 84473889 bytesRequests per second: 662.27 [#/sec] (mean)Time per request: 150.995 [ms] (mean)Time per request: 1.510 [ms] (mean, across all concurrent requests)Transfer rate: 54792.57 [Kbytes/sec] receivedConnection Times (ms) min mean[+/-sd] median maxConnect: 0 0 0.3 0 2Processing: 8 144 24.0 150 184Waiting: 4 137 23.6 143 155Total: 9 144 23.7 150 184Percentage of the requests served within a certain time (ms) 50% 150 66% 152 75% 152 80% 153 90% 155 95% 157 98% 158 99% 160 100% 184 (longest request) 查看 xcache 的命中率： ¶四、部署bbs论坛 ¶1、Discuz 的程序文件解压，并且将 upload 中所有文件放置到网站目录(php 服务器的操作) 123[root@phpserver ~]# mkdir discus[root@phpserver ~]# unzip Discuz_7.0.0_FULL_SC_UTF8.zip -d discus[root@phpserver ~]# mv discus/Discuz_7.0.0_FULL_SC_UTF8/upload/ /var/www/benet/bbs ¶2、设置 php-fpm 的服务用户为下面文件的属主或者对其设置写权限，否则安装时会报错 1[root@phpserver ~]# chmod -R 777 /var/www/benet/bbs/ ¶3、修改 php.ini 文件 12[root@phpserver ~]# vim /etc/php.inishort_open_tag = On # 将Off改为On，否则程序无法正常运行 ¶4、重启 php-fpm 1[root@phpserver ~]# service php-fpm restart ¶5、web 服务器也需要有静态文件 1[root@phpserver ~]# scp -r /var/www/benet/bbs/ root@192.168.1.70:/var/www/benet/ ¶6、在数据库服务器上创建 bbs 数据库及授权帐户 12345mysql&gt; create database bbsdb;Query OK, 1 row affected (0.00 sec)mysql&gt; grant all on bbsdb.* to runbbs@&#39;%&#39; identified by &#39;pwd@123&#39;;Query OK, 0 rows affected, 1 warning (0.00 sec) 置完成之后，输入 httd//192.168.1.70/bbs/install 即可安装 填写数据库的相关信息，添加数据库服务器的地址和 MariaDB 创建的数据库和用户密码，而 后在设置 bbs 的管理员帐号密码就可以继续安装了 出现上面这种情况是由于 php 服务器安装了 discuz 之后导致程序发生变化从而导致动态服 务器和静态服务器的程序不一致，只需要手动把 bbs 服务器的文件和 web 服务器进行一次 同步即可，如果想实现自动同步，需要使用其他服务，如 initory+rsync、sersync 等工具 1[root@phpserver ~]# scp -r /var/www/benet/bbs/* root@192.168.1.70:/var/www/benet/bbs/ 动态服务器和静态服务器同步文件之后，再次访问 bbs 的网址就正常了","categories":[{"name":"架构","slug":"架构","permalink":"https://pdxblog.top/categories/%E6%9E%B6%E6%9E%84/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://pdxblog.top/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"Apache深度优化","slug":"Apache深度优化","date":"2020-06-08T16:00:00.000Z","updated":"2020-07-12T06:35:17.285Z","comments":true,"path":"Apache深度优化.html","link":"","permalink":"https://pdxblog.top/Apache%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%8C%96.html","excerpt":"","text":"¶Apache深度优化 ¶1）开启apache的Gzip（defate）功能 gzip 可以极大的加速网站，有时压缩比率高到 80%,最少都有 40%以上，还是相当不错的。 在 Apache2 之后的版本，模块名不叫 gzip,而叫 mod_deflate 未使用 Gzip： 开始使用Gzip： 如果要开启 deflate 的话,一定要打开下面二个模块 LoadModule deflate_module modules/mod_deflate.so LoadModule headers_module modules/mod_headers.so 设置压缩比率,取值范围在 1(最低) 到 9(最高)之间,不建议设置太高,虽然有很高的压缩率, 但是占用更多的 CPU 资源. ¶mod_deflate 模块检查及安装 检查模块是否安装： 1[root@apache ~]# apachectl -M | grep deflte 如果没有安装，有两种安装方法： ¶a、编译时安装方法 在编译安装Apache的时候跟上–enable-deflate 即可实现安装，Apache安装部署点击这里 ¶b、DSO方式安装 切到apache 源码包 mod_deflate 所在 的目录下 1[root@apache ~]# cd /root/httpd-2.4.23/modules/filters/ 以 dso 的方式编译安装到 apache 中 1[root@apache filters]# apxs -c -i -a mod_deflate.c 如果报错： 12345678[root@apache filters]# apxs -c -i -a mod_deflate.c/usr/local/apr/build-1/libtool --silent --mode=compile gcc -std=gnu99 -prefer-pic -DLINUX -D_REENTRANT -D_GNU_SOURCE -g -O2 -pthread -I/usr/local/http-2.4.23/include -I/usr/local/apr/include/apr-1 -I/usr/local/apr-util/include/apr-1 -c -o mod_deflate.lo mod_deflate.c &amp;&amp; touch mod_deflate.slomod_deflate.c:51:18: fatal error: zlib.h: No such file or directory #include \"zlib.h\" ^compilation terminated.apxs:Error: Command failed with rc=65536. 原因是缺少了zlib-devel 的安装包，装上就可以了 1[root@apache filters]# yum -y install zlib-devel 再次安装模块，检查mod_deflate是否安装，成功安装这里会显示出该文件 12[root@apache filters]# ll /usr/local/http-2.4.23/modules/mod_deflate.so-rwxr-xr-x. 1 root root 98104 6月 9 09:20 /usr/local/http-2.4.23/modules/mod_deflate.so apxs 命令参数说明： -i：此选项表示需要执行安装操作，以安装一个或多个动态共享对象到服务器的 modules 目 录中 -a：此选项自动增加一个 LoadModule 行到 httpd.conf 文件中，以启用此模块，或者，如果 此行已经存在，则启用之 -c：此选项表示需要执行编译操作 如果重启的时候出现错误： 123456[root@apache ~]# apachectl -thttpd: Syntax error on line 104 of /usr/local/http-2.4.23/conf/httpd.conf: Cannot load modules/mod_deflate.so into server: /usr/local/http-2.4.23/modules/mod_deflate.so: undefined symbol: inflate[root@apache ~]# apachectl -Mhttpd: Syntax error on line 104 of /usr/local/http-2.4.23/conf/httpd.conf: Cannot load modules/mod_deflate.so into server: /usr/local/http-2.4.23/modules/mod_deflate.so: undefined symbol: inflate[root@apache ~]# httpd -Mhttpd: Syntax error on line 104 of /usr/local/http-2.4.23/conf/httpd.conf: Cannot load modules/mod_deflate.so into server: /usr/local/http-2.4.23/modules/mod_deflate.so: undefined symbol: inflate 需要在 LoadModule deflate_module modules/mod_deflate.so 的前面加载 zlib.so 这里需要注意的是 LoadModule deflate_module 需要放在 LoadModule php5_module 之后 LoadFile /usr/lib/libz.so(x64 系统中该库文件位于/usr/lib64 目录下，可以软链接到/usr/lib 下 或者就在 LoadModule deflate_module modules/mod_deflate.so 这行的上一行添加 LoadFile /usr/lib64/libz.so 即可 1234[root@apache ~]# vim /usr/local/http-2.4.23/conf/httpd.confLoadFile /usr/lib64/libz.so # 追加LoadModule deflate_module modules/mod_deflate.so # 去掉注释LoadModule headers_module modules/mod_headers.so # 去掉注释 这样 apache 就会启用这两个模块， mod_deflate 是压缩模块，就是对要传输到客户端的代码进行 gzip 压缩 mod_headers 模块的作用是告诉浏览器页面使用了 gzip 压缩，如果不开启 mod_headers 那么浏览器就会 对 gzip 压缩过的页面进行下载，而无法正常显示 LoadModule /usr/lib64/libz.so：如果使用DSO方式安装的deflate模块需要声明，没用可以不用写 ¶在添加压缩级别等参数： 在 httpd.conf 中加入以下代码，可以加到任何空白地方，不了解 apache 的话，如果担心加 错地方，就放到 http.conf 文件的最后一行 注：在添加代码前最好先查一查要添加的代码是否存在 12345678910&lt;IfModule mod_deflate.c&gt; DeflateCompressionLevel 9 SetOutputFilter DEFLATE AddOutputFilterByType DEFLATE text/* AddOutputFilterByType DEFLATE application/ms* application/vnd* application/postscript application/javascript application/x-javascript AddOutputFilterByType DEFLATE application/x-httpd-php application x-httpd-fastphp SetEnvIfNoCase Request_URI .(?:gif|jpe?g|png)$ no-gzip dont-vary SetEnvIfNoCase Request_URI .(?:exe|t?gz|zip|bz2|sit|rar)$ no-gzip dont-vary SetEnvIfNoCase Request_URI .(?:pdf|mov|avi|mp3|mp4|rm)$ no-gzip dont-vary&lt;/IfModule&gt; DeflateCompressionLevel 9： 压缩程度的等级，预设可以采用 6 这个数值，以维持 耗用处理器效能与网页压缩质量的平衡 SetOutputFilter DEFLATE： 设置输出过滤器，对输出启用压缩，必须的，就像一个 开关一样，告诉 apache 对传输到浏览器的内容进行压缩 AddOutputFilterByType DEFLATE text/*： 设置对文件是文本的内容进行压缩，例如 text/html text/css text/plain 等 AddOutputFilterByType DEFLATE application/x-httpd-php application/x-httpd-fastphp： 对 php 类型的文件进行压缩 SetEnvIfNoCase Request_URI .(?:gif|jpe?g|png)$ no-gzip dont-vary： 设置不对后缀 gif，jpg，jpeg，png 的图片文件进行压缩。注：?:表示不会捕获 ( )里内容了 SetEnvIfNoCase Request_URI .(?:exe|t?gz|zip|bz2|sit|rar)$ no-gzip dont-vary： 同上，设置不对 exe，tgz，gz 等的文件进行压缩 SetEnvIfNoCase Request_URI .(?:pdf|mov|avi|mp3|mp4|rm)$ no-gzip dont-vary 同上，设置不对 pdf，avi，mp3 等的文件进行压缩 ¶设置日志输出 12345DeflateFilterNote Input input_infoDeflateFilterNote Output output_infoDeflateFilterNote Ratio ratio_infoLogFormat '\"%r\" %&#123;output_info&#125;n/%&#123;input_info&#125;n (%&#123;ratio_info&#125;n%%)' deflateCustomLog logs/deflate_log.log deflate DeflateFilterNote Input input_info： 声明输入流的 byte 数量 DeflateFilterNote Output output_info： 声明输出流的 byte 数量 DeflateFilterNote Ratio ratio_info： 声明压缩的百分比 LogFormat ‘&quot;%r&quot; %{output_info}n/%{input_info}n (%{ratio_info}n%%)’ deflate： 声明日志格式 修改完成后保存退出并重启 apache服务 1[root@apache ~]# systemctl restart httpd 使用谷歌浏览器测试访问，如下图显示结果：（提示：在访问测试页之前按 F12 键） 查看日志： 123[root@apache ~]# cat /usr/local/http-2.4.23/logs/deflate_log.log\"GET /test.html HTTP/1.1\" 6421/19949 (32%)\"GET /test1.html HTTP/1.1\" 1360/4266 (31%) 注：图片是不需要启用 GZip 压缩的，从 GZip 检测结果来看，压缩后的图片体积竟然大过原 体积！这就解释了为什么图片不用启用 GZip 压缩的原因了！ 可以检测了几个门户网站的图片，还有 Google、baidu 的图片，统统都没有启用图片 GZip 压缩，只是启用了 html、css、js 等文件的 GZip 压缩，这就更加说明了 GZip 压缩不适用于图 片上。另外，除了图片之外，flash 的 swf 文件也是不用启用 GZip 压缩的 ¶2）配置 mod_expires 模块 这个非常有用的优化，mod_expires 可以减少 20-30%左右的重复请求，让重复的用户对指定 的页面请求结果都 CACHE 在本地，根本不向服务器发出请求。但要注意更新快的文件不要 这么做 这个模块控制服务器应答时的 Expires 头内容和 Cache-Control 头的 max-age 指令。有效期 (expiration date)可以设置为相对于源文件的最后修改时刻或者客户端的访问时刻。 未启用 expire 的效果： 123456789[root@apache ~]# curl -I 192.168.1.70/12.pngHTTP/1.1 200 OKDate: Tue, 09 Jun 2020 02:11:04 GMTServer: Apache/2.4.23 (Unix)Last-Modified: Sat, 28 Sep 2019 02:39:14 GMTETag: \"206701-59393e8841880\"Accept-Ranges: bytesContent-Length: 2123521Content-Type: image/png ¶启用 expire 缓存： mod_expires 的安装配置： 启用 expires_module 1LoadModule expires_module modules/mod_expires.so # 去掉注释 然后添加 Expires 配置规则 123456789101112&lt;IfModule mod_expires.c&gt;ExpiresActive OnExpiresByType text/css \"now plus 1 month\"ExpiresByType application/x-javascript \"now plus 5 day\"ExpiresByType image/jpeg \"access plus 1 month\"ExpiresByType image/gif \"access plus 1 month\"ExpiresByType image/bmp \"access plus 1 month\"ExpiresByType image/x-icon \"access plus 1 month\"ExpiresByType image/png \"access plus 1 minute\"ExpiresByType application/x-shockwave-flash \"access plus 1 month\"ExpiresDefault \"now plus 0 minute\"&lt;/IfModule&gt; 语法： ExpiresByType：定义缓存页面 text/html：指定缓存界面的类型 A60：缓存页面的时间 ExpireActive On：开启缓存功能 ExpiresByType text/html M60：页面最后一次修改缓存60 ExpiresByType image/png A60：图片缓存，和ExpiresByType image/png &quot;access plus 1 month&quot;意思相同 ExpiresDefault “now plus 0 minute”：其他页面不进行缓存 验证： 1234567891011[root@apache ~]# curl -I 192.168.1.70/12.pngHTTP/1.1 200 OKDate: Tue, 09 Jun 2020 02:14:55 GMTServer: Apache/2.4.23 (Unix)Last-Modified: Sat, 28 Sep 2019 02:39:14 GMTETag: \"206701-59393e8841880\"Accept-Ranges: bytesContent-Length: 2123521Cache-Control: max-age=60Expires: Tue, 09 Jun 2020 02:15:55 GMTContent-Type: image/png ExpiresDefault 和 ExpiresByType 指令同样能够用易懂的语法格式进行定义： ExpiresDefault &quot; [plus] {}&quot; ExpiresByType type/encoding &quot; [plus] {}&quot; 其中bash是下列之一： access now (等价于’access ') modification plus 关键字是可选的。num必须是整数，type是下列之一 years moths weeks days hours minutes seconds 例如，下列 3 个指令都表示文档默认的有效期是一个月： ExpiresDefault “access plus 1 month” ExpiresDefault “access plus 4 weeks” ExpiresDefault “access plus 30 days” 有效期可以通过增加&quot;num type&quot;子句进一步调整 ExpiresByType text/html “access plus 1 month 15 days 2 hours” ExpiresByType image/gif “modification plus 5 hours 3 minutes” 注意，如果你使用基于最后修改日期的设置，&quot;Expires:&quot;头将不会 被添加到那些并非来自于 磁盘文件的内容。这是因为这些内容并不存在&quot;最后修改时间&quot;的属性 12345678910# GIF 有效期为 1 个月（秒数）ExpiresByType image/gif A2592000ExpiresByType image/jpeg A2592000ExpiresByType image/png A2592000ExpiresByType image/x-icon A2592000ExpiresByType application/x-javascript A604800ExpiresByType text/plain A604800# HTML 文档的有效期是最后修改时刻后的一星期ExpiresByType text/html M604800&lt;/IfModule&gt; &quot;M&quot;表示源文件的最后修改时刻，&quot;A&quot;表示客户端对源文件的访问时刻。后面的时间则以秒计 算 有关 Apache Expires Module 的介绍，可以参阅其官方文档: ¶3）Apache禁止目录遍历 未禁用的效果： 将 Options Indexes FollowSymLinks 中的 Indexes 去掉，就可以禁止 Apache 显示该目录结构。 Indexes 的作用就是当该目录下没有 index.html 文件时，就显示目录结构 在配置文件（httpd.conf）中搜索Options，找到Options Indexes FollowSymLinks 并修改为Options FollowSymLinks 重启服务验证： ¶4）Apache隐藏版本信息 测试默认 apache 的状态信息 12345[root@apache ~]# curl -I 192.168.1.70HTTP/1.1 403 ForbiddenDate: Tue, 09 Jun 2020 02:29:20 GMTServer: Apache/2.4.23 (Unix) # 版本信息直接暴露Content-Type: text/html; charset=iso-8859-1 ¶1、主配置中启用httpd-default.conf 1Include conf/extra/httpd-default.conf # 去掉注释 ¶2、修改 httpd-default.conf 文件：/usr/local/http-2.4.23/conf/extra/httpd-default.conf 123456找到ServerTokens FullServerSignature On改成ServerTokens ProdServerSignature Off 重启 apache 测试 123456[root@apache ~]# apachectl restart[root@apache ~]# curl -I 192.168.1.70HTTP/1.1 403 ForbiddenDate: Tue, 09 Jun 2020 02:34:30 GMTServer: ApacheContent-Type: text/html; charset=iso-8859-1 如果你需要彻底将版本之类的信息进行改头换面，你就需要在编译之前做准备或者进行从新 编译了。在重新编译时，修改源码包下 include 目录下的 ap_release.h 文件 #define AP_SERVER_BASEVENDOR “Apache Software Foundation” #服务的供应商名称 123456#define AP_SERVER_BASEPROJECT “Apache HTTP Server” #服务的项目名称#define AP_SERVER_BASEPRODUCT “Apache” #服务的产品名#define AP_SERVER_MAJORVERSION_NUMBER 2 #主要版本号#define AP_SERVER_MINORVERSION_NUMBER 4 #小版本号#define AP_SERVER_PATCHLEVEL_NUMBER 23 #补丁级别#define AP_SERVER_DEVBUILD_BOOLEAN 0 # 上述列出的行，已经给出了注释，大家可以修改成自己想要的，然后编译安装之后，对方就彻底不知道你的版本号了 ¶5）Apache日志分割 ¶为什么要分割日志 1随着网站的访问越来越大，WebServer 产生的日志文件也会越来越大，如果不对日志进行分 割，那么只能一次将大的日志(如 Apache 的日志)整个删除，这样也丢失了很多对网站比较 宝贵的信息，因为这些日志可以用来进行访问分析、网络安全监察、网络运行状况监控等， 因此管理好这些海量的日志对网站的意义是很大的 ¶方法 1:使用 rotatelogs（apache 自带的工具）每隔一天记录一个日志 编辑Apache 的主配置文件，更改内容如下： 注释掉如下两行 12ErrorLog \"logs/error_log\"CustomLog \"logs/access_log\" common 然后添加如下两行 12ErrorLog \"|/usr/local/http-2.4.23/bin/rotatelogs -l logs/error_%Y%m%d.log 86400\"CustomLog \"|/usr/local/http-2.4.23/bin/rotatelogs -l logs/access_%Y%m%d.log 86400\" combined 注：其中 86400 为轮转的时间单位为秒 注：rotatelogs这个要写绝对路径，可以使用which来查询它的路径 验证：查看 logs 目录下的日志文件 12[root@apache ~]# ls /usr/local/http-2.4.23/logs/access_20200609.log access_log deflate_log.log error_20200609.log error_log httpd.pid 由于 apache 自带的日志轮询工具 rotatelogs，据说在进行日志切割时容易丢日志，因此我们 通常使用 cronolog 进行日志轮询 ¶方法 2、使用 cronolog 为每一天建立一个新的日志 安装 cronolog 程序 下载 cronolog 提取码：uzra 123[root@apache ~]# tar zxf cronolog-1.6.2.tar.gz [root@apache ~]# cd cronolog-1.6.2/[root@apache cronolog-1.6.2]# ./configure &amp;&amp; make &amp;&amp; make install 主配置文件中的使用方法，添加如下两行 12ErrorLog \"|/usr/local/sbin/cronolog logs/error-%Y%m%d.log\" CustomLog \"|/usr/local/sbin/cronolog logs/access-%Y%m%d.log\" combined 如果 Apache 中有多个虚拟主机，最好每个虚拟主机中放置一个这样的代码，并将日志文件 名改成不同的名字 扩展： 这个保证了每天一个文件夹文件夹下每个小时产生一个 log CustomLog “|/usr/local/sbin/cronolog logs /%Y%m%d/access_log.%H” combined 按天轮询（生产环境常见用法，推荐使用）： CustomLog “|/usr/local/sbin/cronolog logs/access_www_%Y%m%d.log” combined 按小时轮询（生产环境较常见用法）： CustomLog “|/usr/local/sbin/cronolog logs /access_www_ %Y%m%d%H.log” combined 验证：查看 logs 目录下的日志文件 123[root@apache ~]# ls /usr/local/http-2.4.23/logs/access_20200609.log access_log error_20200609.log error_logaccess-20200609.log deflate_log.log error-20200609.log httpd.pid 注意： 这两个管道日志文件程序还有一点不同之处是使用 cronolog 时如果日志是放在某个不存 在的路径则会自动创建目录，而使用 rotatelogs 时不能自动创建，这一点要特别注意 ¶6）配置防盗链 有时候，你的网站莫名其妙的访问量变大，不要高兴的太早，有可能是被别人盗链了。 举个例子：比如你搭了个 discuz 论坛，里面有些热点图片、视频；然后别人将他网站上访问 图片的地址重定向到你的 discuz 上，这样他的服务器就可以空闲出来了；也就是说别人访问 他网站的图片视频，消耗的确是你服务器的资源 解决这个问题的方法是配置下防盗链，让外来的盗不了链 ¶方法 1：Apache 防盗链的第一种实现方法，可以用 rewrite 实现 打开 httpd.conf，确保有这么一行配置: 1LoadModule rewrite_module modules/mod_rewrite.so # 去掉注释 防盗链配置 在&lt;Directory &quot;/usr/local/http-2.4.23/htdocs&quot;&gt;这个区域下添加 1234567RewriteEngine OnRewriteCond %&#123;HTTP_REFERER&#125; !^$RewriteCond %&#123;HTTP_REFERER&#125; !^http://192.168.1.70/.*$ [NC]RewriteCond %&#123;HTTP_REFERER&#125; !^http://192.168.1.70$ [NC]RewriteCond %&#123;HTTP_REFERER&#125; !^http://192.168.1.70/.*$ [NC]RewriteCond %&#123;HTTP_REFERER&#125; !^http://192.168.1.70$ [NC]RewriteRule .*\\.(gif|jpg|swf)$http://192.168.1.70/image/error.png[R,NC,L] 注：相关选项的解释 RewriteEngine On： 启用 rewrite，要想 rewrite 起作用，必须要写上 RewriteCond test-string condPattern ： 写在 RewriteRule 之前，可以有一或 N 条，用于测试 rewrite 的匹配条件，具体怎么写，后面会详细说到 RewriteRule Pattern Substitution： 规则 %{HTTP_REFERER}： 服务器变量，HTTPReferer 是 header 的一部分，当浏览器向 web 服务器发送请求的时候，一般会带上 Referer，告诉服务器我是从哪个页面链接过来的，服 务器藉此可以获得一些信息用于处理。比如从我主页上链接到一个朋友那里，他的服务器就 能够从 HTTP Referer 中统计出每天有多少用户点击我主页上的链接访问他的网站 [ NC]： 指的是不区分大小写,[R]强制重定向 redirect 字母 L 表示如果能匹配本条规则，那么本条规则是最后一条(Last)，忽略之后的规则 防盗链配置的说明： 192.168.1.70： 表示自己的信任站点，如果有域名的可以写域名 gif|jpg|swf： 要保护文件的扩展名(以|分开)。以这些为扩展名的文件，必须通过红色标注的网址引用， 才可以访问 192.168.1.70/image/error.png： 定义被盗链时替代的图片，让所有盗链 jpg、gif、swf 等文件的网页，显示网页文档根目 录下的 image/ error.png 文件。注意：替换显示的图片不要放在设置防盗链的目录中，并且该图片文件体积越小越好。当然你也可以不设置替换图片，而是使用下面的语句即可：RewriteRule .*.(gif|jpg|png)$ - [F] 注：[F] (强制 URL 为被禁止的 forbidden),强制当前 URL 为被禁止的，即，立即反馈一 个 HTTP 响应代码 403(被禁止的) ¶验证 再打开一个虚拟机（192.168.1.50），验证防盗链是否配置成功： 1、安装一个httpd服务： 1[root@localhost ~]# yum -y install httpd 2、模拟web页面： 12[root@localhost ~]# vim /var/www/html/index.html&lt;a href=\"http://192.168.1.70/12.png\"&gt;lianjie&lt;/a&gt; ¶方法 2 通过判断浏览器头信息来阻止某些请求，即利用 SetEnvIfNoCase 和 access。 这个方法可以通过阻止某些机器人或蜘蛛爬虫抓取你的网站来节省你的带宽流量 语法: SetEnvIfNoCase attribute regex [!]env-variable[=value] [[!]env-variable[=value]] … SetEnvIfNoCase 当满足某个条件时，为变量赋值，即根据客户端请求属性设置环境变量 注：Referer ：指明了请求当前资源原始资源的 URL，使用 referer 是可以防盗链 然后在找到自己网站对应的配置的地方（如在主配置文件中或虚拟主机中），加入下列代码： 1234SetEnvIfNoCase Referer \"^$\" local_refSetEnvIfNoCase Referer\"^http://www.benet.com/.*$\" local_refSetEnvIfNoCase Referer\"^http://benet.com/.*$\"local_ref&lt;filesmatch\"\\.(mp3|mp4|zip|rar|jpg|gif|png)\"&gt; 2.4 版本以下的： 方法一： 123Order Deny,AllowAllow from env=local_refDeny from all 方法二： 12Order Allow,DenyAllow from env=local_ref 2.4 版本以上，方法如下： 123Require all denied Require env local_ref&lt;/filesmatch&gt;","categories":[{"name":"架构","slug":"架构","permalink":"https://pdxblog.top/categories/%E6%9E%B6%E6%9E%84/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://pdxblog.top/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"Apache安装部署及工作模式","slug":"Apache安装部署及工作模式","date":"2020-06-07T16:00:00.000Z","updated":"2020-06-09T02:47:45.825Z","comments":true,"path":"Apache安装部署及工作模式.html","link":"","permalink":"https://pdxblog.top/Apache%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E5%8F%8A%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F.html","excerpt":"","text":"¶Apache安装部署及工作模式 新版本的httpd-2.4新增一下特性： 新增模块： mod_proxy_fcgi(可提供 fcgi 代理） mod_ratelimit（限制用户带宽） mod_request（请求模块，对请求做过滤） 对于基于 IP 的访问控制做了修改，不再支持 allow,deny,order 机制，而是统一使用 require 进行 还新增以下几条新特性； 1、MPM 支持在运行时装载;不过要开启这种特性，在编译安装要启用这三种功能； –enable-mpms-shared=all --with-mpm=event 2、支持 event 3、支持异步读写 4、在每个模块及每个目录上指定日志级别 5、增强版的表达式分析器 6、每请求配置：If, Elseif 7、毫秒级别的 keepalive timeout 8、基于 FQDN 的虚拟主机不再需要 NameVirtualHost 指令 9、支持使用自定义变量 ¶一、部署apache 安装环境： 操作系统：Centos7.5，关闭selinux 检查http是否安装，如查安装则卸载 ¶1、安装apache2.4.23 ¶（1）下载源码包： httpd-2.4.23.tar.gz apr-1.5.2.tar.gz apr-util-1.5.4.tar.gz zlib-1.2.8.tar.gz pcre-8.39.tar.gz 软件链接 提取码：uzra 注：apr(Apache Portable Runtime)Apache 可移植运行库，它是一个对操作系统调用的抽 象库，用来实现 Apache 内部组件对操作系统的使用，提高系统的可移植性。 ¶（2）安装apr和apr-util apr 1234[root@apache ~]# tar zxf apr-1.5.2.tar.gz [root@apache ~]# cd apr-1.5.2/[root@apache apr-1.5.2]# ./configure --prefix=/usr/local/apr[root@apache apr-1.5.2]# make &amp;&amp; make install apr-util 1234[root@apache ~]# tar zxf apr-util-1.5.4.tar.gz [root@apache ~]# cd apr-util-1.5.4/[root@apache apr-util-1.5.4]# ./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr[root@apache apr-util-1.5.4]# make &amp;&amp; make install ¶（3）安装zlib 1234[root@apache ~]# tar zxf zlib-1.2.8.tar.gz [root@apache ~]# cd zlib-1.2.8/[root@apache zlib-1.2.8]# ./configure --prefix=/usr/local/zlib[root@apache zlib-1.2.8]# make &amp;&amp; make install ¶（4）安装pcre 1234[root@apache ~]# tar zxf pcre-8.39.tar.gz [root@apache ~]# cd pcre-8.39/[root@apache pcre-8.39]# ./configure --prefix=/usr/local/pcre[root@apache pcre-8.39]# make &amp;&amp; make install ¶（5）安装openssl 安装 apache2.4.23 时提示 openssl 版本过低，centos7 自带版本 openssl-1.0.1e 下载openssl： 1[root@apache ~]# wget https://www.openssl.org/source/openssl-1.0.1u.tar.gz 安装： 123456[root@apache ~]# tar zxf openssl-1.0.1u.tar.gz [root@apache ~]# cd openssl-1.0.1u/[root@apache openssl-1.0.1u]# ./config -fPIC --prefix=/usr/local/openssl enable-shared[root@apache openssl-1.0.1u]# make &amp;&amp; make install[root@apache ~]# mv /usr/bin/openssl /usr/bin/openssl.1.0.1e[root@apache ~]# ln -s /usr/local/openssl/bin/openssl /usr/bin/openssl ¶（6）安装apache2.4.23 123456[root@apache httpd-2.4.23]# ./configure --prefix=/usr/local/http-2.4.23 --enable-so \\&gt; --enable-cgi --enable-cgid --enable-ssl --with-ssl=/usr/local/openssl \\&gt; --enable-rewrite --with-pcre=/usr/local/pcre --with-z=/usr/local/zlib \\&gt; --with-apr=/usr/local/apr --with-apr-util=/usr/local/apr-util \\&gt; --enable-modeles=most --enable-mods-shared=most --enable-mpms-shared=all \\&gt; --with-mpm=event --enable-proxy --enable-proxy-fcgi --enable-expires --enable-deflate 相关参数解释： 12345678910111213141516171819202122232425262728293031--enable-so：支持动态共享模块（即打开 DSO 支持）--enable-rewrite：支持 url 重写--enable-ssl：支持 ssl--with-ssl=/usr/local/openssl：指定 ssl 安装位置--enable-cgi：启用 cgi--enable-cgid：MPM 使用的是 event 或 worker 要启用 cgid--enable-modules=most：明确指明要静态编译到 httpd 二进制文件的模块，为 空格分隔的模块名列表、all 或者 most，all 表示包含所有模块，most 表示包含大部分常用模块--enable-mods-shared=most：明确指明要以 DSO 方式编译的模块，为空格分隔 的模块名列表、all 或者 most，all 表示包含所有模 块，most 表示包含大部分模块--enable-mpms-shared=all：启用 MPM 所有支持的模式，这样 event、worker、prefork 就会以 模块化的方式安装，要用哪个就在 httpd.conf 里配置就好了--with-mpm=event：指定启用的 mpm 模式，默认使用 enevt 模式，在 apache 的早期版本 2.0 默认 prefork,2.2 版本是 worker，2.4 版本是 event--with-pcre=/usr/local/pcre：支持 pcre--with-z=/usr/local/zlib：使用 zlib 压缩库--with-apr=/usr/local/apr：指定 apr 的安装路径--with-apr-util=/usr/local/apr-util：指定 apr-util 的安装路径--enable-expires：激活彧通过配置文件控制 HTTP 的“Expires:”和“Cache-Control:”头内容，即 对网站图片、js、css 等内容，提供客户端浏览器缓存的设置。这个是 apache 调优的一个重 要选项之一--enable-deflate提供对内容的压缩传输编码支持，一般是 html、js、css 等内容的站点。使 用此参数会打打提高传输速度，提升访问者访问的体验。在生产环境中，这是 apache 调优 的一个重要选项之一 1[root@apache httpd-2.4.23]# make &amp;&amp; make install ¶（7）优化http程序执行路径 1[root@apache ~]# ln -s /usr/local/http-2.4.23/bin/* /usr/local/bin/ ¶1）修改配置文件 httpd.conf，设置其中的 ServerName 值 例如：ServerName www.benet.com 12[root@apache ~]# vim /usr/local/http-2.4.23/conf/httpd.confServerName 127.0.0.1 ¶2）开启 apache 服务器： 1[root@apache ~]# apachectl start ¶3）开机后自动启动 1[root@apache ~]# cp /usr/local/http-2.4.23/bin/apachectl /etc/init.d/httpd 编辑 /etc/init.d/httpd 文件，在首行 #!/bin/sh 下面加入两行： 123[root@apache ~]# vim /etc/init.d/httpd# chkconfig: 35 85 15# description: apache 2.4.23 chkconfig: 35 85 15 （在 3 和 5 启动模式下的–启动优先级） 将 Apache 加入开机自动启动： 12[root@apache ~]# chkconfig --add httpd[root@apache ~]# chkconfig httpd on ¶（8）启动编译好的 Apache 2.4.23： 123[root@apache ~]# systemctl start httpd[root@apache ~]# netstat -anplt | grep 80tcp6 0 0 :::80 :::* LISTEN 51792/httpd ¶（9）客户端测试访问（注意防火墙） ¶2、Apache的优化配置 apache 所运行的硬件环境都是对性能影响最大的因素，即使不能对硬件进行升级，也最好 给 apache 一个单独的主机以免受到其他应用的干扰。各个硬件指标中，对性能影响最大的 是内存，对于静态内容（图片、javascript 文件、css 文件等），它决定了 apache 可以缓存多 少内容，它缓存的内容越多，在硬盘上读取内容的机会就越少，大内存可以极大提高静态站 点的速度；对动态高负载站点来说，每个请求保存的时间更多一些，apache 的 mpm 模块会 为每个请求派生出相应的进程或线程分别处理，而进程或线程的数量与内存的消耗近似成正 比，因此增大内存对提高动态站点的负载和运行速度也极为有利 其次是硬盘的速度，静态站点尤为突出，apache 不断的在读取文件并发送给相应的请求， 硬盘的读写是极其频繁的；动态站点也要不断的加载 web 程序(php 等)，一个请求甚至要读 取十几个文件才能处理完成，因此尽可能的提高硬盘速度和质量对提高 apache 的性能是有 积极意义的 最后是 cpu 和网络，cpu 影响的是 web 程序执行速度，网络影响流量大小 ¶二、Apache的工作模式 Apache HTTP 服务器被设计为一个强大的、灵活的能够在多种平台以及不同环境下工作的服 务器。这种模块化的设计就叫做“多进程处理模块”（Multi-Processing Module，MPM），也叫 做工作模式 ¶Prefork 模式（一个非线程型的）： ¶其主要工作方式是： 当 Apache 服务器启动后，mpm_prefork 模块会预先创建多个子进程(默 认为 5 个)，每个子进程只有一个线程，当接收到客户端的请求后，mpm_prefork 模块再将 请求转交给子进程处理，并且每个子进程同时只能用于处理单个请求。如果当前的请求数将 超过预先创建的子进程数时，mpm_prefork 模块就会创建新的子进程来处理额外的请求。 Apache 总是试图保持一些备用的或者是空闲的子进程用于迎接即将到来的请求。这样客户 端的请求就不需要在接收后等候子进程的产生 由于在 mpm_prefork 模块中，每个请求对应一个子进程，因此其占用的系统资源相对其他 两种模块而言较多。不过 mpm_prefork 模块的优点在于它的每个子进程都会独立处理对应 的单个请求，这样，如果其中一个请求出现问题就不会影响到其他请求。Prefork 在效率上 要比 Worker 要高，但是内存使用大得多不擅长处理高并发的场景 ¶Apache 在 prefork 工作模式下影响性能的重要参数说明 12345678# prefork MPM&lt;IfModule mpm_prefork_module&gt; StartServers 5 MinSpareServers 5 MaxSpareServers 10 MaxRequestWorkers 250 MaxConnectionsPerChild 500&lt;/IfModule&gt; StartServers： apache 启动时候默认开始的子进程数 MinSpareServers： 最小的闲置子进程数 MaxSpareServers： 最大的闲置子进程数 MaxRequestWorkers： MaxRequestWorkers 设置了允许同时的最大接入请求数量 任何 超 过 MaxRequestWorkers 限 制 的 请 求 将 进 入 等 候 队 列 ， 在 apache2.3.1 以 前 的 版 本 MaxRequestWorkers 被称为 MaxClients，旧的名字仍旧被支持 MaxConnectionsPerChild 设置的是每个子进程可处理的请求数。每个子进程在处理了“MaxConnectionsPerChild” 个请求后将自动销毁。0 意味着无限，即子进程永不销毁。虽然缺省设为 0 可以使每个 子进程处理更多的请求，但如果设成非零值也有两点重要的好处： 1、可防止意外的内 存泄漏 2、在服务器负载下降的时侯会自动减少子进程数。因此，可根据服务器的负 载来调整这个值。在 Apache2.3.9 之前称之为 MaxRequestsPerChild ¶注意： ¶注1 MaxRequestWorkers 是这些指令中最为重要的一个，设定的是 Apache 可以同时处理 的请求，是对 Apache 性能影响最大的参数。如果请求总数已达到这个值（可通过 ps -ef|grep http|wc -l 来确认），那么后面的请求就要排队，直到某个已处理请求完毕。这就是系统资源 还剩下很多而 HTTP 访问却很慢的主要原因。虽然理论上这个值越大，可以处理的请求就越 多，建议将初始值设为(以 Mb 为单位的最大物理内存/2),然后根据负载情况进行动态调整。 比如一台 4G 内存的机器，那么初始值就是 4000/2=2000 ¶注2 prefork 控制进程在最初建立“StartServers”个子进程后，为了满足 MinSpareServers 设 置的需要创建一个进程，等待一秒钟，继续创建两 个，再等待一秒钟，继续创建四个……如 此按指数级增加创建的进程数，最多达到每秒 32 个，直到满足 MinSpareServers 设置的值为止。这种模式 可以不必在请求到来时再产生新的进程，从而减小了系统开销以增加性能。 MaxSpareServers 设置了最大的空闲进程数，如果空闲进程数大于这个 值，Apache 会自动 kill 掉一些多余进程。这个值不要设得过大，但如果设的值比 MinSpareServers 小，Apache 会自 动把其调整为 MinSpareServers+1。如果站点负载较大，可考虑同时加大 MinSpareServers 和 MaxSpareServers ¶注3 ServerLimit 和 MaxClients（MaxRequestWorkers）有什么区别呢？ 是因为在 apache1 时代，控制最大进程数只有 MaxClients 这个参数，并且这个参数最大值为 256，并且是写死了的，试图设置为超过 256 是无效的，这是由于 apache1 时代的服务器硬 件限制的。但是 apache2 时代由于服务器硬件的升级，硬件已经不再是限制，所以使用 ServerLimit 这个参数来控制最大进程数，ServerLimit 值&gt;=MaxClient 值才有效。ServerLimit 要放在 MaxClients 之前，值要不小于 MaxClients ¶注4 查看 Apache 加载的模块 12345[root@apache conf]# apachectl -t -D DUMP_MODULES或[root@apache conf]# apachectl -M或[root@apache conf]# apachectl -l # 小写 L，只显示静态模块 如何查看 Apache 的工作模式呢？可以使用 httpd -V 命令查看，另外使用 httpd -l 也可以查 看到 ¶注5 如何修改 prefork 参数和启用 prefork 模式 123456789101112[root@apache ~]# vim /usr/local/http-2.4.23/conf/extra/httpd-mpm.conf&lt;IfModule mpm_prefork_module&gt; StartServers 5 MinSpareServers 5 MaxSpareServers 10 MaxRequestWorkers 250 MaxConnectionsPerChild 500&lt;/IfModule&gt;[root@apache ~]# vim /usr/local/http-2.4.23/conf/httpd.conf# 注释掉当前的工作模式，开启新的工作模式LoadModule mpm_prefork_module modules/mod_mpm_prefork.soInclude conf/extra/httpd-mpm.conf 重启服务 1[root@apache ~]# systemctl restart httpd ¶Worker 模式(多线程多进程)： 和 prefork 模式相比，worker 使用了多进程和多线程的混合模式，worker 模式也同样会先预 派生一些子进程，然后每个子进程创建一些线程，同时包括一个监听线程，每个请求过来会 被分配到一个线程来服务。线程比起进程会更轻量，因为线程是通过共享父进程的内存空间， 因此，内存的占用会减少一些，在高并发的场景下会比 prefork 有更多可用的线程，表现会 更优秀一些；另外，如果一个线程出现了问题也会导致同一进程下的线程出现问题，如果是 多个线程出现问题，也只是影响 Apache 的一部分，而不是全部。由于用到多进程多线程， 需要考虑到线程的安全了，在使用 keep-alive 长连接的时候，某个线程会一直被占用，即使 中间没有请求，需要等待到超时才会被释放（该问题在 prefork 模式下也存在） 总的来说，prefork 方式速度要稍高于 worker，然而它需要的 cpu 和 memory 资源也稍多于 woker ¶Apache 在 worker 工作模式下影响性能的重要参数说明 123456789# worker MPM&lt;IfModule mpm_worker_module&gt; StartServers 3 MinSpareThreads 75 MaxSpareThreads 250 ThreadsPerChild 25 MaxRequestWorkers 400 MaxConnectionsPerChild 0&lt;/IfModule&gt; StartServers：apache 启动时候默认开始的子进程数 MinSpareThreads：最小空闲数量的工作线程 MaxSpareThreads：最大空闲数量的工作线程 ThreadsPerChild：每个子进程产生的线程数量 MaxRequestWorkers：与 prefork 模式相同 MaxConnectionsPerChild：与 prefork 模式相同 ¶注意 ¶注1 Worker 由主控制进程生成“StartServers”个子进程，每个子进程中包含固定的 ThreadsPerChild 线程数，各个线程独立地处理请求。同样， 为了不在请求到来时再生成线 程，MinSpareThreads 和 MaxSpareThreads 设置了最少和最多的空闲线程数； 而 MaxRequestWorkers 设置了同时连入的 clients 最大总数。如果现有子进程中的线程总数不 能满足负载，控制进程将派生新的子进程 MinSpareThreads 和 MaxSpareThreads 的最大缺省值分别是 75 和 250。这两个参数对 Apache 的性能影响并不大，可以按照实际情况相应调节 ¶注2 ThreadsPerChild 是 worker MPM 中与性能相关最密切的指令。ThreadsPerChild 的最大 缺省值是 64，如果负载较大，64 也是不够的。这时要显式使用 ThreadLimit 指令，它的最大 缺省值是 20000。 ¶注3 Worker 模式下所能同时处理的请求总数是由子进程总数乘以 ThreadsPerChild 值决定 的，应该大于等于 MaxRequestWorkers。如果负载很大，现有的子进程数不能满足时，控制 进程会派生新的子进程。默认最大的子进程总数是 16，加大时 也需要显式声明 ServerLimit （系统配置的最大进程数量，最大值是 20000）。需要注意的是，如果显式声明了 ServerLimit， 那么它乘以 ThreadsPerChild的值必须大于等于MaxRequestWorkers，而且MaxRequestWorkers 必须是 ThreadsPerChild 的整数倍，否则 Apache 将会自动调节到一个相应值 ¶注4：进程与线程的区别 线程是指进程内的一个执行单元,也是进程内的可调度实体 与进程的区别: （1）地址空间:进程内的一个执行单元;进程至少有一个线程;它们共享进程的地址空间;而进程 有自己独立的地址空间; （2）资源拥有:进程是资源分配和拥有的单位,同一个进程内的线程共享进程的资源 （3）线程是处理器调度的基本单位,但进程不是 （4）二者均可并发执行. 进程和线程都是由操作系统所体会的程序运行的基本单元，系统利用该基本单元实现系统对 应用的并发性 进程和线程的区别在于： 简而言之,一个程序至少有一个进程,一个进程至少有一个线程. 线程的划分尺度小于进程，使得多线程程序的并发性高。 另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程 序的运行效率 ¶Event模式 这是 Apache 最新的工作模式，是 worker 模式的变种，它把服务进程从连接中分离出来，一 worker 模式不同的是在于它解决了 keep-alive 长连接的时候占用线程资源被浪费的问题，在 event 工作模式中，会有一些专门的线程用来管理这些 keep-alive 类型的线程，当有真实请求过来的时候，将请求传递给服务器的线程，执行完毕后，又允许它释放。这增强了在高并 发场景下的请求处理。event 模式不能很好的支持 https 的访问（HTTP 认证相关的问题） ¶三、apache 配置参数 ¶（1）KeepAlive On/Off KeepAlive 指的是保持连接活跃，换一句话说，如果将 KeepAlive 设置为 On，那么来自 同一客户端的请求就不需要再一次连接，避免每次请求都要新建一个连接而加重服务器的负 担。一般情况下，图片较多的网站应该把 KeepAlive 设为 On ¶（2）KeepAliveTimeOut number 如果第二次请求和第一次请求之间超过 KeepAliveTimeOut 的时间的话，第一次连接就会 中断，再新建第二个连接。它的设置一般考虑图片或者 JS 等文件两次请求间隔，一般设置 为 3-5 秒 ¶（3）MaxKeepAliveRequests 100 一次连接可以进行的 HTTP 请求的最大请求次数。将其值设为 0 将支持在一次连接内进 行无限次的传输请求。事实上没有客户程序在一次连接中请求太多的页面，通常达不到这个 上限就完成连接了 ¶（4）HostnameLookups on|off|double 如果是使用 on，那么只有进行一次反查，如果用 double，那么进行反查之后还要进行一次 正向解析，只有两次的结果互相符合才行，而 off 就是不进行域名验证。 如果为了安全，建议使用 double；为了加快访问速度，建议使用 off。 域名查找开启这个会增加 apache 的负担, 减慢访问速度建议关闭 ¶（5）timeout 5 推荐 5 这个是 apache 接受请求或者发出相应的时间超过这个时间断开 注：以上配置项可在/usr/local/http-2.4.23/conf/extra/httpd-default.conf 设置并在 httpd.conf 文件中通过 include 选项引用 ¶MPM 这个比较关键是影响并发效率的主要因素 ¶（1）StartServers 10 设置服务器启动时建立的子进程数量。因为子进程数量动态的取决于负载的轻重,所以 一般没有必要调整这个参数 ¶（2）MinSpareServers 10 设置空闲子进程的最小数量。所谓空闲子进程是指没有正在处理请求的子进程。如果当 前空闲子进程数少于 MinSpareServers ,那么 Apache 将以最大每秒一个的速度产生新的子进 程。只有在非常繁忙机器上才需要调整这个参数。将此参数设的太大通常是一个坏主意 ¶（3）MaxSpareThreads 75 设置空闲子进程的最大数量。如果当前有超过 MaxSpareServers 数量的空闲子进程,那么 父进程将杀死多余的子进程。只有在非常繁忙机器上才需要调整这个参数。将此参数设的太 大通常是一个坏主意。如果你将该指令的值设置为比 MinSpareServers 小,Apache 将会自动将 其修改成”MinSpareServers+1″ ¶（4）ServerLimit 2000 服务器允许配置的进程数上限。只有在你需要将 MaxClients 设置成高于默认值 256 的时 候才需要使用。要将此指令的值保持和 MaxClients 一样。修改此指令的值必须完全停止服务 后再启动才能生效，以 restart 方式重启动将不会生效 ¶（5）MaxClients/MaxRequestWorkers 256 用于客户端请求的最大请求数量（最大子进程数），任何超过 MaxClients 限制的请求都 将进入等候队列。默认值是 256，如果要提高这个值必须同时提高 ServerLimit 的值。建议将初始值设为(以 Mb 为单位的最大物理内存/2),然后根据负载情况进行动态调整。比如一台 4G 内存的机器，那么初始值就是 4000/2=2000。 ¶（6）MaxRequestsPerChild /MaxConnectionsPerChild 0 设置的是每个子进程可处理的请求数。每个子进程在处理了“MaxRequestsPerChild”个请 求后将自动销毁。0 意味着无限，即子进程永不销毁。内存较大的服务器可以设置为 0 或较 大的数字。内存较小的服务器不妨设置成 30、50、100。所以一般情况下，如果你发现服务 器的内存直线上升，建议修改该参数试试 效，以 restart 方式重启动将不会生效 ¶（5）MaxClients/MaxRequestWorkers 256 用于客户端请求的最大请求数量（最大子进程数），任何超过 MaxClients 限制的请求都 将进入等候队列。默认值是 256，如果要提高这个值必须同时提高 ServerLimit 的值。建议将初始值设为(以 Mb 为单位的最大物理内存/2),然后根据负载情况进行动态调整。比如一台 4G 内存的机器，那么初始值就是 4000/2=2000。 ¶（6）MaxRequestsPerChild /MaxConnectionsPerChild 0 设置的是每个子进程可处理的请求数。每个子进程在处理了“MaxRequestsPerChild”个请 求后将自动销毁。0 意味着无限，即子进程永不销毁。内存较大的服务器可以设置为 0 或较 大的数字。内存较小的服务器不妨设置成 30、50、100。所以一般情况下，如果你发现服务 器的内存直线上升，建议修改该参数试试 注：以上配置项可在/usr/local/http-2.4.23/conf/extra/httpd-mpm.conf 设置并在 httpd.conf 文 件中通过 include 选项引用","categories":[{"name":"架构","slug":"架构","permalink":"https://pdxblog.top/categories/%E6%9E%B6%E6%9E%84/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://pdxblog.top/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"Python列表(list)练习题","slug":"Python列表(list)练习题","date":"2020-05-28T16:00:00.000Z","updated":"2020-05-29T08:04:06.818Z","comments":true,"path":"Python列表(list)练习题.html","link":"","permalink":"https://pdxblog.top/Python%E5%88%97%E8%A1%A8(list)%E7%BB%83%E4%B9%A0%E9%A2%98.html","excerpt":"","text":"¶Python列表(list)练习题 @[toc] ¶一、姓名： 将一些朋友的姓名存储在一个列表中，并将其命名为names。依次访问该列表中的每个元素，从而将每个朋友的姓名都打印出来 123names = ['张三', '李四', '王五', '赵六', '田七']for name in names: print(name) 12345张三李四王五赵六田七 ¶二、问候语 继续使用上一个的列表，但不打印每个朋友的姓名，而为每人打印一条消息。 每条消息都包含相同的问候语，但抬头为相应朋友的姓名 123names = ['张三', '李四', '王五', '赵六', '田七']for name in names: print(name + '，Good moning!') 12345张三，Good moning!李四，Good moning!王五，Good moning!赵六，Good moning!田七，Good moning! ¶三、自己的列表 想想你喜欢的通勤方式，如骑摩托车或开汽车，并创建一个包含多种通勤方式的列表。根据该列表打印一系列有关这些通勤方式的宣言，如“I would like to own a Honda motorcycle”。 1234commuting = ['car', 'bicycle', 'motorcycle']brands = ['Benz', 'GIANT', 'Honda']for num in range(0, 3): print('I would like to own a ' + brands[num] + ' ' + commuting[num]) 123I would like to own a Benz carI would like to own a GIANT bicycleI would like to own a Honda motorcycle ¶四、嘉宾名单 如果你可以邀请任何人一起共进晚餐（无论是在世的还是故去的），你会邀请哪些人？请创建一个列表，其中包含至少3你想邀请的人；然后，使用这个列表打印消息，邀请这些人来与你共进晚餐 123guests = [\"Tom\", \"John\", \"Mike\", \"Padma\"]for guest in guests: print(guest + \", 我可以邀请你共进晚餐吗?\") 1234Tom, 我可以邀请你共进晚餐吗?John, 我可以邀请你共进晚餐吗?Mike, 我可以邀请你共进晚餐吗?Padma, 我可以邀请你共进晚餐吗? ¶五、修改嘉宾名单 你刚得知有位嘉宾无法赴约，因此需要另外邀请一位嘉宾。 以完成练习4时编写的程序为基础，在程序末尾添加一条print语句，指出哪位嘉宾无法赴约。 修改嘉宾名单，将无法赴约的嘉宾的姓名替换为新邀请的嘉宾的姓名。 再次打印一系列消息，向名单中的每位嘉宾发出邀请 1234print(guests[2] + \"不能一起吃饭!\" + \"\\n\")guests[2] = 'Bob'for guest in guests: print(guest + \", 我可以邀请你共进晚餐吗?\") 123456Mike不能一起吃饭!Tom, 我可以邀请你共进晚餐吗?John, 我可以邀请你共进晚餐吗?Bob, 我可以邀请你共进晚餐吗?Padma, 我可以邀请你共进晚餐吗? ¶六、添加嘉宾 你刚找到了一个更大的餐桌，可容纳更多的嘉宾。请想想你还想邀请哪三位嘉宾。 以完成练习4或练习5时编写的程序为基础，在程序末尾添加一条print语句，指出你找到了一个更大的餐桌。 使用insert()将一位新嘉宾添加到名单开头。 使用insert()将另一位新嘉宾添加到名单中间。 使用append()将最后一位新嘉宾添加到名单末尾。 打印一系列消息，向名单中的每位嘉宾发出邀请 123456print(\"我找到了一个更大的餐桌!\" + \"\\n\")guests.insert(0, 'zhangsan')guests.insert(3, 'lisi')guests.append('wangwu')for guest in guests: print(guest + \", 我可以邀请你共进晚餐吗?\") 123456789我找到了一个更大的餐桌!zhangsan, 我可以邀请你共进晚餐吗?Tom, 我可以邀请你共进晚餐吗?John, 我可以邀请你共进晚餐吗?lisi, 我可以邀请你共进晚餐吗?Bob, 我可以邀请你共进晚餐吗?Padma, 我可以邀请你共进晚餐吗?wangwu, 我可以邀请你共进晚餐吗? ¶七、缩减名单 你刚得知新购买的餐桌无法及时送达，因此只能邀请两位嘉宾。 以完成练习6时编写的程序为基础，在程序末尾添加一行代码，打印一条你只能邀请两位嘉宾共进晚餐的消息。 使用 pop()不断地删除名单中的嘉宾，直到只有两位嘉宾为止。每次从名单中弹出一位嘉宾时，都打印一条消息，让该嘉宾知悉你很抱歉，无法邀请他来共进晚餐。 对于余下的两位嘉宾中的每一位，都打印一条消息，指出他依然在受邀人之列。 使用del()将最后两位嘉宾从名单中删除，让名单变成空的。打印该名单，核实程序结束时名单确实是空的 12345678910print(\"sorry,我只能邀请两位嘉宾共进晚餐!\" + \"\\n\")while len(guests) &gt; 2: honored = guests.pop() print(honored + \",我很抱歉,我不能邀请你一起共进晚餐!\")print(\"------------\")for guest in guests: print(guest + \", 我仍然希望你能和我一起吃饭!\")del guests[0]del guests[0]print(guests) 1234567891011sorry,我只能邀请两位嘉宾共进晚餐!wangwu,我很抱歉,我不能邀请你一起共进晚餐!Padma,我很抱歉,我不能邀请你一起共进晚餐!Bob,我很抱歉,我不能邀请你一起共进晚餐!lisi,我很抱歉,我不能邀请你一起共进晚餐!John,我很抱歉,我不能邀请你一起共进晚餐!------------zhangsan, 我仍然希望你能和我一起吃饭!Tom, 我仍然希望你能和我一起吃饭![] ¶八、放眼世界 想出至少5个你渴望去旅游的地方。 ​ 将这些地方存储在一个列表中，并确保其中的元素不是按字母顺序排列的。 ​ 按原始排列顺序打印该列表。不要考虑输出是否整洁的问题，只管打印原始Python列表。 ​ 使用sorted()按字母顺序打印这个列表，同时不要修改它。 ​ 再次打印该列表，核实排列顺序未变。 ​ 使用sorted()按与字母顺序相反的顺序打印这个列表， 同时不要修改它。 ​ 再次打印该列表，核实排列顺序未变。 ​ 使用reverse()修改列表元素的排列顺序。打印该列表，核实排列顺序确实变了。 ​ 使用reverse()再次修改列表元素的排列顺序。打印该列表，核实已恢复到原来的排列顺序。 ​ 使用sort()修改该列表，使其元素按字母顺序排列。打印该列表，核实排列顺序确实变了。 ​ 使用sort()修改该列表，使其元素按与字母顺序相反的顺序排列。打印该列表，核实排列顺序确实变了 123456789101112131415161718192021222324resort = [ \"Santorini\", \"Aegean Sea\", \"Pink Sands\", \"Rose Lake\", \"The blue hole\"]print(resort)print(\"------------\")print(sorted(resort))print(\"------------\")print(resort)print(\"------------\")print(sorted(resort, reverse=True))print(\"------------\")print(resort)print(\"------------\")resort.reverse()print(resort)print(\"------------\")resort.reverse()print(resort)print(\"------------\")resort.sort()print(resort)print(\"------------\")resort.sort(reverse=True)print(resort) 1234567891011121314151617['Santorini', 'Aegean Sea', 'Pink Sands', 'Rose Lake', 'The blue hole']------------['Aegean Sea', 'Pink Sands', 'Rose Lake', 'Santorini', 'The blue hole']------------['Santorini', 'Aegean Sea', 'Pink Sands', 'Rose Lake', 'The blue hole']------------['The blue hole', 'Santorini', 'Rose Lake', 'Pink Sands', 'Aegean Sea']------------['Santorini', 'Aegean Sea', 'Pink Sands', 'Rose Lake', 'The blue hole']------------['The blue hole', 'Rose Lake', 'Pink Sands', 'Aegean Sea', 'Santorini']------------['Santorini', 'Aegean Sea', 'Pink Sands', 'Rose Lake', 'The blue hole']------------['Aegean Sea', 'Pink Sands', 'Rose Lake', 'Santorini', 'The blue hole']------------['The blue hole', 'Santorini', 'Rose Lake', 'Pink Sands', 'Aegean Sea'] ¶九、晚餐嘉宾 使用len()打印一条消息，指出你邀请了多少位嘉宾来与你共进晚餐 12guests = [\"Tom\", \"John\", \"Mike\", \"Padma\"]print(\"我一共邀请了\" + str(len(guests)) + \"位嘉宾\") 1我一共邀请了4位嘉宾","categories":[{"name":"Python一些列练习题","slug":"Python一些列练习题","permalink":"https://pdxblog.top/categories/Python%E4%B8%80%E4%BA%9B%E5%88%97%E7%BB%83%E4%B9%A0%E9%A2%98/"}],"tags":[{"name":"Python一系列练习题","slug":"Python一系列练习题","permalink":"https://pdxblog.top/tags/Python%E4%B8%80%E7%B3%BB%E5%88%97%E7%BB%83%E4%B9%A0%E9%A2%98/"}]},{"title":"for循环和原作练习题","slug":"for循环和原作练习题","date":"2020-05-28T16:00:00.000Z","updated":"2020-05-29T08:04:06.827Z","comments":true,"path":"for循环和原作练习题.html","link":"","permalink":"https://pdxblog.top/for%E5%BE%AA%E7%8E%AF%E5%92%8C%E5%8E%9F%E4%BD%9C%E7%BB%83%E4%B9%A0%E9%A2%98.html","excerpt":"","text":"¶for循环和原作练习题 @[toc] ¶1、比萨： 想出至少三种你喜欢的比萨，将其名称存储在一个列表中，再使用for循环将每种比萨的名称都打印出来。 123pizzas = ['鸡肉披萨', '牛肉披萨', '培根披萨']for pizza in pizzas: print(pizza) 123鸡肉披萨牛肉披萨培根披萨 ¶（1）I like pepperoni pizza 修改这个for循环，使其打印包含比萨名称的句子，而不仅仅是比萨的名称。对于每种比萨，都显示一行输出，如“Ilikepepperonipizza”。 12for pizza in pizzas: print('I like ' + pizza) 123I like 鸡肉披萨I like 牛肉披萨I like 培根披萨 ¶（2）I really love pizza! 在程序末尾添加一行代码，它不在for循环中，指出你有多喜欢比萨。输出应包含针对每种比萨的消息，还有一个总结性句子，如“Ireallylovepizza!”。 123for pizza in pizzas: print('I like ' + pizza + ' very much')print('I really love pizza!') 1234I like 鸡肉披萨 very muchI like 牛肉披萨 very muchI like 培根披萨 very muchI really love pizza! ¶2、动物： 想出至少三种有共同特征的动物，将这些动物的名称存储在一个列表中，再使用for循环将每种动物的名称都打印出来。 ¶（1）A dog would make great pet 修改这个程序，使其针对每种动物都打印一个句子，如“Adogwouldmakeagreatpet”。 123zoos = ['dog', 'cat', 'pig']for zoo in zoos: print(zoo + ' would make great pet!') 123dog would make great pet!cat would make great pet!pig would make great pet! ¶（2）Any of these animals would make a great pet 在程序末尾添加一行代码，指出这些动物的共同之处，如打印诸如“Anyoftheseanimalswouldmakeagreatpet!”这样的句子。 123for zoo in zoos: print(zoo + ' would make great pet!')print(\"Any of these animals would make a great pet!\") 1234dog would make great pet!cat would make great pet!pig would make great pet!Any of these animals would make a great pet! ¶3、数到20： 使用一个for循环打印数字1~20（含） 12for num in range(1, 21): print(num, end=' ') 11 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ¶4、一百万： 创建一个列表，其中包含数字1~1000000，再使用一个for循环将这些数字打印出来（如果输出的时间太长，按Ctrl+C停止输出，或关闭输出窗口）。 12for nums in range(1, 1000001): print(nums, end=' ') ¶5、计算1~1000000的总和： 创建一个列表，其中包含数字1~1000000，再使用min()和max()核实该列表确实是从1开始，到1000000结束的。另外，对这个列表调用函数sum()，看看Python将一百万个数字相加需要多长时间。 1234number = list(range(1, 1000001))print(min(number))print(max(number))print(sum(number)) 12311000000500000500000 ¶6、奇数： 通过给函数range()指定第三个参数来创建一个列表，其中包含1~20的奇数；再使用一个for循环将这些数字都打印出来。 12for i in range(1, 21, 2): print(i, end=' ') 11 3 5 7 9 11 13 15 17 19 ¶7、3的倍数： 创建一个列表，其中包含3~30内能被3整除的数字；再使用一个for循环将这个列表中的数字都打印出来。 12for j in range(3,30,3): print(j,end=' ') 13 6 9 12 15 18 21 24 27 ¶8、立方： 将同一个数字乘三次称为立方。例如，在Python中，2的立方用2**3表示。请创建一个列表，其中包含前10个整数（即1~10）的立方，再使用一个for循环将这些立方数都打印出来。 12345values = []for value in range(1,11): cube = value**3 values.append(cube)print(values) 1[1, 8, 27, 64, 125, 216, 343, 512, 729, 1000] ¶9、立方解析： 使用列表解析生成一个列表，其中包含前10个整数的立方。 12cubes = [value ** 3 for value in range(1,11)]print(cubes) 1[1, 8, 27, 64, 125, 216, 343, 512, 729, 1000] ¶10、自助餐： 有一家自助式餐馆，只提供五种简单的食品。请想出五种简单的食品，并将其存储在一个元组中。 ¶（1）使用一个for循环将该餐馆提供的五种食品都打印出来。 123buffets = ('饮料','甜品','水果','肉食','素食')for buffet in buffets: print(buffet,end=' ') 1饮料 甜品 水果 肉食 素食 ¶（2）尝试修改其中的一个元素，核实Python确实会拒绝你这样做。 1buffets[0] = '啤酒' ¶（3）餐馆调整了菜单，替换了它提供的其中两种食品。请编写一个这样的代码块： 给元组变量赋值，并使用一个for循环将新元组的每个元素都打印出来。 123buffets = ('啤酒','蛋糕','水果','肉食','素食')for buffet in buffets: print(buffet,end=' ') 1啤酒 蛋糕 水果 肉食 素食","categories":[{"name":"Python一些列练习题","slug":"Python一些列练习题","permalink":"https://pdxblog.top/categories/Python%E4%B8%80%E4%BA%9B%E5%88%97%E7%BB%83%E4%B9%A0%E9%A2%98/"}],"tags":[{"name":"Python一系列练习题","slug":"Python一系列练习题","permalink":"https://pdxblog.top/tags/Python%E4%B8%80%E7%B3%BB%E5%88%97%E7%BB%83%E4%B9%A0%E9%A2%98/"}]},{"title":"Python制作疫情地图","slug":"疫情地图","date":"2020-05-28T16:00:00.000Z","updated":"2020-05-29T08:08:11.342Z","comments":true,"path":"疫情地图.html","link":"","permalink":"https://pdxblog.top/%E7%96%AB%E6%83%85%E5%9C%B0%E5%9B%BE.html","excerpt":"","text":"¶疫情地图 话不多说，直接上代码 1234567891011121314151617181920212223242526# coding:utf-8from pyecharts.charts import Mapimport pyecharts.options as optimport requestsimport json# 获取数据result = requests.get('https://gwpre.sina.cn/interface/fymap2020_data.json').textresult = json.loads(result)# print(result)# 清洗数据data = list()for i in result['data']['list']: data.append((i['name'], i['value']))# print(data)# 绘制中国地图new_map = Map()new_map.set_global_opts( title_opts=opt.TitleOpts('疫情地图', subtitle='数据来源于新浪网', subtitle_link='http://www.sina.cn'), visualmap_opts=opt.VisualMapOpts(max_=10000, is_piecewise=True))new_map.add('确诊', data, maptype='china')new_map.render('20200528.html') 效果图：","categories":[{"name":"Python一些列练习题","slug":"Python一些列练习题","permalink":"https://pdxblog.top/categories/Python%E4%B8%80%E4%BA%9B%E5%88%97%E7%BB%83%E4%B9%A0%E9%A2%98/"}],"tags":[{"name":"Python一系列练习题","slug":"Python一系列练习题","permalink":"https://pdxblog.top/tags/Python%E4%B8%80%E7%B3%BB%E5%88%97%E7%BB%83%E4%B9%A0%E9%A2%98/"}]},{"title":"Python网络管理","slug":"Python网络管理","date":"2020-05-14T16:00:00.000Z","updated":"2020-05-15T06:31:34.497Z","comments":true,"path":"Python网络管理.html","link":"","permalink":"https://pdxblog.top/Python%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86.html","excerpt":"","text":"¶网络 网络可以将多台主机进行连接，使得网络中的主机可以相互通信。在网络通信中，使用最广泛的通信协议是TCP/IP协议簇，因此，Python也提供了相应的应用程序接口（API), 使得工程师可以在Python程序中创建网络连接、进行网络通信。 计算机之间可以相互通信以后，就开始涉及网络安全问题。现如今网络情况复杂安全环境恶劣。 2017年5月12日起，全球范围内爆发基于Windows网络共享协议进行攻击传播的蠕虫恶意代码，这是不法分子通过改造之前泄露的NSA黑客武器库中“永恒之蓝”攻击程序发起的网络攻击事件。五个小时内，包括英国、俄罗斯、整个欧洲以及中国国内多个高校校内网、大型企业内网和政府机构专网中招，被勒索支付高额赎金才能解密恢复文件，对重要数据造成严重损失。 被袭击的设备被锁定，并索要300美元比特币赎金。要求尽快支付勒索赎金，否则将删除文件，甚至提出半年后如果还没支付的穷人可以参加免费解锁的活动。原来以为这只是个小范围的恶作剧式的勒索软件，没想到该勒索软件大面积爆发，许多高校学生中招，愈演愈烈。 Python是一门应用领域非常广泛的语言，除了在科学计算、大数据处理、自动化运维等领域广泛应用以外，在计算机网络领域中使用也非常广泛。这主要得益于Python语言的开发效率高、入门门槛低、功能强大等优点。工程师可以使用Python语言管理网络，计算机黑客可以使用Python语言或者Python语言编写的安全工具进行渗透测试、网络分析、安全防范等。 在这章中，我们将介绍Python在网络方面的应用，包括网络通信、网络管理和网络安全。我们首先介绍如何使用Python语言列出网络上所有活跃的主机；然后介绍一个 端口扫描工具；接着介绍如何使用IPy方便地进行IP地址管理；随后，介绍了一个DNS工具包；最后，我们介绍了一个非常强大的网络嗅探工具。 ¶一、列出网络上所有活跃的主机 在这一小节中，我们将会学习如何在shell脚本中调用ping命令得到网络上活跃的主机列表，随后，我们使用Python语言改造这个程序，以此支持并发的判断。 ¶1、使用ping命令判断主机是否活跃 ping命令是所有用户都应该了解的最基础的网络命令，ping命令可以探测主机到主机之间是否能够通信，如果不能ping到某台主机，则表明不能和这台主机进行通信。ping命令最常使用的场景是验证网络上两台主机的连通性以及找出网络上活跃的主机。 为了检査网络上两台主机之间的连通性，ping命令使用互联网控制协议（ICMP)中的 ECHO_REQUEST数据报，网络设备收到该数据报后会做出回应。ping命令可以通过网络设备的回复得知两台主机的连通性以及主机之间的网络延迟。 ping命令的使用非常简单，直接使用主机名、域名或IP地址作为参数调用ping命令即可。如下所示： 123456[root@bogon ~]# ping 192.168.1.10PING 192.168.1.10 (192.168.1.10) 56(84) bytes of data.64 bytes from 192.168.1.10: icmp_seq=1 ttl=64 time=0.023 ms64 bytes from 192.168.1.10: icmp_seq=2 ttl=64 time=0.034 ms64 bytes from 192.168.1.10: icmp_seq=3 ttl=64 time=0.033 ms64 bytes from 192.168.1.10: icmp_seq=4 ttl=64 time=0.039 ms ping命令会连续发送包，并将结果打印到屏幕终端上。如果主机不可达，ping将会显示“Destination Host Unreachable”的错误信息。如下所示： 123456[root@bogon ~]# ping www.baidu.comPING www.a.shifen.com (220.181.38.150) 56(84) bytes of data.From bogon (192.168.1.10) icmp_seq=1 Destination Host UnreachableFrom bogon (192.168.1.10) icmp_seq=2 Destination Host UnreachableFrom bogon (192.168.1.10) icmp_seq=3 Destination Host UnreachableFrom bogon (192.168.1.10) icmp_seq=4 Destination Host Unreachable 除了检查网络上两台主机之间的连通性外，ping命令还可以粗略地估计主机之间的网络延迟情况。在ping命令的输出结果中，time字段的取值表示网络上两台主机之间的往返时间，它是分组从源主机到B的主机一个来回的时间，单位是毫秒。我们可以通过这个时间粗略估计网络的速度以及监控网络状态。例如，有这样一个使用ping命令解决线上问题的案例。当时的情况是应用程序使用我们提供的数据库服务，在每个整点时都会出现应用程序建立数据库连接失败的情况。通过前期排査，可以确定的是应用的请求已成功发出，数据库的压力并不是特别大，数据库连接也没有满。因此，问题很有可能出在网络上面。为此，我们增加了一个ping延迟监控。通过监控发现，在每个整点时ping的网络延迟变大，甚至大到了不可接受的程度。有了这个线索以后，接着排查网络问题。通过分析定位，发现是因为宿主机上有定时任务，导致每个整点宿主机的cpu压力增加，从而引发了前面所说的建立数据库连接失败的错误。 默认情况下，ping命令会不停地发送ECHO_REQUEST数据报并等待回复，到按下Ctrl+C为止。我们可以用选项-c限制所发送的ECHO_REQUEST数据报数量。用法如下： 12345678[root@bogon ~]# ping -c 2 192.168.1.10PING 192.168.1.10 (192.168.1.10) 56(84) bytes of data.64 bytes from 192.168.1.10: icmp_seq=1 ttl=64 time=0.030 ms64 bytes from 192.168.1.10: icmp_seq=2 ttl=64 time=0.047 ms--- 192.168.1.10 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1000msrtt min/avg/max/mdev = 0.030/0.038/0.047/0.010 ms 在这个例子中，ping命令发送了 2个ECHO_REQUEST数据报就停止发送，这个功能对于脚本中检查网络的连通性非常有用。 ping命令将结果打印到屏幕终端，我们通过ping命令的输出结果判断主机是否可达, 这种方式虽然直观，但是不便于程序进行处理。在程序中可以通过ping命令的返回码判断主机足否可达，当主机活跃时，ping命令的返回码为0，当主机不可达时，ping命令的返回码非0。 有了上面的基础以后，要判断网络上活跃的主机就非常容易了。我们只需要ping每一台主机，然后通过ping命令的返回值判断主机是否活跃。下面这段Shell程序就是用来判断网络中的主机是否可达： 123456789for ip in 'cat ips.txt'do if ping $ip -c 2 &amp; &gt; /dev/null then echo \"$ip is alive\" else echo \"$ip is unreachable\" fidone 在这个例子中，我们首先将主机地址以每行一个地址的形式保存到ips.txt文件中，然后通过cat命令读取ips.txt文件中的内容，使用for循环迭代ips.txt中保存的主机。 为了减少视觉杂讯，使用输出重定向的方式将ping命令的结果输出到/dev/null中，以此避免信息在终端上打印。为了简化起见，我们直接在if语句中调用ping命令，Shell脚本能够根据ping命令的返回码判断命令执行成功还是失败。 ¶2、使用Python判断主机是否活跃 前面的Shell脚本中，虽然所有的IP地址都是彼此独立，但是，我们的程序依然是顺序调用ping命令进行主机探活。由于每执行一次ping命令都要经历一段时间延迟（或者接收回应，或者等待回应超时)，所以，当我们要检査大量主机是否处于活跃状态时需要很长的时间。对于这种情况可以考虑并发地判断主机是否活跃。 Shell脚本可以非常快速地解决简单的任务，但是，对于比较复杂的任务，Shell脚本就无能为力。如这里的并发判断主机是否活跃的需求。对于这种情况，可以使用Python语言编写并发的程序，以此加快程序的执行。如下所示： 1234567891011121314151617181920212223242526272829#/usr/bin/python#_*_ coding:utf-8 _*_from __future__ import print_functionimport subprocessimport threadingdef is_reacheable(ip): if (subprocess.call(['ping', '-c', '1', ip])): print('&#123;0&#125; is alive'.format(ip)) else: print('&#123;0&#125; is unreacheable'.format(ip))def main(): with open('ips.txt') as f: lines = f.readlines(); threads = [] for line in lines: thr = threading.Thread(target=is_reacheable, args=(line,)) thr.start() threads.append(thr) for thr in threads: thr.join()if __name__ == \"__main__\": main() 在这个例子中，我们首先打开ips.txt文件，并通过File对象的readlines函数将所有IP 地址读入内存。读入内存以后，IP地址保存在一个列表中，列表的每一项正好是一个地址。 对于每一个IP地址都创建一个线程。由于线程之间不共享任何数据，因此，不需要进行并发控制，这也使得整个程序变得简单。 在Python 中要判断两台主机是否可达有两种不同的方法，一种是在Python程序中调用ping命令实 现，另一种是使用socket编程发送ICMP数据报。为了简单起见，在我们这里的例子中使用前一种方法。为了调用系统中的ping命令，我们使用了subprocess模块。 我们的Python程序最终也是调用ping命令判断主机是否活跃，从思路上来说，和前面的Shell脚本是一样的。区别就在于Python程序使用并发加快了程序的执行效率。在我的测试环境中，测试了36个IP地址，其中，有12个IP地址不可达，需要等待网络超时才能返回，另外24个IP地址可达。使用Linux自带的time命令进行粗略计时，Shell脚本的执行时间是1分48秒，Python程序的执行时间是10秒。两个程序执行时间的差异，根据网络规模和网络环境将会显著不同。这里要表达的是，使用Python语言只需要很少的代码就能够将一个程序改造成并发的程序，通过并发来大幅提升程序的效率。 ¶3、使用生产者消费者模型减少线程的数量 在前面的例子中，我们为每一个IP地址创建一个线程，这在IP地址较少的时候还算可行，但在IP地址较多时就会暴露出各种问题（如频繁的上下文切换）。因此，我们需要限制线程的数量。 列出网络上所有活跃主机的问题，其实是一个简单的生产者和消费者的问题。生产者 和消费者问题是多线程并发中一个非常经典的问题，该问题描述如下： 有一个或多个生产者在生产商品，这些商品将提供给若干个消费者去消费。为了使生产者和消费者能并发执行，在两者之间设置一个缓冲期，生产者将它生产的商品放入缓冲中，消费者可以从缓冲区中取走商品进行消费。生产者只需要关心这个缓冲区是否已满， 如果未满则向缓冲区中放入商品，如果已满，则需要等待。同理，消费者只需要关心緩冲区中是否存在商品，如果存在商品则进行消费，如果缓冲区为空，则需要等待。 生产者和消费者模型的好处是，生产者不需要关心有多少消费者、消费者何时消费、 以怎样的速度进行消费。消费者也不需要关心生产者，这就实现了程序模块的解耦。 我们这里的问题比生产者和消费者模型还要简单，只需要一次性将所有的IP地址读入到内存中，然后交由多个线程去处理。也就是说，我们一开始就生产好了所有的商品，只需要消费者消费完这些商品即可。如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445#/usr/bin/python#_*_ coding:utf-8 _*_from __future__ import print_functionimport subprocessimport threadingfrom sqlalchemy.util.queue import Empty, Queuedef call_ping(ip): if (subprocess.call(['ping', '-c', '1', ip])): print('&#123;0&#125; is alive'.format(ip)) else: print('&#123;0&#125; is unreacheable'.format(ip))def is_reacheable(q): try: while True: ip = q.get_nowait() call_ping(ip) except Empty: passdef main(): q = Queue() with open('ips.txt') as f: for line in f: q.put(line) threads = [] for i in range(10): thr = threading.Thread(target=is_reacheable, args=(q,)) thr.start() threads.append(thr) for thr in threads: thr.join()if __name__ == \"__main__\": main() 在这个例子中创建了10个线程作为消费者线程，我们可以修改range函数的参数控制线程的个数。此外，我们还用到了一个新的数据结构，即Queue。引入Queue足因为多个消费者之间存在并发访问的问题，即多个消费者可能同时从缓冲区中获取商品。为了解决并发问题，我们使用了 Python标准库的Queue。Queue是标准库中线程安全的队列（FIFO) 实现，提供了一个适用于多线程编程的先进先出的数据结构，非常适合用于生产者和消费者线程之间的数据传递。 在这段程序中，我们首先将所有1P地址读入内存并放入Queue中，消费者不断从 Queue中获取商品。需要注意的是，如果我们使用Queue的get方法，当Queue中没有商品时，线程将会阻塞等待直到有新的商品为止。而在这个例子中不需要消费者阻塞等待， 因此，使用了Queue的get_nowait方法。该方法在冇商品时直接返回商品，没有商品时抛出Empty异常。消费者线程不断从Queue中获取IP地址，获取到IP地址以后调用call_ ping函数判断主机是否可达，直到没有商品以后退出线程。 ¶二、端口扫描 仅仅知道网络上的主机是否可达还不够，很多情况下，我们需要的是一个端口扫描器。使用端口扫描器吋以进行安全检测与攻击防范。例如，在2017年5月12日，全球范围内爆发了基于Windows网络共享协议的永恒之蓝（Wannacry)勒索蠕虫。仅仅五个小时，包 括美国、中国、俄罗斯以及整个欧洲在内的100多个国家都不问程度地遭受永恒之蓝病毒攻击，尤其是高校、大型企业内网和政府机构专网，被攻击的电脑被勒索支付高额赎金才能解密恢复文件，对重要数据造成严重损失。永恒之蓝利用Windows系统的445端口进行蠕虫攻击，部分运营商已经在主干网络上封禁了 445端口，但是教育网以及大量企业内网并没有此限制，从而导致了永恒之蓝勒索蠕虫的泛滥。 所以作为工程师，一方面需要在日常维护养成良好的习惯，如配置防火墙、进行网络隔离、关闭不必要的服务、及时更新补丁；另一方面可以掌握一些安全相关的工具，在日常中进行安全防范，在紧急悄况下进行安全检测。在这一小节，我们将介绍如何使用Python进行端口扫描。有了端口扫描器，我们可以快速了解主机打开了哪些不必要的端口，以便及时消灭安全隐患。 在这一小节中，我们将使用Python语言编写一个端口扫描器，然后介绍大名鼎鼎的端 口扫描工具nmap，最后，通过python-nmap在Python代码中调用nmap进行端口扫描。 ¶1、使用Python编写端口扫描工具 在Linux下，可以使用ping命令要判断一台主机是否可达，而判断一个端口是否打开可以使用telnet命令。我们可以模仿前面小节中并行ping的例子，在Python代码中调用 telnet命令判断一个端口是否打开。但是telnet命令存在一个问题，当我们telnet—个不可达的端口时，telnet需要很久才能够超时返回，并且telnet命令没有参数控制超时时间。 此外，如果Python标准库中有相应的模块，应该尽可能地使用Python的标准库，而不是在 Python代码中执行Linux命令。这一方面能够增加代码的可读性、可维护性，另一方面也能够保证程序跨平台运行。 为了使用Python编写端口扫描器，我们需要简单了解socket模块。socket模块为操作系统的socket连接提供了一个Python接口。有了 socket模块，我们可以完成任何使用 socket的任务。 socket模块提供了一个工厂函数socket，socket函数会返冋一个socket对象。我们可以给socket函数传递参数，以此创建不同网络协议和网络类塑的socket对象。默认情况下，socket函数会返回一个使用TCP协议的socket对象。如下所示： 123456789101112131415In [1]: import socketIn [2]: s = socket.socket()In [3]: s.connect(('47.100.98.242',80))In [4]: s.send(\"GET/HTTP/1.0\".encode())Out[4]: 12In [5]: print(s.recv(200))b'HTTP/1.1 400 Bad Request\\r\\nServer: nginx\\r\\nDate: Sat, 29 Feb 2020 15:44:51 GMT\\r\\nContent-Type: text/html\\r\\nContent-Length: 150\\r\\nConnection: close\\r\\n\\r\\n&lt;html&gt;\\r\\n&lt;head&gt;&lt;title&gt;400 Bad Request&lt;/title&gt;&lt;/head&gt;\\r\\n&lt;b'In [6]: s.close() 在这个例子中，socket工厂函数以默认参数AF_INET和SOCK_STREAM创建了一个 名为s的socket对象，该对象可以在进程间进行TCP通信。创建完对象以后，我们使用connect函数连接到远程服务器的80端口，并发送一个HTTP请求到远程服务器，发送完 毕之后，接收服务器响应的前200个宇节。最后，调用socket对象的close方法关闭连接。 在这个例子中，我们用到了 socket工厂函数、socket的connect方法、send方法、recv 方法和close方法，这也是socket中最常使用的一些方法。 接下来，我们就看一下如何使用简单的socket接口编写一个端口扫描器。如下所示： 1234567891011121314151617181920212223242526#/usr/bin/python#_*_ coding:utf-8 _*_from __future__ import print_functionfrom socket import *def conn_scan(host, port): conn = socket(AF_INET, SOCK_STREAM) try: conn.connect((host, port)) print(host, port, 'is avaliable') except Exception as e: print(host, port, 'is not avaliable') finally: conn.close()def main(): host = '47.100.98.242' for port in range(80, 5000): conn_scan(host, port)if __name__ == '__main__': main() 在这个端口扫描的例子中，conn_scan用来判断端口是否可用。该函数尝试建立与目标主机和端口的连接，如果成功，打印一个端口开放的消息，否则，打印一个端口关闭的消息。 除广使用socket套接字编程的方式判断端口是否可用以外，还可以使用Python标准库的telnet模块。该模块中包含了一个Telnet类，该类的对象表示一个telnet的连接。创建一 个Telnet对象并不会建立到远程主机的连接，需要显式地使用open方法建立连接。open方法接受三个参数，分别是主机名、端口号和超时时间。如下所示： 123456789101112131415161718192021222324252627#/usr/bin/python#_*_ coding:utf-8 _*_from __future__ import print_functionfrom socket import *import telnetlibdef conn_scan(host, port): t = telnetlib.Telnet() try: t.open(host,port,timeout=1) print(host, port, 'is avaliable') except Exception as e: print(host, port, 'is not avaliable') finally: t.close()def main(): host = '47.100.98.242' for port in range(20, 5000): conn_scan(host, port)if __name__ == '__main__': main() 对于上面这段程序，我们可以参考多线程的ping程序，以及使用生产者和消费者模型的ping程序，将这段程序扩展成多主机和多线程的端口扫描器。 与ping程序不同的是，端U扫描需要用到两个参数，即主机地址和端口号。当我们有了主机的列表和端口号的列表以后，如何能够快速地得到所有主机与端口号的组合呢？对于这个问题，有多种不同的方法。其中比较方便的是使用列表推导。如下所示： 123456In [1]: l1 = ('a','b','c')In [2]: l2 = (22,80)In [3]: list([(x,y) for x in l1 for y in l2])Out[3]: [('a', 22), ('a', 80), ('b', 22), ('b', 80), ('c', 22), ('c', 80)] 使用列表推导虽然比较方便，但是，这个列表推导表达式本身比较复杂。因此，我们可以考虑使用itertools模块中的product函数。Python标准库的itertools模块提供了一组非常常用的函数，读者很有必要了解hertooU模块中提供的函数。在itertools模块中有一个名为product的函数，该函数用来返回多个可迭代对象的笛卡尔积。注意，product比前面的列表推导表达式更加通用，它可以返回多个可迭代对象的笛长尔积。这里的例子只需要计算两个可迭代对象的笛卡尔积。如下所示： 1234In [4]: from itertools import productIn [5]: list(product(l1,l2))Out[5]: [('a', 22), ('a', 80), ('b', 22), ('b', 80), ('c', 22), ('c', 80)] 有了主机和端口的组合以后，我们可以参照生产者和消费者模型的例子，开发一个多线程的端口扫描器。但是我们并没有必要这么做，因为除了使用多线程编程编写端口扫描器以外，还可以使用Python-nmap模块更加方便地进行端口扫描。 ¶2、使用nmap扫描端口 Python-nmap模块是对nmap命令的封装。nmap是知名的网络探测和安全扫描程序, 是Network Mapper的简称。nmap可以进行主机发现（Host Discovery)、端口扫描（Port Scanning)、版本侦测（Version Detection〉、操作系统侦测（Operating System Detection)，nmap是网络管理员必用的软件之一。nmap因为功能强大、跨平台、开源、文档丰富等诸多优点，在安全领域使用非常广泛。 在使用之前，需要先安装nmap。如下所示： 1[root@bogon ~]# yum install nmap nmap的使用非常灵活，功能又很强大，因此nmap有很多命令行选项。使用nmap时， 首先需要确定要对哪些主机进行扫描，然后确定怎么进行扫描（如使用何种技术，对哪些端 口进行扫描）。 nmap具有非常灵活的方式指定需要扫描的主机，我们可以使用nmap命令的-sL选项 来进行测试。-sL选项仅仅打印IP列表，不会进行任何操作。如下所示： 123456[root@bogon ~]# nmap -sL 47.100.98.242/80Starting Nmap 6.40 ( http://nmap.org ) at 2020-03-01 00:18 CSTIllegal netmask in \"47.100.98.242/80\". Assuming /32 (one host)Nmap scan report for 47.100.98.242Nmap done: 1 IP address (0 hosts up) scanned in 0.04 seconds nmap提供了非常灵活的方式来指定主机，包括同时指定多个IP、通过网段指定主机、通过通配符指定主机等。如下所示： 123456nmap -sL 47.100.98.242 14.215.177.39nmap -sL 47.100.98.*nmap -sL 47.100.98.242,243,245nmap -sL 47.100.98.242-250nmap -sL 47.100.98.* --exclude 47.100.98.242nmap -sL 47.100.98.242/30 除了上面指定主机的方式，我们也可以将IP地址保存到文本中，通过-iL选项读取文件中的IP地址。如下所示： 1nmap -iL ip.list ¶（1）主机发现 端口扫描是nmap的重点，除此之外，我们也可以使用nmap检查网络上所有在线的主机，实现类似前边小节中列出网络上所有活跃的主机的功能。使用-sP或-sn选项可以告诉nmap不要进行端口扫描，仅仅判断主机是否可达。如下所示： 1234567[root@bogon ~]# nmap -sP 47.100.98.*Starting Nmap 6.40 ( http://nmap.org ) at 2020-03-01 00:25 CSTNmap done: 256 IP addresses (0 hosts up) scanned in 206.44 seconds [root@bogon ~]# nmap -sn 47.100.98.*Starting Nmap 6.40 ( http://nmap.org ) at 2020-03-01 00:35 CSTNmap done: 256 IP addresses (0 hosts up) scanned in 205.38 seconds ¶（2）端口扫描 端口扫描是nmap最基本，也是最核心的功能，用于确定目标主机TCP/UDP端口的开放情况。不添加任何参数便是对主机进行端口扫描。默认情况下，nmap将会扫描1000个最常用的端口号。如下所示： 1234[root@bogon ~]# nmap 14.215.177.39Starting Nmap 6.40 ( http://nmap.org ) at 2020-03-01 00:42 CSTNote: Host seems down. If it is really up, but blocking our ping probes, try -PnNmap done: 1 IP address (0 hosts up) scanned in 3.09 seconds 在进行端口扫描时，nmap提供了大M的参数控制端口扫描。包括端口扫描协议、端口扫描类型、扫描的端口号。如下所示： 端口扫描协议：T (TCP)、U (UDP)、S (SCTP&gt;、P (IP); 端口扫描类型：-sS/sT/sA/sW/sM: TCP SYN/Connect()/ACK/Window/Maimon scans; 扫描的端口号：-p 80,443 -p 80-160 nmap中的端口扫描协议、扫描类型和端口号相关的选项，可以结合起来使用。如下所示： -p22; -p1-65535; -p U:53,111,137,T:21-25,80,139,8080,S:9 nmap通过探测将端口划分为6个状态，下表给出了每个状态的含义。 端口状态 状态含义 open 端口是开放的 closed 端口是关闭的 filtered 端口被防火墙IDS/IPS屏蔽，无法确认其状态 unfiltered 端口没有被屏蔽，但是否开放需要进一步确定 open|filtered 端口是开放的或被屏蔽 closed|filtered 端口是关闭的或被屏蔽 在进行端口扫描时，可以使用不同的端口扫描类型。常见的端口扫描类型如下： 123TCP SYNC SCAN:半开放扫描，这种类沏的扫描为发送一个SYN包，启动一个TCP会话，并等待响应的数据包。如果收到的是一个reset包，表明端口是关闭的; 如果收到的是一个SYNC/ACK包，则表示端口是打开的。TCP NULL SCAN: NULL扫描把TCP头中的所有标志位都设置为NULL。如果收到的是一个RST包，则表示相应的端口是关闭的。TCP FIN SCAN : TCP FIN扫描发送一个表示结束一个活跃的TCP连接的FIN包， 让对方关闭连接。如果收到了一个RST包，则表示相应的端口是关闭的。 TCPXMASSCAN: TCPXMAS扫描发送PSH、FIN、URG和TCP标志位被设置为1的数据包，如果收到一个RST包，则表示相砬端口是关闭的。 ¶（3）版本侦测 nmap在进行端口扫描时，还可以进行版本侦测。版本监测功能用于确定开放端口上运行的应用程序及版本信息。如下所示： 1nmap -sV 47.100.98.242 ¶（4）操作系统监测 操作系统侦测用于监测主机运行的操作系统类型及设备类型等信息。nmap拥有丰富的系统数据库，可以识别2600多种操作系统与设备类型。如下所示： 1nmap -sO 47.100.98.242 ¶3、使用python-nmap进行端口扫描 我们在上一小节中，花f较多的篇幅介绍nmap。Python的Python-nmap仅仅趋对nmap的封装，因此，要使用Python-nmap,必须先了解nmap。Python-nmap相对于nmap, 主要的改进在于对输出结果的处理。Python-nmap将nmap的输出结果保存到宇典之中，我们只需要通过Python的字典就可以获取到nmap的输出信息，不用像Shell脚本一样通过字符串处理和正则表达式来解析nmap的结果。Python-nmap将nmap的强大功能与Python语言优秀的表达能力进行了完美的结合，使用Python语言丰富的数据结构保存结果，以便后续继续进行处理，如使用Python-nmap生成相关的报告。 Python-nmap是开源的库，因此，在使用之前需要手动进行安装。如下所示： 1pip3 install python-nmap Python-nmap的使用非常简单，我们只要创建一个PortScarmer对象，并调用对象的 scan方法就能够完成基本的nmap端口扫描。如下所示： 12345678910111213141516171819202122232425262728293031323334In [1]: import nmap In [2]: nm = nmap.PortScanner() In [3]: nm.scan('192.168.79.129','22-1000')Out[3]: &#123;'nmap': &#123;'command_line': 'nmap -oX - -p 22-1000 -sV 192.168.79.129', 'scaninfo': &#123;'tcp': &#123;'method': 'syn', 'services': '22-1000'&#125;&#125;, 'scanstats': &#123;'timestr': 'Mon Mar 2 16:31:17 2020', 'elapsed': '6.33', 'uphosts': '1', 'downhosts': '0', 'totalhosts': '1'&#125;&#125;, 'scan': &#123;'192.168.79.129': &#123;'hostnames': [&#123;'name': '192.168.79.129', 'type': 'PTR'&#125;], 'addresses': &#123;'ipv4': '192.168.79.129'&#125;, 'vendor': &#123;&#125;, 'status': &#123;'state': 'up', 'reason': 'localhost-response'&#125;, 'tcp': &#123;22: &#123;'state': 'open', 'reason': 'syn-ack', 'name': 'ssh', 'product': 'OpenSSH', 'version': '7.4', 'extrainfo': 'protocol 2.0', 'conf': '10', 'cpe': 'cpe:/a:openbsd:openssh:7.4'&#125;, 111: &#123;'state': 'open', 'reason': 'syn-ack', 'name': 'rpcbind', 'product': '', 'version': '2-4', 'extrainfo': 'RPC #100000', 'conf': '10', 'cpe': ''&#125;&#125;&#125;&#125;&#125; 当我们创建PortScanner对象时，Python-nmap会检査系统中是否已经安装了 nmap，如果没有安装，抛出PortScannerError异常。调用PortScanner对象的scan方法进行扫描以后就可以通过该类的其他方法获取本次扫描的信息。如命令行参数、主机列表、扫描的方法等。如下所示： 12345678In [4]: nm.command_line() Out[4]: 'nmap -oX - -p 22-1000 -sV 192.168.79.129'In [5]: nm.scaninfo() Out[5]: &#123;'tcp': &#123;'method': 'syn', 'services': '22-1000'&#125;&#125;In [6]: nm.all_hosts() Out[6]: ['192.168.79.129'] Python-nmap还提供了以主机地址为键，获取单台主机的详细信息。包括获取主机网络状态、所有的协议、所有打开的端口号，端口号对应的服务等。如下所示： 123456789101112131415161718192021222324252627282930In [7]: nm['192.168.79.129'].state()Out[7]: 'up'In [8]: nm['192.168.79.129'].all_protocols()Out[8]: ['tcp']In [9]: nm['192.168.79.129'].keys() Out[9]: dict_keys(['hostnames', 'addresses', 'vendor', 'status', 'tcp']) In [10]: nm['192.168.79.129']['tcp'][22]Out[10]: &#123;'state': 'open', 'reason': 'syn-ack', 'name': 'ssh', 'product': 'OpenSSH', 'version': '7.4', 'extrainfo': 'protocol 2.0', 'conf': '10', 'cpe': 'cpe:/a:openbsd:openssh:7.4'&#125;In [11]: nm['192.168.79.129']['tcp'][111]Out[11]: &#123;'state': 'open', 'reason': 'syn-ack', 'name': 'rpcbind', 'product': '', 'version': '2-4', 'extrainfo': 'RPC #100000', 'conf': '10', 'cpe': ''&#125; Python-nmap是对nmap的Python封装，因此我们也可以通过Python-nmap指定nmap命令的复杂选项。如下所示： 1nm.scan(hosts='192.168.79.129/24',arguments='-n -sP -PE -PA21,23,80,3389') ¶三、使用IPy进行IP管理 在网络设计中，首先要做的就是规划IP地址。IP地址规划的好坏直接影响路由算法的效率，包括网络性能和扩展性。在IP地址规划中，需要进行大量的IP地址计算，包括网段、网络掩码、广播地址、子网数、IP类型等计算操作。在大量的计算操作中，如果没有一个好的工具，计算IP地址是一个很无趣有容易出错的事情。在Perl语言中，可以使用NET::IP模块，在Python语言中，可以使用开源的IPy模块进行操作。 ¶1、IPy模块介绍 IPy模块是一个处理IP地址的模块，它能够自动识别IP地址的版本、IP地址的类型。使用IPy模块，可以方便地进行IP地址的计算。 IPy模块是第三方的开源模块，因此，在使用之前需要进行安装。直接使用pip安装即可： 1pip3 install ipy ¶2、IPy模块的基本使用 IPy模块有一个IP类，这个类几乎可以接受任何格式的IP地址和网段。如下所示： 123456789101112131415161718In [1]: import IPy In [2]:from IPy import IP In [3]: IP(0x7f000001) Out[3]: IP('127.0.0.1')In [4]: IP('127.0.0.1') Out[4]: IP('127.0.0.1')In [5]: IP('127.0.0.0/30') Out[5]: IP('127.0.0.0/30')In [6]: IP('1080:0:0:0:8:800:200C:417A')Out[6]: IP('1080::8:800:200c:417a')In [7]: IP('127.0.0.0-127.255.255.255')Out[7]: IP('127.0.0.0/8') IP类包含了许多的方法，用来进行灵活的IP地址操作。例如： ¶（1）version:获取IP地址的版本 12345678In [9]: IP('127.0.0.0-127.255.255.255') Out[9]: IP('127.0.0.0/8')In [10]: IP('10.0.0.0/8').version() Out[10]: 4In [11]: IP('::1').version() Out[11]: 6 ¶（2）len:得到子网IP地址的个数 12345In [12]: IP('127.0.0.0/30').len() Out[12]: 4 In [13]: IP('127.0.0.0/28').len() Out[13]: 16 ¶（3）iptype:返回IP地址的类型 12345In [14]: IP('127.0.0.1').iptype() Out[14]: 'LOOPBACK'In [15]: IP('8.8.8.8').iptype() Out[15]: 'PUBLIC' ¶（4）int:返回IP地址的整数形式 12In [16]: IP('8.8.8.8').int() Out[16]: 134744072 ¶（5）strHex:返回IP地址的十六进制形式 12In [17]: IP('8.8.8.8').strHex() Out[17]: '0x8080808' ¶（6）strBin:返回IP地址的二进制形式 12In [18]: IP('8.8.8.8').strBin()Out[18]: '00001000000010000000100000001000' 有一个方便的函数能够将IP转换为不同的格式，在工作环境中将会非常有用。例如，以数宇的形式在数据库中存储IP地址，在数据库中存储IP地址有两种形式，第一种是以变长字符串的形式将IP地址保存到数据库中，另一种是将IP地址转换为整数以后保存到数据库中。将IP地址转换为整数进行存储能够有效地节省存储空间，提高数据库的存储效率和访问速度。因此，在最佳实践中，我们一般将IP地址以数字的形式保存到数据库中。需要 IP地址时，再将数字形式的IP地址转换为字符串格式的IP地址。这个需求十分常见，因 此，MySQL提供了两个函数，分别用以将字符串形式的IP地址转换为数据格式的IP地址，以及将数字格式的IP地址转换为字符串形式的IP地址。如下所示： 123456789101112131415mysql&gt; select INET_ATON('10.166.224.14');+----------------------------+| INET_ATON('10.166.224.14') |+----------------------------+| 178708494 |+----------------------------+1 row in set (0.00 sec)mysql&gt; select INET_NTOA('178708494');+------------------------+| INET_NTOA('178708494') |+------------------------+| 10.166.224.14 |+------------------------+1 row in set (0.00 sec) 除了使用MySQL自带的函数以外，我们也可以使用IP类提供的int方法将字符串形式的IP地址转换为数字形式的IP地址。要将数字形式的IP地址转换会字符串形式的IP地址，可以直接使用数字的方式创建IP对象。如下所示： 12345In [9]: IP('178708494') Out[9]: IP('10.166.224.14')In [10]: '&#123;0&#125;'.format(IP(\"178708494\"))Out[11]: '10.166.224.14' ¶3、网段管理 IP类的构造函数可以接受不同格式的IP地址，也可以接受网段。如下所示： 12345678910In [1]: from IPy import IP In [2]: IP('127.0.0.0/24') Out[2]: IP('127.0.0.0/24')In [3]: IP('127.0.0.0-127.255.255.255')Out[3]: IP('127.0.0.0/8')In [4]: IP('127.0.0.0/127.255.255.255')Out[4]: IP('127.0.0.0/31') 网段包含多个IP地址，我们可以直接使用len方法或者Python内置的len函数得到网段中IP地址的个数，也可以直接使用for循环迭代网段，以此遍历各个IP。如下所示： 12345678910111213141516171819202122232425262728293031323334353637In [1]: from IPy import IP In [2]: IP('127.0.0.0/24') Out[2]: IP('127.0.0.0/24')In [3]: IP('127.0.0.0-127.255.255.255')Out[3]: IP('127.0.0.0/8')In [4]: IP('127.0.0.0/127.255.255.255')Out[4]: IP('127.0.0.0/31')In [5]: ips = IP('10.166.224.144/28')In [6]: ips.len() Out[6]: 16In [7]: len(ips) Out[7]: 16In [8]: [ip for ip in ips] Out[8]: [IP('10.166.224.144'), IP('10.166.224.145'), IP('10.166.224.146'), IP('10.166.224.147'), IP('10.166.224.148'), IP('10.166.224.149'), IP('10.166.224.150'), IP('10.166.224.151'), IP('10.166.224.152'), IP('10.166.224.153'), IP('10.166.224.154'), IP('10.166.224.155'), IP('10.166.224.156'), IP('10.166.224.157'), IP('10.166.224.158'), IP('10.166.224.159')] IP类有一个名为strNormal的方法，该方法接受一个wantprefixlen参数，参数的合法取值为0~3，每一个取值代表一种网段的显示方式。如下所示： 1234567891011In [12]: ips.strNormal(0) Out[12]: '10.166.224.144'In [13]: ips.strNormal(1) Out[13]: '10.166.224.144/28'In [14]: ips.strNormal(2) Out[14]: '10.166.224.144/255.255.255.240'In [15]: ips.strNormal(3) Out[15]: '10.166.224.144-10.166.224.159' 通过IP类，我们也可以方便地判断一个IP是否属于一个网段，判断子网是否包含于另一个网段中，以及两个网段是否有重叠。如下所示： 12345678In [16]: '10.166.224.144' in IP('10.166.224.144/28')Out[16]: TrueIn [17]: IP('10.166.224.144/29') in IP('10.166.224.144/28')Out[17]: TrueIn [18]: IP('10.166.224.0/28').overlaps('10.166.224.144/28')Out[18]: 0 对于网段，我们可以方便地获取网络地址掩码以及网络的广播地址。如下所示： 12345In [22]: ips.netmask() Out[22]: IP('255.255.255.240')In [23]: ips.broadcast() Out[23]: IP('10.166.224.159') ¶四、使用dnspython解析DNS ¶1、dnspython简介与安装 dnspython是Python实现的一个DNS工具集，它支持几乎所有的记录类型，可以用于查询、传输并动态更新ZONE信息，同时支持TSIG（事务签名）验证消息和EDNS0（扩展DNS）。使用dnspython可以代替Linux命令行下的nslookup以及dig等工具。 dnspython是第三方的开源模块，因此，使用之前需要先进行安装： 1pip3 install dnspython ¶2、使用dnspython进行域名解析 dnspython提供了丰富的API，其中，高层次的API根据名称和类型执行查询操作，低层次的API可以直接更新ZONE信息、消息、名称和记录。在所有的API中，最常使用的是域名查询。dnspython提供了一个DNS解析类resolver，使用它的query方法可以实现域名的查询功能。 1dns.resolver.query(qname,rdtype=1,rdclass=1,tcp=False,source=None,raise_on_no_answer=True,source_port=0) query方法各参数的含义如下： qname:査询的域名； rdtype:指定RR资源； 12345A:地址记录（Address),返回域名指向的IP地址；NS:域名服务器记录（Name Server)，返回保存下一级域名信息的服务器地址。该记录只能设罝为域名，不能设置为IP地址；MX:邮件记录（Mail exchange),返回接收电子邮件的服务器地址；CNAME:规范名称记录（Canonical Name)，别名记录，实现域名间的映射；PTR:逆向査询记录（Pointer Record),反向解析，与A记录相反，将IP地址转换为主机名。 rdclass:网络类型； tcp:指定査询是否启用TCP协议； source:査询源的地址； source_port:査询源的端口 ; raise_on_no_answer:指定査询无应答时是否触发异常，默认为True。 在使用dnspython查询DNS相关信息之前，我们先简单了解一下dig命令，以便对照查看Python程序的输出结果与dig命令的输出结果。 dig的全称是domain information groper,它是一个灵活探测DNS的工具，可以执行DNS査找，并显示从查询的名称服务器返回的答案。由于dig命令灵活易用、输出明确， 因此，大多数DNS管理员都使用dig解决DNS问题。 在我的主机上运行dig命令査找dnspython.org域名的信息。运行结果如下： 1234567891011121314151617181920212223242526272829[root@192 ~]# dig qiniu.lexizhi.com; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-72.el7 &lt;&lt;&gt;&gt; qiniu.lexizhi.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 35907;; flags: qr rd ra; QUERY: 1, ANSWER: 12, AUTHORITY: 0, ADDITIONAL: 0;; QUESTION SECTION:;qiniu.lexizhi.com. IN A;; ANSWER SECTION:qiniu.lexizhi.com. 5 IN CNAME www.lexizhi.com.qiniudns.com.www.lexizhi.com.qiniudns.com. 5 IN CNAME dt003.china.line.qiniudns.com.dt003.china.line.qiniudns.com. 5 IN CNAME tinychinacdnweb.qiniu.com.w.kunlunno.com.tinychinacdnweb.qiniu.com.w.kunlunno.com. 5 IN A 150.138.180.231tinychinacdnweb.qiniu.com.w.kunlunno.com. 5 IN A 150.138.180.234tinychinacdnweb.qiniu.com.w.kunlunno.com. 5 IN A 150.138.180.232tinychinacdnweb.qiniu.com.w.kunlunno.com. 5 IN A 150.138.180.233tinychinacdnweb.qiniu.com.w.kunlunno.com. 5 IN A 219.147.157.66tinychinacdnweb.qiniu.com.w.kunlunno.com. 5 IN A 150.138.180.228tinychinacdnweb.qiniu.com.w.kunlunno.com. 5 IN A 150.138.180.235tinychinacdnweb.qiniu.com.w.kunlunno.com. 5 IN A 150.138.180.229tinychinacdnweb.qiniu.com.w.kunlunno.com. 5 IN A 150.138.180.230;; Query time: 633 msec;; SERVER: 192.168.79.2#53(192.168.79.2);; WHEN: 一 3月 02 17:29:51 CST 2020;; MSG SIZE rcvd: 300 在Python代码中，可以使用dnspython查询A记录。如下所示： 123456from __future__ import print_functionimport dns.resolverdata = dns.resolver.query('www.lexizhi.com', 'A')for item in data: print(item) Python程序的输出结果如下： 147.100.98.242 使用dnspython实现NS记录，查询方法如下： 123456from __future__ import print_functionimport dns.resolverdata = dns.resolver.query('dnspython.org', 'NS')for item in data: print(item) Python程序查询NS记录的结果如下： 1234ns-343.awsdns-42.com.ns-518.awsdns-00.net.ns-1253.awsdns-28.org.ns-2020.awsdns-60.co.uk. 从输出结果来看，使用dig命令或dnspython模块都是一样的。如果在命令行操作，建议使用dig命令。如果要使用程序管理DNS或查询DNS的内容，则推荐使用dnspython模块。 ¶五、网络嗅探器Scapy Scapy是一个Python语言编写的工具，使用Scapy可以发送、嗅探、剖析和伪造网络数据报。Scapy涉及比较底层的网络协议，因此，不可避免地导致Scapy的接口复杂。虽然 Scapy的接口复杂，但整体思路却非常简单，就是发送数据报和接收数据报。在发送数据报时，Scapy提供了相关的辅助类来帮助我们构造数据报，在接收数据报时，Scapy也提供了相应的函数来帮助我们过滤和解析数据报。 在这一小节中，首先我们将介绍Scapy的功能和安装方式，然后介绍Scapy的基本使用，接着介绍如何使用Scapy发送数据报，并通过 —个DNS査询的例子演示Scapy发送数据报，最后介绍如何使用Scapy进行网络嗅探，并通过一个抓取敏感信息的例子来演示Scapy的网络嗅探。 ¶1、Scapy简介与安装 Scapy是一个强大的交互式数据报处理程序，它能够伪造或者解码大量的网络协议数据报，能够发送、捕捉、匹配请求和回复数据报。Scapy可以轻松处理大多数经典任务，如端口扫描、路由跟踪、探测、攻击或网络发现等。使用Scapy可以替代hping, arpspoof，arp-sk, arping，p0f等功能，甚至可以替代nmap, tcpdump和tshark的部分功能。此外，Scapy 还有很多其他工具没有的优秀特性，如发送无效数据帧、注入修改的802.11数据帧、在 WEP上解码加密通道（VOIP)、ARP缓存攻击（VLAN)等。 Scapy是使用Python语言开发的丁.具，因此，我们可以直接使用pip安装： 1pip3 install scapy Scapy运行时要对网络接口进行控制，所以需要root权限。在这一小节的例子中， 我们都使用root用户来运行Scapy程序或与Scapy相关的Python程序。 Scapy提供了非常丰富的功能，不同的功能依赖不同的软件。启动Scapy命令行工具时，Scapy会进行相应的检査并给出提示。如下所示： 1234567891011121314151617181920212223242526[root@192 ~]# scapyINFO: Can't import matplotlib. Won't be able to plot.INFO: Can't import PyX. Won't be able to use psdump() or pdfdump().WARNING: No route found for IPv6 destination :: (no default route?)INFO: Can't import python-cryptography v1.7+. Disabled WEP decryption/encryption. (Dot11)INFO: Can't import python-cryptography v1.7+. Disabled IPsec encryption/authentication. aSPY//YASa apyyyyCY//////////YCa | sY//////YSpcs scpCY//Pp | Welcome to Scapy ayp ayyyyyyySCP//Pp syY//C | Version 2.4.3 AYAsAYYYYYYYY///Ps cY//S | pCCCCY//p cSSps y//Y | https://github.com/secdev/scapy SPPPP///a pP///AC//Y | A//A cyP////C | Have fun! p///Ac sC///a | P////YCpc A//A | Craft packets before they craft scccccp///pSP///p p//Y | you. sY/////////y caa S//P | -- Socrate cayCyayP//Ya pY/Ya | sY/PsY////YCc aC//Yp sc sccaCY//PCypaapyCP//YSs spCPY//////YPSps ccaacs using IPython 7.12.0&gt;&gt;&gt; 例如，使用Scapy生成图形化的示意图需要安装matplotlib库，但没有安装matplotlib并不影响Scapy的基本使用。 ¶2、Scapy的基本使用 在本教程中，我们会介绍Scapy的一些基本用法，完整的使用方法可以参考Scapy的官方文档http://www.secdev.org/projects/scapy/doc/usage.html。 我们有两种方式运行Scapy，一种是直接启动Scapy进入一个交互式界面，另一种是在Python程序中调用Scapy提供的功能。与其他软件不同的是，Scapy的交互模式其实就是Python的交互模式。因此我们可以在Scapy的交互模式下导入Python的包，使用Python的语法，执行Python中的语句。如下所示： 1234&gt;&gt;&gt; import sys &gt;&gt;&gt; print(sys.version) 3.8.1 (default, Jan 14 2020, 10:59:16) [GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] 既然知道了Scapy的交换模式是Python的交换模式这个事实，那我们就可以轻易地将Scapy交换模式中的代码放置在Python的源文件中，使用Python程序的方式进行软件开发。要在Python程序中使用Scapy的功能，只需要导入scapy.all模块即可。如下所示： 1234567891011121314&gt;&gt;&gt; import sys &gt;&gt;&gt; print(sys.version) 3.8.1 (default, Jan 14 2020, 10:59:16) [GCC 4.8.5 20150623 (Red Hat 4.8.5-39)]&gt;&gt;&gt; from __future__ import print_function &gt;&gt;&gt; from scapy.all import * &gt;&gt;&gt; print(ls()) AH : AHAKMSuite : AKM suiteARP : ARPASN1P_INTEGER : NoneASN1P_OID : NoneASN1P_PRIVSEQ : NoneASN1_Packet : None 在Scapy的交互式工具中，我们可以通过ls()显示Scapy支持的所有协议、lsc()列出Scapy支持的所有命令、conf显示所有的配置信息、help(cmd)显示某一命令的使用帮助等。如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&gt;&gt;&gt; ls() AH : AHAKMSuite : AKM suiteARP : ARPASN1P_INTEGER : NoneASN1P_OID : NoneASN1P_PRIVSEQ : NoneASN1_Packet : None &gt;&gt;&gt; lsc() IPID_count : Identify IP id values classes in a list of packetsarpcachepoison : Poison target's cache with (your MAC,victim's IP) couplearping : Send ARP who-has requests to determine which hosts are uparpleak : Exploit ARP leak flaws, like NetBSD-SA2017-002.bind_layers : Bind 2 layers on some specific fields' values.bridge_and_sniff : Forward traffic between interfaces if1 and if2, sniff and returnchexdump : Build a per byte hexadecimal representationcomputeNIGroupAddr : Compute the NI group Address. Can take a FQDN as input parametercorrupt_bits : Flip a given percentage or number of bits from a stringcorrupt_bytes : Corrupt a given percentage or number of bytes from a stringdefrag : defrag(plist) -&gt; ([not fragmented], [defragmented],defragment : defragment(plist) -&gt; plist defragmented as much as possible dhcp_request : Send a DHCP discover request and return the answerdyndns_add : Send a DNS add message to a nameserver for \"name\" to have a new \"rdata\"dyndns_del : Send a DNS delete message to a nameserver for \"name\"etherleak : Exploit Etherleak flawexplore : Function used to discover the Scapy layers and protocols.fletcher16_checkbytes: Calculates the Fletcher-16 checkbytes returned as 2 byte binary-string.fletcher16_checksum : Calculates Fletcher-16 checksum of the given buffer.fragleak : --fragleak2 : --fragment : Fragment a big IP datagramfuzz : getmacbyip : Return MAC address corresponding to a given IP addressgetmacbyip6 : Returns the MAC address corresponding to an IPv6 addresshexdiff : Show differences between 2 binary strings&gt;&gt;&gt; help(sniff)Help on function sniff in module scapy.sendrecv:sniff(*args, **kwargs) Sniff packets and return a list of packets. Args: count: number of packets to capture. 0 means infinity. store: whether to store sniffed packets or discard them prn: function to apply to each packet. If something is returned, it is displayed. --Ex: prn = lambda x: x.summary() session: a session = a flow decoder used to handle stream of packets. e.g: IPSession (to defragment on-the-flow) or NetflowSession filter: BPF filter to apply. 【按q退出】 如果你对网络编程特别感兴趣，你一定会喜欢上Scapy。我们不但可以使用Scapy嗅探和发送数据报，甚至还可以使用Scapy学习计算机网络相关知识。例如，我们可以使用ls查看协议的详细格式。如下所示： 12345678910&gt;&gt;&gt; ls(ARP) hwtype : XShortField = (1)ptype : XShortEnumField = (2048)hwlen : FieldLenField = (None)plen : FieldLenField = (None)op : ShortEnumField = (1)hwsrc : MultipleTypeField = (None)psrc : MultipleTypeField = (None)hwdst : MultipleTypeField = (None)pdst : MultipleTypeField = (None) ¶3、使用Scapy发送数据报 Scapy的数据报遵循了网络协议中经典的TCP/IP四层模型，即链路层、网络层、运输层和应用层。Scapy为每个层协议都提供了辅助类，我们要做的就是把这些类实例化并修改对象的取值，以此来构造数据报。每一层都可以通过类调用创建相应的数据报，如IP()、TCP()、UDP()等，不同层之间通过“/”来连接。如下所示： 123&gt;&gt;&gt; packet1 = IP(dst='10.166.244.14')&gt;&gt;&gt; packet2 = IP(dst='10.166.244.14')/TCP(dport=80)&gt;&gt;&gt; packet3 = IP(dst='10.166.244.14')/ICMP() display方法可以查看当前数据报的内容，即各个参数的取值情况。例如，下面就显示了我们构造的第一个数据报中各个字段的取值。 123456789101112131415&gt;&gt;&gt; packet1.display() ###[ IP ]### version= 4 ihl= None tos= 0x0 len= None id= 1 flags= frag= 0 ttl= 64 proto= hopopt chksum= None src= 192.168.79.129 dst= 10.166.244.14 \\options\\ 字段都有默认值，如果我们建立一个类的实例，没有传给它任何参数，那么它的参数取值就是默认值。如果传递了相应的参数，就使用用户传递的参数。如果使用del删除了某个参数，就恢复了默认值。如下所示： 12345678&gt;&gt;&gt; packet1.dst '10.166.244.14'&gt;&gt;&gt; packet1.ttl = 32 &gt;&gt;&gt; packet1.ttl 32&gt;&gt;&gt; del packet1.ttl &gt;&gt;&gt; packet1.ttl 64 如果我们没有提供相应的参数取值（user set fields)，参数将使用默认值（default fields）。之后，如果我们在这个类的上层进行操作 (比如IP的上面定义TCP)，那么，数据报的取值将由上层协议进行覆盖。 ¶4、使用Scapy构造DNS查询请求 下面以DNS解析为例，介绍如何使用Scapy构造数据报并发送请求。假设我们使用的 DNS服务器地址为8.8,8.8,现在，我们需要获取百度（&lt;www.baidu.com&gt; )的IP地址。 为了获取百度的IP地址，我们需要创建一个DNS的请求包。如下所示： 1&gt;&gt;&gt; dns=DNS(rd=1,qd=DNSQR(qname='www.baidu.com')) DNS是一个应用层协议，底层可以使用UDP或TCP协议。无论是TCP协议还是UDP 协议，都依赖IP协议进行网络报传输。因此，完整的DNS清求数据报如下所示： 12345&gt;&gt;&gt; packet = sr1(IP(dst='8.8.8.8')/UDP()/dns)Begin emission:...Finished sending 1 packets...*Received 6 packets, got 1 answers, remaining 0 packets 在这个例子中，我们使用sr1函数发送和接收数据报，sr1在三层发送数据报，并且接收第一个回复。收到回复后，我们可以使用show方法来查看数据报的详细内容。如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&gt;&gt;&gt; packet[DNS].show()###[ DNS ]### id= 0 qr= 1 opcode= QUERY aa= 0 tc= 0 rd= 1 ra= 1 z= 0 ad= 0 cd= 0 rcode= ok qdcount= 1 ancount= 3 nscount= 0 arcount= 0 \\qd\\ |###[ DNS Question Record ]### | qname= 'www.baidu.com.' | qtype= A | qclass= IN \\an\\ |###[ DNS Resource Record ]### | rrname= 'www.baidu.com.' | type= CNAME | rclass= IN | ttl= 332 | rdlen= None | rdata= 'www.a.shifen.com.' |###[ DNS Resource Record ]### | rrname= 'www.a.shifen.com.' | type= CNAME | rclass= IN | ttl= 93 | rdlen= None | rdata= 'www.wshifen.com.' |###[ DNS Resource Record ]### | rrname= 'www.wshifen.com.' | type= A | rclass= IN | ttl= 58 | rdlen= None | rdata= 103.235.46.39 ns= None ar= None DNS应答包里面包含了非常详细的信息。例如，在这个应答中我们可以看到，DNS支持递归查询（ra取值为1表示DNS服务器支持递归查询，ra取值为0表示不支持递归查询）。百度的域名解析给出了 3个结果（ancount取值为3）。在这个例子中，我们通过手动构造数据报的方式，正确发送了DNS请求，解析了百度的IP地址。 在构造数据报时，如果有应用的数据，数据部分可以直接使用字符。如下所示： 12345678&gt;&gt;&gt; a=Ether()/IP(dst='www.slashdot.org')/TCP()/\"GET /index.html HTTP/1.0 \\n\\n\" &gt;&gt;&gt; hexdump(a)0000 00 50 56 FE 43 5E 00 0C 29 58 4A 96 08 00 45 00 .PV.C^..)XJ...E.0010 00 43 00 01 00 00 40 06 6C 12 C0 A8 4F 81 D8 69 .C....@.l...O..i0020 26 0F 00 14 00 50 00 00 00 00 00 00 00 00 50 02 &amp;....P........P.0030 20 00 AF 0F 00 00 47 45 54 20 2F 69 6E 64 65 78 .....GET /index0040 2E 68 74 6D 6C 20 48 54 54 50 2F 31 2E 30 20 0A .html HTTP/1.0 .0050 0A 如果我们安装了PyX，还可以直接将数据报dump成一个PostScript或PDF文件。 ¶5、使用Scapy进行网络嗅探 Scapy除了可以伪造数据报并接收响应结果以外，还可以用于数据报嗅探。对数据报进行嗅探的函数为sniff，sniff函数的详细使用方法如下： 1sniff(filter=\"\", iface=\"any\", prn=function, count=N) sniff函数的参数说明如下： filter:用来表示想要捕获数据报类型的过滤器，如只捕获ICMP数据报，则filter取值为“ICMP”，只捕获80端口的TCP数据报，则filter取值为“TCP and （port 80)&quot;； iface:设置嗅探器所要嗅探的网卡，默认对所有网卡进行嗅探； pm:指定嗅探到符合过滤器条件的数据报时所调用的回调函数，这个回调函数只接受一个参数，即收到的数据报。 count:指定需要嗅探的数据报的个数。 123def pack_callback(packet): print(packet.show())sniff(prn=pack_calback, iface=\"ens33\", count=1) 下面是一个非常简单的sniff使用示例。在这个例子中，我们仅仅捕获三个ICMP的数据报，并且直接打印数据报的信息。前面说过，Scapy的交互模式就是Python的交互模式，因此，我们可以直接使用Python的库、语法和语句。sniff要求prn是一个回调函数，因此，我们传递给prn参数的是一个Lambda函数。如下所示： 1234&gt;&gt;&gt; a = sniff(filter=\"tcp\", prn=lambda x:x.summary(), count=3) Ether / IP / TCP 192.168.79.1:65134 &gt; 192.168.79.129:ssh PA / RawEther / IP / TCP 192.168.79.129:ssh &gt; 192.168.79.1:65134 PA / RawEther / IP / TCP 192.168.79.129:ssh &gt; 192.168.79.1:65134 PA / Raw","categories":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/tags/Python/"}]},{"title":"使用Python监控Linux系统","slug":"使用Python监控Linux系统","date":"2020-05-11T16:00:00.000Z","updated":"2020-05-12T09:10:20.608Z","comments":true,"path":"使用Python监控Linux系统.html","link":"","permalink":"https://pdxblog.top/%E4%BD%BF%E7%94%A8Python%E7%9B%91%E6%8E%A7Linux%E7%B3%BB%E7%BB%9F.html","excerpt":"","text":"¶使用Python监控Linux系统 Linux下有许多使用Python语言编写的监控工具，如inotify-sync、dstat和glances。此外，如果要根据业务编写简单的监控脚本，很多工程师也会选择Python语言。Python语言是一门简单易学/语法清晰/表达能力强的编程语言，非常适合于编写监控程序的场景。使用Python语言编写监控程序具有以下几个优势： 1、Python语言开发效率高。Python语言有自己的优势与劣势，使用Python开发监控程序是一个充分发挥Python优势，避免Python劣势的领域。对于监控程序来说，能够利用Python语言开发效率高的优势尽快完成程序的编写工作。同时，监控程序也不要求性能，因此避免了Python语言性能不如C、C++和Java的劣势。 2、Python语言表达能力强。相信任何一个学习Linux的工程师都使用过shell脚本编写过监控程序。虽然Linux下有很多监控工具，也有很多文本处理程序，但是获取监控与解析结果是完全不同的工具。解析监控结果的程序不理解监控程序输出结果的具体含义。Python语言中有非常丰富的数据结构，可以用各种方式保存监控结果，以便后续处理。 3、利用第三方库开发监控程序。Python的标准库本身非常强大，被称为“连电池都包含在内”。对于一个问题，如果标准库没有提供相应的工具，那么也会有开源的项目来填补这个空白。监控程序正式这样一种情况，在Python语言中，具有非常成熟的第三方库帮助开发者简化监控程序的编写工作。 ¶一、Python编写的监控工具 我们将介绍两个Python语言编写的监控工具，分别是dstat和glances。 ¶1、多功能系统资源统计工具dstat dstat是一个用Python语言实现的多功能系统资源统计工具，用来取代Linux下的vmstat、iostat、netstat、和ifstat等命令。并且，dstat克服了这些命令的限制，增加了额外的功能，以及更多的计数器与更好的灵活性。dstat可以在一个界面上展示非常全面的监控信息，因此，在系统监控、基准测试和故障排除等应用场景下特别有用。 我们可以使用dstat监控所有系统资源的使用情况，并且可以结合不同的场景定制监控的资源。例如，在同一时间段以相同的时间频率比较网络带宽与磁盘的吞吐率。 dstat将以列表的形式显示监控信息，并且使用不同的颜色进行输出，以可读性较强的单位展示监控数值。例如，对于字节数值，dstat自动根据数值的大小，以K、M、G等单位进行显示，避免了开发者使用其他命令时因为数值太大造成的困惑和错误。此外，使用dstat还可以非常方便地编写插件，用来收集默认情况下没有收到的监控信息。dstat是专门为人们实时查看监控信息设计的，因此默认将监控结果输出到屏幕终端。我们也可以将监控信息以CSV格式输出到文件，以便后续处理。 ¶（1）dstat介绍 作为一个多功能系统资源统计工具，dstat具有以下特性： 1234567891011121314结合了vmstat，iostat，ifstat，netstat以及更多的信息实时显示统计情况在分析和排障时可以通过启用监控项并排序模块化设计使用python编写的，更方便扩展现有的工作任务容易扩展和添加你的计数器（请为此做出贡献）包含的许多扩展插件充分说明了增加新的监控项目是很方便的可以分组统计块设备/网络设备，并给出总数可以显示每台设备的当前状态极准确的时间精度，即便是系统负荷较高也不会延迟显示显示准确地单位和和限制转换误差范围用不同的颜色显示不同的单位显示中间结果延时小于1秒支持输出CSV格式报表，并能导入到Gnumeric和Excel以生成图形 如果操作系统默认没有安装dstat，那么需要我们手动进行安装。如下所示： 1yum install dstat 查看dstat命令的帮助信息与支持选项，如下所示： 1dstat --help dstat命令的–version选项，处理显示dstat的版本以外，还会显示操作系统的版本、Python语言的版本、CPU的个数，以及dstat支持的插件列表等详细信息。如下所示： 123456789101112131415161718192021222324252627282930313233[root@192 ~]# dstat --versionDstat 0.7.2Written by Dag Wieers &lt;dag@wieers.com&gt;Homepage at http://dag.wieers.com/home-made/dstat/Platform posix/linux2Kernel 3.10.0-957.el7.x86_64Python 2.7.5 (default, Oct 30 2018, 23:45:53) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]Terminal type: xterm (color support)Terminal size: 16 lines, 83 columnsProcessors: 1Pagesize: 4096Clock ticks per secs: 100internal: aio, cpu, cpu24, disk, disk24, disk24old, epoch, fs, int, int24, io, ipc, load, lock, mem, net, page, page24, proc, raw, socket, swap, swapold, sys, tcp, time, udp, unix, vm/usr/share/dstat: battery, battery-remain, cpufreq, dbus, disk-tps, disk-util, dstat, dstat-cpu, dstat-ctxt, dstat-mem, fan, freespace, gpfs, gpfs-ops, helloworld, innodb-buffer, innodb-io, innodb-ops, lustre, memcache-hits, mysql-io, mysql-keys, mysql5-cmds, mysql5-conn, mysql5-io, mysql5-keys, net-packets, nfs3, nfs3-ops, nfsd3, nfsd3-ops, ntp, postfix, power, proc-count, qmail, rpc, rpcd, sendmail, snooze, squid, test, thermal, top-bio, top-bio-adv, top-childwait, top-cpu, top-cpu-adv, top-cputime, top-cputime-avg, top-int, top-io, top-io-adv, top-latency, top-latency-avg, top-mem, top-oom, utmp, vm-memctl, vmk-hba, vmk-int, vmk-nic, vz-cpu, vz-io, vz-ubc, wifi[root@192 ~]# 除了使用dstat命令的–version选项查看dstat的详细信息获取可支持的插件以外，还可以使用dstat命令的–list选项获取dstat的插件列表。如下所示： 123456789101112[root@192 ~]# dstat --listinternal: aio, cpu, cpu24, disk, disk24, disk24old, epoch, fs, int, int24, io, ipc, load, lock, mem, net, page, page24, proc, raw, socket, swap, swapold, sys, tcp, time, udp, unix, vm/usr/share/dstat: battery, battery-remain, cpufreq, dbus, disk-tps, disk-util, dstat, dstat-cpu, dstat-ctxt, dstat-mem, fan, freespace, gpfs, gpfs-ops, helloworld, innodb-buffer, innodb-io, innodb-ops, lustre, memcache-hits, mysql-io, mysql-keys, mysql5-cmds, mysql5-conn, mysql5-io, mysql5-keys, net-packets, nfs3, nfs3-ops, nfsd3, nfsd3-ops, ntp, postfix, power, proc-count, qmail, rpc, rpcd, sendmail, snooze, squid, test, thermal, top-bio, top-bio-adv, top-childwait, top-cpu, top-cpu-adv, top-cputime, top-cputime-avg, top-int, top-io, top-io-adv, top-latency, top-latency-avg, top-mem, top-oom, utmp, vm-memctl, vmk-hba, vmk-int, vmk-nic, vz-cpu, vz-io, vz-ubc, wifi[root@192 ~]# 直接在终端输入dstat命令，dstat将以默认参数运行。默认情况下，dstat会收集CPU、磁盘、网络、交换页和系统消息，并以1秒钟1次的频率进行输出，直到我们按Ctrl+C结束。 ¶（2）dstat常用选项 如下所示，dstat会提示我们没有指定任何参数，因此使用-cdngy参数运行。 123456789101112131415[root@192 ~]# dstatYou did not select any stats, using -cdngy by default.----total-cpu-usage---- -dsk/total- -net/total- ---paging-- ---system--usr sys idl wai hiq siq| read writ| recv send| in out | int csw 9 3 88 0 0 0| 219k 60k| 0 0 |2682B 5427B| 163 1542 20 5 75 0 0 0| 0 0 | 66B 894B| 0 0 | 326 4218 19 6 75 0 0 0| 0 0 | 126B 410B| 0 0 | 330 4431 18 7 75 0 0 0| 0 0 | 66B 416B| 0 0 | 341 2998 20 6 74 0 0 0| 0 0 | 66B 350B| 0 0 | 340 4098 19 6 75 0 0 0| 0 0 | 66B 350B| 0 0 | 319 4010 20 5 75 0 0 0| 0 0 | 66B 350B| 0 0 | 326 4378 19 6 75 0 0 0| 0 0 | 66B 350B| 0 0 | 322 4407 20 5 75 0 0 0| 0 0 | 66B 350B| 0 0 | 332 4520 21 6 73 0 0 0|1140k 0 | 66B 350B| 0 0 | 345 3341 20 7 72 0 0 1| 0 0 | 66B 358B| 0 0 | 348 3821 常用选项如下： 直接跟数字，表示#秒收集一次数据，默认为一秒；dstat 5表示5秒更新一次 12345678910111213-c,--cpu 统计CPU状态，包括system, user, idle, wait, hardware interrupt, software interrupt等；-d, --disk 统计磁盘读写状态-D total,sda 统计指定磁盘或汇总信息-l, --load 统计系统负载情况，包括1分钟、5分钟、15分钟平均值-m, --mem 统计系统物理内存使用情况，包括used, buffers, cache, free-s, --swap 统计swap已使用和剩余量-n, --net 统计网络使用情况，包括接收和发送数据-N eth1,total 统计eth1接口汇总流量-r, --io 统计I/O请求，包括读写请求-p, --proc 统计进程信息，包括runnable、uninterruptible、new-y, --sys 统计系统信息，包括中断、上下文切换-t 显示统计时时间，对分析历史数据非常有用--fs 统计文件打开数和inodes数 除了前面介绍的与监控相关的参数以外，dstat还可以像vmstat和iostat一样使用参数控制报告的时间间隔，或者同事指定时间间隔与报告次数。 例如，下面的命令表示以默认的选项运行dstat，每2秒钟输出一条监控信息，并在输出10条监控信息以后退出dstat。如下所示： 12345678910111213141516[root@192 ~]# dstat 2 10You did not select any stats, using -cdngy by default.----total-cpu-usage---- -dsk/total- -net/total- ---paging-- ---system--usr sys idl wai hiq siq| read writ| recv send| in out | int csw 9 3 88 0 0 0| 218k 60k| 0 0 |2674B 5409B| 164 1550 20 6 74 0 0 0| 0 0 | 66B 594B| 0 0 | 326 3956 21 6 73 0 0 0| 0 147k| 66B 346B| 0 0 | 360 4114 20 5 76 0 0 0| 0 0 | 66B 346B| 0 0 | 320 4494 20 6 74 0 0 0| 0 0 | 96B 372B| 0 0 | 349 4144 20 5 75 0 0 0| 0 0 | 66B 342B| 0 0 | 331 4360 21 6 74 0 0 0| 0 0 | 66B 342B| 0 0 | 344 3607 19 6 75 0 0 0| 0 0 | 66B 342B| 0 0 | 334 4475 21 6 74 0 0 0| 0 0 | 66B 342B| 0 0 | 338 4580 20 7 73 0 0 1| 0 0 | 66B 342B| 0 0 | 340 4341 20 6 74 0 0 0| 0 0 | 66B 342B| 0 0 | 344 3899 [root@192 ~]# ¶（3）dstat高级用法 dstat的强大之处不仅仅是因为它聚合了多种工具的监控结果，还因为它能通过附带的插件实现一些更高级功能。如：找出磁盘中占用资源最高的进程和用户。 dstat -cdlmnpsyt 5 可以得到较全面的系统性能数据。 dstat的–top-(io|bio|cpu|cputime|cputime-avg|mem) 通过这几个选项，可以看到具体是哪个用户哪个进程占用了相关系统资源，对系统调优非常有效。如查看当前占用I/O、cpu、内存等最高的进程信息可以使用dstat --top-mem --top-io --top-cpu选项。以下示例演示了如何找出占用资源最多的进程。 12345678910[root@192 ~]# dstat --top-mem --top-io --top-cpu--most-expensive- ----most-expensive---- -most-expensive- memory process | i/o process | cpu process gnome-shell 115M|polkitd 203k 10k|polkitd 3.8gnome-shell 115M|polkitd 459k 23k|polkitd 10gnome-shell 115M|polkitd 625k 31k|polkitd 9.0gnome-shell 115M|polkitd 592k 29k|dbus-daemon 8.0gnome-shell 115M|polkitd 606k 30k|polkitd 9.0gnome-shell 115M|polkitd 525k 26k|polkitd 10gnome-shell 115M|polkitd 525k 26k|dbus-daemon 8.0 dstat的插件保存在/usr/share/dstat目录下，我们可以参考它们的实现，编写自己的插件。 ¶（4）将结果输出到CSV文件 dstat还可以将监控信息保存到CSV文件中，以便后续进行处理。通过–output选项指定监控数据输出的文件。如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142[root@192 ~]# dstat -a --output dstat_output.csv----total-cpu-usage---- -dsk/total- -net/total- ---paging-- ---system--usr sys idl wai hiq siq| read writ| recv send| in out | int csw 9 3 88 0 0 0| 217k 60k| 0 0 |2656B 5370B| 165 1568 19 8 50 22 0 0| 11M 50k| 66B 838B| 128k 0 | 428 3116 19 6 75 0 0 0| 0 0 | 66B 374B| 0 0 | 325 4514 25 7 25 43 0 0|5284k 0 | 66B 350B| 476k 0 | 448 4227 18 7 74 0 0 1| 32k 144k| 66B 366B| 52k 0 | 334 4524 31 11 6 52 0 0|1944k 4096B| 66B 374B| 868k 0 | 613 3846 19 6 69 6 0 0| 116k 4096B| 66B 374B| 116k 0 | 337 4367 20 6 74 0 0 0| 0 0 | 66B 374B| 0 0 | 331 4573 20 7 73 0 0 0| 0 0 | 66B 350B| 0 0 | 339 3787 18 6 76 0 0 0| 0 0 | 66B 350B| 0 0 | 317 4472 20 6 74 0 0 0| 0 0 | 66B 350B| 0 0 | 338 3675 20 5 75 0 0 0| 0 0 | 66B 350B| 0 0 | 324 4633 21 5 74 0 0 0| 0 0 | 66B 350B| 0 0 | 318 4597 19 6 75 0 0 0| 0 0 | 66B 350B| 0 0 | 333 4847 18 6 76 0 0 0| 0 0 | 66B 350B| 0 0 | 308 4742 ^C[root@192 ~]# cat dstat_output.csv \"Dstat 0.7.2 CSV output\"\"Author:\",\"Dag Wieers &lt;dag@wieers.com&gt;\",,,,\"URL:\",\"http://dag.wieers.com/home-made/dstat/\"\"Host:\",\"192.168.32.138\",,,,\"User:\",\"root\"\"Cmdline:\",\"dstat -a --output dstat_output.csv\",,,,\"Date:\",\"22 Feb 2020 00:22:08 CST\"\"total cpu usage\",,,,,,\"dsk/total\",,\"net/total\",,\"paging\",,\"system\",\"usr\",\"sys\",\"idl\",\"wai\",\"hiq\",\"siq\",\"read\",\"writ\",\"recv\",\"send\",\"in\",\"out\",\"int\",\"csw\"8.683,2.816,88.156,0.313,0.0,0.032,222019.623,61103.678,0.0,0.0,2655.691,5370.227,164.807,1568.44719.388,8.163,50.0,22.449,0.0,0.0,11702272.0,51200.0,66.0,838.0,131072.0,0.0,428.0,3116.019.192,6.061,74.747,0.0,0.0,0.0,0.0,0.0,66.0,374.0,0.0,0.0,325.0,4514.024.510,6.863,25.490,43.137,0.0,0.0,5410816.0,0.0,66.0,350.0,487424.0,0.0,448.0,4227.018.182,7.071,73.737,0.0,0.0,1.010,32768.0,147456.0,66.0,366.0,53248.0,0.0,334.0,4524.030.928,11.340,6.186,51.546,0.0,0.0,1990656.0,4096.0,66.0,374.0,888832.0,0.0,613.0,3846.019.192,6.061,68.687,6.061,0.0,0.0,118784.0,4096.0,66.0,374.0,118784.0,0.0,337.0,4367.019.802,5.941,74.257,0.0,0.0,0.0,0.0,0.0,66.0,374.0,0.0,0.0,331.0,4573.020.0,7.0,73.0,0.0,0.0,0.0,0.0,0.0,66.0,350.0,0.0,0.0,339.0,3787.018.367,6.122,75.510,0.0,0.0,0.0,0.0,0.0,66.0,350.0,0.0,0.0,317.0,4472.020.0,6.0,74.0,0.0,0.0,0.0,0.0,0.0,66.0,350.0,0.0,0.0,338.0,3675.020.202,5.051,74.747,0.0,0.0,0.0,0.0,0.0,66.0,350.0,0.0,0.0,324.0,4633.021.0,5.0,74.0,0.0,0.0,0.0,0.0,0.0,66.0,350.0,0.0,0.0,318.0,4597.019.192,6.061,74.747,0.0,0.0,0.0,0.0,0.0,66.0,350.0,0.0,0.0,333.0,4847.018.182,6.061,75.758,0.0,0.0,0.0,0.0,0.0,66.0,350.0,0.0,0.0,308.0,4742.0[root@192 ~]# ¶2、交互式监控工具glances 在紧急情况下，工程师需要在尽可能短的时间内查看尽可能多的信息。此时，glances是一个不错的选择。glances的设计初衷就是在当前窗口中尽可能多地显示系统消息。 glances是一款使用Python语言开发、基于psutil的跨平台系统监控工具，在所有Linux命令行工具中，它与top命令最相似，都是命令行交互监控工具。但是，glances实现了比top命令更齐全的接口，提供了更加丰富的功能。 ¶（1）glances提供的系统信息 glances提供的系统信息如下所示： 12345678910CPU 使用率内存使用情况内核统计信息和运行队列信息磁盘 I/O 速度、传输和读/写比率文件系统中的可用空间磁盘适配器网络 I/O 速度、传输和读/写比率页面空间和页面速度消耗资源最多的进程计算机信息和系统资源 glances 工具可以在用户的终端上实时显示重要的系统信息，并动态地对其进行更新。这个高效的工具可以工作于任何终端屏幕。另外它并不会消耗大量的 CPU 资源，通常低于百分之二。glances 在屏幕上对数据进行显示，并且每隔2秒钟对其进行更新。您也可以自己将这个时间间隔更改为更长或更短的数值。 glances 工具还可以将相同的数据捕获到一个文件，便于以后对报告进行分析和绘制图形。输出文件可以是电子表格的格式 (.csv) 或者 html 格式。 ¶（2）Linux下glances的安装 在Linux系统中，可以使用yum命令或者pip命令安装glances。如下所示： 12yum install epel-releaseyum install glances glances的使用非常简单，直接输入glances命令便进入了一个类似top命令的交互式界面。在这个界面中，显示了比top更加全面，更加具有可读性的信息。如下所示： glances 工作界面的说明 : 在图 1 的上部是 CPU 、Load（负载）、Mem（内存使用）、 Swap（交换分区）的使用情况。在图 1 的中上部是网络接口、Processes（进程）的使用情况。通常包括如下字段： 1234567891011VIRT: 虚拟内存大小RES: 进程占用的物理内存值%CPU：该进程占用的 CPU 使用率%MEM：该进程占用的物理内存和总内存的百分比PID: 进程 ID 号USER: 进程所有者的用户名TIME+: 该进程启动后占用的总的 CPU 时间IO_R 和 IO_W: 进程的读写 I/O 速率NAME: 进程名称NI: 进程优先级S: 进程状态，其中 S 表示休眠，R 表示正在运行，Z 表示僵死状态。 ¶（3）glances的可读性 对比可以发现，glances对屏幕的利用率比top明显高很多，信息量很大，有许多top所没有显示的数据。而且，glances的实时变动比top颜值高太多了。 Glances 会用一下几种颜色来代表状态，如下所示： 1234绿色：OK（一切正常）蓝色：CAREFUL（需要注意）紫色：WARNING（警告）红色：CRITICAL（严重） ¶（4）glances常见命令 glances是一个交互式的工具，因此我们也可以输入命令来控制glances的行为。glances常见的命令有： 123456789101112h：显示帮助信息q：离开程序退出c：按照 CPU 实时负载对系统进程进行排序m：按照内存使用状况对系统进程排序i：按照 I/O 使用状况对系统进程排序p：按照进程名称排序d：显示磁盘读写状况w：删除日志文件l：显示日志s：显示传感器信息f：显示系统信息1：轮流显示每个 CPU 内核的使用情况（次选项仅仅使用在多核 CPU 系统） glances还支持将采集的数据导入到其他服务中心，包括InfluxDB、Cassandra、CouchDB、OpenTSDB、Prometheus、StatsD、ElasticSearch、RabbitMQ/ActiveMQ、ZeroMQ、Kafaka和Riemann。 ¶二、Python监控Linux shell查看磁盘的监控信息，如下所示： 1234567[root@bogon proc]# cat /proc/diskstats 8 0 sda 85935 21845 10913707 101067 3119 81257 743486 15647 0 31410 109079 8 1 sda1 1822 0 12456 397 4 0 4096 74 0 457 462 8 2 sda2 84082 21845 10897907 100659 3115 81257 739390 15573 0 30950 108604 11 0 sr0 0 0 0 0 0 0 0 0 0 0 0 253 0 dm-0 80726 0 10688467 99971 2275 0 82606 10224 0 27927 110196 253 1 dm-1 25123 0 205184 7367 82098 0 656784 616558 0 5167 623924 编写一个Python脚本，监控磁盘信息，如下所示： 1234567891011121314151617181920212223242526#/usr/bin/python#_*_ coding:utf-8 _*_from __future__ import print_functionfrom collections import namedtupledisk = namedtuple('Disk','major_number minor_number device_name' ' read_count read_merged_count read_sections' ' time_spent_reading write_count write_merged_count' ' write_sections time_spent_write io_requests' ' time_spent_doing_io weighted_time_spent_dong_io')def get_disk_info(device): with open('/proc/diskstats') as f: for line in f: if line.split()[2] == device: return disk(*(line.split())) raise RuntimeError('设备(&#123;0&#125;)没找到。。。'.format(device))def main(): disk_info = get_disk_info('sda1') print(disk_info)if __name__ == '__main__': main() ¶三、使用开源库监控Linux 在这一小节，我们将介绍一个在Python生态中广泛使用的开源项目，即psutil。随后，我们将使用psutil重构前一小节编写的监控程序。另外，还会简单介绍psutil提供的进程管理功能。 ¶1、psutil介绍 psutil = process and system utilities psutil是一个开源且跨平台的库，其提供了便利的函数用来获取操作系统的信息，比如CPU，内存，磁盘，网络等。此外，psutil还可以用来进行进程管理，包括判断进程是否存在、获取进程列表、获取进程详细信息等。而且psutil还提供了许多命令行工具提供的功能，包括：ps，top，lsof，netstat，ifconfig， who，df，kill，free，nice，ionice，iostat，iotop，uptime，pidof，tty，taskset，pmap。 psutil是一个跨平台的库，支持Linux、Windows、OSX、FreeBSD、OpenBSD、NetBSD、Sun Solaris、AIX等操作系统。同时，psutil也支持32位与64位的系统架构，支持Python2.6到Python3.x之间的所有Python版本。 psutil具有简单易用、功能强大、跨平台等诸多优点，广泛应用于开源项目中，比较有名的有glances、Facebook的osquery、Google的grr等。psutil不但广泛应用于Python语言开发的开源项目中，还被移植到了其他编程语言中，如Go语言的gopsutil、C语言的cpslib、Rust语言的rust-psutil、Ruby语言的posixpsutil等。 psutil是一个第三方的开源项目，因此，需要先安装才能够使用。如果安装了Anaconda，psutil就已经可用了。否则，需要在命令行下通过pip安装： 1234567[root@localhost ~]# pip install psutilCollecting psutil Downloading psutil-5.7.0.tar.gz (449 kB) |████████████████████████████████| 449 kB 4.6 kB/s Installing collected packages: psutil Running setup.py install for psutil ... doneSuccessfully installed psutil-5.7.0 psutil包含了异常、类、功能函数和常量，其中功能函数用来获取系统的信息，如CPU、磁盘、内存、网络等。类用来实现进程的管理功能。 ¶2、psutil提供的功能函数 根据函数的功能，主要分为CPU、磁盘、内存、网络几类，下面将会总几个方面来介绍psutil提供的功能函数。在这一小节，我们也将学习如何使用psutil来简化使用shell脚本获取监控信息的程序，并获取CPU、内存、磁盘和网络等不同维度。 ¶（1）CPU 与CPU相关的功能函数如下： 函数 描述 psutil.cpu_count() cpu_count(,[logical]):默认返回逻辑CPU的个数,当设置logical的参数为False时，返回物理CPU的个数。 psutil.cpu_percent() cpu_percent(,[percpu],[interval])：返回CPU的利用率,percpu为True时显示所有物理核心的利用率,interval不为0时,则阻塞时显示interval执行的时间内的平均利用率 psutil.cpu_times() cpu_times(,[percpu])：以命名元组(namedtuple)的形式返回cpu的时间花费,percpu=True表示获取每个CPU的时间花费 psutil.cpu_times_percent() cpu_times_percent(,[percpu])：功能和cpu_times大致相同，看字面意思就能知道，该函数返回的是耗时比例。 psutil.cpu_stats() cpu_stats()以命名元组的形式返回CPU的统计信息，包括上下文切换，中断，软中断和系统调用次数。 psutil.cpu_freq() cpu_freq([percpu])：返回cpu频率 ¶1）cpu_count 默认返回逻辑CPU的个数,当设置logical的参数为False时，返回物理CPU的个数。 1234567In [1]: import psutil In [2]: psutil.cpu_count() Out[2]: 2In [3]: psutil.cpu_count(logical&#x3D;False) Out[3]: 1 ¶2）cpu_percent 返回CPU的利用率，percpu为True时显示所有物理核心的利用率，interval不为0时，则阻塞时显示interval执行的时间内的平均利用率。 12345678In [4]: psutil.cpu_percent() Out[4]: 1.5In [5]: psutil.cpu_percent(percpu=True) Out[5]: [1.3, 1.5]In [6]: psutil.cpu_percent(percpu=True,interval=2) Out[6]: [1.0, 0.0] ¶3）cpu_times 以命名元组(namedtuple)的形式返回cpu的时间花费，percpu=True表示获取每个CPU的时间花费。 12345In [7]: psutil.cpu_times() Out[7]: scputimes(user=41.51, nice=2.05, system=35.36, idle=2096.05, iowait=5.45, irq=0.0, softirq=1.31, steal=0.0, guest=0.0, guest_nice=0.0)In [8]: psutil.cpu_times_percent() Out[8]: scputimes(user=0.3, nice=0.0, system=0.1, idle=99.5, iowait=0.0, irq=0.0, softirq=0.0, steal=0.0, guest=0.0, guest_nice=0.0) ¶4）cpu_stats 以命名元组的形式返回CPU的统计信息，包括上下文切换，中断，软中断和系统调用次数。 12In [10]: psutil.cpu_stats() Out[10]: scpustats(ctx_switches=538642, interrupts=238329, soft_interrupts=273448, syscalls=0) ¶5）cpu_freq 返回cpu频率。 12In [11]: psutil.cpu_freq() Out[11]: scpufreq(current=2394.464, min=0.0, max=0.0) ¶（2）内存 与内存相关的功能函数如下： ¶1）virtual_memory 以命名元组的形式返回内存使用情况，包括总内存、可用内存、内存利用率、buffer和cache等。除了内存利用率，其它字段都以字节为单位返回。 1234In [1]: import psutil In [2]: psutil.virtual_memory() Out[2]: svmem(total=1019797504, available=95744000, percent=90.6, used=758079488, free=67502080, active=295485440, inactive=417394688, buffers=0, cached=194215936, shared=19103744, slab=92905472) 单位转换 1234567891011121314151617#/usr/bin/python#-*- conding:utf-8 _*_import psutildef bytes2human(n): symbols = ('K','M','G','T','P','E','Z','Y') prefix = &#123;&#125; for i,s in enumerate(symbols): prefix[s] = 1 &lt;&lt; (i + 1) * 10 for s in reversed(symbols): if n &gt;= prefix[s]: value = float(n) / prefix[s] return '%.1f%s' % (value,s) return '%sB' % nprint(bytes2human(psutil.virtual_memory().total)) 运行结果如下所示： 12[root@localhost ~]# python mem.py 972.6M ¶2）swap_memory 以命名元组的形式返回swap/memory使用情况，包含swap中页的换入和换出。 12In [3]: psutil.swap_memory() Out[3]: sswap(total=2147479552, used=141819904, free=2005659648, percent=6.6, sin=24666112, sout=147292160) ¶（3）磁盘 与磁盘相关的功能如下： 函数 描述 psutil.disk_io_counters() disk_io_counters([perdisk])：以命名元组的形式返回磁盘io统计信息(汇总的)，包括读、写的次数，读、写的字节数等。 当perdisk的值为True，则分别列出单个磁盘的统计信息(字典：key为磁盘名称，value为统计的namedtuple)。 psutil.disk_partitions() disk_partitions([all=False])：以命名元组的形式返回所有已挂载的磁盘，包含磁盘名称，挂载点，文件系统类型等信息。 当all等于True时，返回包含/proc等特殊文件系统的挂载信息 psutil.disk_usage() disk_usage(path)：以命名元组的形式返回path所在磁盘的使用情况，包括磁盘的容量、已经使用的磁盘容量、磁盘的空间利用率等。 ¶1）psutil.disk_io_counters 以命名元组的形式返回磁盘io统计信息(汇总的)，包括读、写的次数，读、写的字节数等。 当perdisk的值为True，则分别列出单个磁盘的统计信息(字典：key为磁盘名称，value为统计的namedtuple)。有了disk_io_counters函数，省去了解析/proc/diskstats文件的烦恼。 12345678910111213In [1]: import psutil In [2]: psutil.disk_io_counters() Out[2]: sdiskio(read_count=86913, write_count=46560, read_bytes=5038501376, write_bytes=408987648, read_time=77974, write_time=79557, read_merged_count=5933, write_merged_count=35916, busy_time=42153)In [3]: psutil.disk_io_counters(perdisk=True) Out[3]: &#123;'sda': sdiskio(read_count=41472, write_count=5340, read_bytes=2524417024, write_bytes=205662720, read_time=38302, write_time=4484, read_merged_count=5933, write_merged_count=35916, busy_time=21074), 'sda1': sdiskio(read_count=1854, write_count=4, read_bytes=6441472, write_bytes=2097152, read_time=370, write_time=35, read_merged_count=0, write_merged_count=0, busy_time=396), 'sda2': sdiskio(read_count=39587, write_count=5337, read_bytes=2516263424, write_bytes=203570688, read_time=37925, write_time=4449, read_merged_count=5933, write_merged_count=35916, busy_time=20675), 'sr0': sdiskio(read_count=0, write_count=0, read_bytes=0, write_bytes=0, read_time=0, write_time=0, read_merged_count=0, write_merged_count=0, busy_time=0), 'dm-0': sdiskio(read_count=38566, write_count=5197, read_bytes=2483773952, write_bytes=55885312, read_time=37685, write_time=3546, read_merged_count=0, write_merged_count=0, busy_time=19410), 'dm-1': sdiskio(read_count=6875, write_count=36059, read_bytes=30310400, write_bytes=147697664, read_time=1987, write_time=71537, read_merged_count=0, write_merged_count=0, busy_time=1673)&#125; ¶2）psutil.disk_partitions 以命名元组的形式返回所有已挂载的磁盘，包含磁盘名称，挂载点，文件系统类型等信息。当all等于True时，返回包含/proc等特殊文件系统的挂载信息。 123456789101112131415161718In [4]: psutil.disk_partitions() Out[4]: [sdiskpart(device='/dev/mapper/centos-root', mountpoint='/', fstype='xfs', opts='rw,seclabel,relatime,attr2,inode64,noquota'), sdiskpart(device='/dev/sda1', mountpoint='/boot', fstype='xfs', opts='rw,seclabel,relatime,attr2,inode64,noquota')]In [5]: [device for device in psutil.disk_partitions() if device.mountpoint == '/']Out[5]: [sdiskpart(device='/dev/mapper/centos-root', mountpoint='/', fstype='xfs', opts='rw,seclabel,relatime,attr2,inode64,noquota')]In [6]: def get_disk_via_mountpoint(point): ...: disk = [item for item in psutil.disk_partitions() if item.mountpoint == point] ...: return disk[0].device ...: In [7]: get_disk_via_mountpoint('/')Out[7]: '/dev/mapper/centos-root'In [8]: get_disk_via_mountpoint('/boot') Out[8]: '/dev/sda1' ¶3）psutil.disk_usage 以命名元组的形式返回path所在磁盘的使用情况，包括磁盘的容量、已经使用的磁盘容量、磁盘的空间利用率等。 12345678In [9]: psutil.disk_usage('/') Out[9]: sdiskusage(total=18238930944, used=6775488512, free=11463442432, percent=37.1)In [10]: psutil.disk_usage('/').percentOut[10]: 37.2In [11]: type(psutil.disk_usage('/').percent)Out[11]: float ¶（4）网络 与网络相关的函数如下： 函数 详情 psutil.net_io_counter([pernic]) 以命名元组的形式返回当前系统中每块网卡的网络io统计信息，包括收发字节数，收发包的数量、出错的情况和删包情况。当pernic为True时，则列出所有网卡的统计信息。 psutil.net_connections([kind]) 以列表的形式返回每个网络连接的详细信息(namedtuple)。命名元组包含fd, family, type, laddr, raddr, status, pid等信息。kind表示过滤的连接类型，支持的值如下：(默认为inet) psutil.net_if_addrs() 以字典的形式返回网卡的配置信息，包括IP地址和mac地址、子网掩码和广播地址。 psutil.net_if_stats() 返回网卡的详细信息，包括是否启动、通信类型、传输速度与mtu。 psutil.users() 以命名元组的方式返回当前登陆用户的信息，包括用户名，登陆时间，终端，与主机信息 psutil.boot_time() 以时间戳的形式返回系统的启动时间 ¶1）psutil.net_io_counter 以命名元组的形式返回当前系统中每块网卡的网络io统计信息，包括收发字节数，收发包的数量、出错的情况和删包情况。当pernic为True时，则列出所有网卡的统计信息。使用net_io_counter函数与自己解析/proc/net/dev文件内容实现的功能相同。 123456789101112In [1]: import psutil In [2]: psutil.net_io_counters() Out[2]: snetio(bytes_sent=720405, bytes_recv=3661606, packets_sent=5520, packets_recv=14886, errin=0, errout=0, dropin=0, dropout=0)In [3]: psutil.net_io_counters(pernic=True) Out[3]: &#123;'ens37': snetio(bytes_sent=724145, bytes_recv=3365944, packets_sent=5538, packets_recv=10017, errin=0, errout=0, dropin=0, dropout=0), 'lo': snetio(bytes_sent=0, bytes_recv=0, packets_sent=0, packets_recv=0, errin=0, errout=0, dropin=0, dropout=0), 'virbr0-nic': snetio(bytes_sent=0, bytes_recv=0, packets_sent=0, packets_recv=0, errin=0, errout=0, dropin=0, dropout=0), 'virbr0': snetio(bytes_sent=0, bytes_recv=0, packets_sent=0, packets_recv=0, errin=0, errout=0, dropin=0, dropout=0), 'ens33': snetio(bytes_sent=0, bytes_recv=298202, packets_sent=0, packets_recv=4899, errin=0, errout=0, dropin=0, dropout=0)&#125; ¶2）net_connections 以列表的形式返回每个网络连接的详细信息(namedtuple)，可以使用该函数查看网络连接状态，统计连接个数以及处于特定状态的网络连接个数。 123456789101112In [4]: psutil.net_connections() Out[4]: [sconn(fd=6, family=&lt;AddressFamily.AF_INET6: 10&gt;, type=&lt;SocketKind.SOCK_STREAM: 1&gt;, laddr=addr(ip='::', port=111), raddr=(), status='LISTEN', pid=6558), sconn(fd=7, family=&lt;AddressFamily.AF_INET6: 10&gt;, type=&lt;SocketKind.SOCK_DGRAM: 2&gt;, laddr=addr(ip='::', port=111), raddr=(), status='NONE', pid=6558), sconn(fd=8, family=&lt;AddressFamily.AF_INET6: 10&gt;, type=&lt;SocketKind.SOCK_STREAM: 1&gt;, laddr=addr(ip='::1', port=6010), raddr=(), status='LISTEN', pid=9047), sconn(fd=6, family=&lt;AddressFamily.AF_INET: 2&gt;, type=&lt;SocketKind.SOCK_STREAM: 1&gt;,......In [5]: conns = psutil.net_connections()In [6]: len([conn for conn in conns if conn.status == 'TIME_WAIT']) Out[6]: 0 ¶3）net_if_addrs 以字典的形式返回网卡的配置信息，包括IP地址和mac地址、子网掩码和广播地址。 12345678In [7]: psutil.net_if_addrs() Out[7]: &#123;'lo': [snicaddr(family=&lt;AddressFamily.AF_INET: 2&gt;, address='127.0.0.1', netmask='255.0.0.0', broadcast=None, ptp=None), snicaddr(family=&lt;AddressFamily.AF_INET6: 10&gt;, address='::1', netmask='ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff', broadcast=None, ptp=None), snicaddr(family=&lt;AddressFamily.AF_PACKET: 17&gt;, address='00:00:00:00:00:00', netmask=None, broadcast=None, ptp=None)], 'ens37': [snicaddr(family=&lt;AddressFamily.AF_INET: 2&gt;, address='192.168.1.131', netmask='255.255.255.255', broadcast='192.168.1.131', ptp=None), snicaddr(family=&lt;AddressFamily.AF_INET6: 10&gt;, address='240e:82:e03:7342:4378:7be3:558c:fc88', netmask='ffff:ffff:ffff:ffff::', broadcast=None, ptp=None)...... ¶4）psutil.net_if_stats 返回网卡的详细信息，包括是否启动、通信类型、传输速度与mtu。 1234567In [8]: psutil.net_if_stats() Out[8]: &#123;'ens37': snicstats(isup=True, duplex=&lt;NicDuplex.NIC_DUPLEX_FULL: 2&gt;, speed=1000, mtu=1500), 'lo': snicstats(isup=True, duplex=&lt;NicDuplex.NIC_DUPLEX_UNKNOWN: 0&gt;, speed=0, mtu=65536), 'virbr0-nic': snicstats(isup=False, duplex=&lt;NicDuplex.NIC_DUPLEX_FULL: 2&gt;, speed=10, mtu=1500), 'virbr0': snicstats(isup=True, duplex=&lt;NicDuplex.NIC_DUPLEX_UNKNOWN: 0&gt;, speed=0, mtu=1500), 'ens33': snicstats(isup=True, duplex=&lt;NicDuplex.NIC_DUPLEX_FULL: 2&gt;, speed=1000, mtu=1500)&#125; ¶（5）其他 ¶1）users 以命名元组的方式返回当前登陆用户的信息，包括用户名，登陆时间，终端，与主机信息。 123456In [9]: psutil.users() Out[9]: [suser(name='root', terminal=':0', host='localhost', started=1582366080.0, pid=7991), suser(name='root', terminal='pts/0', host='localhost', started=1582366208.0, pid=8927), suser(name='root', terminal='pts/1', host='192.168.1.4', started=1582370816.0, pid=10099), suser(name='root', terminal='pts/3', host='192.168.1.4', started=1582369408.0, pid=9787)] ¶2）boot_time 以时间戳的形式返回系统的启动时间。 12345In [10]: psutil.boot_time() Out[10]: 1582527367.0 In [11]: datetime.datetime.fromtimestamp(psutil.boot_time()).strftime('%Y-%m-%d %H:%M:%S') Out[11]: '2020-02-24 14:56:07' ¶3、综合案例：使用psutil实现监控程序 ¶4、psutil进程管理 psutil还提供了作为进程管理的功能函数，包括获取进程列表，判断是否存在，以及进程管理的类封装。 函数 详情 psutil.Process() 对进程进行封装，可以使用该类的方法获取进行的详细信息，或者给进程发送信号。 psutil.pids() 以列表的形式返回当前正在运行的进程 psutil.pid_exists(1) 判断给点定的pid是否存在 psutil.process_iter() 迭代当前正在运行的进程，返回的是每个进程的Process对象 ¶1）Process类 对进程进行封装，可以使用该类的方法获取进行的详细信息，或者给进程发送信号。 123456In [1]: import psutil In [2]: init_process = psutil.Process()In [3]: init_process.cmdline() Out[3]: ['/usr/local/python38/bin/python3.8', '/usr/local/python38/bin/ipython'] Process类包含很多方法来获取进程的详细信息。下面是几个较常用的方法： 123456789name：获取进程的名称cmdline：获取启动进程的命令行参数create_time：获取进程的创建时间(时间戳格式)num_fds：进程打开的文件个数num_threads：进程的子进程个数is_running：判断进程是否正在运行send_signal：给进程发送信号，类似与os.kill等kill：发送SIGKILL信号结束进程terminate：发送SIGTEAM信号结束进程 ¶2）pids 以列表的形式返回当前正在运行的进程。 123456789In [1]: import psutil In [2]: init_process = psutil.Process()In [3]: init_process.cmdline() Out[3]: ['/usr/local/python38/bin/python3.8', '/usr/local/python38/bin/ipython']In [4]: psutil.pids()[:5] Out[4]: [1, 2, 3, 5, 7] ¶3）pid_exists 判断给点定的pid是否存在。 12345In [5]: psutil.pid_exists(1) Out[5]: TrueIn [6]: psutil.pid_exists(10245) Out[6]: False ¶4）process_iter 迭代当前正在运行的进程，返回的是每个进程的Process对象，而pids返回的是进程的列表。 ¶四、使用Python监控MongoDB 对于MongoDB数据库来说，获取监控的方法比较简单，因为MongoDB本身流返回给我们一个字典形式的数据。如下所示： 1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pymongo 1234567891011121314#/usr/bin/python#_*_ coding:utf-8 _*_from __future__ import print_functionimport pymongoclient = pymongo.MongoClient(host='127.0.0.1:27017')client.admin.authenticate('laoyu','laoyu')rs = client.admin.command('replSetGetStatus')print(\"set:\",rs['set'])print(\"myState:\",rs['myState'])print('num of members:',len(rs['members'])) ¶3）pid_exists 判断给点定的pid是否存在。 12345In [5]: psutil.pid_exists(1) Out[5]: TrueIn [6]: psutil.pid_exists(10245) Out[6]: False ¶4）process_iter 迭代当前正在运行的进程，返回的是每个进程的Process对象，而pids返回的是进程的列表。 ¶四、使用Python监控MongoDB 对于MongoDB数据库来说，获取监控的方法比较简单，因为MongoDB本身流返回给我们一个字典形式的数据。如下所示： 1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pymongo 1234567891011121314#/usr/bin/python#_*_ coding:utf-8 _*_from __future__ import print_functionimport pymongoclient = pymongo.MongoClient(host='127.0.0.1:27017')client.admin.authenticate('laoyu','laoyu')rs = client.admin.command('replSetGetStatus')print(\"set:\",rs['set'])print(\"myState:\",rs['myState'])print('num of members:',len(rs['members']))","categories":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/tags/Python/"}]},{"title":"Python3+Django3开发简单的人员管理系统","slug":"Python3+Django3开发简单的人员管理系统","date":"2020-04-26T16:00:00.000Z","updated":"2020-04-27T14:43:16.438Z","comments":true,"path":"Python3+Django3开发简单的人员管理系统.html","link":"","permalink":"https://pdxblog.top/Python3+Django3%E5%BC%80%E5%8F%91%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E5%91%98%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F.html","excerpt":"","text":"¶Python3+Django3开发简单的人员管理系统 ¶1、创建工程和应用 ¶1.1 使用pycharm创建项目 ¶1.2安装mysqlclient 在设置里面找创建的项目点击右边的“+”号直接安装 ¶2、应用配置 ¶2.1、修改项目配置文件（UserSystem/settings.py） ¶1）注释csrf校验 123456789MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', # 'django.middleware.csrf.CsrfViewMiddleware', # 注释此项 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware',] ¶2）修改数据库的默认配置：sqlite3改为mysql 1234567891011121314DATABASES = &#123; # 'default': &#123; # 'ENGINE': 'django.db.backends.sqlite3', # 'NAME': os.path.join(BASE_DIR, 'db.sqlite3'), # &#125;'default': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': 'userinfo', 'USER': 'root', 'PASSWORD': '123.com', 'HOST':'localhost', 'PORT':'3306', &#125;&#125; ¶3）修改语言和时区 12345# LANGUAGE_CODE = 'en-us'LANGUAGE_CODE = 'zh-Hans'# TIME_ZONE = 'UTC'TIME_ZONE = 'Asia/Shanghai' ¶4）允许所有IP访问 1ALLOWED_HOSTS = ['*'] ¶2.2、定义用户信息的数据模型：UserInfo/models.py 12345678910111213from django.db import modelsclass User(models.Model): GENDER_CHOICES = ( ('男', '男'), ('女', '女'), ) name = models.CharField(max_length=30, unique=True, verbose_name='姓 名') birthday = models.DateField(blank=True, null=True, verbose_name='生 日') gender = models.CharField(max_length=30, choices=GENDER_CHOICES, verbose_name='性 别') account = models.IntegerField(default=0, verbose_name='工 号') age = models.IntegerField(default=18, verbose_name='年 龄') ¶2.3、初始化模型数据库兵生成数据库文件 简言之：在Django 1.9及未来的版本种使用migrate代替原先的syscdb. 先在Mysql中创建数据库&quot;userinfo&quot; 执行下面代码：（直接再Pycharm里的&quot;Terminal&quot;终端执行 ） 12(venv) F:\\python1\\UserSystem&gt;python manage.py makemigrations(venv) F:\\python1\\UserSystem&gt;python ./manage.py migrate ¶2.4、显示注册信息修改默认标题（UserInfo/admin.py） 123456789101112131415161718from django.contrib import adminfrom . models import Userclass HostAdmin(admin.ModelAdmin): list_display = [ 'name', 'age', 'birthday', 'gender', 'account', ] search_fields = ('name',)admin.site.register(User, HostAdmin)admin.AdminSite.site_header = '运维系统管理后台'admin.AdminSite.site_title = '运维系统' ¶2.5、添加应用的url访问（UserSystem/urls.py） 123456from django.contrib import adminfrom django.urls import pathurlpatterns = [ path('admin/', admin.site.urls),] ¶3、启动Django服务 ¶3.1、命令启动 1(venv) F:\\python1\\UserSystem&gt;python ./manage.py runserver ¶3.2、创建超级用户 12345678910(venv) F:\\python1\\UserSystem&gt;python ./manage.py createsuperuser用户名: accp电子邮件地址:Password:Password (again):密码长度太短。密码必须包含至少 8 个字符。这个密码太常见了。密码只包含数字。Bypass password validation and create user anyway? [y/N]: ySuperuser created successfully. ¶3.3、浏览器访问登录：http://127.0.0.1:8000/admin ¶3.4、登录成功后即可添加对应的信息到系统中 ¶3.5、前往数据库查看，用户信息是否保存","categories":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/tags/Python/"}]},{"title":"Python对Linux系统的管理","slug":"Python对Linux系统的管理","date":"2020-04-26T16:00:00.000Z","updated":"2020-04-27T14:43:53.427Z","comments":true,"path":"Python对Linux系统的管理.html","link":"","permalink":"https://pdxblog.top/Python%E5%AF%B9Linux%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86.html","excerpt":"","text":"¶Python对Linux系统的管理 ¶一、OS模块常用功能 ¶1、os模块打开文件 方法如下： os.open(filename, flag, [,mode]) flag参数说明： 1234os.O_CREAT # 创建文件os.O_RDONLY # 只读方式打开os.O_WRONLY # 只写方式打开os.O_RDWR # 读写方式打开 ¶2、os模块对文件进行操作 常用方法如下： 12345678# 读取文件os.read(fd, buffersize)# 写入文件os.write(fd, string)# 文件指针操作os.lseek(fd, pos, how)# 关闭文件os.close(fd) 代码演示： 文件创建和写入 123456789101112131415161718import os# 打开文件fd = os.open(\"abc.txt\", os.O_RDWR | os.O_CREAT)# 写入字符串str = \"Hello Python!\"ret = os.write(fd, bytes(str, 'UTF-8'))# 输入返回值print(\"写入的位数为: \")print(ret)print(\"写入成功\")# 关闭文件os.close(fd)print(\"关闭文件成功!!\") 文件读取 123456789101112import os# 打开文件fd = os.open(\"abc.txt\", os.O_RDWR)# 读取文本ret = os.read(fd, 6)print(ret)# 关闭文件os.close(fd)print(\"关闭文件成功!!\") ¶3、os模块管理文件和目录 常用方法如下： os方法 说明 getcwd() 获取当前目录 listdir(path) 返回当前目录下所有文件组成的列表 chdir(path) 切换目录 rename(old, new) 修改文件或者目录名 mkdir(path [,mode]) 创建目录 makedirs(path [,mode]) 创建多级目录 rmdir(path) 删除目录（目录必须为空目录） removedirs(path) 删除多级目录（目录必须为空目录） remove(path) 删除文件 代码演示： 123456789101112131415# coding=utf-8import osprint(os.getcwd()) # pwdprint(os.listdir()) # lsos.chdir('/opt') # cd /optos.rename('abc.txt','test.txt') # mv abc.txt test.txtos.remove('read.py') # rm -f abc.txtos.mkdir('test') # mkdir dir1os.makedirs('demo/abc') # mkdir -p dir2/dir22os.rmdir('test') # 目录必须为空os.removedirs('demo') # 目录必须为空 ¶4、os模块管理文件权限 os方法 说明 access(path, mode) 判断该文件权限：F_OK表示该路径存在；权限：R_OK，W_OK，X_OK chmod(path, mode) 修改文件权限：0o755 chown(path, uid, gid) 更改文件所有者，如果不修改可以设置为 -1 代码演示： 123456789101112131415161718192021222324import os# 测试路径是否存在：os.F_OKres = os.access('test.txt',os.F_OK)print(res)# 测试当前用户对该文件是否有读的权限res = os.access('test.txt',os.R_OK)print(res)# 测试当前用户对该文件是否有写的权限res = os.access('test.txt',os.W_OK)print(res)# 测试当前用户对该文件是否有执行的权限res = os.access('test.txt',os.X_OK)print(res)# 更改当前用户的权限os.chmod('test.txt',0o755)# 更改文件的所有者os.chown('test.txt', 1001, 1002) ¶5、os.path模块管理文件与路径 ¶（1）拆分路径 os.path方法 说明 os.path.split(path) 返回一个二元组，包含文件的路径和文件名 os.path.dirname(path) 返回文件的路径 os.path.basename(path) 返回文件名 os.path.splitext(path) 返回一个去掉文件扩展名的部分和扩展名的二元组 代码演示： 12345678910111213141516171819In [10]: os.getcwd()Out[10]: '/opt/os_demo'In [11]: os.listdir()Out[11]: ['os_access.py', 'test.txt']In [12]: path = '/opt/os_demo/test.txt' In [13]: os.path.split(path)Out[13]: ('/opt/os_demo', 'test.txt')In [14]: os.path.dirname(path)Out[14]: '/opt/os_demo'In [15]: os.path.basename(path)Out[15]: 'test.txt'In [16]: os.path.splitext(path) Out[16]: ('/opt/os_demo/test', '.txt') ¶（2）构建路径 os.path方法 说明 os.path.expanduser(path) 展开用户的HOME目录，如，oracle os.path.abspath(path) 得到文件或路径的绝对路径 os.path.join(path) 根据不同的操作系统平台，使用不同的路径分隔符拼接路径 os.path.isabs(path) 检查一个路径是不是一个绝对路径 代码演示： 1234567891011121314151617181920212223242526In [19]: os.path.expanduser('~') Out[19]: '/root'In [20]: os.path.expanduser('~oracle') Out[20]: '/home/oracle'In [21]: os.path.expanduser('~accp')Out[21]: '/home/accp'In [22]: os.path.expanduser('~acp') Out[22]: '~acp' # 错误演示In [23]: os.path.abspath('.')Out[23]: '/opt/os_demo'In [24]: os.path.abspath('..')Out[24]: '/opt'In [25]: os.path.join('/opt/os_demo','test.txt')Out[25]: '/opt/os_demo/test.txt'In [26]: os.path.isabs('/opt/os_demo/') Out[26]: TrueIn [27]: os.path.isabs('.') Out[27]: False ¶（3）获取文件属性 os.path方法 说明 os.path.getatime(path) 返回最近访问时间（浮点型秒数） os.path.getmtime(path) 返回最近文件修改时间 os.path.getctime(path) 返回文件 path 创建时间 os.path.getsize(path) 返回文件大小，如果文件不存在就返回错误 代码演示： 1234567891011In [33]: os.path.getatime(path)Out[33]: 1587547270.7306058 # 时间戳In [34]: os.path.getmtime(path)Out[34]: 1587547270.7306058In [35]: os.path.getctime(path)Out[35]: 1587548055.4721448In [36]: os.path.getsize(path)Out[36]: 0 ¶（4）判断文件类型 os.path方法 说明 os.path.isfile(path) 判断路径是否为文件 os.path.isdir(path) 判断路径是否为目录 os.path.islink(path) 判断路径是否为链接 os.path.ismount(path) 判断路径是否为挂载点 代码演示： 1234567891011In [37]: os.path.isfile(path)Out[37]: TrueIn [38]: os.path.isdir(path)Out[38]: FalseIn [39]: os.path.islink(path)Out[39]: FalseIn [40]: os.path.ismount(path)Out[40]: False ¶6、os模块执行shell命令 os.system()的作用： 123执行shell命令返回shell命令的返回值命令的输出会输出到标准输出 代码演示： os.system(‘cls’) ¶案例1：编写自动安装Python的脚本 实现步骤： 123下载Python版本源码安装Python需要的依赖库编译安装Python 伪代码： 123451. 判断用户是不是root2. 如果是，等待用户输入Python版本3. 执行shell命令下载源码包4. 安装依赖开发包5. 编译安装Python 脚本内容如下（基于Python2）： auto_install_python.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# coding=utf-8import os# 判断用户是否是root用户if os.getuid() == 0: passelse: print '当前用户不是root用户！' SystemExit(1)# 安装Python依赖库cmd_module = 'yum -y install wget gcc zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel libffi-devel'res = os.system(cmd_module)if res != 0: print 'Python依赖库安装失败，请重新执行该脚本。' SystemExit(1)else: print 'python依赖库安装成功！'# 输入Python版本，下载Python源码包到本地目录# wget urlversion = raw_input('请输入Python版本：（3.6/3.8）')if version == '3.6': url = 'https://www.python.org/ftp/python/3.6.10/Python-3.6.10.tgz'else: url = 'https://www.python.org/ftp/python/3.8.1/Python-3.8.1.tgz'cmd = 'wget ' + urlres = os.system(cmd)if res != 0: print 'Python源码包下载失败！' SystemExit(1)else: print('======================&gt;&gt;&gt;Python源码包下载成功！')# 解压Python源码包# tar zxvf Python-3.6.10.tgzif version == '3.6': package_name = 'Python-3.6.10'else: package_name = 'Python-3.8.1'res = os.system('tar zxvf ' + package_name + '.tgz')if res != 0: print '解压失败。。。' SystemExit(1)else: print('#########################解压成功！#########################')# 配置语言os.system('export LANG=zh_CN.UTF-8')os.system('export LANGUAGE=zh_CN.UTF-8')# 切换到Python目录os.chdir(package_name)os.system('./configure --prefix=/usr/local/python3')res = os.system('make &amp;&amp; make install')if res !=0: print '源码编译失败。。。' SystemExit(1)else: print('####################Python安装成功，请进行验证！####################')# 修改用户环境变量os.system('echo \"export PYTHON3=/usr/local/python3\" &gt;&gt;~/.bash_profile')os.system('echo \"export PATH=$PYTHON3/bin:$PATH\" &gt;&gt;~/.bash_profile')os.system(\"source ~/.bash_profile\")os.system('cat ~/.bash_profile')print('####################用户环境变量已修改，请进行验证！####################')os.system('python3 --version') ¶7、os.walk函数遍历目录树 os.walk() 方法遍历某个目录及其子目录，对于每一个目录，walk()函数返回一个三元组（dirpath、dirnames、filenames）。其中dirpath保存的是当前目录，dirnames是当前目录下的子目录列表，filenames是当前目录下的文件列表。 12345678910# coding=utf-8import osfor root, dirs, files in os.walk(\".\", topdown=False): for name in files: print(os.path.join(root, name)) for name in dirs: print(os.path.join(root, name)) os.walk() 方法是一个简单易用的文件、目录遍历器，可以帮助我们高效的处理文件、目录方面的事情。 ¶案例2：打印最常用的10条Linux命令 123456789101112import osfrom collections import Countercount &#x3D; Counter()with open(os.path.expanduser(&#39;~&#x2F;.bash_history&#39;)) as f: for line in f: cmd &#x3D; line.strip().split() if cmd: count[cmd[0]] +&#x3D;1print(count.most_common(10)) ¶二、使用ConfigParser类解析配置文件 Python中有ConfigParser类，可以很方便的从配置文件中读取数据（如DB的配置，路径的配置），所以可以自己写一个函数，实现读取config配置。 ¶1、配置文件的格式 12节： [session]参数(键=值) name=value mysql配置文件部分内容如下： 1234567891011[client]port = 3306user = mysqlpassword = mysqlhost = 127.0.0.1[mysqld]basedir = /usrdatadir = /var/lib/mysqltmpdir = /tmpskip-external-locking ¶2、ConfigParser类的使用方法 ¶（1）创建configParser对象 123In [1]: import configparser In [2]: cf = configparser.ConfigParser(allow_no_value=True) ¶（2）读取配置文件内容 12In [3]: cf.read('my.inf')Out[3]: ['my.ini'] ¶（3）获取配置文件信息 12345678sections: 返回一个包含所有章节的列表options：返回一个包含章节下所有选项的列表has_section：判断章节是否存在has_options：判断某个选项是否存在items：以元组的形式返回所有的选项get、getboolean、getint、getfloat：获取选项的值 方法测试： 1234567891011121314151617In [4]: cf.sections()Out[4]: ['client', 'mysqld']In [5]: cf.has_section('client')Out[5]: TrueIn [6]cf.options('client')Out[6]: ['port', 'user', 'password', 'host']In [7]: cf.has_option('client','user')Out[7]: TrueIn [8]: cf.get('client','port')Out[8]: '3306'In [9]: cf.getint('client','port')Out[9]: 3306 ¶（4）修改配置文件 常用方法： 12345remove_section：删除一个章节add_section：添加一个章节remove_option：删除一个选项set：添加一个选项write：将ConfigParser兑现中的数据保存到文件中 方法测试： 123456789101112131415161718192021In [11]: cf.remove_section('client')Out[11]: TrueIn [12]: cf.write(open('my.ini', 'w'))In [13]: cf.add_section('client')In [14]: cf.set('client','port','3306')In [15]: cf.set('client','user','mysql')In [16]: cf.set('client','password','mysql')In [17]: cf.set('client','host','127.0.0.1')In [18]: cf.write(open('my.ini','w'))In [19]: cf.remove_option('client','host')Out[19: TrueIn [20]: cf.write(open('my.ini','w')) ¶三、查找文件 ¶1、使用fnmatch找到特定文件 fnmatch.fnmatch()函数一次只能处理一个文件 12345678910import osimport fnmatchfor item in os.listdir('.'): if os.path.isfile(item): # if fnmatch.fnmatch(item, '*.jpg'): if fnmatch.fnmatch(item, '[a-e]*'): # if fnmatch.fnmatch(item, '[a-g]?.txt'): # if fnmatch.fnmatch(item, '[!a-c]*'): print(item) fnmatch.filter()函数一次可以处理多个文件 123456import osimport fnmatchitems = os.listdir('.')files = fnmatch.filter(items, '[a-c]*')print(files) ¶2、使用glob找到特定文件 标准库glob的作用相当于os.listdir()加上fnmatch。使用glob以后，不需要调用os.listdir()获取文件列表，直接通过模式匹配即可。如下所示： 1234import globfiles = glob.glob('*.jpg')print(files) ¶案例3：找到目录下最大（或最老）的10个文件 ¶四、高级文件处理接口shutil ¶1、复制文件和文件夹 12shutil.copy(file1,file2)shuti.copytree(dir1, dir2) ¶2、文件和文件夹的移动与重命名 12shutil.move(file1, file2)shutil.move(file, dir) ¶3、删除目录 12shutil.rmtree(dir)os.unlink(file) ¶五、文件内容管理 ¶1、目录和文件对比 filecmp模块包含了比较目录和文件的操作。 目录结构如下，其中，a.txt和c.txt内容是一样的，a_copy.txt是a.txt的拷贝。 1234567891011121314├─dir1│ │ a.txt│ │ a_copy.txt│ │ b.txt│ │ c.txt│ └─subdir1│ sa.txt└─dir2 │ a.txt │ b.txt │ c.txt ├─subdir1 │ sb.txt └─subdir2 ¶（1）比较两个文件 使用filecmp模块的cmp函数比较两个文件是否相同，如果文件相同则返回True，否则返回False。 12345678910111213In [1]: import filecmpIn [2]: cd dir1E:\\git-project\\python_project\\cloud33\\Python常用模块\\compare\\dir1In [3]: filecmp.cmp('a.txt','b.txt')Out[3]: FalseIn [4]: filecmp.cmp('a.txt','c.txt')Out[4]: TrueIn [5]: filecmp.cmp('a.txt','a_copy.txt')Out[5]: True ¶（2）比较多个文件 filecmp目录下还有一个名为cmpfiles的函数，该函数用来同时比较两个不同的目录下的多个文件，并且返回一个三元组，分别包含相同的文件、不同的文件和无法比较的文件。示例如下： 12In [6]: filecmp.cmpfiles('dir1','dir2',['a.txt','b.txt','c.txt','a_copy.txt'])Out[6]: (['a.txt', 'b.txt', 'c.txt'], [], ['a_copy.txt']) cmpfiles函数同时用来比较两个目录下的文件，也可以使用该函数比较两个目录。但是，在比较两个目录时，需要通过参数指定可能的文件，因此比较繁琐。 ¶（3）比较目录 filecmp中还有一个名为dircmp的函数，用来比较两个目录。调用dircmp函数以后，会返回一个dircmp类的对象，该对象保存了诸多属性，我们可以通过查看这些属性获取目录之间的差异。如下所示： 123456789101112131415161718192021In [7]: d = filecmp.dircmp('dir1','dir2')In [8]: d.report()diff dir1 dir2Only in dir1 : ['a_copy.txt']Only in dir2 : ['subdir2']Identical files : ['c.txt']Differing files : ['a.txt', 'b.txt']Common subdirectories : ['subdir1']In [9]: d.left_listOut[9]: ['a.txt', 'a_copy.txt', 'b.txt', 'c.txt', 'subdir1']In [10]: d.right_listOut[10]: ['a.txt', 'b.txt', 'c.txt', 'subdir1', 'subdir2']In [11]: d.left_onlyOut[11]: ['a_copy.txt']In [12]: d.right_onlyOut[12]: ['subdir2'] ¶2、MD5校验和比较 校验码是通过散列函数计算而成，是一种从任何数据中创建小的数字“指纹”的方法。散列函数把消息或数据压缩成摘要，使得数据量变小，便于进行比较。MD5是目前使用最广泛的散列算法。 MD5哈希一般用于检查文件的完整性，尤其常用于检查文件传输、磁盘错误或其他情况下文件的正确性。 Linux下计算一个文件的MD5校验码，如下所示： 12[root@192 demo]# md5sum a.txtd41d8cd98f00b204e9800998ecf8427e a.txt 在Python中计算文件的MD5校验码也非常简单，使用标准库hashlib模块即可。如下所示： 123456789101112131415import hashlibd = hashlib.md5()with open('b.txt') as f: for line in f: d.update(line.encode('utf-8'))print(d.hexdigest())# 或者可以这样（最常见的写法，常用于图片的命名）&gt;&gt;&gt; hashlib.md5(b'123').hexdigest()'202cb962ac59075b964b07152d234b70'# 也可以使用hash.new()这个一般方法，hashlib.new(name[, data])，name传入的是哈希加密算法的名称，如md5&gt;&gt;&gt; hashlib.new('md5', b'123').hexdigest()'202cb962ac59075b964b07152d234b70' ¶六、使用Python管理压缩包 ¶1、tarfile ¶（1）读取tar包 123456789import tarfilewith tarfile.open('cmake-3.17.0.tar.gz') as t: for member in t.getmembers(): print(member.name) with tarfile.open('cmake-3.17.0.tar.gz') as t:t.extractall()t.extract('cmake-3.17.0/Help','a') 常用方法说明： 1234getmembers():获取tar包中的文件列表member.name:获取tar包中文件的文件名extract(member, path):提取单个文件extractall(path, memebers):提取所有的文件 ¶（2）创建tar包 1234import tarfilewith tarfile.open('readme.tar', mode='w') as out: out.add('read.txt') ¶（3）读取与创建压缩包 1234567import tarfilewith tarfile.open('tarfile_add.tar',mode='r:gz') as out: passwith tarfile.open('tarfile_add.tar',mode='r:bz2') as out: pass ¶案例4：备份指定文件到压缩包中 123456789101112131415161718192021222324252627import osimport fnmatchimport tarfileimport datetimedef is_file_math(filename, patterns): '''查找特定类型的文件''' for pattern in patterns: if fnmatch.fnmatch(filename, pattern): return True return Falsedef find_files(root, patterns=['*']): for root, dirnames, filenames in os.walk(root): for filename in filenames: if is_file_math(filename, patterns): yield os.path.join(root, filename)patterns = ['*.txt','*.md']now = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')filename = 'backup_all_file_&#123;0&#125;.tar.gz'.format(now)with tarfile.open(filename, 'w') as f: for item in find_files('.', patterns): f.add(item) ¶2、zipfile ¶（1）读取zip文件 123456import zipfiledemo_zip = zipfile.ZipFile('read.zip')print(demo_zip.namelist())demo_zip.extractall('1')demo_zip.extract('a.jpg','2') 常用方法说明： 123namelist():返回zip文件中包含的所有文件和文件夹的字符串列表extract(filename, path)：从zip文件中提取单个文件extractall(path)：从zip文件中提取所有文件 ¶（2）创建zip文件 12345import zipfilenewZip = zipfile.ZipFile('new.zip',mode='w')newZip.write('a.jpg')newZip.close() ¶（3）Python命令行调用zipfile zipfile模块提供的命令行接口包含的选项： 1234-l:显示zip格式压缩包中的文件列表-e:提取zip格式的压缩包-c:创建zip格式的压缩包-t:验证文件是不是一个有效的zip格式压缩包 示例如下所示： 12345678910# 创建zip文件python -m zipfile -c new1.zip archive_tar.py# 查看zip文件列表python -m zipfile -l new1.zipFile Name Modified Sizearchive_tar.py 2020-04-26 16:32:54 239# 提取zip文件到指定目录python -m zipfile -e new1.zip new_dir ¶3、shutil创建和读取压缩包 shutil支持的格式如下： 12345import shutilprint(shutil.get_archive_formats())[('bztar', \"bzip2'ed tar-file\"), ('gztar', \"gzip'ed tar-file\"), ('tar', 'uncompressed tar file'), ('xztar', \"xz'ed tar-file\"), ('zip', 'ZIP file')] ¶（1）创建压缩包 1234# 参数1：生成的压缩包文件名# 参数2：压缩包的格式# 参数3：压缩的目录shutil.make_archive('a.jpg','gztar', 'ddd') ¶（2）解压 123# 参数1：需要解压的压缩包# 参数2：解压的目录print(shutil.unpack_archive('a.jpg.tar.gz','jpg')) ¶七、Python执行外部命令 ¶1、subprocess模块简介 这个模块用来创建和管理子进程。它提供了高层次的接口，用来替换os.system()、os.spawn*()、os.popen*()、os.popen2.*()和commands.*等模块和函数。 subprocess提供了一个名为Popen的类启动和设置子进程的参数，由于这个类比较复杂，subprosess还提供了若干便利的函数，这些函数都是对Popen类的封装。 ¶2、subprocess模块的便利函数 ¶（1）call call函数的定义如下 1subprocess.call(args, *, stdin=None, stdout=None, stderr=None, shell=False) 示例如下： 12345678910111213141516171819In [1]: import subprocess In [2]: subprocess.call(['ls','-l']) 总用量 8-rw-------. 1 root root 2049 8月 11 2019 anaconda-ks.cfg-rw-r--r--. 1 root root 2077 8月 11 2019 initial-setup-ks.cfgdrwxr-xr-x. 2 root root 21 4月 22 16:32 osdrwxr-xr-x. 2 root root 6 8月 11 2019 公共drwxr-xr-x. 2 root root 6 8月 11 2019 模板drwxr-xr-x. 2 root root 6 8月 11 2019 视频drwxr-xr-x. 2 root root 6 8月 11 2019 图片drwxr-xr-x. 2 root root 6 8月 11 2019 文档drwxr-xr-x. 2 root root 6 8月 11 2019 下载drwxr-xr-x. 2 root root 6 8月 11 2019 音乐drwxr-xr-x. 2 root root 6 8月 11 2019 桌面Out[2]: 0 In [3]: subprocess.call('exit 1', shell=True) Out[3]: 1 ¶（2）check_call check_all函数的作用与call函数类似，区别在于异常情况下返回的形式不同。 对于call函数，工程师通过捕获call命令的返回值判断命令是否执行成功，如果成功则返回0，否则的话返回非0。对于check_call函数，如果执行成功，返回0，如果执行失败，抛出subprocess.CallProseccError异常，示例如下所示： 123456789101112131415161718192021222324252627282930In [6]: subprocess.check_call(['ls','-l']) 总用量 8-rw-------. 1 root root 2049 8月 11 2019 anaconda-ks.cfg-rw-r--r--. 1 root root 2077 8月 11 2019 initial-setup-ks.cfgdrwxr-xr-x. 2 root root 21 4月 22 16:32 osdrwxr-xr-x. 2 root root 6 8月 11 2019 公共drwxr-xr-x. 2 root root 6 8月 11 2019 模板drwxr-xr-x. 2 root root 6 8月 11 2019 视频drwxr-xr-x. 2 root root 6 8月 11 2019 图片drwxr-xr-x. 2 root root 6 8月 11 2019 文档drwxr-xr-x. 2 root root 6 8月 11 2019 下载drwxr-xr-x. 2 root root 6 8月 11 2019 音乐drwxr-xr-x. 2 root root 6 8月 11 2019 桌面Out[6]: 0In [7]: subprocess.check_call('lsljdl', shell=True) /bin/sh: lsljdl: 未找到命令---------------------------------------------------------------------------CalledProcessError Traceback (most recent call last)&lt;ipython-input-7-885ea94380a9&gt; in &lt;module&gt;----&gt; 1 subprocess.check_call('lsljdl', shell=True)/usr/local/python3/lib/python3.8/subprocess.py in check_call(*popenargs, **kwargs) 362 if cmd is None: 363 cmd = popenargs[0]--&gt; 364 raise CalledProcessError(retcode, cmd) 365 return 0 366 CalledProcessError: Command 'lsljdl' returned non-zero exit status 127. ¶（3）check_output 1234567891011121314151617181920212223242526272829303132333435363738394041In [8]: output = subprocess.check_output(['df','-h']) In [9]: print(output.decode()) 文件系统 容量 已用 可用 已用% 挂载点/dev/mapper/cl-root 37G 5.1G 32G 14% /devtmpfs 897M 0 897M 0% /devtmpfs 912M 84K 912M 1% /dev/shmtmpfs 912M 9.0M 903M 1% /runtmpfs 912M 0 912M 0% /sys/fs/cgroup/dev/sda1 1014M 173M 842M 18% /boottmpfs 183M 16K 183M 1% /run/user/42tmpfs 183M 0 183M 0% /run/user/0 In [10]: lines = output.decode().split('\\n') In [11]: lines Out[11]: ['文件系统 容量 已用 可用 已用% 挂载点', '/dev/mapper/cl-root 37G 5.1G 32G 14% /', 'devtmpfs 897M 0 897M 0% /dev', 'tmpfs 912M 84K 912M 1% /dev/shm', 'tmpfs 912M 9.0M 903M 1% /run', 'tmpfs 912M 0 912M 0% /sys/fs/cgroup', '/dev/sda1 1014M 173M 842M 18% /boot', 'tmpfs 183M 16K 183M 1% /run/user/42', 'tmpfs 183M 0 183M 0% /run/user/0', '']In [12]: for line in lines[1:-1]: ...: if line: ...: print(line.split()[-2]) ...: t14%0%1%1%0%18%1%0% ¶3、subprocess模块的Popen类 1234567891011121314151617# coding=utf-8import subprocessdef execute_cmd(cmd): p = subprocess.Popen(cmd, shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE) stdout, stderr = p.communicate() if p.returncode != 0: return p.returncode, stderr return p.returncode, stdoutexecute_cmd('ls') ¶八、综合案例：使用Python部署MongoDB 看一个综合案例，使用Python不俗MongoDB数据库。在这个例子中，将会用到各种与系统管理相关的标准库，包括os、os.path、shutil、tarfile和subprocess模块。 假设当前目录下存在一个MongoDB安装包，我们的Python程序需要将他解压到当前目录的mongo目录下，并且当前目录创建一个mongodata目录用老保存MongoDB的数据库文件。 在部署MongoDB数据库之前，当前目录下的文件结构如下： 123.├── auto_install_mongodb.py└── ./mongodb-linux-x86_64-rhel70-4.2.3.tgz 程序部署完成后，当前目录的文件结构大致如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748.├── ./auto_install_mongodb.py├── ./mongo│ ├── ./mongo/bin│ │ ├── ./mongo/bin/bsondump│ │ ├── ./mongo/bin/install_compass│ │ ├── ./mongo/bin/mongo│ │ ├── ./mongo/bin/mongod│ │ ├── ./mongo/bin/mongodump│ │ ├── ./mongo/bin/mongoexport│ │ ├── ./mongo/bin/mongofiles│ │ ├── ./mongo/bin/mongoimport│ │ ├── ./mongo/bin/mongoreplay│ │ ├── ./mongo/bin/mongorestore│ │ ├── ./mongo/bin/mongos│ │ ├── ./mongo/bin/mongostat│ │ └── ./mongo/bin/mongotop│ ├── ./mongo/LICENSE-Community.txt│ ├── ./mongo/MPL-2│ ├── ./mongo/README│ ├── ./mongo/THIRD-PARTY-NOTICES│ └── ./mongo/THIRD-PARTY-NOTICES.gotools├── ./mongodata│ ├── ./mongodata/collection-0-4813754152483353608.wt│ ├── ./mongodata/collection-2-4813754152483353608.wt│ ├── ./mongodata/collection-4-4813754152483353608.wt│ ├── ./mongodata/diagnostic.data│ │ ├── ./mongodata/diagnostic.data/metrics.2020-04-27T10-17-57Z-00000│ │ └── ./mongodata/diagnostic.data/metrics.interim│ ├── ./mongodata/index-1-4813754152483353608.wt│ ├── ./mongodata/index-3-4813754152483353608.wt│ ├── ./mongodata/index-5-4813754152483353608.wt│ ├── ./mongodata/index-6-4813754152483353608.wt│ ├── ./mongodata/journal│ │ ├── ./mongodata/journal/WiredTigerLog.0000000001│ │ ├── ./mongodata/journal/WiredTigerPreplog.0000000001│ │ └── ./mongodata/journal/WiredTigerPreplog.0000000002│ ├── ./mongodata/_mdb_catalog.wt│ ├── ./mongodata/mongod.lock│ ├── ./mongodata/mongod.log│ ├── ./mongodata/sizeStorer.wt│ ├── ./mongodata/storage.bson│ ├── ./mongodata/WiredTiger│ ├── ./mongodata/WiredTigerLAS.wt│ ├── ./mongodata/WiredTiger.lock│ ├── ./mongodata/WiredTiger.turtle│ └── ./mongodata/WiredTiger.wt└── ./mongodb-linux-x86_64-rhel70-4.2.3.tgz MongoDB下载地址如下： 1wget https://fastdl.mongodb.org/linux/mongodb-linux-s390x-rhel72-4.3.3.tgz MongoDB是当下最流行的文档数据库，具有很好的易用性。启动一个MongoDB数据库实例，只需要执行一下几条shell命令即可： 1234tar -zxf mongodb-linux-x86_64-rhel70-4.2.3.tgzmv mongodb-linux-x86_64-rhel70-4.2.3 mongomkdir mongodatamongo/bin/mongod --fork --logpath mongodata/mongod.log --dbpath mongodata 这里给出的shell命令，只是为了便于不熟悉MongoDB的人了解MongoDB数据库的启动过程，还有很多的情况没有考虑。例如，要将当前目录下的MongoDB安装包解压到当前目录下的mongo目录中，但是当前目录下已经存在一个名为mongo的目录，则会报错 下面的程序时使用Python部署MongoDB数据库的完整代码，这段程序综合应用了很多与系统管理相关的模块。如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# coding=utf-8import subprocessimport osimport shutilimport tarfiledef execute_cmd(cmd): '''执行shell命令''' p = subprocess.Popen(cmd, shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE) stdout, stderr = p.communicate() if p.returncode != 0: return p.returncode, stderr return p.returncode, stdoutdef unpackage_mongo(package, package_dir): unpackage_dir = os.path.splitext(package)[0] if os.path.exists(unpackage_dir): shutil.rmtree(unpackage_dir) if os.path.exists(package_dir): shutil.rmtree(package_dir) # 解压 t = tarfile.open(package, 'r:gz') t.extractall('.') print('tar is ok.') # 重命名mongodb-linux-x86_64-rhel70-4.2.3为mongo shutil.move(unpackage_dir, 'mongo')def create_datadir(data_dir): if os.path.exists(data_dir): shutil.rmtree(data_dir) os.mkdir(data_dir)def format_mongod_commamd(package_dir, data_dir, logfile): mongod = os.path.join(package_dir, 'bin', 'mongod') mongod_format = \"\"\"&#123;0&#125; --fork --dbpath &#123;1&#125; --logpath &#123;2&#125;\"\"\" return mongod_format.format(mongod, data_dir, logfile)def start_mongod(cmd): returncode, out = execute_cmd(cmd) if returncode != 0: raise SystemExit('execute &#123;0&#125; error:&#123;1&#125;'.format(cmd, out.decode())) else: print('execute &#123;0&#125; sucessfully.'.format(cmd))def main(): package = 'mongodb-linux-x86_64-rhel70-4.2.3.tgz' cur_dir = os.path.abspath('.') package_dir = os.path.join(cur_dir, 'mongo') data_dir = os.path.join(cur_dir, 'mongodata') logfile = os.path.join(data_dir, 'mongod.log') if not os.path.exists(package): raise SystemExit('&#123;0&#125; not found.'.format(package)) unpackage_mongo(package, package_dir) create_datadir(data_dir) start_mongod(format_mongod_commamd(package_dir, data_dir, logfile))main() 代码说明： 123456789在这段过程中，我们首先在main函数中定义了几个变量，包括当前目录的路径，MongoDB二进制文件所在的路径、MongoDB数据目录所在的路径，以及MongoDB的日志问紧啊随后，我们判断MongoDB的安装包是否存在，如果不存在，则通过抛出SystemExit异常的方式结束程序在unpackage_mongo函数中，我们通过Python程序得到MongoDB安装包解压以后的目录。如果目录已经存在，则删除该目录。随后，我们使用tarfile解压MongoDB数据库，解压完成后，将命令重命名为mongo目录在create_datadir目录红，我们首先判断MongoDB数据库目录是否存在，如果存在，则删除该目录，随后在创建MongoDB数据库目录在start_mongod函数中，我们执行MongoDB数据库的启动命令启动MongoDB数据库。为了在Python代码中执行shell命令，我们使用了subprocess库，我们将subprocess库执行shell命令的瑞吉封装成execute_cmd函数，在执行shell命令时，直接调用该函数即可","categories":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/tags/Python/"}]},{"title":"Python生态工具","slug":"Python生态工具","date":"2020-04-26T16:00:00.000Z","updated":"2020-04-27T14:45:09.576Z","comments":true,"path":"Python生态工具.html","link":"","permalink":"https://pdxblog.top/Python%E7%94%9F%E6%80%81%E5%B7%A5%E5%85%B7.html","excerpt":"","text":"¶Python生态工具 ¶一、Python内置小工具 ¶1.1、 1秒钟启动一个下载服务器 在实际工作中，时常会有这样的一个需求：将文件传给其他同事。将文件传给同事本身并不是一个很繁 琐的工作，现在的聊天工具一般都支持文件传输。但是，如果需要传送的文件较多，操作起来就会比较 麻烦。此外，如果文件在远程的服务器上，则需要先将远程服务器的文件下载到本地，然后再通过聊天 工具传给同事。再或者，你并不是特别清楚要传哪几个文件给同事，所以，你们需要进行交流，而交流 的时间成本是比较高的，会降低办事效率。 此时，如果你知道Python内置了一个下载服务器就能够显著提升效率了。例如，你的同事要让你传的文 件位于某一个目录下，那么，你可以进入这个目录，然后执行下面的命令启动一个下载服务器： 1python -m SimpleHTTPServer 在Python 3中，由于对系统库进行了重新整理，因此，使用方式会有不同： 1python -m http.server 执行上面的命令就会在当前目录下启动一个文件下载服务器，默认打开8000端口。完成以后，只需要将 IP和端口告诉同事，让同事自己去操作即可，非常方便高效。 使用浏览器访问Python启动的下载服务器，可以看到一个类似于FTP下载的界面，这个时候单击文件下 载即可。通过这种方式传输文件，可以降低大家的沟通成本，提高文件传输的效率。 上面使用的Python语句，从工作原理来说，仅仅是启动了一个Python内置的Web服务器。如果当前目 录下存在一个名为index.html的文件，则默认显示该文件的内容。如果当前目录下不存在这样一个文 件，则默认显示当前目录下的文件列表，也就是大家看到的下载服务器。 ¶1.2、字符串转换为JSON JSON是一种轻量级的数据交换格式，易于人类阅读和编写，同时也易于机器解析和生成。由于JSON的 诸多优点，已被广泛使用在各个系统中。JSON使用越广泛，需要将JSON字符串转换为JSON对象的需求 就越频繁。 例如，在工作过程中，我们的系统会调用底层服务的API。底层服务的API一般都是以JSON的格式返 回，为了便于问题追踪，我们会将API返回的JSON转换为字符串记录到日志文件中。当需要分析问题 时，就需要将日志文件中的JSON字符串拿出来进行分析。这个时候，需要将一个JSON字符串转换为 JSON对象，以提高日志的可读性。 这个需求十分常见，以至于使用搜索引擎搜索&quot;JSON&quot;，处于搜索结果的第一项便是“在线JSON格式化工 具”。除了打开浏览器，使用在线JSON格式化工具以外，我们也可以使用命令行终端的Python解释器来 解析JSON串，如下所示 123456789[root@oracle ~]# echo '&#123;\"address\": &#123;\"province\": \"zhejiang\", \"city\": \"hangzhou\"&#125;, \"name\": \"lmx\", \"sex\": \"male\"&#125;' | python -m json.tool &#123; \"address\": \"city\": \"hangzhou\", \"province\": \"zhejiang &#125;, \"name\": \"lmx\" \"sex\": \"male\"&#125; 使用命令行解释器解析JSON串非常方便，而且，为了便于阅读，该工具还会自动将转换的结果进行对 齐和格式化。如下所示： 12345678910[root@oracle ~]# echo '&#123;\"address\": &#123;\"province\": \"zhejiang\", \"city\":\"hangzhou\"&#125;, \"name\": \"lmx\", \"sex\": \"male\"&#125;' | python -m json.tool&#123; \"address\": &#123; \"city\": \"hangzhou\", \"province\": \"zhejiang\" &#125;, \"name\": \"lmx\", \"sex\": \"male\"&#125; ¶1.3、检查第三方库是否正常安装 安装完Python的第三方库以后，如何确认这个库已经正确安装了呢？答案很简单，只需要尝试进行 import导入即可。如果导入没有任何错误，则认为安装成功；如果导入失败，则认为安装失败。 12345[root@oracle ~]# pythonPython 2.7.5 (default, Oct 30 2018, 23:45:53)[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux2Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; 验证Python的第三方库是否安装成功，本身也是一件很简单的事情，但是，如果我们使用脚本对大批量 的服务器进行自动部署，又应该如何验证第三方库安装成功了呢？肯定不能登录每一台服务器进行验 证。这个时候，我们可以使用Python解释器的-c参数快速地执行import语句，如下所示： 1234[root@oracle ~]# python -c \"import paramiko\"Traceback (most recent call last):File \"&lt;string&gt;\", line 1, in &lt;module&gt;ImportError: No module named paramiko ¶二、pip高级用法 为了便于用户安装和管理第三方库和软件，越来越多的编程语言拥有自己的包管理工具，如nodejs的 npm，ruby的gem。Python也不例外，现在Python生态主流的包管理工具是pip ¶2.1、pip介绍 pip是一个用来安装和管理Python包的工具，是easy_install的替代品，如果读者使用的是Python 2.7.9+或Python 3.4+版本的Python，则已经内置了pip，无须安装直接使用即可。如果系统中没有安装 pip，也可以手动安装 ¶2.2、python3安装pip 方法1：python33安装完成后默认已经带有pip3 12345[root@oracle bin]# pip3 -Vpip 19.2.3 from /usr/local/python38/lib/python3.8/site-packages/pip (python3.8)[root@oracle bin]# pwd/usr/local/python38/bin 你可以用以下命令,创建软链接 1ln -s /usr/local/python38/bin/pip3 /usr/bin/pip3 方法2：使用以下方法重新安装pip插件 下载get-pip.py脚本 1wget https://bootstrap.pypa.io/3.2/get-pip.py 运行脚本 1python3 get-pip.py python3创建pip3索引 1ln -s /usr/python3.6.1/bin/pip /usr/bin/pip3 测试是否安装成功 1pip3 install requests pip之所以能够成为最流行的包管理工具，并不是因为它被Python官方作为默认的包管理器，而是因为 它自身的诸多优点。pip的优点有： 123456pip提供了丰富的功能，其竞争对手easy_install则只支持安装，没有提供卸载和显示已安装列表的功能；pip能够很好地支持虚拟环境；pip可以通过requirements.txt集中管理依赖；pip能够处理二进制格式(.whl)；pip是先下载后安装，如果安装失败，也会清理干净，不会留下一个中间状态。 如果用户没有将软件打包上传到pypi.python.org，则无法使用pip进行安装。对于这种情况，Python生 态也有标准的做法，例如，我们尝试从源码安装paramiko。需要注意的是，我们也可以通过pip安装 paramiko的，这里只是为了演示Python生态中源码安装： 123$ git clone https://github.com/paramiko/paramiko.git$ cd paramiko$ python setup.py install ¶2.3、给pip3重命名 切换至家目录，通过.bashrc添加别名 1234567[root@oracle bin]# cd ~[root@localhost ~]# vim .bashrcalias pip=pip3[root@localhost ~]# source .bashrc[root@localhost ~]# pip -Vpip 19.2.3 from /usr/local/python38/lib/python3.8/site-packages/pip (python3.8) ¶2.4、pip3常用命令 子命令 解释说明 install 安装软件包 download 下载软件包 uninstall 卸载安装包 freeze 按照requirements格式输出安装包，可以到其他服务器上执行pip install -r requirements.txt直接安装软件 list 列出当前系统中的安装包 show 查看安装包的信息，包括版本、依赖、许可证、作者、主页等信息 check 检查安装包依赖是否完整 search 查找安装包 wheel 打包软件到wheel格式 hash 计算安装包的hash值 completion 生成命令补全配置 help 获取pip和子命令的帮助信息 ¶2.5、加速pip安装的技巧 如果大家使用Python的时间比较长的话，会发现Python安装的一个问题，即pypi.python.org不是特别 稳定，有时候会很慢，甚至处于完全不可用的状态。这个问题有什么好办法可以解决呢？根据笔者的经 验，至少有两种不同的方法。 ¶1、使用豆瓣或阿里云的源加速软件安装 访问pypi.python.org不稳定的主要原因是因为网络不稳定，如果我们从网络稳定的服务器下载安装 包，问题就迎刃而解了。我们国内目前有多个pypi镜像，推荐使用豆瓣的镜像源或阿里的镜像源。如果 要使用第三方的源，只需要在安装时，通过pip命令的-i选项指定镜像源即可。如下所示： 1pip install -i https://pypi.douban.com/simple/ flask 每次都要指定镜像源的地址比较麻烦，我们也可以修改pip的配置文件，将镜像源写入配置文件中。对 于Linux系统来说，需要创建～/.pip/pip.conf文件，然后在文件中保存如下内容： 123456[root@localhost ~]# mkdir .pip[root@localhost ~]# cd .pip[root@localhost .pip]# touch pip.conf[root@localhost .pip]# vim pip.conf[global]index-url = https://pypi.douban.com/simple/ ¶2、将软件下载到本地部署 如果需要对大批量的服务器安装软件包，并且安装包比较多或者比较大，则可以考虑将软件包下载到本 地，然后从本地安装。这对于使用脚本部署大量的服务器非常有用，此外，对于服务器无法连接外网的 情况，也可以使用这种方法。如下所示： 12345# 下载到本地pip install --download='pwd' -r requirements.txt# 本地安装pip install --no-index -f file://'pwd' -r requirements.txt 使用这种方式，只需要下载一次，就可以多处安装，不用担心网络不稳定的问题。并且，pip能够自动 处理软件依赖问题。例如，我们通过这种方式下载Flask到当前目录下，则Flask的依赖click、 itsdangerous、Jinja2、MarkupSafe和Werkzeug也会被下载到本地，如下所示： 123456pip install --download='pwd' flask$ lsclick-6.7-py2.py3-none-any.whl itsdangerous-0.24.tar.gzMarkupSafe-0.23.tar.gz Flask-0.12-py2.py3-none-any.whlJinja2-2.9.5-py2.py3-none-any.whl Werkzeug-0.11.15-py2.py3-none-any.whl ¶三、Python变成辅助工具 因为Python是一门动态类型语言，所以，Python程序不需要编译和链接就可以直接运行。Python程序 运行时是从上至下逐行执行，因此Python工程师可以进行交互式的编程，从而快速验证代码的运行结果 是否符合预期。同时，Python工程师也可以通过交互式编程的方式学习Python编程。也正是因为 Python交互式编程的诸多优点，所以，Python交互式编程使用非常广泛。 ¶3.1、Python交互式编程 要使用Python的交互式编程，最简单的方式是使用标准的Python Shell。在命令行直接输入python命 令便可进入Python Shell，如下所示： 12345678[root@localhost ~]# pythonPython 3.8.1 (default, Jan 14 2020, 12:20:36)[GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] on linuxType \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; a=3&gt;&gt;&gt; b=4&gt;&gt;&gt; a+b7 虽然标准的Python Shell也支持交互式编程，但是，它有很多不足，包括： 123456没有语法高亮；不支持Tab自动补全；没有自动缩进功能；不能保存历史记录；不能很好地与操作系统交互；无法导入外部文件中的程序。 虽然Python自带的交互式编程满足了功能性需求，但是在易用性上仍有诸多不足。IPython是增强型的 Python Shell，不但解决了上面提到的各种问题，而且提供了非常丰富的组件，可以方便地进行交互式 编程和数据分析。IPython功能丰富，不可避免地导致软件变得庞大复杂，因此，IPython 4.0对 IPython进行了拆分，分离成IPython Shell和jupyter两个组件，这两个组件现在需要分别安装。 按照行业惯例，IPython代指IPython Shell，是一个类似于Python Shell的交互式解释器；jupyter代指 IPython Notebook，是一个带图形界面的应用程序。接下来我们分别介绍IPython和jupyter的使用。 ¶3.2、使用IPython交互编程 IPython是一个第三方工具，因此，在使用之前需要先安装。可以直接使用操作系统的包管理工具或pip 进行安装。以下是在centos7上的安装方式： 1234567891011121314151617[root@localhost ~]# pip install ipythonLooking in indexes: https://pypi.douban.com/simple/Collecting ipython Downloadinghttps://pypi.doubanio.com/packages/1c/f3/c8be38ee117d02508bb8b9158eb41ca416f442a6e8e3b3159c2f2d14ed79/ipython-7.11.1-py3-none-any.whl (777kB) |████████████████████████████████| 778kB 934kB/s……省略部分输出信息Installing collected packages: six, ipython-genutils, decorator, traitlets,ptyprocess, pexpect, pickleshare, wcwidth, prompt-toolkit, pygments,backcall, parso, jedi, ipython Running setup.py install for backcall ... doneSuccessfully installed backcall-0.1.0 decorator-4.4.1 ipython-7.11.1ipython-genutils-0.2.0 jedi-0.15.2 parso-0.5.2 pexpect-4.7.0 pickleshare0.7.5 prompt-toolkit-3.0.2 ptyprocess-0.6.0 pygments-2.5.2 six-1.13.0traitlets-4.3.3 wcwidth-0.1.8 安装完成以后，在命令行终端输入ipython就进入了IPython交互式编程界面： 12345678910111213141516171819[root@localhost ~]# ipythonPython 3.8.1 (default, Jan 14 2020, 12:20:36)Type 'copyright', 'credits' or 'license' for more informationIPython 7.11.1 -- An enhanced Interactive Python. Type '?' for help.In [1]: sum=0In [2]: for i in range(5): ...: sum+=i ...: print(sum)10In [3]: import osIn [4]: os.getlogin()Out[4]: 'root'In [5]: 与标准的Python Shell一样，IPython的行显示了所使用的Python解释器版本以及当前的时间。第二行 是获取版权信息的方式，接着给出了IPython的版本。后是简短的使用说明，包括特征介绍、简短的 使用手册和如何获取帮助信息。表2-2给出了IPython提供的使用说明。 接下来我们将从五个不同的维度介绍IPython的使用，分别是： ①更好的编辑器； ②更方便地获取帮助信息； ③IPython提供的magic函数； ④IPython的保存历史功能； ⑤IPython与操作系统交 ¶（1）更好的编辑器 IPython非常强大，有各种高级功能。其中，有用也直观的便是作为交互式编程工具的编辑器功 能。简单来说，IPython相对于标准的Python Shell是一个更好的交互式编程的编辑器，因为它具有： 123456语法高亮； 自动缩进； Tab补全； 快速获取帮助信息； 搜索历史； 执行shell命令 如果只是描述IPython的特征，相信读者并没有完全的概念。这个时候可以坐在计算机旁，打开IPython 随便敲几行Python代码和标准的Python Shell进行比较，就能够直观感受到IPython的优点。 IPython与标准Python Shell的大区别在于，IPython会对命令提示符的每一行进行编号，编号以后能 够提高交互式编程的可读性。更重要的是，我们可以通过IPython提供的特殊函数对编号以后的代码进 行操作。此外，IPython支持语法高亮和自动缩进，相对于标准的Python Shell，是一个更好的编辑 器。如果在编写代码的过错中出现了错误需要删除时，标准的Python Shell无法进行很好的处理，只能 重新进行输入，而IPython则不存在这样的问题。 tab补全是一个特别有用的功能，IPython支持tab补全，而标准的Python Shell不支持。大家可以想象 一下，一个工程师近正在学习Python，他知道一个库里面有他想要的函数，但是，他并不能非常准确 地说出这个函数的名称。这个时候，如果没有tab补全，就只能一边打开Python官方的参考手册，一边 学习编程。有了tab补全以后，即使他对函数名称不是特别熟悉也没有关系，可以先通过tab补全列出当 前命名空间下的函数列表，然后根据函数名称选择自己需要的函数。IPython的补全功能非常强大，不 但可以补全用户的变量名、标准库的函数，在导入包时也可以进行补全。 这一小节，我们一直在强调IPython比标准的Python Shell更好用，拥有更多高级功能。如果读者接触 Python的时间不长，也许不能理解为什么需要使用交互式编程。交互式编程在当前会话退出以后就结束 了，并不满足计算机程序一次编写多次运行的特点。但是，在我们的日常工作中还是会经常用到交互式编程。 交互式编程不但可以快速验证代码执行结果，还可以帮助我们学习Python编程。Python工程师在编写 代码时，通常会使用编辑器和Python Shell组合的方式来完成程序的编写，例如，将代码从编辑器复制 到Python Shell以验证代码的正确性，然后将验证过的代码从Python Shell复制到编辑器中。 ¶（2）使用IPython来解析MySQL的备份日志 为了便于读者理解交互式编程的好处，我们这里演示一个使用Python交互式编程的例子。在这个例子 中，我们使用IPython来解析MySQL的备份日志。 一个典型的MySQL物理备份日志如下所示： 123456789101112131415170221 01:07:48 Executing UNLOCK TABLES170221 01:07:48 All tables unlockedStarting slave SQL thread170221 01:07:48 [00] Streaming ib_buffer_pool to &lt;STDOUT&gt;170221 01:07:48 [00] ...done170221 01:07:48 Backup created in directory '/home/lmx/log/backup'MySQL binlog position: filename 'mysql-bin.000003', position '507946128',GTID of the last change '5a81ea97-daf1-11e6-94c1-fa163ee35df3:1-3409440'MySQL slave binlog position: master host '10.173.33.35', filename 'mysqlbin.000002', position '524993060'170221 01:07:48 [00] Streaming backup-my.cnf170221 01:07:48 [00] ...done170221 01:07:48 [00] Streaming xtrabackup_info170221 01:07:48 [00] ...donextrabackup: Transaction log of lsn (3387315364) to (3451223966) was copied.170221 01:07:48 completed OK! 即使读者对MySQL不了解也没有关系，我们现在的需求是解析下面这一行日志，并获取日志中的host、 filename和position的值。虽然在日志中position的值包含在一对单引号内，但是，我们希望解析以后 position的值是一个整数。 1MySQL slave binlog position: master host '10.173.33.35', filename 'mysqlbin.000002', position '524993060' 在这个例子中，主要就是对字符串进行处理，并提取相应的值。这个问题当然不难，但是，如果不借助 交互式编程工具，需要工程师一次在代码中编写正确也不简单。如果工程师不知道交互式编程工具，就 只能在编辑器里面编写代码，然后运行。如果有错误再修改，直到获取正确的取值，整个过程将会非常 耗时。如果项目庞大，调试起来也会比较困难。这个时候就可以借助Python的交互式编程工具，先验证 代码的正确性，然后将验证过的代码从交互式编程工具复制到编辑器中。如下所示： 12345678910111213141516171819202122232425[root@localhost ~]# ipythonPython 3.8.1 (default, Jan 14 2020, 12:20:36)Type 'copyright', 'credits' or 'license' for more informationIPython 7.11.1 -- An enhanced Interactive Python. Type '?' for help.In [1]: line=\"MySQL slave binlog position: master host '10.173.33.35',filename 'mysql-bin.000002', position '524993060'\"In [2]: line.split(\"'\")Out[2]:['MySQL slave binlog position: master host ','10.173.33.35',', filename ','mysql-bin.000002',', position ','524993060','']In [3]: host=line.split(\"'\")[1]In [4]: filename=line.split(\"'\")[3]In [5]: position=line.split(\"'\")[5]In [6]: print(host,filename,position)10.173.33.35 mysql-bin.000002 524993060In [7]: type(position)Out[7]: strIn [8]: position=int(position)In [9]: print(host,filename,position)10.173.33.35 mysql-bin.000002 524993060 为了节省文章篇幅，我们没有进行错误的尝试，而是直接通过单引号来分解字符串。由于我们使用了交 互式编程，可以很方便地看到字符串分解以后的中间结果。正是有了这个中间结果，我们才知道，字符 串分解成列表以后，下标1对应的字符串是host的值，下标3对应的字符串是filename的值，下标5对应 的字符串是position的值。我们还可以通过交互式编程发现position是一个字符串。由于我们要求 position是一个整数，因此，需要在代码中将position强制转换为一个整数。 如果读者自己尝试从这一行字符串中获取有效的值，很可能一开始会尝试使用逗号或空格来分解字符 串。这两种方法都无法一次取出host、filename和position的值。如下所示： 12345678910111213141516171819In [10]: line.split(',')Out[10]:[\"MySQL slave binlog position: master host '10.173.33.35'\",\" filename 'mysql-bin.000002'\",\" position '524993060'\"]In [11]: line.split(' ')Out[11]:['MySQL','slave','binlog','position:','master','host',\"'10.173.33.35',\",'filename',\"'mysql-bin.000002',\",'position',\"'524993060'\"] 使用交互式编程，我们可以快速尝试不同的方案，先验证自己的想法是否正确，然后将代码拷贝到编辑 器中，组成我们的Python程序文件。通过这种方式，能够有效降低代码出错的概率，减少调试的时间， 从而提高工作效率。 ¶（3）更好地获取帮助信息 Python工程师不但可以通过交互式编程快速验证代码执行结果，还可以通过交互式编程的方式学习 Python编程。之所以说Python工程师可以通过交互式编程学习编程，是因为使用IPython能够方便地获 取到相应的帮助信息。如命名空间下的每个对象以及其定义和使用说明。虽然标准的Python Shell也可 以通过help函数获取到对象的帮助信息，但是，IPython提供了更加灵活的方式获取命名空间下的对象 列表，以及更加全面的帮助信息。 我们知道，在标准库的os模块下的path子模块中有很多操作文件、目录和路径的函数，也有很多 以&quot;is&quot;开始的判断类函数。这些判断类函数的作用非常明确，用以判断给定的对象是否为一个文件或一 个目录。我们可以使用通配符的方式获取该模块下的所有判断类函数，如下所示： 1234567In [10]: import osIn [11]: ?os.path.is*os.path.isabsos.path.isdiros.path.isfileos.path.islinkos.path.ismount 获取当前命名空间下的所有对象，除了使用通配符的方式以外，也可以使用前面介绍的tab补全方式。 tab补全的方式更加实用一些，就如同IPython提供的获取帮助信息的方式比标准的Python Shell获取帮 助信息更实用一样。在IPython中，可以通过标准的help函数获取对象的帮助信息，也可以使用“？”和 “？？”获取对象的帮助信息，如下所示： 123456789101112131415161718192021222324252627282930313233In [12]: import jsonIn [13]: import osIn [14]: os.path.isfile?Signature: os.path.isfile(path)Docstring: Test whether a path is a regular fileFile: ~/.pyenv/versions/3.8.1/lib/python3.8/genericpath.pyType: functionIn [15]: json.dump?Signature:json.dump(obj,fp,*,skipkeys=False,ensure_ascii=True,check_circular=True,allow_nan=True,cls=None,indent=None,separators=None,default=None,sort_keys=False,**kw,)Docstring:Serialize ``obj`` as a JSON formatted stream to ``fp`` (a``.write()``-supporting file-like object).If ``skipkeys`` is true then ``dict`` keys that are not basic types(``str``, ``int``, ``float``, ``bool``, ``None``) will be skippedinstead of raising a ``TypeError``. 当我们输入对象名称，再输入一个问号以后按回车键，就会显示相应的帮助信息。如果帮助信息比较 长，则会以分页的方式显示帮助信息。如果因为帮助信息太多而进入了分页页面，可以通过“q”键退出， 退出以后可以继续进行编程。 例如，json这个标准库下有一个dump函数和一个dumps函数，Python初学者总是容易混淆。这个时 候，如果能够充分利用IPython，就可以方便地获取到帮助信息，使用时不容易犯错。下面就是一个典 型的Python工程师使用json模块的方式，先构造了一个字典，希望将字典转换成json字符串。因为不知 道应该使用json.dump函数还是json.dumps函数，所以，在交互式编程中通过“json.dump?”语句获取dump函数的帮助信息。获取完json.dump函数的帮助信息以后，按“q”键退出，退出以后继续进行编 程。如下所示： 12345In [18]: import jsonIn [19]: d=dict(a=1,b=2,c=3)In [20]: json.dump?In [21]: json.dumps(d)Out[21]: '&#123;\"a\": 1, \"b\": 2, \"c\": 3&#125;' 在IPython中，除了使用一个问号获取帮助信息以外，也可以使用两个问号获取帮助信息。两个问号获 取到的帮助信息更加全面，甚至会包含函数的实现源码。 除了使用问号的方式获取对象的帮助信息以外，IPython还提供了另外一种方式获取对象的信息，可以 分别获取对象的定义、文档和文件等。如下所示： 12345678910111213141516171819202122In [22]: import jsonIn [23]: %pdef jsonObject is not callable.In [24]: %pdef json.dumpjson.dump(obj,fp,*,skipkeys=False,ensure_ascii=True,check_circular=True,allow_nan=True,cls=None,indent=None,separators=None,default=None,sort_keys=False,**kw,)In [25]: %pfile json.dumpIn [26]: %pdoc json.dumpIn [27]: %pinfo json ¶（4）magic函数 IPython提供了很多功能强大的函数，如前面已经提到的%pfile、%pdoc、%pinfo等。为了区分 IPython提供的函数和用户的输入，所有IPython提供的函数都以“%”开头。以“%”开头的这类功能强大的 函数，在IPython中称为magic函数。magic函数主要是为IPython提供增强的功能、与操作系统交互、 操纵用户的输入和输出以及对IPython进行配置。 IPython会将任何第一个字母为“%”的行，视为对magic函数的特殊调用。因此，所有的magic函数都是 以“%”开头。在IPython中，有两种不同的方法可以获取magic函数列表，分别是通过“%”获取所有的 magic函数和通过“%lsmagic”获取所有的magic函数。 下面是一个用lsmagic函数获取magic函数列表的例子： 1234567891011121314151617181920212223In [28]: %lsmagicOut[28]:Available line magics:%alias %alias_magic %autoawait %autocall %autoindent %automagic%bookmark %cat %cd %clear %colors %conda %config %cp %cpaste%debug %dhist %dirs %doctest_mode %ed %edit %env %gui %hist%history %killbgscripts %ldir %less %lf %lk %ll %load %load_ext%loadpy %logoff %logon %logstart %logstate %logstop %ls %lsmagic%lx %macro %magic %man %matplotlib %mkdir %more %mv %notebook%page %paste %pastebin %pdb %pdef %pdoc %pfile %pinfo %pinfo2 %pip%popd %pprint %precision %prun %psearch %psource %pushd %pwd %pycat%pylab %quickref %recall %rehashx %reload_ext %rep %rerun %reset%reset_selective %rm %rmdir %run %save %sc %set_env %store %sx%system %tb %time %timeit %unalias %unload_ext %who %who_ls %whos%xdel %xmodeAvailable cell magics:%%! %%HTML %%SVG %%bash %%capture %%debug %%file %%html %%javascript%%js %%latex %%markdown %%perl %%prun %%pypy %%python %%python2%%python3 %%ruby %%script %%sh %%svg %%sx %%system %%time %%timeit%%writefileAutomagic is ON, % prefix IS NOT needed for line magics. 可以看到，IPython提供了很多magic函数。并且，随着IPython的功能越来越多，magic函数还会不断 增加。那么，有没有一种好的方法能够快速了解magic函数的用法呢？前面介绍的通过问号获取对象帮 助信息的方法对magic函数也适用。因此，只要输入一个magic函数，后面再输入一个问号，回车以后 就能够看到这个magic函数的帮助信息。如下所示： 123456789101112131415In [29]: %save?Docstring:Save a set of lines or a macro to a given filename.Usage: %save [options] filename n1-n2 n3-n4 ... n5 .. n6 ...Options: -r: use 'raw' input. By default, the 'processed' history is used,so that magics are loaded in their transformed version to validPython. If this option is given, the raw input as typed as thecommand line is used instead. -f: force overwrite. If file exists, %save will prompt for overwriteunless -f is given. -a: append to the file instead of overwriting it.: IPython的官方文档将magic函数分为三类，分别是： 1231）操作代码的magic函数，如%run、%edit、%save、%macro、%recall；2）控制IPython的magic函数，如%colors、%xmode、%autoindent、%automagic；3）其他magic函数，如%reset、%timeit、%%writefile、%load、%paste。 为了演示magic函数的使用，我们来看一个实际的例子。假设你是一名DBA，并且非常喜欢Python这门 编程语言，会经常使用Python管理MySQL。因此，你经常需要使用Python连接MySQL执行SQL语句 （Python连接MySQL的知识将在11章介绍）。使用Python执行SQL语句，对于普通的查询语句，返回 的结果将是一个二维的元组。但是，如果执行的是一些管理类的SQL语句或者监控类的SQL语句， Python驱动将会以怎样的方式返回MySQL的查询结果呢？ 例如，需要执行下面的SQL语句，并获取返回结果： 1234567show slave status；show master status；show variables like '%innodb%buffer%'；show status like '%select%'；set global innodb_buffer_pool_dump_pct = 30；GRANT ALL PRIVILEGES ON . TO ['lmx'@'localhost'](mailto:'lmx'@'localhost')WITH GRANT OPTION。 为了得到Python执行上面SQL语句的结果，需要在Python中连接MySQL并进行认证。认证完成以后执 行SQL语句获取输出。由于你经常需要验证SQL语句，因此，使用Python连接MySQL并认证这些代码需 要反复输入。为了节省输入时间，我们可以将Python连接MySQL并认证的逻辑保存到外部文件中，在 需要的时候通过%load这个magic函数将外部代码导入到IPython中执行即可。例如，我们在一个名为 connect.py的外部文件中保存了连接MySQL的代码，在Ipython中使用%load导入外部Python文件： 1234567891011In [30]: %load connect.py In [31]: import MySQLdb as dbconn = db.connect(host=\"localhost\", db=\"test\", user='lmx',passwd='my_passwd', unix_socket='/tmp/mysql.sock')cur = conn.cursor()sql = \"select 1\"cur.execute(sql)rows = cur.fetchall()print rows((1L,),) 使用%load命令导入外部的Python文件并执行以后，可以继续使用已经建立的MySQL连接执行SQL语 句。这个例子主要用以演示magic函数的用法，IPython提供了大量的magic函数，每一个magic函数的 具体用法都可以通过问号表达式获取相应的帮助文档。 ¶（5）保存历史 保存编码历史这方面，IPython相比标准的Python Shell有了质的提升。用户可以非常灵活地操作 IPython的输入历史和输出历史。下面我们简单看几个例子： _i, _ii, _iii 分别保存了最近的三次输入； _, , _ 分别保存了最近的三次输出； 可以像Bash一样，通 过ctrl+p, ctrl+n查找输入； 可以像Bash一样，使用ctrl+r进行反向查找； IPython的输入历史在 当前会话退出以后会进行持久化，下一次进入IPython时，依然可以查找前一次会话的输入历史； %edit IPython可以通过%edit编辑历史输入并重新执行； %save IPython可以通过%save将 IPython中的代码保存到程序文件中； %rerun IPython可以指定代码行数重新运行； 12345In [32]: %rerun 21=== Executing: ===json.dumps(d)=== Output: ===Out[32]: '&#123;\"a\": 1, \"b\": 2, \"c\": 3&#125;' ¶（6）与操作系统交互 IPython比标准的Python Shell好用的另一个理由是，它能够更好地与操作系统进行交互。在使用 Python进行交互式编程时，不用退出Python Shell就可以执行Linux命令。magic函数里的%cd和%pwd 作用相当于Linux下的cd命令和pwd命令。此外，在IPython中，可以通过“!cmd”的形式执行任何Linux 命令。如下所示： 123456In [33]: %lsanaconda-ks.cfg initial-setup-ks.cfg Python-3.8.1/ Python-3.8.1.tgzIn [34]: %pwdOut[34]: '/root'In [35]: ! wc -l /tmp/storage.log0 /tmp/storage.log 也可以通过赋值的方式捕获命令的输出： 1234567891011121314In [36]: data=!dfIn [37]: dataOut[37]:['文件系统 1K-块 已用 可用 已用% 挂载点','/dev/mapper/centos-root 17811456 6060988 11750468 35% /','devtmpfs 480872 0 480872 0% /dev','tmpfs 497948 0 497948 0% /dev/shm','tmpfs 497948 8696 489252 2% /run','tmpfs 497948 0 497948 0% /sys/fs/cgroup','/dev/sda1 1038336 169504 868832 17% /boot','tmpfs 99592 64 99528 1% /run/user/1000','tmpfs 99592 0 99592 0% /run/user/0']In [38]: data[1].split()[4]Out[38]: '35%' 在Python生态中，除了IPython这个增强的Python Shell以外，还有bython和ptpython这两个不错的 Python Shell。后面这两个工具都有自己的特色，但是都没有IPython使用广泛。而且，由于IPython使 用最为广泛，很多开源项目（如流行的爬虫框架Scrapy）对IPython进行了集成，所以，建议读者学习 IPython。 ¶3.3、 jupyter的使用 ¶（1）、jupyter介绍 jupyter就是以前的IPython Notebook，是一种新兴的交互式数据分析与记录工具。它通过浏览器访问 本地或者远端的IPython进程，并利用浏览器的图形界面，增强IPython的可视化输出。jupyter定义了 一种全新的文件格式，文件的后缀名是ipynb。ipynb文件包含了代码，用以说明每一步的计算和输出。 也就是说，ipynb文件完整记录了计算过程中的所有相关信息，并且，能够支持图片、视频和公式等副 文本格式，是科学计算、数据分析和编程教学的优秀工具。 正是由于jupyter丰富的可视化输出，其广泛应用于以下场景： 1234编程教学；数据分析；科学计算；幻灯片演示。 ¶（2）、 jupyter notebook的使用 IPython Shell与jupyter分离以后，jupyter需要额外进行安装。直接使用pip安装即可： 12345678910111213[root@localhost ~]# pip install jupyterLooking in indexes: https://pypi.douban.com/simple/Collecting jupyterDownloadinghttps://pypi.doubanio.com/packages/83/df/0f5dd132200728a86190397e1ea87cd76244e42d39ec5e88efd25b2abd7e/jupyter-1.0.0-py2.py3-none-any.whl……省略部分信息Successfully installed MarkupSafe-1.1.1 Send2Trash-1.5.0 attrs-19.3.0bleach-3.1.0 defusedxml-0.6.0 entrypoints-0.3 ipykernel-5.1.3 ipywidgets7.5.1 jinja2-2.10.3 jsonschema-3.2.0 jupyter-1.0.0 jupyter-client-5.3.4jupyter-console-6.0.0 jupyter-core-4.6.1 mistune-0.8.4 nbconvert-5.6.1nbformat-5.0.3 notebook-6.0.2 pandocfilters-1.4.2 prometheus-client-0.7.1prompt-toolkit-2.0.10 pyrsistent-0.15.7 python-dateutil-2.8.1 pyzmq-18.1.1qtconsole-4.6.0 terminado-0.8.3 testpath-0.4.4 tornado-6.0.3 webencodings0.5.1 widgetsnbextension-3.5.1 由于我们是在Linux下安装jupyter，如果我们的Linux没有图形界面，可以通过设置–no-browser和设 置–ip=0.0.0.0进行外部访问，如果不指定–ip参数，默认IP是localhost，也就是只有本地才能访问。如 下所示： 12345678910111213141516[root@localhost ~]# jupyter notebook --no-browser --ip=0.0.0.0 --allow-root[I 13:06:33.656 NotebookApp] 启动notebooks 在本地路径: /root[I 13:06:33.657 NotebookApp] 本程序运行在: http://localhost:8888/?token=33fdb8256c7c1d13a23b8189ea0f4e7b7f434f14cc07ea5e[I 13:06:33.657 NotebookApp] or http://127.0.0.1:8888/?token=33fdb8256c7c1d13a23b8189ea0f4e7b7f434f14cc07ea5e[I 13:06:33.657 NotebookApp] 使用control-c停止此服务器并关闭所有内核(两次跳过确认).[C 13:06:33.727 NotebookApp] To access the notebook, open this file in a browser: file:///root/.local/share/jupyter/runtime/nbserver-3998-open.html Or copy and paste one of these URLs: http://localhost:8888/?token=33fdb8256c7c1d13a23b8189ea0f4e7b7f434f14cc07ea5e or http://127.0.0.1:8888/?token=33fdb8256c7c1d13a23b8189ea0f4e7b7f434f14cc07ea5e 从jupyter notebook的输出结果可以看到，jupyter notebook命令给出了一个URL，我们只需将该URL 拷贝至浏览器中，然后将0.0.0.0替换为Linux服务器的IP即可。 在Windows下可以使用远程连接工具xmanager来操作 通过浏览器访问jupyter给我们的URL，就可以登录到jupyter的主界面。这个界面会显示当前目录下的 所有文件 登录jupyter的主界面后，我们如果要创建一个文件，只需要单击“新建”，选择你希望启动的Notebook 类型即可。我们选择Python 3。选择Python 3以后，浏览器会打开一个新的页面。在这个新的页面中， 可以看到一个空的Notebook界面。 jupyter界面由以下部分组成： 1234标题栏菜单栏快捷键编辑区 在菜单栏中有一个“帮助”选项，读者可以通过该选项得到jupyter的使用说明。jupyter本身是图形界面的 应用，使用比较简单，因此，本教程不会花很多篇幅来介绍jupyter的使用。 在jupyter的编辑区中默认有一个输入框。输入框在jupyter中称为cell。我们可以通过菜单栏的“cell”选项 控制cell的格式、执行cell的代码。与此同时，我们也可以通过快捷键控制cell，如ctrl+enter快捷键用以 执行cell中的代码，shift+enter快捷键用以执行当前cell中的代码，并且在当前cell下方创建一个新的 cell。 jupyter之所以能够进行编程教学和幻灯片演示，是因为它可以支持富文本格式和markdown格式。我们 只需修改cell的类型为“Markdown”，就可以在cell中使用markdown语句进行输入了。我们也可以在 jupyter中画图。为了在jupyter中画图，我们需要先安装matplotlib。如下所示： 12345678910111213[root@localhost ~]# pip install matplotlibLooking in indexes: https://pypi.douban.com/simple/Collecting matplotlibDownloadinghttps://pypi.doubanio.com/packages/53/6c/7b400d45f0ecd6703b2779a7dfda6578579a353748e1b43d8353cb7f5b7f/matplotlib-3.1.2-cp38-cp38-manylinux1_x86_64.whl(13.1MB)|████████████████████████████████| 13.1MB 1.8MB/s……省略部分信息Installing collected packages: kiwisolver, numpy, pyparsing, cycler,matplotlibSuccessfully installed cycler-0.10.0 kiwisolver-1.1.0 matplotlib-3.1.2numpy-1.18.1 pyparsing-2.4.6 安装matplotlib以后就可以在jupyter中画图了，下面给出了一个jupyter使用的例子。 12345import matplotlib.pyplot as pltimport numpyx = numpy.arange(11)y = x**2plt.plot(x, y) 运行结果如下图： ¶四、Python工作环境管理 Python 2和Python 3之间存在着较大的差异，并且，由于各种原因导致了Python 2和Python 3的长期 共存。在实际工作过程中，我们可能会同时用到Python 2和Python 3，因此，需要经常在Python 2和 Python 3之间进行来回切换。此外，如果你是喜欢尝鲜的人，那么，你很有可能在Python新版本出来 的时候立即下载Python的版本，试验Python的特性。 在Python世界里，除了需要对Python的版本进行管理以外，还需要对不同的软件包进行管理。大部分 情况下，对于开源的库我们使用***版本即可。但是，有时候可能需要对相同的Python版本，在不同的 项目中使用不同版本的软件包。 在这一节里，我们将介绍两个工具，即pyenv和virtualenv。前者用于管理不同的Python版本，后者用 于管理不同的工作环境。有了这两个工具，Python相关的版本问题将不再是问题。 ¶4.1、使用pyenv管理不同的Python版本 安装不同的Python版本并不是一件容易的事情，在不同的Python版本之间来回切换更加困难，而且， 多版本并存非常容易互相干扰。因此，我们需要一个名为pyenv的工具。pyenv是一个Python版本管理 工具，它能够进行全局的Python版本切换，也可以为单个项目提供对应的Python版本。使用pyenv以 后，可以在服务器上安装多个不同的Python版本，也可以安装不同的Python实现。不同Python版本之 间的切换也非常简单。接下来我们就一起看一下pyenv的安装和使用。 ¶1、.pyenv的安装 我们直接从GitHub下载项目到本地，然后，分别执行以下命令进行安装即可 12345678910111213141516[root@localhost .pip]# yum -y install git[root@localhost .pip]# git clone https://github.com/yyuu/pyenv.git ～/.pyenv正克隆到 '～/.pyenv'...remote: Enumerating objects: 8, done.remote: Counting objects: 100% (8/8), done.remote: Compressing objects: 100% (8/8), done.remote: Total 17600 (delta 2), reused 2 (delta 0), pack-reused 17592接收对象中: 100% (17600/17600), 3.44 MiB | 601.00 KiB/s, done.处理 delta 中: 100% (11954/11954), done.[root@localhost .pip]# echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' &gt;&gt;～/.bash_profile[root@localhost .pip]# echo 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' &gt;&gt;～/.bash_profile[root@localhost .pip]# echo 'eval \"$(pyenv init -)\"' &gt;&gt;～/.bash_profile 安装完成以后需要重新载入配置文件，或者退出以后重新登录，以使～/.bash_profile中的配置生效。 笔者一般选择使用source命令重新载入配置文件，如下所示： 1[root@localhost .pip]# source ~/.bash_profile 至此，pyenv就安装完成了，我们可以通过下面的命令验证pyenv是否正确安装并获取pyenv的帮助信 息： 123456789101112131415161718192021222324252627282930[root@localhost ~]# pyenv --helpUsage: pyenv &lt;command&gt; [&lt;args&gt;]Some useful pyenv commands are: commands List all available pyenv commands commands List all available pyenv commands exec Run an executable with the selected Python version global Set or show the global Python version help Display help for a command hooks List hook scripts for a given pyenv command init Configure the shell environment for pyenv install Install a Python version using python-build local Set or show the local application-specific Python version prefix Display prefix for a Python version rehash Rehash pyenv shims (run this after installing executables) root Display the root directory where versions and shims are kept shell Set or show the shell-specific Python version shims List existing pyenv shims uninstall Uninstall a specific Python version version Show the current Python version and its origin --version Display the version of pyenv version-file Detect the file that sets the current pyenv version version-name Show the current Python version version-origin Explain how the current Python version is set versions List all Python versions available to pyenv whence List all Python versions that contain the given executable which Display the full path to an executableSee `pyenv help &lt;command&gt;' for information on a specific command.For full documentation, see: https://github.com/pyenv/pyenv#readme ¶2、pyenv的使用 我们通过pyenv的install命令，可以查看pyenv当前支持哪些Python版本，如下所示 1234567891011121314[root@localhost ~]# pyenv install --listAvailable versions:2.1.3……省略部分信息3.8.03.8-dev3.8.13.9-dev……省略部分信息anaconda3-2018.12anaconda3-2019.03anaconda3-2019.07anaconda3-2019.10……省略部分信息 由于pyenv可以安装的Python版本列表非常长，所以，这里进行了省略。读者可以在自己电脑上安装 pyenv，然后执行pyenv install --list命令进行查看。可以看到，pyenv不但可以安装不同的Python版 本，而且还可以安装不同的Python实现，也可以安装***版本的Python用以学习。 查看当前系统中包含的Python版本： 12[root@localhost ~]# pyenv versions* system (set by /root/.pyenv/version) 使用pyenv安装不同的Python版本： 12pyenv install -v 3.6.0pyenv install -v 2.7.13 再次查看当前系统中包含的Python版本： 1234[root@localhost ~]# pyenv versions* system (set by /root/.pyenv/version)2.7.133.8.1 由于我们安装了2个Python版本，加上我们系统自身的Python，当前系统中存在3个不同的Python版 本。其中，输出结果前面的“*”表示当前正在使用的版本。我们也可以通过pyenv global选择不同的 Python版本，如下所示： 12345678910111213141516[root@localhost ~]# pyenv global 3.8.1[root@localhost ~]# pyenv versionssystem2.7.13* 3.8.1 (set by /root/.pyenv/version)[root@localhost ~]# pythonPython 3.8.1 (default, Jan 14 2020, 12:20:36)[GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] on linuxType \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; exit()[root@localhost ~]# pyenv global 2.7.13[root@localhost ~]# pythonPython 2.7.13 (default, Jan 14 2020, 12:27:38)[GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] on linux2Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; 使用pyenv以后，可以快速切换Python的版本。切换Python版本以后，与版本相关的依赖也会一起切 换。因此，我们不用担心不同的版本在系统中是否会相互干扰。例如，切换Python版本以后，相应的 pip也会跟着切换，所以不用担心自己使用的pip版本和Python版本不匹配的问题，如下所示： 1234[root@localhost ~]# pyenv global 3.8.1[root@localhost ~]# pip --versionpip 19.2.3 from /root/.pyenv/versions/3.8.1/lib/python3.8/site-packages/pip(python 3.8) 如果想要删除Python版本，使用uninstall命令即可。如下所示： 1pyenv uninstall 2.7.10 ¶4.2、 使用virtualenv管理不同的项目 virtualenv本身是一个独立的项目，用以隔离不同项目的工作环境。例如，用户lmx希望在项目A中使用 Flask 0.8这个版本，与此同时，又想在项目B中使用Flask 0.9这个版本。如果我们全局安装Flask，必然 无法满足用户的需求。这个时候，我们就可以使用virtualenv。 读者需要注意pyenv和virtualenv的区别。pyenv用以管理不同的Python版本，例如，你的系统工作时 使用Python 2.7.13，学习时使用Python 3.6.0。virtualenv用以隔离项目的工作环境，例如，项目A和 项目B都是使用Python 2.7.13，但是，项目A需要使用Flask 0.8版本，项目B需要使用Flask 0.9版本。我 们只要组合pyenv和virtualenv这两个工具，就能够构造Python和第三方库的任意版本组合，拥有很好 的灵活性，也避免了项目之间的相互干扰。 virtualenv本身是一个独立的工具，用户可以不使用pyenv而单独使用virtualenv。但是，如果你使用了 pyenv，就需要安装pyenv-virtualenv插件，而不是通过virtualenv软件使用virtualenv的功能。 ¶1、pyenv-virtualenv的安装 安装和使用pyenv-virtualenv插件如下所示： 123456789[root@localhost ~]# git clone https://github.com/yyuu/pyenv-virtualenv.git$(pyenv root)/plugins/pyenv-virtualenv正克隆到 '/root/.pyenv/plugins/pyenv-virtualenv'...remote: Enumerating objects: 2064, done.remote: Total 2064 (delta 0), reused 0 (delta 0), pack-reused 2064接收对象中: 100% (2064/2064), 580.31 KiB | 264.00 KiB/s, done.处理 delta 中: 100% (1413/1413), done.[root@localhost ~]# echo 'eval \"$(pyenv virtualenv-init -)\"'&gt;&gt;~/.bash_profile 与安装pyenv类似，安装完成以后需要重新载入配置文件，或者退出用户再登录，以使得配置文件生 效： 12345678[root@localhost ~]# source ~/.bash_profile[root@localhost ~]# pyenv help virtualenvUsage: pyenv virtualenv [-f|--force] [VIRTUALENV_OPTIONS] [version]&lt;virtualenv-name&gt; pyenv virtualenv --version pyenv virtualenv --help -f/--force Install even if the version appears to be installedalready ¶2、pyenv-virtualenv的使用 有了pyenv-virtualenv以后，我们可以为同一个Python解释器，创建多个不同的工作环境。例如，我们 新建两个工作环境： 12[root@localhost ~]# pyenv virtualenv 3.8.1 first_project[root@localhost ~]# pyenv virtualenv 3.8.1 second_project 可以使用virtualenvs子命令查看工作环境： 12345[root@localhost ~]# pyenv virtualenvs 3.8.1/envs/first_project (created from /root/.pyenv/versions/3.8.1) 3.8.1/envs/second_project (created from /root/.pyenv/versions/3.8.1) first_project (created from /root/.pyenv/versions/3.8.1) second_project (created from /root/.pyenv/versions/3.8.1) 创建完工作环境以后，可以通过activate和deactivate子命令进入或退出一个工作环境。进入工作环境 以后，左边的提示符会显示你当前所在的工作环境，以免因为环境太多导致操作错误。 123456789101112131415[root@localhost ~]# pyenv activate first_projectpyenv-virtualenv: prompt changing will be removed from future release.configure `export PYENV_VIRTUALENV_DISABLE_PROMPT=1' to simulate thebehavior.(first_project) [root@localhost ~]# pip install flask==1.1.1Looking in indexes: https://pypi.douban.com/simple/Collecting flask Downloadinghttps://pypi.doubanio.com/packages/9b/93/628509b8d5dc749656a9641f4caf13540e2cdec85276964ff8f43bbb1d3b/Flask-1.1.1-py2.py3-none-any.whl (94kB) |████████████████████████████████| 102kB 4.7MB/s……省略部分信息Successfully installed Jinja2-2.10.3 MarkupSafe-1.1.1 Werkzeug-0.16.0click-7.0 flask-1.1.1 itsdangerous-1.1.0(first_project) [root@localhost ~]# pyenv deactivate 接下来，我们看一下在不同的工作环境安装不同的Flask版本： 12345[root@localhost ~]# pyenv activate first_project(first_project) [root@localhost ~]# pip install flask==1.1.1(first_project) [root@localhost ~]# pyenv deactivate(second_project) [root@localhost ~]# pip install flask==0.10.1 如果想要删除虚拟环境，则使用： 1(first_project) [root@localhost ~]# pyenv virtualenv-delete first_project 使用pyenv和python-virtualenv插件，我们就能够自由地在不同的版本之间进行切换，相比管理Python 版本，不但节省了时间，也避免了工作过程中的相互干扰。","categories":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/tags/Python/"}]},{"title":"Python数据类型之字典","slug":"Python数据类型之字典","date":"2020-04-26T16:00:00.000Z","updated":"2020-04-27T14:41:05.001Z","comments":true,"path":"Python数据类型之字典.html","link":"","permalink":"https://pdxblog.top/Python%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B9%8B%E5%AD%97%E5%85%B8.html","excerpt":"","text":"¶Python数据类型之字典 ¶字典的语法 键值对形式，键值之间用“:”分隔，键值对包含在一个”{}“里 12345678910111213#之前的数据类型都是与变量所关联name = 'bily' #字符串类型name = 89 #数字类型key = 88.8list = [3,4,5,6] #列表类型tuple = (6,4,68) #元组#字典的例子#字典存放的数据更大#平常查字典的时候目录和页数是对应的#在python中叫做键和值dict = &#123;'name':'老周','age':'29','job':'程序员'&#125;print(dict)&#123;'name': '老周', 'age': '29', 'job': '程序员'&#125; 键是唯一、无序的 123dict = &#123;'name':'老周','age':'29','job':'程序员','age':'33'&#125;print(dict)&#123;'name': '老周', 'age': '33', 'job': '程序员'&#125; #后面的替换了前面的 键值可以是数字、字符串、元组，一般用于字符串 123dict1 = &#123;1:101,2:102&#125;print(dict1)&#123;1: 101, 2: 102&#125; ¶简单的字典 字典的访问：字典名称[键] 123456#定义字典dict2 = &#123;'河北':'邯郸','甘肃':'兰州','四川':'成都'&#125;#对字典进行访问（取值）===&gt; 值=字典名称[键]hd = dict2['河北']print(hd)邯郸 添加键值对 1234#添加键值对（字典的数据）dict2['山西'] = '太原'print(dict2)&#123;'河北': '邯郸', '甘肃': '兰州', '四川': '成都', '山西': '太原'&#125; 修改字典的值 1234#修改字典的值dict2['河北'] = '邢台'print(dict2)&#123;'河北': '邢台', '甘肃': '兰州', '四川': '成都', '山西': '太原'&#125; 删除键值对：del 1234#删除字典的键值对del dict2['四川']print(dict2)&#123;'河北': '邢台', '甘肃': '兰州', '山西': '太原'&#125; 除了这个横向排序，还可以纵向排序 1234567891011121314151617181920212223student = &#123; 'name':'张三', 'gender':'男', 'age':'20', 'phone':'13813812138'&#125;print(student)&#123;'name': '张三', 'gender': '男', 'age': '20', 'phone': '13813812138'&#125;shell = &#123; 'pwd':'显示当前目录', 'cd':'切换目录', 'mv':'移动文件或目录', 'mkdir':'创建目录', 'cp':'复制文件或目录'&#125;for i in shell: print(i+'：'+shell[i])pwd：显示当前目录cd：切换目录mv：移动文件或目录mkdir：创建目录cp：复制文件或目录 ¶遍历字典 遍历所有的键值对： key value items() 123456789101112131415#定义一个字典dict = &#123;'name':'老周','age':'29','job':'程序员'&#125;#遍历字典：键值对的集合、键的集合、值的集合for key,value in dict.items(): print(key+\":\"+value)name:老周age:29job:程序员#字典常用的函数print(dict.items())print(dict.keys())print(dict.values())dict_items([('name', '老周'), ('age', '29'), ('job', '程序员')])dict_keys(['name', 'age', 'job'])dict_values(['老周', '29', '程序员']) 按顺序遍历字典中的所有的键：sorteed() 123456789101112131415#将字典的键排序print(sorted(dict1.keys()))print(sorted(dict1.values()))for info in sorted(dict1.keys()): print(info,end=\" \") print(\"\\n\")for info in sorted(dict1.values()): print(info,end=\" \")['age', 'job', 'name']['29', '程序员', '老周']age job name 29 程序员 老周 遍历字典中所有的值：values() 其他方法（扩展） 计算字典元素个数，即键的总数：len(dict) 123#字典元素的个数print(len(dict))3 返回一个字典的浅复制：dict.copy() 123456#定义一个空字典dict1 = &#123;&#125;#复制字典dict1 = dict.copy()print(dict1)&#123;'name': '老周', 'age': '29', 'job': '程序员'&#125; 返回并删除字典中的最后一对键和值：popitem() 12345678910111213dict = &#123;'name':'老周','age':'29','job':'程序员'&#125;print(dict)print(dict.popitem())print(dict)&#123;'name': '老周', 'age': '29', 'job': '程序员'&#125;('job', '程序员')&#123;'name': '老周', 'age': '29'&#125;#删除指定的值print(dict.pop('age'))print(dict)&#123;'name': '老周', 'age': '29', 'job': '程序员'&#125;29&#123;'name': '老周', 'job': '程序员'&#125; 删除字典内所有元素：dict(clear) 123456dict = &#123;'name':'老周','age':'29','job':'程序员'&#125;print(dict)dict.clear()print(dict)&#123;'name': '老周', 'age': '29', 'job': '程序员'&#125;&#123;&#125; ¶字典的嵌套 列表里嵌套字典 12345678#定义字典dict = &#123;'name':'老周','age':'29','job':'程序员'&#125;dict1 = &#123;'age':'29','job':'程序员'&#125;dict2 = &#123;'name':'老周','job':'程序员'&#125;#列表里嵌套字典list = [dict,dict1,dict2]print(list)[&#123;'name': '老周', 'age': '29', 'job': '程序员'&#125;, &#123;'age': '29', 'job': '程序员'&#125;, &#123;'name': '老周', 'job': '程序员'&#125;] 字典里嵌套列表 123dict3 = &#123;'pet':['cat','dog','duck']&#125;print(dict3&#123;'pet': ['cat', 'dog', 'duck']&#125; 字典里嵌套字典 123456789101112131415dict4 = &#123; 'age':&#123;'girl':'18','boy':'20'&#125;, 'job':&#123;'man':'IT','women':'db'&#125;&#125;print(dict4)for key,value in dict4.items(): print('key:'+key,end=\" \") for v in value.items(): print(v)&#123;'age': &#123;'girl': '18', 'boy': '20'&#125;, 'job': &#123;'man': 'IT', 'women': 'db'&#125;&#125;key:age ('girl', '18')('boy', '20')key:job ('man', 'IT')('women', 'db') ¶练习 1、创建两个字典来表示老师，然后将这两个字典存储到一个名为person的列表中。遍历这个列表，将其中每个老师的信息都打印出来 123456789101112131415teacher1 = &#123; '语文':'张三', '数学':'李四', '英语':'王五',&#125;teacher2 = &#123; '物理':'赵六', '历史':'葛七', '政治':'周八'&#125;person = [teacher1,teacher2]for teacher in person: print(teacher)&#123;'语文': '张三', '数学': '李四', '英语': '王五'&#125;&#123;'物理': '赵六', '历史': '葛七', '政治': '周八'&#125; 2、创建多个字典，每个字典都使用一种宠物的名字命名；在每个字典中，包含宠物的类型和主人的名字。将这些字典存储在一个名为pets的列表中，再遍历该列表，将宠物的信息都打印出来 123456789101112131415161718192021dog = &#123; '小型犬':'贵宾犬', '中型犬':'柯基犬', '大型犬':'金毛犬'&#125;cat = &#123; '小型':'新加坡猫', '中型':'波斯猫', '大型':'沙特尔猫'&#125;pig = &#123; '华北型':'东北民猪', '华南型':'海南猪', '江海型':'太湖猪'&#125;pets = [dog,cat,pig]for pet in pets: print(pet)&#123;'小型犬': '贵宾犬', '中型犬': '柯基犬', '大型犬': '金毛犬'&#125;&#123;'小型': '新加坡猫', '中型': '波斯猫', '大型': '沙特尔猫'&#125;&#123;'华北型': '东北民猪', '华南型': '海南猪', '江海型': '太湖猪'&#125;","categories":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/tags/Python/"}]},{"title":"Python函数","slug":"Python函数","date":"2020-03-24T16:00:00.000Z","updated":"2020-03-25T11:49:43.109Z","comments":true,"path":"Python函数.html","link":"","permalink":"https://pdxblog.top/Python%E5%87%BD%E6%95%B0.html","excerpt":"","text":"¶函数 ¶1、为什么要使用函数 函数中的代码一次编写，所处运行 函数可以让代码复用，减少代码冗余 ¶2、定义函数 关键字：def 函数名称右侧有小括号，结尾处有冒号 函数内第一行通常书写注释，表明该函数的意义 注释后空一行，开始写代码块 函数结束后，空两行 函数调用后空一行，再执行别的代码 ¶函数类型 ¶无参函数 ¶带参函数 注意事项：调用函数时，实参传递的个数要与形参保持一致","categories":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/tags/Python/"}]},{"title":"Python小练习","slug":"Python小练习","date":"2020-03-24T16:00:00.000Z","updated":"2020-03-25T11:49:43.113Z","comments":true,"path":"Python小练习.html","link":"","permalink":"https://pdxblog.top/Python%E5%B0%8F%E7%BB%83%E4%B9%A0.html","excerpt":"","text":"¶1）猜拳游戏 1234567891011121314151617181920212223242526272829303132333435363738'''猜拳游戏：根据用户输入的数字，分别给出提示：“猜大了”或“猜小了”或“猜对了”，只有3次机会，否则退出程序'''import randomnum = random.randint(0, 10)time = 0while time &lt;= 3: guess = int(input('请输入你猜的数字：')) if guess &lt; num: print('猜小了！！！') time += 1 elif guess &gt; num: print('猜大了！！！') time += 1 else: print('恭喜你，猜对了！！！') break print(f'移动三次机会，现在是第&#123;time&#125;次！！！') if time == 3: quiz = input('三次都没对，是否继续（y/n）') if quiz == 'y': time = 0 continue elif quiz == 'n': breakprint(num)# 运行结果请输入你猜的数字：7猜小了！！！移动三次机会，现在是第1次！！！请输入你猜的数字：10恭喜你，猜对了！！！10进程已结束，退出代码 0 ¶2）跑马灯 12345678910111213141516171819202122232425262728293031323334353637383940414243'''跑马灯特效'''import osimport timedef main(): content = '武汉加油，中国加油' while True: os.system('cls') print(content) time.sleep(0.2) content = content[1:] + content[0]if __name__ == '__main__': main()#运行结果 武汉加油，中国加油 汉加油，中国加油武 加油，中国加油武汉 油，中国加油武汉加 ，中国加油武汉加油 中国加油武汉加油， 国加油武汉加油，中 加油武汉加油，中国 油武汉加油，中国加 武汉加油，中国加油 汉加油，中国加油武 加油，中国加油武汉 油，中国加油武汉加 ，中国加油武汉加油 中国加油武汉加油， 国加油武汉加油，中 加油武汉加油，中国 油武汉加油，中国加 武汉加油，中国加油 汉加油，中国加油武进程已结束，退出代码 -1 ¶3）幸运数 1234567891011121314151617181920212223242526272829303132# 输入一个4位数，如果各个数字之和大于20，则次数为幸运数def lucky_numbers(num): # num = int(input('请输入一个4位数：')) # print('您输入的是：' + str(num)) # 分解四位数，获取各位数字 # 获取个位数字 ge_wei = num % 10 shi_wei = int(num % 100 / 10) bai_wei = int(num / 100 % 10) qian_wei = int(num / 1000) # 求四个数值的和，并进行判断，如果大于20，则输出提示：是幸运数 if (ge_wei + shi_wei + bai_wei + qian_wei) &gt; 20: print('是幸运数字') else: print('不是幸运数字,谢谢参与')def main(): num = int(input('请输入一个4位数：')) print('您输入的是：' + str(num)) lucky_numbers(num)main()#运行结果请输入一个4位数：6666您输入的是：6666是幸运数字进程已结束，退出代码 0 ¶4）温度格式转换 123456789101112131415161718192021222324252627282930313233# 使用while实现：输出摄氏温度与华氏温度的对照表，要求它从摄氏温度0度到250度，每隔20度为一项，# 对照表中的条目不超过10条。## 转换关系：华氏温度 = 摄氏温度 * 9 / 5.0 + 32## 循环操作：计算摄氏温度，并输出对照条目# 循环条件：# 条目&lt;=10 &amp;&amp; 摄氏温度 &lt;= 250celsius = 0Fahrenheit = 0i = 0while i &lt; 10 and celsius &lt;= 250: i = i + 1 celsius = celsius + 20 Fahrenheit = celsius * 9 / 5.0 + 32 print('摄氏温度：', celsius, '华氏温度：', Fahrenheit, end=\" \") print()# 运行结果摄氏温度： 20 华氏温度： 68.0 摄氏温度： 40 华氏温度： 104.0 摄氏温度： 60 华氏温度： 140.0 摄氏温度： 80 华氏温度： 176.0 摄氏温度： 100 华氏温度： 212.0 摄氏温度： 120 华氏温度： 248.0 摄氏温度： 140 华氏温度： 284.0 摄氏温度： 160 华氏温度： 320.0 摄氏温度： 180 华氏温度： 356.0 摄氏温度： 200 华氏温度： 392.0 进程已结束，退出代码 0","categories":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/tags/Python/"}]},{"title":"Python编写简单的学生管理系统","slug":"Python编写简单的学生管理系统","date":"2020-03-24T16:00:00.000Z","updated":"2020-03-25T11:49:43.118Z","comments":true,"path":"Python编写简单的学生管理系统.html","link":"","permalink":"https://pdxblog.top/Python%E7%BC%96%E5%86%99%E7%AE%80%E5%8D%95%E7%9A%84%E5%AD%A6%E7%94%9F%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F.html","excerpt":"","text":"¶Python编写简单的学生管理系统 一共两个文件，其中一个定义函数，另一个是主程序，调用函数，运行程序 CMS.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485'''编写“学生信息管理系统”，要求如下：必须使用自定义函数，完成对程序的模块化学生信息至少包含：姓名、年龄、学号，除此以外可以适当添加必须完成的功能：添加、删除、修改、查询、退出'''# 定义一个列表用来存储多个学生信息stuList = []# 定义系统菜单显示函数def displayMenu(): # 完成显示系统菜单的功能 print(\"*\" * 40) print(\"学 生 信 息 管 理 系 统 \") print(\"1、添加学生信息\") print(\"2、删除学生信息\") print(\"3、修改学生信息\") print(\"4、查询学生信息\") print(\"5、退出学生信息管理系统\") print(\"*\" * 40)def addNewStu(): # 完成添加学生信息的功能 name = input(\"请输入学生的姓名：\") stuId = input(\"请输入学生的学号：\") age = input(\"请输入学生的年龄：\") # 定义一个字典用来存储每个学生的信息 stuDict = &#123;&#125; stuDict['name'] = name stuDict['stuId'] = stuId stuDict['age'] = age global stuList # 将每个学生的信息添加到列表中 stuList.append(stuDict)def delStu(): global stuList # 完成删除学生信息的功能 delName = input(\"请输入你要删除的学生姓名：\") delFlag = 0 for tempStu in stuList: if delName == tempStu['name']: delName = stuList.index(tempStu) # 获取要删除的学生所在列表中的索引 del stuList[delName] # 按索引删除 delFlag = 1 # 删除成功 break if delFlag == 0: print(\"没有此人，请中心输入！！！\")def reviseStu(): global stuList # 完成修改学生信息的功能 reviseName = input(\"请输入你要修改信息的学生姓名：\") reviseFlag = 0 for tempStuDict in stuList: if reviseName == tempStuDict['name']: # 修改学生的信息 newStuId = input(\"请输入要修改后学生的学号：\") newAge = input(\"请输入要修改后学生的年龄：\") tempStuDict['stuId'] = newStuId tempStuDict['age'] = newAge reviseFlag = 1 break if reviseFlag == 0: print(\"没有此人，请重新输入\")def inquireStu(): global stuList # 完成查询学生信息的功能 inquireName = input(\"请输入你要查询的学生的姓名：\") inquireFlag = 0 for temp in stuList: if inquireName == temp['name']: print(\"%s\\t%s\\t%s\" % (temp['name'], temp['stuId'], temp['age'])) inquireFlag = 1 # 表示查询成功 break if inquireFlag == 0: print(\"查无此人...\") test_student.py 123456789101112131415161718192021222324252627282930313233343536'''测试学生信息管理系统的功能'''import student_sys.CMS as stu# 主函数：程序从这里开始运行def main(): # 菜单显示 # 1、提示用户选择功能 stu.displayMenu() while True: # 2、获取用户的输入 key = int(input(\"请输入你选择的功能序号：\")) if key == 1: stu.addNewStu() elif key == 2: stu.delStu() elif key == 3: stu.reviseStu() elif key == 4: stu.inquireStu() elif key == 5: print('退出程序！！！') return else: print(\"输入有误，请重新输入！！！只能输入1-5的数字！！！\") print(\"\")# 调用主函数，运行程序main() 运行结果 123456789101112131415161718192021****************************************学 生 信 息 管 理 系 统 1、添加学生信息2、删除学生信息3、修改学生信息4、查询学生信息5、退出学生信息管理系统****************************************请输入你选择的功能序号：1请输入学生的姓名：john请输入学生的学号：003请输入学生的年龄：18请输入你选择的功能序号：4请输入你要查询的学生的姓名：johnjohn 003 18请输入你选择的功能序号：5退出程序！！！进程已结束，退出代码 0","categories":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/tags/Python/"}]},{"title":"Python之if语句","slug":"Python之if语句","date":"2020-03-12T16:00:00.000Z","updated":"2020-03-13T11:48:20.969Z","comments":true,"path":"Python之if语句.html","link":"","permalink":"https://pdxblog.top/Python%E4%B9%8Bif%E8%AF%AD%E5%8F%A5.html","excerpt":"","text":"¶Python之if语句 应用场景 编程时经常需要检查一列条件并根据此条件决定采取什么措施 选择条件的实例：简单的if结构 12345678910111213#如果天气晴朗，我们去室外散步；否则继续宅在家里'''如果 天气晴朗: 我们去室外散步否则: 继续宅在家里'''state = '晴朗'if state == '晴朗': print('室外散步')else: print('宅在家里')室外散步 条件表达测试布尔表达式 比较运算符：（==、!=、&gt;、&lt;、&gt;=、&lt;=） 逻辑运算符：(and、or) 成员运算符：（in、not in） if语句结构 使用不同的条件做不同的事情 简单的if语句 if-else语句 if-elif-else结构 多重if结构 注意事项：else代码也不是必须的 if语句在列表中的应用 检查元素 确定列表是不空的 使用多个列表 条件表达测试布尔表达式 比较运算符 12345678910111213141516171819202122#比较运算符在条件表达式的应用：ATM/客服电话(请输入1，请输入2....)#==key = 1if key == 1: print('存款')else: print('取款')存款#！=if key != 1: print('不存款')else: print('存款')存款#&gt;=age = 18if age &gt;= 18: print(\"允许进入网吧\")else: print('未成年人禁止进入')允许进入网吧#其他运算符都是一个道理 逻逻辑运算符：and、or 12345678910111213141516171819202122232425#andage = 16money = 50if age &gt;= 18 and money &gt;= 100: print('欢迎光临')else: print('抱歉')抱歉 #and两边的条件必须都得成立#orage = 16money = 100if age &gt;= 18 or money &gt;= 100: print('欢迎光临')else: print('抱歉')欢迎光临 #or两边的条件只需要满足一个就行#age = 16money = 100id_hard = True #布尔值if (age &gt;= 18 or money &gt;= 100) and id_hard: #对于布尔值（True/or）可以省略 print('欢迎光临')else: print('抱歉')欢迎光临 总结and和or的区别： and两边的条件必须都得成立 or两边的条件只需要满足一个就行 成员运算符：in、not in 12345678910111213141516171819202122232425262728293031#定义列表#innames = ['John','Bili','Laoyew']name = 'Kety'if name in names: print('存在')else: print('不存在')不存在#在列表中加一个kety查看效果names = ['John','Bili','Laoyew','kety']name = 'Kety'if name in names: print('存在')else: print('不存在')不存在#因为添加的kety是小写，而定义的变量是大写的Kety，对于这种情况可以采用忽略大小写转换的方法names = ['John','Bili','Laoyew','kety']name = 'Kety'if name.lower() in names: print('存在')else: print('不存在')存在#not inif name.upper() not in names: print('no')else: print('yes')no 条件测试的表达是的结果就是布尔值，要么是True，要么是False，不能用一个等值条件来做 if语句结构 123456789101112131415161718192021222324#简单的ifage = 0if age == 0: print('婴儿')婴儿#if-elseage = 3if age &gt;= 2 and age &lt;= 4: print('蹒跚学步')else: print('婴儿')蹒跚学步#if-elif-elseage = 7if age == 0: print('婴儿')elif age &gt;= 2 and age &lt;= 4: print('蹒跚学步')elif age &gt; 4 and age &lt;= 6: print('上幼儿园')else: print('其他')其他#else代码不是必须的，如果去掉else，是没有输出结果的 如果在符合一个条件之后里面又有一个条件该怎么表示 123456789101112131415#男女学生参加100米赛跑，如果在10秒内跑完的，进入决赛；#进入决赛，分男子组合进行比赛#多重if结构second = 6gender = '男'if second &lt; 10: print('进入决赛') if gender == '男': print('进入男子组') elif gender == '女': print('进入女子组')else: print('重在参与，弘扬体育精神')进入决赛进入男子组 if语句在列表中的应用 12345678910111213141516171819202122for f in fruits: if f == 'pear': print('做个梨罐头') elif f == 'orange': print('做句子罐头') elif f == 'apple': print('做苹果罐头') else: print('做沙拉')做苹果罐头做沙拉做个梨罐头做句子罐头 #最后结果的顺序是列表内的顺序fruits = ['apple','banana','pear','orange']if len(fruits) == 0: print('没有水果')else: print('开始做水果罐头了') for fruit in fruits: print(fruit,end=\" \")开始做水果罐头了apple banana pear orange ¶练习 1、求100以内数字的偶数之和与奇数之和 123456#偶数之和print(sum(range(2,101,2)))#奇数之和print(sum(range(1,101,2)))25502500 2、输出100以内7的倍数的数字 1234for i in range(1,101): if i % 7 == 0: print(i,end=\" \") 7 14 21 28 35 42 49 56 63 70 77 84 91 98 3、打印直角三角形，奇数用*号代替，偶数用#号代替 12345678910111213141516for i in range(1,10): for j in range(i): if j+1 in range(1,11,2): print('*',end=\" \") else: print('#',end=\" \") print()* * # * # * * # * # * # * # * * # * # * # * # * # * # * * # * # * # * # * # * # * # * # *","categories":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/tags/Python/"}]},{"title":"Python数据类型之列表的基本操作","slug":"Python数据类型之列表的基本操作","date":"2020-03-12T16:00:00.000Z","updated":"2020-03-13T11:48:20.960Z","comments":true,"path":"Python数据类型之列表的基本操作.html","link":"","permalink":"https://pdxblog.top/Python%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B9%8B%E5%88%97%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C.html","excerpt":"","text":"¶什么是列表 列表是Python中非常重要的数据类型，通常作为函数的返回值。由一组元素组成，列表可以实现添加、删除和查找操作，元素值可以被修改 由一系列按照特定的顺序排列起来的元素所组成列表 123456789101112131415161718#普通的变量定义形式tom = \"Tom\"jack = \"Jack\"john = \"John\"pet1 = \"cat\"pet2 = \"dog\"pet3 = \"bird\"#定义列表，语法格式name = ['Tom','Jack','John']pet = ['cat','dog','bird'] #相比一个一个来定义会比较简洁，方便#打印列表print(name)print(pet)['Tom', 'Jack', 'John']['cat', 'dog', 'bird'] 用索引访问列表元素 12345678910#通过索引读取列表中的元素，索引从0开始，-1代表最后一个print(name[0])print(pet[2])Tombird #这些数字就是列表中排列的顺序，是从0开始，按照一定的顺序，以此类推#-1代表元素的最后一个，-2代表倒数第二个，以此类推print(name[-1])print(pet[-2])Johndog ¶列表的基本操作 修改： 通过索引获取元素，进行修改 添加： append(元素)：在列表末尾添加 insert(索引，元素)：在列表指定位置插入 删除： del：根据元素的索引删除元素，被删除的元素不可以在进行访问 pop()：删除列表末尾的元素 pop(索引)：弹出指定位置的元素，被删除的元素还能继续使用 remove(value)：根据元素的值进行删除 排序 sorted(列表)：临时排序 sort()：永久排序 sort(reverse=True)：倒序排序 len()：列表长度 修改列表的元素 1234#通过索引获取元素，进行修改name[1] = 'San'print(name)['Tom', 'San', 'John'] #之前定义的是Jack，现在修改成了San 向列表中添加元素 1234567891011121314#在列表末尾添加新元素name.append('Bob')print(name)['Tom', 'San', 'John', 'Bob']#在列表指定位置添加新元素print(pet)pet.insert(0,'penguin')print(pet)['cat', 'dog', 'bird']['penguin', 'cat', 'dog', 'bird']pet.insert(-2,'pig')print(pet)['penguin', 'cat', 'pig', 'dog', 'bird'] 删除列表中的元素 1234567891011121314151617181920212223242526272829303132333435363738394041#根据元素的索引删除元素print(pet)del pet[0]print(pet)['penguin', 'cat', 'pig', 'dog', 'bird']['cat', 'pig', 'dog', 'bird'] #使用del删除的元素不可以进行访问#删除列表末尾的元素print(pet)new_pet = pet.pop() #不加参数在表最后一个print(new_pet)print(pet)['cat', 'pig', 'dog', 'bird']bird['cat', 'pig', 'dog'] #弹出指定位置的元素print(pet)pet.pop(2)print(pet)['cat', 'pig', 'dog']['cat', 'pig']#访问刚才删除的值print(new_pet)bird#根据元素的值进行删除print(pet)pet.remove('cat')print(pet)['cat', 'pig']['pig']#删除一个不存在值pet.remove('d')print(pet)---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-16-086f691d7e32&gt; in &lt;module&gt; 1 #删除一个不存在值----&gt; 2 pet.remove('d') 3 print(pet)ValueError: list.remove(x): x not in list#删除的值必须是真实存在的，不然就会报错 列表排序 按照26个字母的顺序进行排序 12345678910111213141516171819202122232425#定义列表：汽车的品牌print('原始顺序：')brand = ['audi','bmw','toyota','byd','luhu']print(brand)#临时排序print('临时排序：')print(sorted(brand))print(brand)#永久排序print('永久排序：')brand.sort()print(brand)#倒序排序print('倒序排序：')brand.sort(reverse=True)print(brand)原始顺序：['audi', 'bmw', 'toyota', 'byd', 'luhu']临时排序：['audi', 'bmw', 'byd', 'luhu', 'toyota']['audi', 'bmw', 'toyota', 'byd', 'luhu'] #排完序之后就又变会原来的顺序了永久排序：['audi', 'bmw', 'byd', 'luhu', 'toyota']倒序排序：['toyota', 'luhu', 'byd', 'bmw', 'audi'] 获取列表的长度 123#获取列表的长度print(len(brand))5 常见错误：索引越界 比如说列表长度为5，也就是说索引最多到4 1234567891011#正确索引print(brand[4])audi#错误索引，索引越界print(brand[5])---------------------------------------------------------------------------IndexError Traceback (most recent call last)&lt;ipython-input-10-173eb23c555f&gt; in &lt;module&gt;----&gt; 1 print(brand[5])IndexError: list index out of range #索引错误，列表索引超出范围 ¶练习 列表练习（一） 定义一个列表，存储5个科目名称 新增科目（末尾新增&amp;指定位置新增） 修改科目 删除科目，并且在打印科目列表的时候，能够显示删除了哪个科目 删除指定名称的科目 删除第2个科目 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#1、定义一个列表，存储5个科目名称print('定义列表：')subjects = ['语文','数学','英语','物理','历史']print(subjects)#2、新增科目（末尾新增&amp;指定位置新增）#末尾新增print('末尾新增：')print(subjects)subjects.append('化学')print(subjects)#指定位置新增print('指定位置新增：')print(subjects)subjects.insert(0,'生物')print(subjects)#3、修改科目print('修改科目：')print(subjects)subjects[1] = '政治'print(subjects)#4、删除科目，并且在打印科目列表的时候，能够显示产出了哪个科目print('删除科目，并且显示删除了哪个科目：')print(subjects)new_subjects = subjects.pop()print(new_subjects)print(subjects)#5、删除指定名称的科目print('删除指定名称的科目：')print(subjects)subjects.remove('物理')print(subjects)#6、删除第二个科目print('删除第二个科目：')print(subjects)subjects.pop(1)print(subjects)---------------------------------------------------------------------------定义列表：['语文', '数学', '英语', '物理', '历史']末尾新增：['语文', '数学', '英语', '物理', '历史']['语文', '数学', '英语', '物理', '历史', '化学']指定位置新增：['语文', '数学', '英语', '物理', '历史', '化学']['生物', '语文', '数学', '英语', '物理', '历史', '化学']修改科目：['生物', '语文', '数学', '英语', '物理', '历史', '化学']['生物', '政治', '数学', '英语', '物理', '历史', '化学']删除科目，并且显示删除了哪个科目：['生物', '政治', '数学', '英语', '物理', '历史', '化学']化学['生物', '政治', '数学', '英语', '物理', '历史']删除指定名称的科目：['生物', '政治', '数学', '英语', '物理', '历史']['生物', '政治', '数学', '英语', '历史']删除第二个科目：['生物', '政治', '数学', '英语', '历史']['生物', '数学', '英语', '历史'] 列表练习（二） 将5个城市的名称存储到列表中，并且保证名称不是按照字母顺序排列的 打印出原始的城市列表信息 使用sorted()方法按字母顺序打印城市列表，但是不要修改列表元素的顺序 打印该列表，确认城市名称排列顺序没有被修改 使用sort()方法排列城市名称，确保永久性修改排列顺序 12345678910111213141516171819202122232425262728#1、将5个城市的名称存储带列表中，并且保证名称不是按照字母顺序排列的print('定义城市列表：')city = ['zhengzhou','shanghai','beijing','guangzhou','luoyang']#2、打印出来原始的城市列表信息print('原始列表信息：')print(city)#3、使用sorted()方法按字母顺序打印城市列表，但不要修改列表元素的顺序print('sorted()方法排序--临时排序：')print(city)print(sorted(city))#4、打印该列表，确认城市名称排序没有被修改print('验证城市名称排序没有被修改：')print(city)#5、使用sort()方法排序城市名称，确保永久性排列顺序print('使用sort()排序--永久排序：')city.sort()print(city)---------------------------------------------------------------------------定义城市列表：原始列表信息：['zhengzhou', 'shanghai', 'beijing', 'guangzhou', 'luoyang']sorted()方法排序--临时排序：['zhengzhou', 'shanghai', 'beijing', 'guangzhou', 'luoyang']['beijing', 'guangzhou', 'luoyang', 'shanghai', 'zhengzhou']验证城市名称排序没有被修改：['zhengzhou', 'shanghai', 'beijing', 'guangzhou', 'luoyang']使用sort()排序--永久排序：['beijing', 'guangzhou', 'luoyang', 'shanghai', 'zhengzhou']","categories":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/tags/Python/"}]},{"title":"Python数据类型之列表的进阶操作","slug":"Python数据类型之列表的进阶操作","date":"2020-03-12T16:00:00.000Z","updated":"2020-03-13T11:48:20.965Z","comments":true,"path":"Python数据类型之列表的进阶操作.html","link":"","permalink":"https://pdxblog.top/Python%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B9%8B%E5%88%97%E8%A1%A8%E7%9A%84%E8%BF%9B%E9%98%B6%E6%93%8D%E4%BD%9C.html","excerpt":"","text":"¶Python数据类型之列表的进阶操作 遍历 重复性的内容需要按照步骤，分步式的读取出来 对文件内容已经有相似结构的循环读取 for循环 魔法推导式 常见的错误：缩进错误、遗漏冒号 创建数值列表 range(参数1，参数2，参数3)：包头不包尾 ​ 参数1：起始值（包含自己） ​ 参数2：终止值（不包含自己） ​ 参数3：步长（间隔数） 创建数字列表 数字列表的简单统计计算{最大值：max()、最小值：min()、总和：sum() } 切片 把一段数据进行分割 遍历切片 复制列表(把某一个列表中的数据给别的一个，同样的制造一份出来) 元组 元组与列表的区别（列表的值可以修改，元组的值不可修改） 定义元组 修改元组变量 ¶遍历列表 123456789#定义一个列表names = [\"张三\",\"李四\",\"王五\",\"赵六\",\"田七\"]zhang_san = names[0]li_si = names[1]wang_wu = names[2]print(zhang_san+\" \"+li_si+\" \"+wang_wu)张三 李四 王五#想要读取某一个值，这样就很麻烦#使用for循环来读取，重复的有规律的读取内容 for循环 123456789for name in names: print(name,end=\" \")张三 李四 王五 赵六 田七#如果是英文的名字，还可以进行一些操作，比如说大小写转换names2 = [\"anlen\",\"bob\"]for name in names2: print(name.title())AnlenBob 魔法推导式 12[name for name in names2]-----------------------------------------------------------------------------------------['anlen', 'bob'] 常见的错误: 缩进错误 1234567names2 = [\"anlen\",\"bob\"]for name in names2:print(name.title()) #print没有缩进 File \"&lt;ipython-input-12-89d8b78a3789&gt;\", line 3 print(name.title()) ^IndentationError: expected an indented bloc #提示缩进错误 遗漏冒号 1234567names2 = [\"anlen\",\"bob\"]for name in names2 #遗漏冒号 print(name.title()) File \"&lt;ipython-input-13-ee6eafbd451b&gt;\", line 2 for name in names2 ^SyntaxError: invalid syntax #提示语法错误 ¶创建数值列表 123456#循环输出1到10nums = [1,2,3,4,5,6,7,8,9,10]for num in nums: print(num,end=\" \")1 2 3 4 5 6 7 8 9 10#这样会很麻烦，使用range()就会很方便 range(参数1，参数2，参数3)：包头不包尾 1234567891011121314for num in range(1,11): print(num,end=\" \")1 2 3 4 5 6 7 8 9 10#输出1-10之间的偶数for num in range(2,11,2): #cong2开始每次加2 print(num,end=\" \")#输出1-10之间的奇数for num in range(1,11,2): #从1开始每次加2 print(num,end=\" \")1 3 5 7 9#输出奇数的平方for num in range(1,11,2): print(num**2,end=\" \")1 9 25 49 81 创建数字列表 123numbers = list(range(1,11))print(numbers)[1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 数字列表的简单计算 1234567#数字列表的最大值、最小值、总和print(max(numbers))print(min(numbers))print(sum(numbers))10155 ¶切片 123#定义一个列表pets = [\"cat\",\"dog\",\"duck\",\"pig\"]print(pets) 把数据进行分割，截取特定的值 1234567891011121314151617181920212223#取开头pets[0] 'cat'#中间截取pets[1:3]['dog', 'duck']#全部截取pets[0:4]['cat', 'dog', 'duck', 'pig']#取最后pets[-1]'pig'#从开头到结尾pets[0:]['cat', 'dog', 'duck', 'pig']#从中间某一个到结尾pets[1:]['dog', 'duck', 'pig'] 遍历切片 123for pet in pets[-3:]: print(pet,end=\" \")dog duck pig 复制列表 1234567games = ['王者','吃鸡','英雄联盟']#friend_games = ['王者','吃鸡'] //这样代码创重复，是不可取的friend_games = games[:2]print('我喜欢的游戏有:'+str(games))print('我朋友喜欢的游戏有:'+str(friend_games)我喜欢的游戏有:['王者', '吃鸡', '英雄联盟']我朋友喜欢的游戏有:['王者', '吃鸡'] ¶元组 123456789101112131415161718192021222324252627#定义列表nums = [1,2,3]nums[0] = 9print(nums)#定义元组numbers = (4,5,6)numbers[0] = 10print(numbers)[9, 2, 3]---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-1-9b5931007d67&gt; in &lt;module&gt; 5 #定义元组 6 numbers = (4,5,6)----&gt; 7 numbers[0] = 10 8 print(numbers[0])TypeError: 'tuple' object does not support item assignment #tuple是只读，而不支持写 #证明元组的值是不能被修改的#但它的访问形式和列表一样print(nums[0])print(numbers[0])94for num in numbers: print(num,end=\" \")4 5 6 给元组变量赋值，打包给它换 12345print(numbers)numbers = (0,1,2)print(numbers)(4, 5, 6)(0, 1, 2) 但是有些地方的值是不允许改变的，也不能改变的，比如（性别），这就可以使用元组 123sex = (\"男\",\"女\")print(sex)('男', '女') #这个值就是固定的，不能被改，也没法该 在日常生活中，要确定内容是否要进行二次修改来决定使用元组，还是列表 ¶练习 批量生成50个C类IP–192.168.1.x 12345pre = '192.168.1.'for ip in list(range(1,51)): print(pre+str(ip),end= \" \")192.168.1.1 192.168.1.2 192.168.1.3 192.168.1.4 192.168.1.5 192.168.1.6 192.168.1.7 192.168.1.8 192.168.1.9 192.168.1.10 192.168.1.11 192.168.1.12 192.168.1.13 192.168.1.14 192.168.1.15 192.168.1.16 192.168.1.17 192.168.1.18 192.168.1.19 192.168.1.20 192.168.1.21 192.168.1.22 192.168.1.23 192.168.1.24 192.168.1.25 192.168.1.26 192.168.1.27 192.168.1.28 192.168.1.29 192.168.1.30 192.168.1.31 192.168.1.32 192.168.1.33 192.168.1.34 192.168.1.35 192.168.1.36 192.168.1.37 192.168.1.38 192.168.1.39 192.168.1.40 192.168.1.41 192.168.1.42 192.168.1.43 192.168.1.44 192.168.1.45 192.168.1.46 192.168.1.47 192.168.1.48 192.168.1.49 192.168.1.50 for的双重循环使用 使用口诀： 外层循环控制行数 内层循环控制列数 外层循环执行1次，内层循环执行1轮 打印数字直角三角形 12345678910111213for i in range(1,10): for j in range(i): print(j+1,end=\"\") print()112123123412345123456123456712345678123456789 打印九九乘法表 12345678910111213for i in range(1,10): for j in range(i): print(str(j+1)+\"x\"+str(i)+\"=\"+str(i*(j+1)),end=\" \") print()1x1=1 1x2=2 2x2=4 1x3=3 2x3=6 3x3=9 1x4=4 2x4=8 3x4=12 4x4=16 1x5=5 2x5=10 3x5=15 4x5=20 5x5=25 1x6=6 2x6=12 3x6=18 4x6=24 5x6=30 6x6=36 1x7=7 2x7=14 3x7=21 4x7=28 5x7=35 6x7=42 7x7=49 1x8=8 2x8=16 3x8=24 4x8=32 5x8=40 6x8=48 7x8=56 8x8=64 1x9=9 2x9=18 3x9=27 4x9=36 5x9=45 6x9=54 7x9=63 8x9=72 9x9=81","categories":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/tags/Python/"}]},{"title":"Python的变量和简单的数据类型","slug":"Python的变量和简单的数据类型","date":"2020-03-10T16:00:00.000Z","updated":"2020-03-11T09:59:20.859Z","comments":true,"path":"Python的变量和简单的数据类型.html","link":"","permalink":"https://pdxblog.top/Python%E7%9A%84%E5%8F%98%E9%87%8F%E5%92%8C%E7%AE%80%E5%8D%95%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.html","excerpt":"","text":"¶IPython介绍 ipython是一个python的交互式shell，比默认的python shell好用得多，支持变量自动补全，自动缩进，支持bash shell命令，内置了许多很有用的功能和函数。学习ipython将会让我们以一种更高的效率来使用python。同时它也是利用Python进行科学计算和交互可视化的一个最佳的平台 IPython提供了两个主要的组件： 一个强大的python交互式shell 供Jupyter notebooks使用的一个Jupyter内核（IPython notebook） IPython的主要功能如下： 运行ipython控制台 使用ipython作为系统shell 使用历史输入(history) Tab补全 使用%run命令运行脚本 使用%timeit命令快速测量时间 使用%pdb命令快速debug 使用pylab进行交互计算 使用IPython Notebook 安装IPython ipython支持Python2.7版本或者3.3以上的版本，我用的是windows下的python 3.8.2版本。 安装ipython很简单，可以直接使用pip管理工具即可: 1C:\\Users\\Admin&gt;pip3 install ipython 下载太慢可以使用国内镜像： 1C:\\Users\\Admin&gt;pip3 install -i https://pypi.douban.com/simple ipython 查看当前库 1234567891011121314151617181920C:\\Users\\Admin&gt;pip3 listPackage Version---------------- -------backcall 0.1.0colorama 0.4.3decorator 4.4.2ipython 7.13.0ipython-genutils 0.2.0jedi 0.16.0parso 0.6.2pickleshare 0.7.5pip 19.2.3prompt-toolkit 3.0.4Pygments 2.6.1setuptools 41.2.0six 1.14.0traitlets 4.3.3wcwidth 0.1.8WARNING: You are using pip version 19.2.3, however version 20.0.2 is available.You should consider upgrading via the 'python -m pip install --upgrade pip' command. 根据提示更新下载源 1C:\\Users\\Admin&gt;python3 -m pip install --upgrade pip 更显失败的利用豆瓣镜像源更新 1C:\\Users\\Admin&gt;python -m pip install --upgrade pip -i https://pypi.douban.com/simple 交互式使用IPython IPython支持所有python的标准输入输出，也就是我们在IDLE中或者Python shell中能用的，在IPython中都能够使用，唯一的不同之处使ipython会使用In [x]和Out [x]表示输入输出，并表示出相应的序号 12345678910#在cmd窗口输出ipython即可C:\\Users\\Admin&gt;ipythonPython 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)]Type 'copyright', 'credits' or 'license' for more informationIPython 7.13.0 -- An enhanced Interactive Python. Type '?' for help.In [1]: print('hello python!')hello python!#退出In [2]: exit ¶Jupyter Notebook介绍 Jupyter Notebook是基于网页的用于交互计算的应用程序。其可被应用于全过程计算：开发、文档编写、运行代码和展示结果。——Jupyter Notebook官方介绍 简而言之，Jupyter Notebook是以网页的形式打开，可以在网页页面中直接编写代码和运行代码，代码的运行结果也会直接在代码块下显示。如在编程过程中需要编写说明文档，可在同一个页面中直接编写，便于作及时的说明和解释 组成部分 1、网页应用 网页应用即基于网页形式的、结合了编写说明文档、数学公式、交互计算和其他富媒体形式的工具。简言之，网页应用是可以实现各种功能的工具 2、文档 即Jupyter Notebook中所有交互计算、编写说明文档、数学公式、图片以及其他富媒体形式的输入和输出，都是以文档的形式体现的。 这些文档是保存为后缀名为.ipynb的JSON格式文件，不仅便于版本控制，也方便与他人共享。 此外，文档还可以导出为：HTML、LaTeX、PDF等格 Jupyter Notebook的主要特点 编程时具有语法高亮、缩进、tab补全的功能。 可直接通过浏览器运行代码，同时在代码块下方展示运行结果。 以富媒体格式展示计算结果。富媒体格式包括：HTML，LaTeX，PNG，SVG等。 对代码编写说明文档或语句时，支持Markdown语法。 支持使用LaTeX编写数学性说明 安装Jupyter Notebook 安装前提 安装Jupyter Notebook的前提是需要安装了Python（3.3版本及以上，或2.7版本 使用pip命令安装 1C:\\Users\\Admin&gt;pip3 install -i https://pypi.douban.com/simple jupyter 运行Jupyter Notebook 1C:\\Users\\Admin&gt;jupyter notebook 执行命令之后，在终端中将会显示一系列notebook的服务器信息，同时浏览器将会自动启动Jupyter Notebook 启动过程中终端显示内容如下： 123456789101112[I 19:14:50.207 NotebookApp] Serving notebooks from local directory: F:\\python1\\1[I 19:14:50.208 NotebookApp] The Jupyter Notebook is running at:[I 19:14:50.208 NotebookApp] http://localhost:8888/?token=c3ac105eef676358b314723d6d56a53ca773fac409c6fac8[I 19:14:50.208 NotebookApp] or http://127.0.0.1:8888/?token=c3ac105eef676358b314723d6d56a53ca773fac409c6fac8[I 19:14:50.208 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[C 19:14:50.227 NotebookApp] To access the notebook, open this file in a browser: file:///C:/Users/Admin/AppData/Roaming/jupyter/runtime/nbserver-6444-open.html Or copy and paste one of these URLs: http://localhost:8888/?token=c3ac105eef676358b314723d6d56a53ca773fac409c6fac8 or http://127.0.0.1:8888/?token=c3ac105eef676358b314723d6d56a53ca773fac409c6fac8 注意：之后在Jupyter Notebook的所有操作，都请保持终端不要关闭，因为一旦关闭终端，就会断开与本地服务器的链接，你将无法在Jupyter Notebook中进行其他操作啦 如果你同时启动了多个Jupyter Notebook，由于默认端口“8888”被占用，因此地址栏中的数字将从“8888”起，每多启动一个Jupyter Notebook数字就加1，如“8889”、“8890”…… 启动服务器不打开浏览器 如果你只是想启动Jupyter Notebook的服务器但不打算立刻进入到主页面，那么就无需立刻启动浏览器。在终端中输入 1F:\\python1\\1&gt;jupyter notebook --no-browser 此时，将会在终端显示启动的服务器信息，并在服务器启动之后，显示出打开浏览器页面的链接。当你需要启动浏览器页面时，只需要复制链接，并粘贴在浏览器的地址栏中，轻按回车变转到了你的Jupyter Notebook页面 12345678910111213F:\\python1\\1&gt;jupyter notebook --no-browser[I 19:17:51.674 NotebookApp] Serving notebooks from local directory: F:\\python1\\1[I 19:17:51.675 NotebookApp] The Jupyter Notebook is running at:[I 19:17:51.675 NotebookApp] http://localhost:8888/?token=703a6064cab58c5fe00f63133ee3dd55573fb09cf6fae2d4[I 19:17:51.675 NotebookApp] or http://127.0.0.1:8888/?token=703a6064cab58c5fe00f63133ee3dd55573fb09cf6fae2d4[I 19:17:51.675 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[C 19:17:51.678 NotebookApp] To access the notebook, open this file in a browser: file:///C:/Users/Admin/AppData/Roaming/jupyter/runtime/nbserver-7204-open.html Or copy and paste one of these URLs: http://localhost:8888/?token=703a6064cab58c5fe00f63133ee3dd55573fb09cf6fae2d4 or http://127.0.0.1:8888/?token=703a6064cab58c5fe00f63133ee3dd55573fb09cf6fae2d4 浏览器输入：http://localhost:8888就可以访问 根据终端的提示输入token 123Or copy and paste one of these URLs: http://localhost:8888/?token=703a6064cab58c5fe00f63133ee3dd55573fb09cf6fae2d4 or http://127.0.0.1:8888/?token=703a6064cab58c5fe00f63133ee3dd55573fb09cf6fae2d4 这个目录取决于你在哪个目录下启动的 ¶安装完成后就开始使用 ¶什么是变量： 简单理解来说就是，起一个名字用等于号给它赋予一个值，这就是变量（固定不变的量叫做常量） 1234567891011121314151617#定义变量sum1 = 0 #定义变量2sum2 = 1 #定义变量2print(sum1) #输出定义的变量10print(sum2) #输出定义的变量21#也可以一次定义多个变量a,b,c = 1,2,3print(a)1print(b)2print(c)3print(a,b,c)1 2 3 变量的用法有什么好处： 在某种程度上可以实现代码的复用 123456789101112131415161718192021222324252627#需要很多地方都用到这个数据，而且这些数据还会存放在计算机内，占用内存print('北京欢迎你')print('北京欢迎你')print('北京欢迎你')print('北京欢迎你')print('北京欢迎你')print('北京欢迎你')北京欢迎你北京欢迎你北京欢迎你北京欢迎你北京欢迎你北京欢迎你#定义一个变量message=\"北京欢迎你\"，message就比北京欢迎你占的字符小，占用内存也小message = \"北京欢迎你\"print(message)print(message)print(message)print(message)print(message)print(message)北京欢迎你北京欢迎你北京欢迎你北京欢迎你北京欢迎你北京欢迎你 变量的命令规则： 只能包换字母、数字、下划线，但是不能以数字打头 不能包含空格，但是可以用下划线分隔其中的单词 不能使用Python关键字和函数的名称用作变量，比如：import、class、and、return、def、from …等等 变量名应该简短并且见名之意 慎用小写字母 i 和大写字母 O（容易和数字混淆的字母） 只能包换字母、数字、下划线，但是不能以数字打头 1234567891011121314#错误例子$a=89$a File \"&lt;ipython-input-6-cf2d0c5b3bb7&gt;\", line 1 $a=89 ^SyntaxError: invalid #非法的输入#数字开头也不行1a=891a File \"&lt;ipython-input-7-e78e6d530639&gt;\", line 1 1a=89 ^SyntaxError: invalid syntax 不能包含空格，但是可以用下划线分隔其中的单词 1234567891011#包换空格示例a b=89a b File \"&lt;ipython-input-9-1917d5b6e6ca&gt;\", line 1 a b=89 ^SyntaxError: invalid syntax#以下划线分隔a_b=89a_b89 不能使用Python关键字和函数的名称用作变量 比如：import、class、and、return、def、from …等等 1234567891011import = 'ere' File \"&lt;ipython-input-11-58ece2b8d285&gt;\", line 1 import = 'ere' ^SyntaxError: invalid syntaxand = \"ddd\" File \"&lt;ipython-input-13-9498d9360549&gt;\", line 1 and = \"ddd\" ^SyntaxError: invalid syntax#只要变量名称是绿色或者是红色的就不能使用 变量名应该简短并且见名之意 12345num1=1num2=2teacher_name = \"苏珊\" #老师的名字student_name = \"吉米\" #学生的名字lengh_of_student = 2 #学生名字的长度 慎用小写字母 i 和大写字母 O 1234l=1 #小写L=数字1O=0 #大写O=数字0i=1 #小写I=数字1#这些容以与数字混淆的慎用 使用常见的错误： 变量未定义就使用 12345678print=(num)---------------------------------------------------------------------------NameError Traceback (most recent call last)&lt;ipython-input-15-f827eafea48a&gt; in &lt;module&gt;----&gt; 1 print=(num)NameError: name 'num' is not defined#变量要定义后再进行使用 ¶Python常用的数据类型 1、字符串 Python中的字符串类型是一组包含数字、字母和符号的集合，作为一个整体使用 字符串的表达形式 在Python中有三种表示字符串的方式，单引号、双引号、三引号 123456789101112131415161718str1 = 'hello'str2 = \"world\"str3 = '''春眠不觉晓处处闻啼鸟夜来风雨声花落知多少'''print(str1)print(str2)print(str3)helloworld春眠不觉晓处处闻啼鸟夜来风雨声花落知多少 需要注意的是，单引号和双引号的作用是一样的，可以根据习惯使用，但是定义多行文字时，必须要使用三引号 使用字符串的注意事项 字符串的定义方式单引号、双引号、三引号大部分情况下作用是相同的，但在特殊情况下使用也有所区别，下面是需要注意的地方 单引号、双引号、三引号它们是成对出现的，如以单引号开头就要以单引号结尾，不能混合使用表示字符串 如果字符串中单独出现单引号或双引号，可以使用另一种引号定义 当字符串中出现单引号、双引号等特殊字符时，还可以使用转义字符定义。Python中的转移字符是“\\”，只要在特殊字符前面加上“\\”，就可以原样输出，而不用去管定义字符串使用的是单引号还是双引号 字符串的常用方法 修改字符串大小写（title、upper、lower） 拼接字符串（+、函数str() ） 添加空白（空格、换行符：\\n、水平制表位：\\t、end=’’：不进行换行直接连起来） 删除空白(开头：lstrip()、末尾：retrip()、两端：strip() ) 修改字符串大小写 1234567name = \"ad loveLace\"print(name.title()) #首字母大写print(name.upper()) #全部大写print(name.lower()) #全部小写Ad LovelaceAD LOVELACEad lovelace 拼接字符串 1234#将name与要定义的age拼接起来age = 18print('我叫'+name+',今年'+str(age)+'岁')我叫ad loveLace,今年18岁 PS：print输出的默认是字符串，而定义的age的值是数字，所以需要函数str() 将数字转化为字符串类型，不然会报错（TypeError: can only concatenate str (not &quot;int&quot;) to str） 添加空白 123456789101112131415161718192021222324#让18岁之间有空格age = 18print('我叫'+name+',今年 '+str(age)+' 岁')我叫ad loveLace,今年 18 岁#换行符：\\nage = 18print('我叫'+name+',\\n今年 '+str(age)+' 岁')我叫ad loveLace,今年 18 岁#水平制表为\\tage = 18print('我叫\\t'+name+',\\n今年 '+str(age)+' 岁')我叫 ad loveLace,今年 18 岁#end=''//先来看看不是使用end=''的效果print('我叫'+name+',')print('今年 '+str(age)+' 岁')我叫ad loveLace,今年 18 岁 #输出为了两行//使用end=''将两行连起来print('我叫'+name+',',end='')print('今年 '+str(age)+' 岁')我叫ad loveLace,今年 18 岁 删除空白 比如说在登录帐户的时候，一不小心手一抖多了个空格，但是是不允许有空格的，这时候就用到了删除空白 12345678910#定义变量，值的坐中又均有空格content = \" test demon \"print(content) #没有改变的情况print(content.lstrip()) #去掉左边的空格print(content.rstrip()) #去掉右边的空格print(content.strip()) #去掉两边的空格 test demontest demon test demontest demon 常见的错误 单引号里面含撇号 12345say = 'Let'go!' File \"&lt;ipython-input-28-5ccc2ed9867a&gt;\", line 1 say = 'Let'go!' ^SyntaxError: invalid syntax 如果引号里面需要用到撇号或着双引号，可以使用不用的引号引用 123456789101112#双引号里套撇号say_content = \"Lest'go!\"print(say_content)Lest'go!#三引号里套撇号s= '''Let'go!''' #这个就有点大材小用了，尽量别这样print(s)Let'go!#单引号里套双引号d = '\"This is my book!\"'print(d)\"This is my book!\" 2、数字 数字类型包括整型、浮点型、布尔型等，声明时由Python内置的基本数据类型来管理变量，在程序的后台实现数值与类型的关联，以及转换等操作。根据变量的值自动判断变量的类型，我们无需关心变量空间是什么类型，只要知道创建的变量中存放了一个数，程序只是对这个数值进行操作 123456789101112num1 = 8num2 = 0.5print(num1+num2)print(num1-num2)print(num1*num2)print(num1/num2)print(num1%num28.57.54.016.00.0 注释（#号和三引号） 12345678910111213141516'''以下代码是关于Python数据类型的演示案例'''#Python中的数字类型num1 = 8num2 = 0.5print(num1+num2)print(num1-num2)print(num1*num2)print(num1/num2)print(num1%num2)8.57.54.016.00.0 ¶小练习 1、将用户的姓名存到一个变量中，并向该用户显示一条信息，显示内容为：“你好，艾瑞克，今天的Python课你学到东西了吗？” 123name = \"艾瑞克\"print('你好，'+name+',今天的Python课你学到东西了吗')你好，艾瑞克,今天的Python课你学到东西了吗 2、将一个人的名字存到变量中，再以小写、大写和首字母大写的方式显示这个人的名字 1234567noe_name = \"mike\"print(noe_name.lower())print(noe_name.upper())print(noe_name.title())mikeMIKEMike 3、按一下格式打印诗词： 《自由》 为人进出的门紧锁着; 想死的门敞开着。 有个病毒在外面高喊着: “出来玩吧，给你自由！” 但我深深地知道…… 出去了，不一定还能回来。 人的生命只有一次， 算球了， 再关十几天就自由了！ 1234567891011121314151617181920212223poem = '''《自由》 为人进出的门紧锁着;想死的门敞开着。有个病毒在外面高喊着:“出来玩吧，给你自由！”但我深深地知道……出去了，不一定还能回来。人的生命只有一次，算球了，再关十几天就自由了！'''print(poem)《自由》 为人进出的门紧锁着;想死的门敞开着。有个病毒在外面高喊着:“出来玩吧，给你自由！”但我深深地知道……出去了，不一定还能回来。人的生命只有一次，算球了，再关十几天就自由了","categories":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/tags/Python/"}]},{"title":"Jenkins+GitLba针对k8s集群持续集成","slug":"Jenkins+GitLba针对k8s集群持续集成","date":"2020-03-08T16:00:00.000Z","updated":"2020-10-20T08:54:45.969Z","comments":true,"path":"Jenkins+GitLba针对k8s集群持续集成.html","link":"","permalink":"https://pdxblog.top/Jenkins+GitLba%E9%92%88%E5%AF%B9k8s%E9%9B%86%E7%BE%A4%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90.html","excerpt":"","text":"¶Jenkins+GitLba针对k8s集群持续集成 持续集成概念 持续集成Continuous Integration ​ 持续集成是指开发者在代码的开发过程中，可以频繁的将代码部署集成到主干，并进程自动化测试 持续交付Continuous Delivery ​ 持续交付指的是在持续集成的环境基础之上，将代码部署到预生产环境 持续部署Continuous Deployment ​ 在持续交付的基础上，把部署到生产环境的过程自动化，持续部署和持续交付的区别就是最终部署到生产环境是自动化的 环境准备 k8s集群环境，三台服务器，IP分别为：192.168.1.70（master）、50（node01）、40（node02） Jenkins+GitLab部署在一台Docker服务器上（192.168.1.30），主要用于向仓库上传私有镜像 环境一共4台服务器，全部指向一个私有仓库，共享Docker镜像 实验所用到的软件都可以在网盘下载： 下载地址 提取码：trv8 验证k8s集群没有问题 12345[root@master ~]# kubectl get nodes NAME STATUS ROLES AGE VERSIONmaster Ready master 64d v1.15.0node01 Ready &lt;none&gt; 64d v1.15.0node02 Ready &lt;none&gt; 64d v1.15.0 首先我们需要做一个registry私有仓库，可以选择任意一台服务器都可以，这里我们选择kubernetes-master作为registry私有仓库 Harbor也是可以的 123456789[root@master ~]# docker run -d --restart=always -p 5000:5000 registry:2[root@master ~]# vim /usr/lib/systemd/system/docker.serviceExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.70:5000[root@master ~]# systemctl daemon-reload [root@master ~]# systemctl restart docker#将nginx镜像上传到私有仓库[root@master ~]# docker pull nginx[root@master ~]# docker tag nginx:latest 192.168.1.70:5000/nginx:v1[root@master ~]# docker push 192.168.1.70:5000/nginx:v1 node01、node02加入私有仓库，并拉去镜像 123456789#注意实在那台机器上操作[root@master ~]# scp /usr/lib/systemd/system/docker.service node01:/usr/lib/systemd/system/docker.service [root@master ~]# scp /usr/lib/systemd/system/docker.service node02:/usr/lib/systemd/system[root@node01 ~]# systemctl daemon-reload [root@node01 ~]# systemctl restart docker[root@node02 ~]# systemctl daemon-reload [root@node02 ~]# systemctl restart docker[root@node01 ~]# docker pull 192.168.1.70:5000/nginx:v1[root@node02 ~]# docker pull 192.168.1.70:5000/nginx:v1 建立yaml配置文件让k8s自己控制容器集群，用来模拟我们部署的服务 123456789101112131415161718192021222324252627[root@master ~]# vim nginx.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginxspec: replicas: 2 template: metadata: labels: name: nginx spec: containers: - name: nginx image: 192.168.1.70:5000/nginx:v1 imagePullPolicy: Always ports: - containerPort: 80[root@master ~]# kubectl apply -f nginx.yaml deployment.extensions/nginx created[root@master ~]# kubectl get deployments.NAME READY UP-TO-DATE AVAILABLE AGEnginx 2/2 2 2 61s[root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGEnginx-57b9fd468d-dn2v7 1/1 Running 0 29snginx-57b9fd468d-q5qm6 1/1 Running 0 29s 容器的ip只能在容器本机上访问，集群内的其他主机和集群外的主机都没办法访问，这个时候就需要将容器的端口映射到服务器上的端口了，所以需要做一个service的模板。service 模板可以将容器的端口映射到服务器的端口上，并且可以固定映射在服务器上的端口 12345678910111213141516171819[root@master ~]# vim nginx-svc.yamlapiVersion: v1kind: Servicemetadata: name: nginxspec: type: NodePort ports: - port: 80 targetPort: 80 nodePort: 31234 selector: name: nginx[root@master ~]# kubectl apply -f nginx-svc.yaml service/nginx created[root@master ~]# kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 64dnginx NodePort 10.105.100.181 &lt;none&gt; 80:31234/TCP 6s 浏览器访问测试：192.168.1.70:31234 kubernetes完毕，开始配hijenkins+gitlab联动 基本环境准备 12345678910111213[root@localhost ~]# hostnamectl set-hostname autoweb[root@localhost ~]# systemctl disable firewalld[root@localhost ~]# systemctl stop firewalld[root@localhost ~]# setenforce 0setenforce: SELinux is disabled[root@localhost ~]# vim /etc/selinux/configSELINUX=disabled[root@localhost ~]# bash#加入私有仓库[root@autoweb ~]# vim /usr/lib/systemd/system/docker.serviceExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.70:5000[root@autoweb ~]# systemctl daemon-reload[root@autoweb ~]# systemctl restart docker 首先安装jenkins 1234567891011121314151617#配置java环境[root@autoweb ~]# tar zxf jdk-8u231-linux-x64.tar.gz [root@autoweb ~]# mv jdk1.8.0_231 /usr/java #注意这里的位置，不要多一个“/”#配置环境变量[root@autoweb ~]# vim /etc/profile#在最后一行添加以下内容export JAVA_HOME=/usr/javaexport JRE_HOME=/usr/java/jreexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATHexport CLASSPATH=$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar#使环境变量生效[root@autoweb ~]# source /etc/profile#验证环境变量[root@autoweb ~]# java -versionjava version \"1.8.0_231\"Java(TM) SE Runtime Environment (build 1.8.0_231-b11)Java HotSpot(TM) 64-Bit Server VM (build 25.231-b11, mixed mode) 部署tomcat，将jenkins的包放进tomcat里 123456789101112131415161718192021[root@autoweb ~]# tar zxf apache-tomcat-7.0.54.tar.gz [root@autoweb ~]# mv apache-tomcat-7.0.54 /usr/tomcat7[root@autoweb ~]# cd /usr/tomcat7/webapps/[root@autoweb webapps]# rm -rf *[root@autoweb webapps]# cp /root/jenkins.war .#修改tomcat的字符集[root@autoweb webapps]# vim /usr/tomcat7/conf/server.xml#在72行左右追加 &lt;Connector port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" URIEncoding=\"UTF-8\" /&gt;#修改启动脚本，添加jenkins的家目录，这个很重要[root@autoweb webapps]# cd /usr/tomcat7/bin/[root@autoweb bin]# vim catalina.sh#!/bin/shexport CATALINA_OPTS=\"-DJENKINS_HOME=/data/jenkins -Djava.awt.headless=true\"export JENKINS_JAVA_OPTIONS=\"-Dhudson.ClassicPluginStrategy.noBytecodeTransformer=true\"#启动tomcat[root@autoweb bin]# ./catalina.sh start[root@autoweb bin]# netstat -anput | grep 8080tcp6 0 0 :::8080 :::* LISTEN 6266/java 浏览器访问：192.168.1.30:8080/jenkins开始配置安装jenkins 根据提示查看密码并输入 12[root@autoweb bin]# cat /data/jenkins/secrets/initialAdminPassword7ea904846c9c4cfbb19d3e31d22f889f 左边是自动安装， 右边是自定义安装，如果不是这个画面则说明网络很卡或者没有网，网速可以的就选择左边的 由于网络问题，下载插件会非常慢，这里我就不下载，回到上一步，断网之后再点继续，跳过插件安装 断网之后，它会等待网络连接，过程有点慢，但是比自动下载插件快多了 在创建用户名密码的时候就可以联网了 然后一路默认就行 因为没有安装，所以就导入插件 插件存放目录：/data/jenkins/plugins 1234567#将原来的插件目录删除[root@autoweb jenkins]# rm -rf plugins/#导入下载好的插件，并解压[root@autoweb jenkins]# tar zxf plugins.tar.gz#重新运行jenkins，让它自动识别新导入的插件[root@autoweb bin]# ./catalina.sh stop[root@autoweb bin]# ./catalina.sh start 使用浏览器重新访问 因为很多插件需要翻墙才可以继续下载，Jenkins还提供了代理的设置 设置插件的国内下载地址 在Jenkins插件管理-高级设置界面，定位到页面最底部中的【升级站点】模块，将对应URL输入框中的url的https修改为http，即http://updates.jenkins.io/update-center.json，然后点击【提交】保存修改项 往下拉，找到插件管理 点击高级 还需要安装三个插件 因为在我导入的插件里就有这三个，所以不需要安装，如果选择推荐安装的可以搜索并安装这三个插件 点击可选插件，搜索GitLab就能找到，然后直接安装即可（搜索的时候注意大小写区分） jenkis安装完成以后，再去安装gitlab 12345[root@autoweb ~]# yum -y install curl policycoreutils openssh-server openssh-clients postfix git[root@autoweb ~]# systemctl enable sshd[root@autoweb ~]# systemctl start sshd[root@autoweb ~]# systemctl enable postfix[root@autoweb ~]# systemctl start postfix 安装gitlab-ce 1[root@autoweb ~]# curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash 因为网络问题，就不使用这种方式，国内的用户，使用清华大学的镜像进行安装 12345678910111213#编写yum源[root@autoweb ~]# vim /etc/yum.repos.d/gitlab-ce.repo[gitlab-ce]name=gitlab-cebaseurl=http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7repo_gpgcheck=0gpgcheck=0enabled=1gpgkey=https://packages.gitlab.com/gpg.key#将gitlab源加入yum[root@autoweb ~]# yum makecache #下载安装gitlab，这个软件包有点大，需要点时间[root@autoweb ~]# yum -y install gitlab-ce 修改端口防止端口冲突，默认是80端口，unicorn默认是8080 也是tomcat的端口 12345[root@autoweb ~]# vim /etc/gitlab/gitlab.rb#在29行左右的地方进行修改和追加external_url 'http://192.168.1.30:90'unicorn['listen'] = '127.0.0.1'unicorn['port'] = 3000 启动gitlab，这个过程可能会有点慢 1[root@autoweb ~]# gitlab-ctl reconfigure 浏览器访问：192.168.1.30:90 设置密码登录gitlab 默认用户名是root jenkins：工具集成平台 gitlab：软件托管平台 部署这两个服务的联动，需要经过ssh验证 首先我们需要在gitlab上绑定jenkins服务器的ssh公钥，因为是在同一台服务器上，所以就自己给自己绑定，这里我们使用的是root用户的公私钥，切记生产环境是不允许随便用root的 1234[root@autoweb ~]# ssh-keygen -t rsa #一路回车即可#复制公钥[root@autoweb ~]# cat /root/.ssh/id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC0PGtK/uFWejdLYfEqEGiimWrpndlkMZMNyvMisdCvWYU2E2UKxpr/h/QCZQpgpe7uAPZpivnsu3XZ4pE4qe7WG4iKEqF6oVmJL9JjmNh86vOUDGttOU3aZJnLp95yoYczBUSObNsSAzkHIMR2u0Zk5nFW2Roe2FHNUyj0e2qM/Zm5+M5EVgpHd9UG5A4Z/Loid/got6Xaufoen1hSFY+S18QPuheN1auaTfnyA0wwf+rlWjqwCLJeUBl0PgOgNNyZ27++U6QBUPNwgC3SVdhbJMCFE9/H2+0aMnjVqnakfJmt95UI/QOJAmnrusps/XPbqdnxZ5u89i97QxuogAgL root@autoweb 在gitlab上导入公钥 新建一个代码仓库 输入一个仓库的名字 权限选择公共的（public）然后直接点击创建 点击新建一个new.file 写入代码，起一个名字然后保存 将项目克隆到本地测试是否可用 123456[root@autoweb ~]# git clone git@192.168.1.30:root/test.git[root@autoweb ~]# cd test/[root@autoweb test]# lsindex.html[root@autoweb test]# cat index.html print: \"hello world!!!\" 测试没有问题 打开jenkins，新建任务 地址粘贴进去后没有报错则没错 下面的这个插件很重要，就是他实现自动化更新的webhook插件，安装过了就会有这条，然后点击这条下面出来的这些东西保持默认就行。同时注意复制 这个里面写的是jenkins构建时候会执行的shell脚本，这个是最重要的，就是他实现了下端kubernetes自动更新容器的操作 代码内容 123456789101112#!/bin/bashbackupcode=\"/data/backcode/$JOB_NAME/$BUILD_NUMBER\"mkdir -p $backupcodechmod 644 \"$JENKINS_HOME\"/workspace/\"$JOB_NAME\"/*rsync -acP \"$JENKINS_HOME\"/workspace/\"$JOB_NAME\"/* $backupcodeecho From 192.168.1.70:5000/nginx:v1 &gt; \"$JENKINS_HOME\"/workspace/Dockerfileecho COPY ./\"$JOB_NAME\"/* /usr/share/nginx/html/ &gt;&gt; \"$JENKINS_HOME\"/workspace/Dockerfiledocker rmi 192.168.1.70:5000/nginx:v1docker build -t 192.168.1.70:5000/nginx:v1 /\"$JENKINS_HOME\"/workspace/.docker push 192.168.1.70:5000/nginx:v1ssh root@192.168.1.70 kubectl delete deployment nginxssh root@192.168.1.70 kubectl apply -f /root/nginx.yaml 复制地址去gitlab上绑定webhook 保存，登录gitlab，点击下图这个设置 将复制的地址粘贴 往下拉，去掉ssh验证，添加webhook 出现报错，提示本地连接不了，因为gitlab默认设置不允许想自己发送web hook 解决办法 保存之后重试，成功的如下图所示 测试jenkins与gitlab连通 403报错的，解决办法 回到Jenkins开启匿名访问权限 点击全局安全配置 保存之后再点击系统设置 去掉勾选 保存之后，回到gitlab上再次测试 出现蓝条说明jenkins已经连通gitlab jenkins和gitlab 都已经互相的ssh通过了，然后我们最后需要做的一个ssh是关于jenkins 这里是从autoweb向master节点做免密登录 1[root@autoweb ~]# ssh-copy-id root@192.168.1.70 环境全部部署完毕！！！开始测试 立即构建 构建完成之后查看网页的变化 回到Gitlab更新代码测试 通过web hook这个插件会自动识别代码的更新，然后自动构建保证实时同步，持续集成 再次查看网页的变化 构建的历史版本的存放目录：/data/backcode/test 123456789[root@autoweb test]# pwd/data/backcode/test[root@autoweb test]# ls1 2 3 4 5#还有一个关键的目录，这个目录下是将新代码构建成镜像的关键，他和上个目录实时同步[root@autoweb workspace]# pwd/data/jenkins/workspace[root@autoweb workspace]# lsDockerfile test 构建的历史版本的存放目录：/data/backcode/test 123456789[root@autoweb test]# pwd/data/backcode/test[root@autoweb test]# ls1 2 3 4 5#还有一个关键的目录，这个目录下是将新代码构建成镜像的关键，他和上个目录实时同步[root@autoweb workspace]# pwd/data/jenkins/workspace[root@autoweb workspace]# lsDockerfile test 测试完成 关于 kubernetes 还有好几种集群管理方法，我们这次用的 deployment模板 就是其中之一， 其他的还有pod 模板 和 rc 模板， 这些都是功能很强大的集群调度模板。 还有更多功能待开发","categories":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]},{"title":"Python的认识与安装","slug":"Python的认识与安装","date":"2020-03-08T16:00:00.000Z","updated":"2020-03-10T12:41:07.527Z","comments":true,"path":"Python的认识与安装.html","link":"","permalink":"https://pdxblog.top/Python%E7%9A%84%E8%AE%A4%E8%AF%86%E4%B8%8E%E5%AE%89%E8%A3%85.html","excerpt":"","text":"¶初识Python 人生苦短，我用Python Python的由来： 1989年圣诞节期间，在阿姆斯特丹，Guido为了打发圣诞节的无趣，决心开发一 个新的脚本解释程序，作为ABC语言的一种继承。 Python是一种跨平台的计算机程序设计语言。是一种面向对象的动态类型语言， 最初被设计用于编写自动化脚本，随着版本的不断更新和语言新功能的添加，越 多被用于独立的、大型项目的开发 Python的应用领域 web全栈 算法工程师 人工只能 游戏开发 机器学习 信息安全 网络爬虫 自动化测试 数据分析 自动化运维 Python语言特点 简单易学 语法优美 丰富强大的库 开发效率高 应用领域广泛 ¶安装python 1、windows系统 下载地址： https://www.python.org/ftp/python/3.8.2/python-3.8.2-amd64.exe 如果感觉下载太慢，这里附上网盘连接 提取码：tp9n 也可以去python官网下载想要的版本 注意事项： 默认安装没有勾选“自动添加python的环境变量” 不要把python抽象安装到含有中文的目录中 双击安装，勾选两个选项，选择第二个自定义安装 默认就行，直接Next 自定义目录禁止中文目录安装，选择目录之后，直接Install 检查python是否安装成功: 12345678C:\\Users\\Admin&gt;pythonPython 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)] on win32Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; print ('hello python.')hello python.&gt;&gt;&gt; exit()C:\\Users\\Admin&gt; 退出python的两种方法 ctrl+z 回车 exit() Python目录介绍 Python二进制文件的启动目录：F:\\Python Python库的安装命令端：F:\\Python\\Scripts 2、linux系统 Linux环境自带了Python 2.x版本，但是如果要更新到3.x的版本，可以在Python的官方网站下载Python的源代码并通过源代码构建安装的方式进行安装，具体的步骤如下所示（以CentOS为例） 1）安装依赖库（因为没有这些依赖库可能在源代码构件安装时因为缺失底层依赖库而失败） 1[root@python ~]# yum -y install wget gcc zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel libffi-devel 这一步可能会出现以下错误： 1234567已加载插件：fastestmirror, langpacks/var/run/yum.pid 已被锁定，PID 为 15320 的另一个程序正在运行。Another app is currently holding the yum lock; waiting for it to exit... 另一个应用程序是：PackageKit 内存：120 M RSS （546 MB VSZ） 已启动： Fri Dec 27 15:48:54 2019 - 09:04之前 状态 ：睡眠中，进程ID：15320 解决办法： 1[root@python ~]# rm -rf /var/run/yum.pid 2）下载python源代码并解压 12[root@python ~]# wget https://www.python.org/ftp/python/3.8.1/Python-3.8.1.tgz[root@python ~]# tar zxf Python-3.8.1.tgz 3）设置全局变量 12[root@python ~]# export LANG=zh_CN.UTF-8[root@python ~]# export LANGUAGE=zh_CN.UTF-8 否则可能会出现以下错误 1234generate-posix-vars failedmake[1]: *** [pybuilldddir.txt] 错误 1make[1]: 离开目录\"/root/Python-3.8.1\"make: *** [profile-opt] 错误2 4）编译安装 123[root@python ~]# cd Python-3.8.1[root@python ~]# ./configure --prefix=/usr/local/python381 --enable-optimizations[root@python ~]# make &amp;&amp; make install 5）修改用户主目录下名为.bash_profile的文件，配置PATH环境变量并使其生效 123[root@python ~]# vim .bash_profile#添加export PATH=$PATH:/usr/local/python381/bin 6）激活环境变量 1[root@python ~]# source .bash_profile 7）运行Python程序 1234#查看Python版本信息[root@python ~]# python3 --version#进入交互环境[root@python ~]# python3 检查Python的版本 123456&gt;&gt;&gt; import sys&gt;&gt;&gt; print(sys.version_info)sys.version_info(major-3, minor=8 micro=1 releaselevel='final', serial=0)&gt;&gt;&gt; print(sys.version)3.8.1 (default, Mar 9 2020, 12:21:51)[GCC 4.8.5 20150623 (Red Hat 4.8.5-.9)]","categories":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/tags/Python/"}]},{"title":"Helm应用以及服务升级与回滚","slug":"Helm应用以及服务升级与回滚","date":"2020-03-03T16:00:00.000Z","updated":"2020-03-04T12:15:12.356Z","comments":true,"path":"Helm应用以及服务升级与回滚.html","link":"","permalink":"https://pdxblog.top/Helm%E5%BA%94%E7%94%A8%E4%BB%A5%E5%8F%8A%E6%9C%8D%E5%8A%A1%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A.html","excerpt":"","text":"¶Helm应用以及服务升级与回滚 helm：包管理工具 官方提提供的仓库：https://hub.helm.sh/ Charts：是一个Helm的程序包，它包含了运行一个kubernetes应用程序所需要的镜像、依赖关系和资源定义等 Release：应用程序运行charts后，得到的一个实例 部署一个实例： helm install + charts -n release名称 根据以一个包运行一个实例 1234[root@master ~]# helm install stable/redis -n redis --dry-run--dry-run：用来测试有没有问题，如果没有问题就可以运行[root@master ~]# helm install stable/redis -n redis#这里是运行不成功的，因为他需要镜像，PV等准备工作 运行之后会有三部分描述 1、关于这个Release的描述 2、关于这个Release资源的描述 3、怎么使用这个Release 根据提示可以获得redis的密码，等等一些信息 12[root@master ~]# kubectl get secret --namespace default redis-redis -o jsonpath=\"&#123;.data.redis-password&#125;\" | base64 --decoderTmeGF2rcY 删除实例： 1[root@master ~]# helm delete redis --purge 查询chart包 1[root@master ~]# helm search mysql 运行一个实例： 1[root@master ~]# helm install stable/mysql -n mysql 我们运行过的实例都会生成一个charts包存放在这个缓存目录下 1234[root@master archive]# pwd/root/.helm/cache/archive[root@master archive]# lsmysql-0.3.5.tgz redis-1.1.15.tgz Charts包解压目录 1234567891011121314[root@master archive]# tar zxf mysql-0.3.5.tgz[root@master archive]# tree -C mysqlmysql├── Chart.yaml├── README.md├── templates│ ├── configmap.yaml│ ├── deployment.yaml│ ├── _helpers.tpl│ ├── NOTES.txt│ ├── pvc.yaml│ ├── secrets.yaml│ └── svc.yaml└── values.yaml Chart.yaml：这个chart包的概要信息 ​ name和version这两个是必填项，其他可选 README.md：是这个chart包的一个使用帮助文档 templates：chart包内各种资源对象模板 values.yaml：是这个chart包的默认的值，可以被template内的yaml文件使用 我们在部署之前还可以提前查看这个包会有什么东西 1[root@master ~]# helm inspect values stable/prometheus 除了部署实例后会生成chart包，还可以下载chart包 1[root@master ~]# helm fetch stable/prometheus Helm部署安装一个Mysql服务 部署NFS服务： 123[root@master ~]# mkdir /data[root@master ~]# vim /etc/exports/data *(rw,sync,no_root_squash) 创建PV： 1234567891011121314151617181920[root@master ~]# vim nfs-pv1.ymlapiVersion: v1kind: PersistentVolumemetadata: name: mysqlpvspec: capacity: storage: 8Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle nfs: path: /data/mysqlpv server: 192.168.1.70[root@master ~]# kubectl apply -f nfs-pv1.yml persistentvolume/mysqlpv created[root@master ~]# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEmysqlpv 8Gi RWO Recycle Available 16s[root@master ~]# mkdir /data/mysqlpv 部署mysql实例（镜像提前准备好）： 123456789101112131415[root@master ~]# helm install stable/mysql -n bdqn-mysql --set mysqlRootPassword=123.com #创建实例，并设置密码[root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGEbdqn-mysql-mysql-7b89c7b99-kg4wf 0/1 Init:0/1 0 17s #正在初始化[root@master ~]# kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEbdqn-mysql-mysql Bound mysqlpv 8Gi RWO 48s#还需要一个小镜像docker pull busybox:1.25.0[root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGEbdqn-mysql-mysql-7b89c7b99-kg4wf 1/1 Running 0 2m10s[root@master ~]# kubectl get deployments.NAME READY UP-TO-DATE AVAILABLE AGEbdqn-mysql-mysql 1/1 1 1 2m13s 查看密码是否设置成功： 12[root@master ~]# kubectl get secret --namespace default bdqn-mysql-mysql -o jsonpath=\"&#123;.data.mysql-root-password&#125;\" | base64 --decode; echo123.com 验证数据有没有问题： 1234567891011[root@master ~]# kubectl exec -it bdqn-mysql-mysql-7b89c7b99-kg4wf -- mysql -u root -p123.commysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+4 rows in set (0.01 sec) 在部署mysql的时候，如何开启storageclass，以及如何使用？ 首先需要部署storageclass（存储类），让他可以自动创建PV 1、需要基于NFS环境 2、RBAC权限 3、nfs-deployment. 4、storageclass helm在创建实例的时候是基于templates模板里的内容创建的，而模板内需要的信息则是在values.yaml文件里，我们则需要修改values.yaml文件里的内容就行 12345[root@master mysql]# vim values.yaml 找到storageClass，去掉注释即可 storageClass: \"test-nfs\" #storageclass的名称 accessMode: ReadWriteOnce size: 8Gi 然后直接部署实例，在部署实例的时候 -f 指定这个values.yaml这个文件即可，它会根据实例的PVC自动创建PV 如果想将sservice资源对象的类型更改为NodePort，又应该怎么做 同样只需要修改values.yaml文件就行 123#将类型给位NodePort即可，还可以自己指定端口 type: NodePort port: 3306 在创建实例的时候只需要指定以下这个文件就行 12345[root@master mysql]# helm install stable/mysql -n bdqn-mysql --set mysqlRootPassword=123.com -f values.yaml[root@master mysql]# kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEbdqn-mysql-mysql NodePort 10.104.45.139 &lt;none&gt; 3306:30165/TCP 13mkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 60d 服务的升级： 1234[root@master mysql]# helm upgrade --set imageTag=5.7.15 bdqn-mysql stable/mysql -f values.yaml[root@master mysql]# kubectl get deployments. -o wideNAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTORzhb-mysql 1/1 1 1 9m22s zhb-mysql mysql:5.7.15 app=zhb-mysql 回滚 1234567891011#查看有哪些版本[root@master mysql]# helm history zhbREVISION UPDATED STATUS CHART DESCRIPTION 1 Mon Mar 2 16:33:26 2020 SUPERSEDED mysql-0.3.5 Install complete2 Mon Mar 2 16:37:04 2020 DEPLOYED mysql-0.3.5 Upgrade complete回滚到1版本[root@master mysql]# helm rollback zhb 1Rollback was a success.[root@master mysql]# kubectl get deployments. -o wideNAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTORzhb-mysql 1/1 1 1 13m zhb-mysql mysql:5.7.14 app=zhb-mysql","categories":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]},{"title":"Helm自定义模板以及私有库部署","slug":"Helm自定义模板以及私有库部署","date":"2020-03-03T16:00:00.000Z","updated":"2020-03-04T12:15:12.351Z","comments":true,"path":"Helm自定义模板以及私有库部署.html","link":"","permalink":"https://pdxblog.top/Helm%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A8%A1%E6%9D%BF%E4%BB%A5%E5%8F%8A%E7%A7%81%E6%9C%89%E5%BA%93%E9%83%A8%E7%BD%B2.html","excerpt":"","text":"¶Helm自定义模板以及私有库部署 开发自己的chart 12345678910111213141516171819202122232425[root@master ~]# helm create mychartCreating mychart[root@master ~]# tree -C mychart/mychart/├── charts├── Chart.yaml├── templates│ ├── deployment.yaml│ ├── _helpers.tpl│ ├── ingress.yaml│ ├── NOTES.txt│ ├── service.yaml│ └── tests│ └── test-connection.yaml└── values.yaml[root@master mychart]# pwd/root/mychart[root@master mychart]# vim values.yamlreplicaCount: 1image: repository: nginx tag: stable pullPolicy: IfNotPresent ---------- #这些都都是默认信息 因为这是我们自己开发的，所以有可能会出现错误，一般我们在部署之前都会进行调试 调试 1[root@master ~]# helm install --dry-run --debug mychart 修改values.yaml文件，模拟一些错误来查看效果 123[root@master ~]# helm install --dry-run --debug mychart): error converting YAML to JSON: yaml: line 12: could not find expected ':'#会告诉你第12行少了个：但是这个12行不是特别准确，只是一个大概的方向 安装chart 四种方法 通过仓库安装 将chart下载下来，通过tar包安装 通过chart本地目录安装（将tar包解压得到的目录） 通过URL安装 1、通过仓库安装（以redis为例） 1[root@master ~]# helm install stable/redis -n redis 2、将chart下载下来，通过tar包安装 12[root@master ~]# helm fetch stable/redis[root@master ~]# helm install redis-1.1.15.tgz 3、通过chart本地目录安装 123456789101112131415[root@master ~]# tar zxf redis-1.1.15.tgz[root@master ~]# tree -C redisredis├── Chart.yaml├── README.md├── templates│ ├── deployment.yaml│ ├── _helpers.tpl│ ├── networkpolicy.yaml│ ├── NOTES.txt│ ├── pvc.yaml│ ├── secrets.yaml│ └── svc.yaml└── values.yaml[root@master ~]# helm install redis 4、通过URL安装 1[root@master ~]# helm install http://xxx/charts/xxx.tgz -n name 使用本地目录安装刚刚自定义的mychart： 要求： 副本Pod数量为3个 service类型为NodePort 映射的端口为31033 123456789[root@master ~]# cd mychart/[root@master mychart]# vim values.yamlreplicaCount: 3service: type: NodePort port: 80 nodePort: 31033[root@master mychart]# helm install -n test ../mychart/ 12345678910111213[root@master mychart]# kubectl get podNAME READY STATUS RESTARTS AGEtest-mychart-657bfc65b8-5j8qn 1/1 Running 0 30stest-mychart-657bfc65b8-bgt2s 1/1 Running 0 30stest-mychart-657bfc65b8-v2sph 1/1 Running 0 30s[root@master mychart]# kubectl get deployments.NAME READY UP-TO-DATE AVAILABLE AGEtest-mychart 3/3 3 3 46s[root@master mychart]# kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 61dtest-mychart NodePort 10.104.53.170 &lt;none&gt; 80:30393/TCP 50s#可以看到这里的端口与我们指定的并不一致 因为这些yaml文件都是引用template模板，template模板目录下的service.yaml里面没有nodePort字段，只需要在service.yaml文件里添加就行 12345678910111213141516171819#实例的更新[root@master templates]# pwd/root/mychart/templates[root@master templates]# vim service.yamspec: type: &#123;&#123; .Values.service.type &#125;&#125; ports: - port: &#123;&#123; .Values.service.port &#125;&#125; targetPort: http protocol: TCP name: http nodePort: &#123;&#123; .Values.service.nodePort&#125;&#125;#再更新以下，进行验证[root@master ~]# helm upgrade test mychart/ -f mychart/values.yaml[root@master ~]# kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 61dtest-mychart NodePort 10.104.53.170 &lt;none&gt; 80:31033/TCP 10m#端口已经改变了 一般在企业都是使用自己的私有镜像，那么就需要搭建私有仓库 12345678910111213[root@master ~]# vim /usr/lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.70:5000[root@master ~]# systemctl daemon-reload [root@master ~]# systemctl restart docke#node01、node02也加入私有仓库[root@node01 ~]# vim /usr/lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.70:5000[root@node01 ~]# systemctl daemon-reload [root@node01 ~]# systemctl restart docke[root@node02 ~]# vim /usr/lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd --insecure-registry 192.168.1.70:5000[root@node02 ~]# systemctl daemon-reload [root@node02 ~]# systemctl restart docke 导入私有镜像，并上传到私有仓库 12345678[root@master ~]# docker load &lt; httpd-v1.tar &amp;&amp; docker load &lt; httpd-v2.tar &amp;&amp; docker load &lt; httpd-v3.tar[root@master ~]# docker tag httpd:v1 192.168.1.70:5000/httpd:v1[root@master ~]# docker push 192.168.1.70:5000/httpd:v1[root@master ~]# docker push 192.168.1.70:5000/httpd:v1 [root@master ~]# docker tag httpd:v2 192.168.1.70:5000/httpd:v2[root@master ~]# docker tag httpd:v3 192.168.1.70:5000/httpd:v3[root@master ~]# docker push 192.168.1.70:5000/httpd:v2[root@master ~]# docker push 192.168.1.70:5000/httpd:v3 node01、node02拉去镜像 123456[root@node01 ~]# docker pull 192.168.1.70:5000/httpd:v1[root@node01 ~]# docker pull 192.168.1.70:5000/httpd:v2[root@node01 ~]# docker pull 192.168.1.70:5000/httpd:v3[root@node02 ~]# docker pull 192.168.1.70:5000/httpd:v1[root@node02 ~]# docker pull 192.168.1.70:5000/httpd:v2[root@node02 ~]# docker pull 192.168.1.70:5000/httpd:v3 练习： 使用mychart部署一个实例，名为bdqn，使用私有镜像v1版本 完成之后，将实例做一个升级，将镜像改为v2版本 123456789101112131415161718192021222324252627282930313233343536#修改yaml文件，运行实例[root@master ~]# vim mychart/values.yamlimage: repository: 192.168.1.70:5000/httpd tag: v1 pullPolicy: IfNotPresent[root@master ~]# helm install -n bdqn mychart/[root@master ~]# kubectl get deployments. -o wideNAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTORbdqn-mychart 1/1 1 1 8s mychart 192.168.1.70:5000/httpd:v1 app.kubernetes.io/instance=bdqn,app.kubernetes.io/name=mychart[root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGEbdqn-mychart-574ffc5496-bd8vf 1/1 Running 0 22s#实例升级，通过yaml文件的方式[root@master ~]# vim mychart/values.yamlimage: repository: 192.168.1.70:5000/httpd tag: v2[root@master ~]# helm upgrade bdqn mychart/ -f mychart/values.yaml[root@master ~]# kubectl get deployments. -o wideNAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTORbdqn-mychart 1/1 1 1 2m54s mychart 192.168.1.70:5000/httpd:v2 app.kubernetes.io/instance=bdqn,app.kubernetes.io/name=mychart[root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGEbdqn-mychart-85dcbbcb8f-8h47q 1/1 Running 0 5m28s#还可以通过命令的方式[root@master ~]# helm upgrade bdqn mychart/ --set imageTAG=v2//这种方法更新完成后，查看deployment的时候，镜像显示是没有更新的#还可以通过edit的方式进行更改[root@master ~]# kubectl edit deployments. bdqn-mychart spec: containers: - image: 192.168.1.70:5000/httpd:v3[root@master ~]# kubectl get deployments. -o wideNAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTORbdqn-mychart 1/1 1 1 28m mychart 192.168.1.70:5000/httpd:v3 app.kubernetes.io/instance=bdqn,app.kubernetes.io/name=mychar 创建自己的Repo仓库 我们自己创建的chart包，如果公司内其他的同事也需要用，我们可以cp一份给他，但是效率太低，所以就可以创建一个repo仓库，解决这个需求 1、在node01上运行一个httpd的容器（作为私有仓库） 12345[root@node01 ~]# mkdir /var/www[root@node01 ~]# docker run -d -p 8080:80 -v /var/www/:/usr/local/apache2/htdocs httpd:latest[root@node01 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES03e5e3ef5c95 httpd:latest \"httpd-foreground\" 13 seconds ago Up 12 seconds 0.0.0.0:8080-&gt;80/tcp kind_roentgen 2、master节点上，使用helm package将mychart目录打包 1234[root@master ~]# helm package mychart/Successfully packaged chart and saved it to: /root/mychart-0.1.0.tgz[root@master ~]# lsmychart-0.1.0.tgz 3、执行helm repo index生成仓库的index文件 123456789101112131415161718192021[root@master ~]# mkdir myrepo[root@master ~]# mv mychart-0.1.0.tgz myrepo/[root@master ~]# ls myrepo/mychart-0.1.0.tgz[root@master ~]# helm repo index myrepo/ --url http://192.168.1.50:8080/charts #第一步运行的容器的IP+端口[root@master ~]# ls myrepo/index.yaml mychart-0.1.0.tgz[root@master ~]# cat myrepo/index.yaml apiVersion: v1entries: mychart: - apiVersion: v1 appVersion: \"1.0\" created: \"2020-03-04T11:08:33.079034645+08:00\" description: A Helm chart for Kubernetes digest: f2a297c4b377ae7f208848bef8823eeb74ebb7270d8bf07f58270678d0784056 name: mychart urls: - http://192.168.1.50:8080/charts/mychart-0.1.0.tgz version: 0.1.0generated: \"2020-03-04T11:08:33.07808906+08:00\" 4、将生成的tar包和index.yaml上传到node01的/var/www/charts目录下 123456789#因为node01上没有sharts目录，所以需要创建[root@node01 ~]# mkdir /var/www/chart[root@master ~]# cd myrepo/[root@master myrepo]# scp index.yaml mychart-0.1.0.tgz node01:/var/www/chartsindex.yaml 100% 400 0.4KB/s 00:00 mychart-0.1.0.tgz 100% 2861 2.8KB/s 00:00#在node01上进行验证[root@node01 ~]# ls /var/www/chartsindex.yaml mychart-0.1.0.tgz 5、添加新的repo仓库 1234567[root@master myrepo]# helm repo add myrepo http://192.168.1.50:8080/charts\"myrepo\" has been added to your repositories[root@master myrepo]# helm repo listNAME URL stable https://kubernetes.oss-cn-hangzhou.aliyuncs.com/chartslocal http://127.0.0.1:8879/charts #这个是不能跨主机的只能在本地使用 myrepo http://192.168.1.50:8080/charts #这个可以跨主机 至此，已经可以正常供内网环境使用这个charts包的私有仓库了 6、验证，我们就可以直接使用新的repo仓库部署实例了 12345678[root@master myrepo]# helm search mychartNAME CHART VERSION APP VERSION DESCRIPTION local/mychart 0.1.0 1.0 A Helm chart for Kubernetesmyrepo/mychart 0.1.0 1.0 A Helm chart for Kubernetes[root@master myrepo]# helm install myrepo/mychart -n test[root@master ~]# helm listNAME REVISION UPDATED STATUS CHART APP VERSION NAMESPACEtest 1 Wed Mar 4 11:23:25 2020 DEPLOYED mychart-0.1.0 1.0 7、如果以后仓库中新添加了chart包，需要用helm repo update命令更新本地的index文件 练习： 新创建一个bdqn的chart包，然后将chart包上传到上述repo源中 123456789101112131415161718192021222324252627#创建新的chart[root@master ~]# helm create bdqnCreating bdqn#将这个chart目录打包[root@master ~]# helm package bdqn/Successfully packaged chart and saved it to: /root/bdqn-0.1.0.tgz#移动到myrepo下[root@master ~]# mv bdqn-0.1.0.tgz myrepo/[root@master ~]# ls myrepo/bdqn-0.1.0.tgz index.yaml mychart-0.1.0.tgz#更新index文件[root@master ~]# helm repo index myrepo/ --url http://192.168.1.50:8080/charts[root@master myrepo]# scp bdqn-0.1.0.tgz index.yaml node01:/var/www/chartsbdqn-0.1.0.tgz 100% 2826 2.8KB/s 00:00 index.yaml 100% 720 0.7KB/s 00:00#更新repo仓库[root@master myrepo]# helm repo updateHang tight while we grab the latest from your chart repositories......Skip local chart repository...Successfully got an update from the \"myrepo\" chart repository...Successfully got an update from the \"stable\" chart repositoryUpdate Complete.#搜索验证[root@master myrepo]# helm search bdqnNAME CHART VERSION APP VERSION DESCRIPTION local/bdqn 0.1.0 1.0 A Helm chart for Kubernetesmyrepo/bdqn 0.1.0 1.0 A Helm chart for Kubernetes 使用url部署这个bdqn实例 12345[root@master ~]# helm install http://192.168.1.50:8080/charts/bdqn-0.1.0.tgz -n t1[root@master ~]# helm listNAME REVISION UPDATED STATUS CHART APP VERSION NAMESPACE t1 1 Wed Mar 4 11:52:50 2020 DEPLOYED bdqn-0.1.0 1.0 default test 1 Wed Mar 4 11:23:25 2020 DEPLOYED mychart-0.1.0 1.0","categories":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]},{"title":"HPA","slug":"HPA","date":"2020-02-28T16:00:00.000Z","updated":"2020-02-29T12:11:53.950Z","comments":true,"path":"HPA.html","link":"","permalink":"https://pdxblog.top/HPA.html","excerpt":"","text":"¶HPA HPA的全称为Horizontal Pod Autoscaling，它可以根据当前pod资源的使用率（如CPU、磁盘、内存等），进行副本数的动态的扩容与缩容，以便减轻各个pod的压力。当pod负载达到一定的阈值后，会根据扩缩容的策略生成更多新的pod来分担压力，当pod的使用比较空闲时，在稳定空闲一段时间后，还会自动减少pod的副本数量 前提条件：系统应该能够获取当前Pod的资源使用情况（意思是可以执行 kubectl top pod命令，并且能够得到反馈信息） heapster：这个组件之前是集成在k8s集群的，不过在1.12版本之后就被移除了。如果还想使用此功能，应该部署metricServer这个k8s集群资源使用情况的聚合器 要是想实现自动扩容缩容的功能，还需要部署heapster服务，而这个服务集成在Prometheus的MetricServer服务中，也就是说需要部署Prometheus服务，但是我们也可以直接部署heapster服务 实现Pod的扩容与缩容示例 因为heapster集成在MetricServer服务中，所以首先部署这个服务 1、首先安装MerticServer服务，从Github上克隆项目 1[root@master ~]# git clone https://github.com/kubernetes-incubator/metrics-server.git 2、修改yaml文件 1234567[root@master ~]# vim metrics-server/deploy/kubernetes/metrics-server-deployment.yaml image: k8s.gcr.io/metrics-server-amd64:v0.3.1 #更换镜像版本 //在44行添加 command: - /metrics-server - --kubelet-insecure-tls - --kubelet-preferred-address-types=InternalIP 3、下载metrics-server镜像k8s.gcr.io/metrics-server-amd64:v0.3.1（因为国内无法访问k8s.gcr.io，所以采用以下办法） pull-google-container 工具脚本 12345678910[root@master ~]# vim pull-google.sh image=$1 echo $1 img=`echo $image | sed 's/k8s\\.gcr\\.io/anjia0532\\/google-containers/g;s/gcr\\.io/anjia0532/g;s/\\//\\./g;s/ /\\n/g;s/_/-/g;s/anjia0532\\./anjia0532\\//g' | uniq | awk '&#123;print \"\"$1\"\"&#125;'` echo \"docker pull $img\" docker pull $img echo \"docker tag $img $image\" docker tag $img $image [root@master ~]# chmod +x pull-google.sh &amp;&amp; cp pull-google.sh /usr/local/bin/pull-google-container [root@master ~]# pull-google-container k8s.gcr.io/metrics-server-amd64:v0.3.1 4、将镜像打包发给k8s各个节点 12345[root@master ~]# docker save &gt; metrics-server-amd64.tar k8s.gcr.io/metrics-server-amd64:v0.3.1 [root@master ~]# scp metrics-server-amd64.tar node01:/root [root@master ~]# scp metrics-server-amd64.tar node02:/root [root@node01 ~]# docker load &lt; metrics-server-amd64.tar [root@node02 ~]# docker load &lt; metrics-server-amd64.tar 5、运行yaml文件 123456789101112[root@master ~]# kubectl apply -f metrics-server/deploy/kubernetes/ clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created serviceaccount/metrics-server created deployment.apps/metrics-server created service/metrics-server created clusterrole.rbac.authorization.k8s.io/system:metrics-server created clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created [root@master ~]# kubectl get pod -n kube-system metrics-server-849dcc6bb4-hr5xp 1/1 Running 0 13s 6、验证 12345678910[root@master ~]# kubectl top node error: metrics not available yet #这里等一会就行 [root@master ~]# kubectl top pod -n kube-system metrics-server-849dcc6bb4-hr5xp NAME CPU(cores) MEMORY(bytes) metrics-server-849dcc6bb4-hr5xp 1m 13Mi [root@master ~]# kubectl top node NAME CPU(cores) CPU% MEMORY(bytes) MEMORY% master 56m 2% 1145Mi 66% node01 12m 0% 478Mi 27% node02 11m 0% 452Mi 26% 这里，我们使用一个测试镜像，这个镜像基于php-apache制作的docker镜像，包含了一些可以运行cpu密集计算任务的代码（模拟压力测试） 12345678910[root@master ~]# kubectl run php-apache --image=mirrorgooglecontainers/hpa-example:latest --requests=cpu=200m --expose --port=80[root@master ~]# kubectl get deployments.NAME READY UP-TO-DATE AVAILABLE AGEphp-apache 1/1 1 1 33s[root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGEphp-apache-794cdd478f-l9kxn 1/1 Running 0 6m27s[root@master ~]# kubectl top pod php-apache-794cdd478f-l9kxn NAME CPU(cores) MEMORY(bytes) php-apache-794cdd478f-l9kxn 0m 9Mi 创建HPA控制器 123456[root@master ~]# kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10horizontalpodautoscaler.autoscaling/php-apache autoscaled[root@master ~]# kubectl get hpaNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGEphp-apache Deployment/php-apache 0%/50% 1 10 1 2m1s限制cpu使用率不能超过50%，最少有一个Pod，最多有10个 实时监控Pod的状态 123[root@master ~]# kubectl get pod -wNAME READY STATUS RESTARTS AGEphp-apache-794cdd478f-l9kxn 1/1 Running 0 40m 创建一个应用，用来不停的访问我们刚刚创建的php-apache的svc资源 1[root@master ~]# kubectl run -i --tty load-generator --image=busybox /bin/sh 进入Pod内，执行此命令用来模拟访问php-apache的svc资源 12#对Pod进行死循环请求/ # while true; do wget -q -O- http://php-apache.default.svc.cluster.local; done 运行一段时间后查看pod的数量变化 123456789101112NAME READY STATUS RESTARTS AGEload-generator-7d549cd44-xm98c 1/1 Running 1 25mphp-apache-867f97c8cb-4r6sk 1/1 Running 0 19mphp-apache-867f97c8cb-4rcpk 1/1 Running 0 13mphp-apache-867f97c8cb-5pbxf 1/1 Running 0 16mphp-apache-867f97c8cb-8htth 1/1 Running 0 13mphp-apache-867f97c8cb-d94h9 0/1 ContainerCreating 0 13mphp-apache-867f97c8cb-drh52 1/1 Running 0 18mphp-apache-867f97c8cb-f67bs 0/1 ContainerCreating 0 17mphp-apache-867f97c8cb-nxc2r 1/1 Running 0 19mphp-apache-867f97c8cb-vw74k 1/1 Running 0 39mphp-apache-867f97c8cb-wb6l5 0/1 ContainerCreating 0 15m 当停止死循环请求后，也并不会立即减少pod数量，会等一段时间后减少pod数量，防止流量再次激增。 至此，pod副本数量的自动扩缩容就实现了 12345678910[root@master ~]# kubectl get hpa -wNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGEphp-apache Deployment/php-apache 106%/50% 1 10 8 50mphp-apache Deployment/php-apache 102%/50% 1 10 8 50mphp-apache Deployment/php-apache 93%/50% 1 10 8 51mphp-apache Deployment/php-apache 87%/50% 1 10 8 51mphp-apache Deployment/php-apache 82%/50% 1 10 8 51mphp-apache Deployment/php-apache 77%/50% 1 10 8 51mphp-apache Deployment/php-apache 68%/50% 1 10 8 52mphp-apache Deployment/php-apache 61%/50% 1 10 8 52m ¶资源限制 以下只是yaml文件中的一段，并不是整个yaml文件 ¶基于Pod kubernetes对资源的限制实际上是通过cgroup来控制的，cgroup是容器的一组用来控制内核如何运行进程的相关属性集合，针对内存、cpu和各种设备都有对应的cgroup 默认情况下，Pod运行没有cpu和内存的限额，这意味着系统中的任何Pod将能够想执行该Pod所在的节点一样，消耗足够多的cpu和内存，一般会针对某些应用的pod资源进行资源限制，这个资源限制通过resources的requeste和limits来实现 12345678910111213141516[root@master ~]# vim cgroup-pod.yamlspec: containers: - name: xxx imagePullPolicy: Always image: xxx ports: - protocol: TCP containerPort: 80 resources: limits: cpu: \"4\" memory: 2Gi requests: cpu: 260m memory: 260Mi requests：要分配的资源，limits为最高请求的资源值。可以简单的理解为初始值和最大值 ¶基于名称空间 1）计算资源配额 123456789101112[root@master ~]# vim compute-resources.yamlapiVersion: v1kind: ResourceQuotametadata: name: compute-resourcesspec: hard: pods: \"20\" requests.cppu: \"20\" requests.memory: 100Gi limits.cpu: \"40\" limits.memory: 200Gi 2）配置对象数量配额限制 123456789101112[root@master ~]# vim object-counts.yamlapiVersion: v1kind: ResourceQuotametadata: name: object-countsspec: hard: configmaps: \"10\" persistentvolumeclaims: \"4\" replicationcontrollers: \"20\" secrets: \"10\" service.loadbalancers: \"2\" 3）配置CPU和内存的LimitRange 1234567891011121314[root@master ~]# vim limitRange.yamlapiVersion: v1kind: LimiRangemetadata: name: mem-limit-rangespec: limits: - default: memory: 50Gi cpu: 5 defaultRequest: memory: 1Gi cpu: 1 type: Container default即limit的值 defaultRequest即request的值","categories":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]},{"title":"Heldm工具部署","slug":"Helm工具部署","date":"2020-02-28T16:00:00.000Z","updated":"2020-02-29T12:11:53.955Z","comments":true,"path":"Helm工具部署.html","link":"","permalink":"https://pdxblog.top/Helm%E5%B7%A5%E5%85%B7%E9%83%A8%E7%BD%B2.html","excerpt":"","text":"¶Helm 在Kubernetes中部署容器云的应用也是一项有挑战性的工作，Helm就是为了简化在Kubernetes中安装部署容器云应用的一个客户端工具。通过helm能够帮助开发者定义、安装和升级Kubernetes中的容器云应用，同时，也可以通过helm进行容器云应用的分享。在Kubeapps Hub中提供了包括Redis、MySQL和Jenkins等常见的应用，通过helm可以使用一条命令就能够将其部署安装在自己的Kubernetes集群中 helm的整体架构如下图所示，Helm架构由Helm客户端、Tiller服务器端和Chart仓库所组成；Tiller部署在Kubernetes中，Helm客户端从Chart仓库中获取Chart安装包，并将其安装部署到Kubernetes集群中 Helm是管理Kubernetes包的工具，Helm能提供下面的能力： 创建新的charts 将charts打包成tgz文件 与chart仓库交互 安装和卸载Kubernetes的应用 管理使用Helm安装的charts的生命周期 在Helm中，有三个需要了解的重要概念： chart：是创建Kubernetes应用实例的信息集合； config：创建发布对象的chart的配置信息 release：chart的运行实例，包含特定的config helm组件 在Helm中有两个主要的组件，既Helm客户端和Tiller服务器： Helm客户端：这是一个供终端用户使用的命令行工具，客户端负责如下的工作： 本地chart开发 管理仓库 与Tiller服务器交互 ​ 发送需要被安装的charts，请求关于发布版本的信息，求更新或者卸载已安装的发布版本 Tiller服务器：Tiller服务部署在Kubernetes集群中，Helm客户端通过与Tiller服务器进行交互，并最终与Kubernetes API服务器进行交互。 Tiller服务器负责如下的工作： 监听来自于Helm客户端的请求 组合chart和配置来构建一个发布 在Kubernetes中安装，并跟踪后续的发布 通过与Kubernetes交互，更新或者char 客户端负责管理chart，服务器发展管理发布 Helm技术实现 Helm客户端是使用Go语言编写的，它通过gRPC协议与Tiller服务器交互。 Tiller服务器也是使用Go语言编写的，它使用Kubernetes客户端类库（当前是哦那个REST+JSON）与Kubernetes进行通讯。 Tiller服务器通过Kubernetes的ConfigMap存储信息，因此本身没有用于存储数据库 ¶helm安装部署 12345678910#从GitHub上下载helm[root@master ~]# wget https://get.helm.sh/helm-v2.14.3-linux-amd64.tar.gz#解压，获取helm的命令[root@master ~]# tar -zxvf helm-v2.14.3-linux-amd64.tar.gz[root@master ~]# mv linux-amd64/helm /usr/local/bin/[root@master ~]# chmod +x /usr/local/bin/helm #确认命令可用[root@master ~]# helm help#设置tab键自动补全[root@master ~]# source &lt;(helm completion bash) 安装Tiller服务 1234567891011121314151617181920212223#创建授权用户，并授予权限[root@master ~]# vim tiller-rbac.yamlapiVersion: v1kind: ServiceAccountmetadata: name: tiller namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: tillerroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects: - kind: ServiceAccount name: tiller namespace: kube-system[root@master ~]# kubectl apply -f tiller-rbac.yaml serviceaccount/tiller createdclusterrolebinding.rbac.authorization.k8s.io/tiller created 初始化，生成一个包的仓库 1[root@master ~]# helm init --service-account=tiller 查看pod 12345678910[root@master ~]# kubectl get pod -n kube-systemtiller-deploy-8557598fbc-5cfv6 0/1 ImagePullBackOff 0 4m6s//这个镜像是下载不下来的，因为默认是从谷歌下载的#修改yaml文件，将镜像改为阿里云的[root@master ~]# kubectl edit pod -n kube-system tiller-deploy-8557598fbc-5cfv6//修改spec字段的image image: registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.14.3保存退出，它会自动下载镜像[root@master ~]# kubectl get pod -n kube-system | grep tillertiller-deploy-8557598fbc-5cfv6 1/1 Running 0 13m 查看helm仓库信息 1234[root@master ~]# helm repo listNAME URL stable https://kubernetes-charts.storage.googleapis.comlocal http://127.0.0.1:8879/charts 添加阿里云的仓库源 123456[root@master ~]# helm repo add stable https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts\"stable\" has been added to your repositories[root@master ~]# helm repo listNAME URL stable https://kubernetes.oss-cn-hangzhou.aliyuncs.com/chartslocal http://127.0.0.1:8879/charts 查看版本信息，必须保证可以看到client和server，才可以正常使用helm 123[root@master ~]# helm versionClient: &amp;version.Version&#123;SemVer:\"v2.14.3\", GitCommit:\"0e7f3b6637f7af8fcfddb3d2941fcc7cbebb0085\", GitTreeState:\"clean\"&#125;Server: &amp;version.Version&#123;SemVer:\"v2.14.3\", GitCommit:\"0e7f3b6637f7af8fcfddb3d2941fcc7cbebb0085\", GitTreeState:\"clean\"&#125;","categories":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]},{"title":"k8s监控","slug":"k8监控","date":"2020-02-27T16:00:00.000Z","updated":"2020-02-28T07:02:46.103Z","comments":true,"path":"k8监控.html","link":"","permalink":"https://pdxblog.top/k8%E7%9B%91%E6%8E%A7.html","excerpt":"","text":"¶一、k8s的UI访问界面-dashboard General-purpose web UI for Kubernetes clusters 用于Kubernetes集群的通用web UI 在dashbord中，虽然可以做到创建、删除、修改资源等操作，但通常情况下，我们会把它当作监控k8s集群的软件 dashboard能够直观的看到rc、deployment、pod、services等k8s组件的运行情况和日志信息。 1、从Github搜索dasgboard，下载yaml文件 1234567[root@master ~]# mkdir dashboard[root@master ~]# cd dashboard/[root@master dashboard]# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-rc5/aio/deploy/recommended.yaml[root@master dashboard]# lsrecommended.yaml[root@node01 ~]# docker pull kubernetesui/dashboard:v2.0.0-rc5[root@node02 ~]# docker pull kubernetesui/dashboard:v2.0.0-rc5 2、运行yaml文件： 1234567891011121314151617181920修改service类型类NodePort#在40行的spec字段修改[root@master dashboard]# vim recommended.yamlspec: type: NodePort[root@master dashboard]# kubectl apply -f recommended.yaml namespace/kubernetes-dashboard createdserviceaccount/kubernetes-dashboard createdservice/kubernetes-dashboard createdsecret/kubernetes-dashboard-certs createdsecret/kubernetes-dashboard-csrf createdsecret/kubernetes-dashboard-key-holder createdconfigmap/kubernetes-dashboard-settings createdrole.rbac.authorization.k8s.io/kubernetes-dashboard createdclusterrole.rbac.authorization.k8s.io/kubernetes-dashboard createdrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard createdclusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard createddeployment.apps/kubernetes-dashboard createdservice/dashboard-metrics-scraper createddeployment.apps/dashboard-metrics-scraper created 123456789101112[root@master dashboard]# kubectl get pod -n kubernetes-dashboard NAME READY STATUS RESTARTS AGEdashboard-metrics-scraper-7f5767668b-f7nh6 1/1 Running 0 9m32skubernetes-dashboard-57b4bcc994-2rj9k 1/1 Running 0 9m32s[root@master dashboard]# kubectl get svc -n kubernetes-dashboard NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEdashboard-metrics-scraper ClusterIP 10.111.237.119 &lt;none&gt; 8000/TCP 16mkubernetes-dashboard NodePort 10.107.77.172 &lt;none&gt; 443:30361/TCP 16m[root@master dashboard]# kubectl get deployments. -n kubernetes-dashboard NAME READY UP-TO-DATE AVAILABLE AGEdashboard-metrics-scraper 1/1 1 1 11m #将收集到的数据制作成图表的形式kubernetes-dashboard 1/1 1 1 11m 3、通过浏览器访问：https://192.168.1.70:30361 两种登录方式： kubeconfig：配置文件 Token：令牌 基于Token的方法登录dashboard 1、创建一个dashboaed的管理用户 12[root@master dashboard]# kubectl create serviceaccount dashboard-admin -n kube-system serviceaccount/dashboard-admin created 2、将这个用户绑定为集群管理用户 1[root@master dashboard]# kubectl create clusterrolebinding dashboard-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin 3、获取Token 1234567891011#得到Token的名称[root@master dashboard]# kubectl get secrets -n kube-system | grep dashboard-admindashboard-admin-token-mwht2 kubernetes.io/service-account-token 3 5m30s#查看上述得到的secret资源的详细信息，会得到Token[root@master dashboard]# kubectl get secrets -n kube-system dashboard-admin-token-mwht2 NAME TYPE DATA AGEdashboard-admin-token-mwht2 kubernetes.io/service-account-token 3 7m19s//这个类型不是Opaque，说明不是隐藏的，我们可以看到他的详细信息#获取详细信息，得到Token[root@master dashboard]# kubectl describe secrets -n kube-system dashboard-admin-token-mwht2token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4tbXdodDIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiNjliODE4YjYtOTA3Zi00NTBmLWI3NjgtMTc2ODIyM2Y1OTIyIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhc2hib2FyZC1hZG1pbiJ9.WCcVrx6oXs0k7-0hQOOik30ZPJl0sNeQE987PHv_Jm9ZpLQ4P9VIQdN49uRvNsd7DF4Ozgu5enWFvNsiaCDmYHauK2LAoHbDBURE9wGx8VlMaaquZ1B_ur4lOluP6Ha3wdZB64fEdtrg-6-DjIS7SC2Kqr2Bcl8NeRdtABh3cufgJ2EQoU40-FUy-0ahegYixIrrQ-DXgZeGrXP79RzHmBXaSwbRwTqWXwNf0e25on_gCiiMC-MVmbZ0MXhNNv-jc8uD2obaEUTdOCLg__f482Zy7xLEMjBv9eVn0P5u7c8r45VfDs08zK4Leh5GI4KIgcuxt37TCtfmEz5XEoTLnA 4、在浏览器上使用Token登录 PS：如果是使用的是旧版本的dashboard，使用谷歌浏览器登录，可能不成功，需要换成其他的浏览器，比如火狐 //如果没有显示，就说明serviceaccount，没有绑定账号，就说明没有权限，就什么都看不到 这里我们可以创建资源，有三种方式 从表单创建默认的是Deployment资源对象 还有一些扩容缩容、更新，删除的操作 除了基于Token的方法登录dashboard，还有基于kuberconfig配置文件的登录方式 1、获取Tonke 1234567#得到Token的名称[root@master dashboard]# kubectl get secrets -n kube-system | grep dashboard-admindashboard-admin-token-mwht2 kubernetes.io/service-account-token 3 5m30s#查看上述得到的secret资源的详细信息，会得到Token[root@master dashboard]# kubectl get secrets -n kube-system dashboard-admin-token-mwht2 NAME TYPE DATA AGEdashboard-admin-token-mwht2 kubernetes.io/service-account-token 3 7m19s 2、生成kubeconfig配置文件 12345678910#设置一个环境变量代表获取Token[root@master dashboard]# DASH_TOKEN=$(kubectl get secrets -n kube-system dashboard-admin-token-mwht2 -o jsonpath=&#123;.data.token&#125; | base64 -d)#将k8s集群的配置信息写入kubeconfig配置文件中[root@master dashboard]# kubectl config set-cluster kubernetes --server=192.168.1.70:6443 --kubeconfig=/root/.dashboard-admin.conf#将Token写入配置文件里[root@master dashboard]# kubectl config set-credentials dashboard-admin --token=$DASH_TOKEN --kubeconfig=/root/.dashboard-admin.conf[root@master dashboard]# kubectl config set-context dashboard-admin@kubernetes --cluster=kubernetes --user=dashboard-admin --kubeconfig=/root/.dashboard-admin.conf[root@master dashboard]# kubectl config use-context dashboard-admin@kubernetes --kubeconfig=/root/.dashboard-admin.conf 3、将生成的/root/.dashboard-admin.config的配置文件，导出并保存 1[root@master dashboard]# sz /root/.dashboard-admin.conf 4、从浏览器选择kubeconfig的登录方式，然后导入配置文件即可 ¶二、weave-scope监控k8s集群Scope Weave Scope是Weaveworks开发的监控工具。Weave Scope在Kubernetes集群中生成进程，容器和主机的映射，以帮助实时了解Docker容器。还可基于图形UI管理容器并在容器上运行诊断命令 1、在Github上直接搜索scope，找到yaml文件并下载下来 2、往下拉找到kubernetes，点击 3、将这个yaml文件下载下来 1[root@master ~]# wget https://cloud.weave.works/k8s/scope.yaml 4、修改yaml，修改service的端口类型 123456789101112131415161718192021222324[root@master ~]# vim scope.yaml#在212行的spec字段中添加 type: NodePort#保存并退出，运行yaml文件root@master ~]# kubectl apply -f scope.yaml namespace/weave createdserviceaccount/weave-scope createdclusterrole.rbac.authorization.k8s.io/weave-scope createdclusterrolebinding.rbac.authorization.k8s.io/weave-scope createddeployment.apps/weave-scope-app createdservice/weave-scope-app createddeployment.apps/weave-scope-cluster-agent createddaemonset.apps/weave-scope-agent created[root@master ~]# kubectl get deployments. -n weave NAME READY UP-TO-DATE AVAILABLE AGEweave-scope-app 1/1 1 1 26m #展示信息weave-scope-cluster-agent 1/1 1 1 26m #收集信息[root@master ~]# kubectl get pod -n weave NAME READY STATUS RESTARTS AGEweave-scope-agent-jv4g8 1/1 Running 0 21sweave-scope-agent-kw7x9 1/1 Running 0 21sweave-scope-agent-vnqks 1/1 Running 0 21sweave-scope-app-78cff98cbc-nx6p5 1/1 Running 0 21sweave-scope-cluster-agent-7cc889fbbf-tnrhv 1/1 Running 0 21s 5、查看端口，使用浏览器访问：192.168.1.70:30366 123[root@master ~]# kubectl get svc -n weave NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEweave-scope-app NodePort 10.110.46.45 &lt;none&gt; 80:30366/TCP 41s 在scope的web界面中，可以查看很多的东西，pod、node节点等详细信息，包括打开容器的终端，查看其日志信息等等… ¶三、Prometheus Prometheus可以原生地监测Kubernetes，Prometheus Operator简化了Kubernetes上的Prometheus设置，并允许使用Prometheus适配器提供自定义指标API。 Prometheus提供强大的查询语言和内置仪表板，用于查询和可视化数据 PS：在这里部署的prometheus，并不是Prometheus官网提供的，而是使用的coreOS提供的Prometheus项目 Prometheus各个组件的作用： MetricsServer：是k8s集群资源使用情况的聚合器，收集数据给k8s集群内使用，如kubectl，hpa，scheduler等 Prometheus Operator：是一个系统检测和警报工具箱，用来存储监控数据 Prometheus node-exporter：收集k8s集群内资源的数据，指定告警规则 Prometheus：收集apiServer，scheduler，contorller-manager，kubelet组件的数据，通过http协议传输 Grnfana：可视化数据统计和监控平台 1、克隆Prometheus的项目地址到本地 12345[root@master ~]# mkdir prometheus[root@master ~]# cd prometheus/[root@master prometheus]# git clone https://github.com/coreos/kube-prometheus.git[root@master prometheus]# lskube-prometheus 2、修改grafana-service.yaml文件，使用NodePort的暴露方式，暴露的端口为31001 12345678910[root@master prometheus]# cd kube-prometheus/manifests/[root@master manifests]# vim grafana-service.yaml#在spec字段下添加spec: type: NodePort ports: - name: http port: 3000 targetPort: http nodePort: 31001 3、修改prometheus-service.yaml文件，使用NodePort的暴露方式，暴露的端口为31002 123456789[root@master manifests]# vim prometheus-service.yaml#在spec字段下添加spec: type: NodePort ports: - name: web port: 9090 targetPort: web nodePort: 31002 4、修改alertmanager-service.yaml（配置告警模板）文件，使用NodePort的暴露方式，暴露的端口为31003 123456789[root@master manifests]# vim alertmanager-service.yaml#在spec字段下添加spec: type: NodePort ports: - name: web port: 9093 targetPort: web nodePort: 31003 5、将这个目录中的yaml，全部运行，是运行以上yaml文件的基础环境配置 12345[root@master manifests]# cd setup/ #如果想要运行上面的yaml，首先要运行基础环境的设置[root@master setup]# cd ..[root@master manifests]# pwd/root/prometheus/kube-prometheus/manifests[root@master manifests]# kubectl apply -f setup/ 6、运行主yaml文件 1234[root@master manifests]# cd ..[root@master kube-prometheus]# pwd/root/prometheus/kube-prometheus[root@master kube-prometheus]# kubectl apply -f manifests/ 7、浏览器访问：192.168.1.70:31001 //根据提示修改密码，然后保存登录 //将这三个导入一下 浏览器访问grafan官网：https://grafana.com/导入监控模板 搜索prometheus，选择相应的模板 复制ID号 回到grafan，导入模板 部署成功以后，就可运行一条命令，查看资源使用情况（MetricsServer必须部署成功） 12345[root@master ~]# kubectl top node NAME CPU(cores) CPU% MEMORY(bytes) MEMORY% master 182m 9% 1380Mi 80% node01 383m 19% 1402Mi 81% node02 396m 19% 1406Mi 81% ¶总结 dashboard： 可以查看集群中应用的运行状态，也能够修改、创建k8s集群中的个各种资源 用于Kubernetes集群的通用web UI，在dasgboard中，虽然可以做到创建、删除、修改资源等操作，但通常情况下，我们会把它仿作监控k8s集群的软件。dashboard能够直观的看到rc、deployment、pod、service等k8s组件与逆行的情况和日志信息 weave-scope： 可以查看集群中应用的运行状态，也能够修改、创建k8s集群中的个各种资源 Weave Scope是Weaveworks开发的监控工具。Weave Scope在Kubernetes集群中生成进程，容器和主机的映射，以帮助实时了解Docker容器。还可基于图形UI管理容器并在容器上运行诊断命令 Prometheus： Prometheus是一个开源系统监控和报警工具。 Prometheus服务可以直接通过目标拉取数据，或者间接地通过中间网关拉取数据。它在本地存储抓取的所有数据，并通过一定规则进行清理和整理数据，并把得到的结果存储到新的时间序列中，PromQL和其他API可视化展示收集的数据在K8s中，关于集群的资源有metrics度量值的概念，有各种不同的exporter可以通过api接口对外提供各种度量值的及时数据，prometheus在与k8s融合工作的过程中就是通过与这些提供metric值的exporter进行交互，获取数据，整合数据，展示数据，触发告警的过程 Prometheus可以原生地监测Kubernetes，Prometheus Operator简化了Kubernetes上的Prometheus设置，并允许使用Prometheus适配器提供自定义指标API。 Prometheus提供强大的查询语言和内置仪表板，用于查询和可视化数据","categories":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]},{"title":"Ingress实现虚拟主机和Https代理访问","slug":"Ingress实现虚拟主机","date":"2020-02-25T16:00:00.000Z","updated":"2020-02-28T07:01:19.747Z","comments":true,"path":"Ingress实现虚拟主机.html","link":"","permalink":"https://pdxblog.top/Ingress%E5%AE%9E%E7%8E%B0%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA.html","excerpt":"","text":"¶Ingress实现虚拟主机和Https代理访问 虚拟主机，也叫“网站空间”，就是把一台运行在互联网上的物理服务器划分成多个“虚拟”服务器。虚拟主机技术极大的促进了网络技术的应用和普及。同时虚拟主机的租用服务也成了网络时代的一种新型经济形式 1、首先确定要运行Ingress-nginx-controller服务 123[root@master ~]# kubectl get pod -n ingress-nginx NAME READY STATUS RESTARTS AGEnginx-ingress-controller-5954d475b6-ktpf9 1/1 Running 1 43h 2、将Ingress-nginx-controller暴露为一个service资源对象 123[root@master ~]# kubectl get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.100.97.246 &lt;none&gt; 80:32007/TCP,443:30741/TCP 43h 3、创建一个Deployment资源和一个Service资源，并相互关联 1234567891011121314151617181920212223242526272829[root@master ~]# vim deploy1.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: deploy1spec: replicas: 2 template: metadata: labels: app: nginx1 spec: containers: - name: nginx1 image: nginx---apiVersion: v1kind: Servicemetadata: name: svc-1spec: selector: app: nginx1 ports: - port: 80 targetPort: 80[root@master ~]# kubectl apply -f deploy1.yaml deployment.extensions/deploy1 createdservice/svc-1 created 12345678[root@master ~]# kubectl get pod NAME READY STATUS RESTARTS AGEdeploy1-7df6778547-v6ww9 1/1 Running 0 2m33sdeploy1-7df6778547-vkvwf 1/1 Running 0 2m33s[root@master ~]# kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 52dsvc-1 ClusterIP 10.109.213.247 &lt;none&gt; 80/TCP 3m17s 4、创建另外“一对”服务（delpoy2.yaml和svc-2） 1234567891011121314151617181920212223242526272829[root@master ~]# vim deploy2.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: deploy2spec: replicas: 2 template: metadata: labels: app: nginx2 spec: containers: - name: nginx2 image: nginx #这里没有更换镜像，使用相同的nginx镜像---apiVersion: v1kind: Servicemetadata: name: svc-2spec: selector: app: nginx2 ports: - port: 80 targetPort: 80[root@master ~]# kubectl apply -f deploy2.yaml deployment.extensions/deploy2 createdservice/svc-2 created 12345678[root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGEdeploy2-7b6786d8bf-6xnjs 1/1 Running 0 19sdeploy2-7b6786d8bf-dvjqt 1/1 Running 0 19s[root@master ~]# kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 52dsvc-2 ClusterIP 10.106.67.155 &lt;none&gt; 80/TCP 24s 4、创建Ingress规则 12345678910111213141516171819202122232425262728293031[root@master ~]# vim ingress.yamlapiVersion: extensions/v1beta1kind: Ingressmetadata: name: ingress-1spec: rules: - host: www1.bdqn.com http: paths: - path: / backend: serviceName: svc-1 servicePort: 80---apiVersion: extensions/v1beta1kind: Ingressmetadata: name: ingress-2spec: rules: - host: www2.bdqn.com http: paths: - path: / backend: serviceName: svc-2 servicePort: 80[root@master ~]# kubectl apply -f ingress.yaml ingress.extensions/ingress-1 createdingress.extensions/ingress-2 created 123456789101112131415[root@master ~]# kubectl describe ingresses. ingress-1Rules: Host Path Backends ---- ---- -------- www1.bdqn.com / svc-1:80 (10.244.1.4:80,10.244.2.4:80)[root@master ~]# kubectl describe ingresses. ingress-1Rules: Host Path Backends ---- ---- -------- www2.bdqn.com / svc-2:80 (10.244.1.5:80,10.244.2.5:80)[root@master ~]# kubectl get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.100.97.246 &lt;none&gt; 80:32007/TCP,443:30741/TCP 43h 5、由于实验环境限制（这个域名是假的），所以自己用来模拟一个域名 123在windows上添加域名解析：C:\\Windows\\System32\\drivers\\etc192.168.1.70 www1.bdqn.com192.168.1.70 www2.bdqn.com ¶Ingress资源实现https代理访问 在上面的操作中，实现了使用ingress-nginx为后端所有pod提供一个统一的入口，那么，有一个非常严肃的问题需要考虑，就是如何为我们的pod配置CA证书来实现HTTPS访问？在pod中直接配置CA么？那需要进行多少重复性的操作？而且，pod是随时可能被kubelet杀死再创建的。当然这些问题有很多解决方法，比如直接将CA配置到镜像中，但是这样又需要很多个CA证书。 这里有更简便的一种方法，就拿上面的情况来说，后端有多个pod，pod与service进行关联，service又被ingress规则发现并动态写入到ingress-nginx-controller容器中，然后又为ingress-nginx-controller创建了一个Service映射到群集节点上的端口，来供client来访问。 在上面的一系列流程中，关键的点就在于Ingress规则，我们只需要在Ingress的yaml文件中，为域名配置CA证书即可，只要可以通过HTTPS访问到域名，至于这个域名是怎么关联到后端提供服务的pod，这就是属于k8s群集内部的通信了，即便是使用http来通信，也无伤大雅 1、生成一个证书： 1234567891011[root@master ~]# mkdir https[root@master ~]# cd https[root@master https]# openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj \"/CN=testsvc /0=testsvc\"Generating a 2048 bit RSA private key......................................................................................+++............+++writing new private key to 'tls.key'-----Subject Attribute 0 has no known NID, skipped[root@master https]# lstls.crt tls.key 2、创建secret资源，保存证书： 12[root@master https]# kubectl create secret tls tls-secret --key=tls.key --cert tls.crtsecret/tls-secret created 3、创建一个Deployment资源对象，用来模拟web服务 1234567891011121314151617181920212223242526272829[root@master https]# vim deploy3.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: deploy3spec: replicas: 2 template: metadata: labels: app: nginx3 spec: containers: - name: nginx3 image: nginx---apiVersion: v1kind: Servicemetadata: name: svc-3spec: selector: app: nginx3 ports: - port: 80 targetPort: 80[root@master https]# kubectl apply -f deploy3.yamldeployment.extensions/deploy3 createdservice/svc-3 created 12345678910[root@master https]# kubectl get podNAME READY STATUS RESTARTS AGEdeploy3-5c545fcc5f-4n9bw 1/1 Running 0 17sdeploy3-5c545fcc5f-7b4g2 1/1 Running 0 17s[root@master https]# kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 52dsvc-3 ClusterIP 10.97.212.56 &lt;none&gt; 80/TCP 22m[root@master https]# curl -I 10.97.212.56HTTP/1.1 200 OK 4、创建对应的Ingress规则 12345678910111213141516171819202122[root@master https]# vim ingress.yamlapiVersion: extensions/v1beta1kind: Ingressmetadata: name: ingress-3spec: tls: #引用CA证书 - hosts: - www3.bdqn.com secretName: tls-secret rules: - host: www3.bdqn.com http: paths: - path: / backend: serviceName: svc-3 servicePort: 80[root@master https]# kubectl apply -f ingress.yaml ingress.extensions/ingress-3 created//同样，添加域名解析192.168.1.70 www3.bdqn.com 5、查找对应service-NodePort的443端口映射的端口，直接用浏览器访问即可 123[root@master https]# kubectl get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.100.97.246 &lt;none&gt; 80:32007/TCP,443:30741/TCP 44h 通过浏览器访问：https://www3.bdqn.com:30741","categories":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]},{"title":"Ingress原理及配置","slug":"Ingress","date":"2020-02-23T16:00:00.000Z","updated":"2020-02-24T06:19:01.787Z","comments":true,"path":"Ingress.html","link":"","permalink":"https://pdxblog.top/Ingress.html","excerpt":"","text":"¶Ingress 在Kubernetes中，服务和Pod的IP地址仅可以在集群网络内部使用，对于集群外的应用是不可见的。为了使外部的应用能够访问集群内的服务，在Kubernetes中目前提供了以下几种方案： NodePort LoadBalancer Ingress NodePort：简单的来说就是通过Service资源对象，为后端的Pod提供一个统一的访问入口，然后将Service的统一访问接口映射到集群节点上，最终实现client通过映射到集群节点上的端口访问到后端Pod提供的服务 但是，这种方法有个弊端，就是当新生成一个pod服务就需要创建对应的service将其映射到节点端口，当运行的pod过多时，我们节点暴露给client端的端口也会随之增加，这样我们整个k8s群集的危险系数就会增加，因为我们在搭建群集之处，官方明确指出，必须关闭firewalld防火墙及清空iptables规则，现在我们又暴露了那么多端口给client，安全系数可想而知 Ingress就解决了这个弊端： 简单的理解：原先暴露的service，现在给定一个统一的访问入口 Ingress资源对象的组成： Ingress-nginx-controller： 将新加入的Ingress转化为反向代理服务器的配置文件，并使之生效（动态的感知k8s集群内Ingress资源的变化，通过lua脚本实现） Ingress： 将反向代理服务器抽象成一个Ingress对象，每添加一个新的服务，只需要写一个新的Ingress的yaml文件即可，或修改已经存在的Ingress规则的yaml 在k8s集群前边部署一个反向代理服务器，这个服务器代理着k8s集群内部的service资源 Ingress-nginx可以解决什么问题： 动态的配置服务 ​ 如果按照传统方式, 当新增加一个服务时, 我们可能需要在流量入口加一个反向代理指向我们新的k8s服务. 而如果用了Ingress-nginx, 只需要配置好这个服务, 当服务启动时, 会自动注册到Ingress的中, 不需要而外的操作 减少不必要的端口暴露 ​ 配置过k8s的都清楚, 第一步是要关闭防火墙的, 主要原因是k8s的很多服务会以NodePort方式映射出去, 这样就相当于给宿主机打了很多孔, 既不安全也不优雅. 而Ingress可以避免这个问题, 除了Ingress自身服务可能需要映射出去, 其他服务都不要用NodePort方式 Ingress-nginx工作原理： 1）Ingress controller通过和kubernetes api交互，动态的去感知集群中Ingress规则变化， 2）然后读取它，按照自定义的规则，规则就是写明了哪个域名对应哪个service，生成一段nginx配置， 3）再写到nginx-ingress-controller的pod里，这个Ingress controller的pod里运行着一个Nginx服务，控制器会把生成的nginx配置写入/etc/nginx.conf文件中， 4）然后reload一下使配置生效。以此达到域名分别配置和动态更新的问题 基于Nginx的Ingress controller根据不同的开发公司，又分为两种： k8s社区版的：Ingress-nginx nginx公司自己开发的：nginx-ingress ¶Ingress-nginx配置实例： 1）创建一个web服务，用deployment资源，用httpd奖项，然后创建一个service资源与之关联 1234567891011121314151617181920212223242526272829303132333435363738394041424344[root@master ~]# vim deploy_1.yamlapiVersion: v1kind: Namespacemetadata: name: bdqn-ns labels: name: bdqn-ns---apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: httpd-deploy namespace: bdqn-nsspec: replicas: 2 template: metadata: labels: app: bdqn-ns spec: containers: - name: httpd image: httpd---apiVersion: v1kind: Servicemetadata: name: httpd-svc namespace: bdqn-nsspec: type: NodePort selector: app: bdqn-ns ports: - name: httpd-port port: 80 targetPort: 80 nodePort: 31033[root@master ~]# kubectl apply -f deploy_1.yaml namespace/bdqn-ns createddeployment.extensions/httpd-deploy createdservice/httpd-svc created 1234567891011121314151617181920[root@master ~]# kubectl get svc -n bdqn-ns NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEhttpd-svc NodePort 10.97.86.190 &lt;none&gt; 80:31033/TCP 3m31s[root@master ~]# kubectl get pod -n bdqn-ns NAME READY STATUS RESTARTS AGEhttpd-deploy-966699d76-25wkn 1/1 Running 0 3m33shttpd-deploy-966699d76-6cdwf 1/1 Running 0 3m34s[root@master ~]# kubectl get deployments. -n bdqn-ns NAME READY UP-TO-DATE AVAILABLE AGEhttpd-deploy 2/2 2 2 3m37s[root@master ~]# kubectl describe svc -n bdqn-nsSelector: app=bdqn-nsType: NodePortIP: 10.97.86.190Port: httpd-port 80/TCPTargetPort: 80/TCPNodePort: httpd-port 31033/TCPEndpoints: 10.244.1.2:80,10.244.2.2:80Session Affinity: NoneExternal Traffic Policy: Cluster 2）创建一个web服务，用deployment资源，用tomcat镜像，然后创建一个service资源与之关联 1234567891011121314151617181920212223242526272829303132333435[root@master ~]# vim deploy_2.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: tomcat-deploy namespace: bdqn-nsspec: replicas: 2 template: metadata: labels: app: bdqn-tomcat spec: containers: - name: tomcat image: tomcat:8.5.45---apiVersion: v1kind: Servicemetadata: name: tomcat-svc namespace: bdqn-nsspec: type: NodePort selector: app: bdqn-tomcat ports: - name: tomcat-port port: 8080 targetPort: 8080 nodePort: 32033[root@master ~]# kubectl apply -f deploy_2.yaml deployment.extensions/tomcat-deploy createdservice/tomcat-svc created 1234567891011121314[root@master ~]# kubectl get deployments. -n bdqn-ns NAME READY UP-TO-DATE AVAILABLE AGEhttpd-deploy 2/2 2 2 9m58stomcat-deploy 2/2 2 2 58s[root@master ~]# kubectl get pod -n bdqn-ns NAME READY STATUS RESTARTS AGEhttpd-deploy-966699d76-25wkn 1/1 Running 0 10mhttpd-deploy-966699d76-6cdwf 1/1 Running 0 10mtomcat-deploy-759dc8c885-9wgqw 1/1 Running 0 70stomcat-deploy-759dc8c885-9xmhj 1/1 Running 0 70s[root@master ~]# kubectl get svc -n bdqn-ns NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEhttpd-svc NodePort 10.97.86.190 &lt;none&gt; 80:31033/TCP 10mtomcat-svc NodePort 10.98.122.36 &lt;none&gt; 8080:32033/TCP 75s 3）创建Ingress -nginx-controller 12345678910[root@master ~]# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.29.0/deploy/static/mandatory.yaml//将yaml文件下载下来在yaml文件中添加：hostNetwork: true spec: //在212行的spec字段下添加 hostNetwork: true //添加这行就行 # wait up to five minutes for the drain of connections[root@master ~]# kubectl apply -f mandatory.yaml[root@master ~]# kubectl get pod -n ingress-nginx NAME READY STATUS RESTARTS AGEnginx-ingress-controller-5954d475b6-xtzbc 1/1 Running 0 16m hostNetwork: true 在deployment资源中，如果添加了此字段，意味着Pod中运行的应用可以直接使用node节点的端口，这样node节点主机所在网络的其他主机，就可以通过访问该端口访问此应用。（类似于docker映射到宿主机的端口） 4）创建Ingress资源：（定义Ingress规则） 12345678910111213141516171819202122232425262728293031[root@master ~]# vim ingress.yamlapiVersion: extensions/v1beta1kind: Ingressmetadata: name: bdqn-ingress namespace: bdqn-ns annotations: nginx.ingress.kubernetes.io/rewrite-target: / #这个千万不要写错，不然后面无法访问spec: rules: - host: ingress.bdqn.com http: paths: - path: / backend: serviceName: httpd-svc servicePort: 80 - path: /tomcat backend: serviceName: tomcat-svc servicePort: 8080[root@master ~]# kubectl apply -f ingress.yaml ingress.extensions/bdqn-ingress created[root@master ~]# kubectl describe ingresses. -n bdqn-ns bdqn-ingressRules: Host Path Backends ---- ---- -------- ingress.bdqn.com / httpd-svc:80 (10.244.1.5:80,10.244.2.4:80) /tomcat httpd-tomcat:8080 (10.244.1.4:8080,10.244.2.5:8080)//如果没有这个信息说明Ingress创建的有问题 1234567891011121314151617[root@master ~]# kubectl exec -it -n ingress-nginx nginx-ingress-controller-5954d475b6-wkqr2 sh/etc/nginx $ cat nginx.conf//没创建Ingress之前这些值都是空的，这就是动态的感知，然后写入配置文件 location / &#123; set $namespace \"bdqn-ns\"; set $ingress_name \"bdqn-ingress\"; set $service_name \"httpd-svc\"; set $service_port \"80\"; set $location_path \"/\"; location ~* \"^/tomcat\" &#123; set $namespace \"bdqn-ns\"; set $ingress_name \"bdqn-ingress\"; set $service_name \"tomcat-svc\"; set $service_port \"8080\"; set $location_path \"/tomcat\"; 因为域名是自定义的，所以要配置域名解析，修改windows的host文件，将IP与域名绑定 1234567//查看Ingress-controller运行在哪个节点，IP 是 ingress-controller Pod运行所在的节点[root@master ~]# kubectl get pod -n ingress-nginx -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESnginx-ingress-controller-5954d475b6-wkqr2 1/1 Running 1 44h 192.168.1.50 node01 &lt;none&gt; &lt;none&gt;//找到host文件，进行修改C:\\Windows\\System32\\drivers\\etc192.168.1.50 ingress.bdqn.com 现在已经达到了我们想要的功能，现在可以通过ingress.bdqn.com访问httpd服务，通过ingress.bdqn.com/tomcat访问tomcat服务 在上面的访问测试中，虽然访问到了对应的服务，但是有一个弊端，就是在做DNS解析的时候，只能指定Ingress-nginx容器所在的节点IP。而指定k8s集群内部的其他节点IP（包括master）都是不可以访问到的，如果这个节点一旦宕机，Ingress-nginx容器被转移到其他节点上运行（不考虑节点标签的问题，其实保持Ingress-nginx的yaml文件中默认的标签的话，那么每个节点都是有那个标签的）。随之还要我们手动去更改DNS解析的IP（要更改为Ingress-nginx容器所在节点的IP，通过命令“kubectl get pod -n ingress-nginx -o wide”可以查看到其所在节点），很是麻烦 所以就要为ingress资源对象创建一个Service（NodePort），这样在配置DNS解析的时候，就可以通过Ingress.bdqn.com 所有node节点，包括master节点的IP来配置，很方便 5）创建service资源： 12345[root@master ~]# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.29.0/deploy/static/provider/baremetal/service-nodeport.yaml[root@master ~]# kubectl apply -f service-nodeport.yaml[root@master ~]# kubectl get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.100.167.12 &lt;none&gt; 80:32756/TCP,443:30501/TCP 2m7s Service-Nodeport 因为Ingress-nginx-controller运行在了集群内的其中一个节点，为了保证即使这个节点宕机，我们对应的域名仍然能够正常的访问服务，所以我们将Ingress-nginx-controller也暴露为一个service资源 至此，这个域名就可以和集群中任意节点的 32756/30501端口进行绑定了","categories":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]},{"title":"ConfigMap、Secret","slug":"ConfigMap、Secret","date":"2020-02-16T16:00:00.000Z","updated":"2020-02-17T07:16:38.374Z","comments":true,"path":"ConfigMap、Secret.html","link":"","permalink":"https://pdxblog.top/ConfigMap%E3%80%81Secret.html","excerpt":"","text":"¶ConfigMap、Secret 为什么有这两个东西： 我们在kubernetes上部署应用的时候，经常会需要传一些配置给我们的应用，比如数据库地址啊，用户名密码啊之类的。我们要做到这个，有好多种方案，比如： 我们可以直接在打包镜像的时候写在应用配置文件里面，但是这种方式的坏处显而易见而且非常明显。 我们可以在配置文件里面通过env环境变量传入，但是这样的话我们要修改env就必须去修改yaml文件，而且需要重启所有的container才行。 我们可以在应用启动的时候去数据库或者某个特定的地方拿，没问题！但是第一，实现起来麻烦；第二，如果配置的地方变了怎么办？ 当然还有别的方案，但是各种方案都有各自的问题。 而且，还有一个问题就是，如果说我的一个配置，是要多个应用一起使用的，以上除了第三种方案，都没办法进行配置的共享，就是说我如果要改配置的话，那得一个一个手动改。假如我们有100个应用，就得改100份配置，以此类推…… kubernetes对这个问题提供了一个很好的解决方案，就是用ConfigMap和Secret 应用场景： 镜像往往是一个应用的基础，还有很多需要自定义的参数或配置，例如资源的消耗、日志的位置级别等等，这些配置可能会有很多，因此不能放入镜像中，Kubernetes中提供了Configmap来实现向容器中提供配置文件或环境变量来实现不同配置，从而实现了镜像配置与镜像本身解耦，使容器应用做到不依赖于环境配置 Secret资源对象： 可以保存轻量的敏感信息，比如数据库的用户名和密码或者认证秘钥等。它保存的数据是以秘文的方式存放的 configMap资源对象： 和Secret一样，拥有大多数共同的特性，但是区别是，configMap保存的是一些不太重要的信息，它保存的数据是以明文的方式存放的。 当我们创建上述两种资源对象时，其实就是将这两种资源对象存储的信息写入了k8s群集中的etcd数据中心 Secret与ConfigMap的异同： 相同之处： 都是用来保存轻量级信息的，可以供其他资源对象（Deployment、RC、RS和Pod）进行挂载使用 这两种资源对象的创建方法（4种）及引用方法（2种）都是一样的，都是以键值对的方式进行存储的 不同之处： Secret是用来保存敏感信息的，而configMap是用来保存一些不太重要的数据的，具体表现在当我们执行“kubectl describe …”命令时，Secret这种类型的资源对象时查看不到其具体的信息的，而configMap是可以查看到其保存的具体内容的 ¶Secret: Secret：用于保存一些敏感信息，比如数据库的用户名密码或者密钥。这些数据是比较少量的，将这些信息放在 secret中比放在 pod 的定义或者 docker 镜像中来说更加安全和灵活 用户可以创建自己的secret，系统也会有自己的secret 内置 secret 1[root@master ~]# kubectl get secrets -n kube-system Secret有三种类型： Opaque：base64编码格式的Secret，用来存储密码、密钥等；但数据也通过base64 –decode解码得到原始数据，所有加密性很弱 kubernetes.io/dockerconfigjson：用来存储私有docker registry的认证信息 kubernetes.io/service-account-token： 用于被serviceaccount引用，serviceaccout创建时Kubernetes会默认创建对应的secret。Pod如果使用了serviceaccount，对应的secret会自动挂载到Pod目录/run/secrets/ kubernetes.io/serviceaccount中 举例：保存数据库的用户名和密码 用户名：root 密码：123.com 有四种方法： 1、通过- -from-literal（文字的）： 也就是说需要保存什么，直接写出来就行 注意：每一个–from-literal只能保存一条信息 1[root@master ~]# kubectl create secret generic mysecret1 --from-literal=username=root --from-literal=password=123.com generic：通用的、一般的加密方式 1234[root@master ~]# kubectl get secrets NAME TYPE DATA AGEdefault-token-x9ptl kubernetes.io/service-account-token 3 42dmysecret1 Opaque（不透明的） 2 2m13s Opaque（不透明的）：也就是说你看不到 12345678[root@master ~]# kubectl describe secretsType: OpaqueData====password: 7 bytesusername: 4 bytes//这里看不到真正的值是什么 2、- -from-file（文件）： 同样，每一个只能保存一条信息 12345678[root@master ~]# echo root &gt; username[root@master ~]# echo 123.com &gt; password[root@master ~]# kubectl create secret generic mysecret2 --from-file=username --from-file=password [root@master ~]# kubectl get secrets NAME TYPE DATA AGEdefault-token-x9ptl kubernetes.io/service-account-token 3 42dmysecret1 Opaque 2 28mmysecret2 Opaque 2 28s 既然是通过文件创建的，那么把文件删除，这个secret是否还在 1234567[root@master ~]# rm -rf username password [root@master ~]# kubectl get secrets NAME TYPE DATA AGEdefault-token-x9ptl kubernetes.io/service-account-token 3 42dmysecret1 Opaque 2 29mmysecret2 Opaque 2 92s//它确实还会存在 3、通过- -from-env-file： 这种方法可以把用户名和密码写在一个文件里面，这样就比前两种方便 123456789101112131415[root@master ~]# vim env.txtusername=rootpassword=123.com[root@master ~]# kubectl create secret generic mysecret3 --from-env-file=env.txt[root@master ~]# kubectl get secrets NAME TYPE DATA AGEdefault-token-x9ptl kubernetes.io/service-account-token 3 42dmysecret1 Opaque 2 34mmysecret2 Opaque 2 6m27smysecret3 Opaque 2 16s[root@master ~]# kubectl describe secretsData====password: 7 bytesusername: 4 bytes 4、通过yaml配置文件 先看一下yaml怎么写 1234567891011121314[root@master ~]# kubectl get secrets mysecret1 -o yamlapiVersion: v1data: password: MTIzLmNvbQ== username: cm9vdA==kind: Secretmetadata: creationTimestamp: \"2020-02-14T02:01:34Z\" name: mysecret1 namespace: default resourceVersion: \"13766\" selfLink: /api/v1/namespaces/default/secrets/mysecret1 uid: ffce8c7a-2dfc-4958-9e3b-0fcb50d00ccatype: Opaque 可以看到数据是被加密后写入yaml文件里的，所以我们写的时候不能直接写数据，而是要加密一下 把保存的数据加密： 通过base64方式： 1234[root@master ~]# echo root | base64cm9vdAo=[root@master ~]# echo 123.com | base64MTIzLmNvbQo= 创建secret资源对象： 12345678910111213141516[root@master ~]# vim secret4.yamlapiVersion: v1kind: Secretmetadata: name: mysecret4data: username: cm9vdAo= password: MTIzLmNvbQo=[root@master ~]# kubectl apply -f secret4.yaml[root@master ~]# kubectl get secrets NAME TYPE DATA AGEdefault-token-x9ptl kubernetes.io/service-account-token 3 42dmysecret1 Opaque 2 42mmysecret2 Opaque 2 14mmysecret3 Opaque 2 8mmysecret4 Opaque 2 18s 这种方法虽然说我们看不到真正的数据是什么，但是这种方式也是不安全的，每一次编码后的数据是一样的，是由规律的，同样它是可以被解码的 解码： 12[root@master ~]# echo -n cm9vdAo | base64 --decoderoot 如何来使用Secret资源： Secret 可以作为数据卷被挂载，或作为环境变量 暴露出来以供 pod 中的容器使用。它们也可以被系统的其他部分使用，而不直接暴露在 pod 内 两种方法： 1、以Volume挂载的方式 1234567891011121314151617181920212223242526//创建Pod来引用secret[root@master ~]# vim pod.yamlapiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: mypod image: busybox args: - /bin/sh - -c - sleep 300000 volumeMounts: - name: secret-test mountPath: \"/etc/secret-test\" readOnly: true //是否只读，也就是说对于/etc/secret-test只有只读的权限，不能修改 volumes: - name: secret-test secret: secretName: mysecret1[root@master ~]# kubectl apply -f pod.yaml[root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGEmypod 1/1 Running 0 2m4s 进入容器查看是否有我们保存的数据 123456789[root@master ~]# kubectl exec -it mypod /bin/sh/ # cd /etc/secret-test/etc/secret-test # cat usernameroot/etc/secret-test # cat password123.com/etc/secret-test # echo admin &gt; username/bin/sh: can't create username: Read-only file system//这个文件也是不能修改的，因为是只读文件 还可以自定义存放数据的文件名： 1234567891011121314151617181920212223//在volumes字段下追加items字段： volumes: - name: secret-test secret: secretName: mysecret1 items: - key: username path: my-group/my-username - key: password path: my-group/my-password[root@master ~]# kubectl apply -f pod.yaml pod/mypod created[root@master ~]# kubectl exec -it mypod /bin/sh/ # cd /etc/secret-test//etc/secret-test # lsmy-group/etc/secret-test # cd my-group//etc/secret-test/..2020_02_17_01_40_09.035305611/my-group # lsmy-username my-password/etc/secret-test/..2020_02_17_01_40_09.035305611/my-group # cat my-username root/etc/secret-test/..2020_02_17_01_40_09.035305611/my-group # cat my-password 123.com 2、以环境变量的方式 123456789101112131415161718192021222324252627282930[root@master ~]# cp pod.yaml pod-env.yaml [root@master ~]# vim pod-env.yamlapiVersion: v1kind: Podmetadata: name: mypod2spec: containers: - name: mypod2 image: busybox args: - /bin/sh - -c - sleep 300000 env: - name: SECRET_USERNAME valueFrom: secretKeyRef: //翻译过来就是机密键引用，提取mysecret2里面的数据到SECRET_USERNAME name: mysecret2 key: username - name: SECRET_PASSWORD valueFrom: secretKeyRef: //与上面同理 name: mysecret2 key: password[root@master ~]# kubectl apply -f pod-env.yaml[root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGEmypod 1/1 Running 0 18mmypod2 1/1 Running 0 79s 同样，进入pod查看 12345[root@master ~]# kubectl exec -it mypod2 /bin/sh/ # echo $SECRET_USERNAMEroot/ # echo $SECRET_PASSWORD123.com 如果现在将secret资源内保存的数据进行更新，使用此数据的应用内，数据是否也会更新 更新mysecret1的数据：把password-----&gt;123.com----&gt;admin 12345678910111213[root@master ~]# echo admin | base64YWRtaW4K[root@master ~]# kubectl get secrets zhbsecret2 -o yaml//可以通过edit命令直接修改：[root@master ~]# kubectl edit secrets zhbsecret2data: username: cm9vdAo= password: YWRtaW4K //更改[root@master ~]# kubectl exec -it mypod /bin/sh/ # cd /etc/secret-test/my-group//etc/secret-test/..2020_02_17_01_57_25.223684048/my-group # cat my-password admin//可以看到已经跟着改变了 注意： ​ 这里引用数据是以volumes挂载使用数据的方式，才会实时更新 那么，以环境变量的方式引用的数据，是否会实时更新？ 12345678[root@master ~]# kubectl edit secrets mysecret4data: username: cm9vdAo= password: YWRtaW4K[root@master ~]# kubectl exec -it mypod2 /bin/sh/ # echo $SECRET_PASSWORD123.com//没有变化 总结： ​ 如果引用secret数据的应用，要求会随着secret资源对象内保存的数据的更新而实时更新，那么应该使用volumes挂载的方式引用资源。因为用环境变量的方式引用不会实时更新数据 ¶ConfigMap: 和Secret资源类似，不同之处在于，secret资源保存的是敏感信息，而configmap保存的方式是以明文的方式存放的数据 什么是ConfigMap： ConfigMap对像是一系列配置的集合，k8s会将这一集合注入到对应的Pod对像中，并为容器成功启动使用。注入的方式一般有两种，一种是挂载存储卷，一种是传递变量。ConfigMap被引用之前必须存在，属于名称空间级别，不能跨名称空间使用，内容明文显示。ConfigMap内容修改后，对应的pod必须重启或者重新加载配置 创建ConfigMap的4种方式： username：adam age：18 和secretc创建的方式一模一样 1、通过- -from-literal（文字的）： 1234567891011121314[root@master ~]# kubectl create configmap myconfigmap1 --from-literal=username=adam --from-literal=age=18configmap/myconfigmap1 created[root@master ~]# kubectl get configmaps NAME DATA AGEmyconfigmap1 2 32s[root@master ~]# kubectl describe configmapsData====age:----18username:----adam 2、- -from-file（文件）： 12345678[root@master ~]# touch adam &gt; username[root@master ~]# touch 18 &gt; age[root@master ~]# kubectl create configmap myconfigmap2 --from-file=username --from-file=age configmap/myconfigmap2 created[root@master ~]# kubectl get configmaps NAME DATA AGEmyconfigmap1 2 4m23smyconfigmap2 2 63s 3、通过- -from-env-file： 12345678910[root@master ~]# vim env.txtusername&#x3D;adamage&#x3D;18[root@master ~]# kubectl create configmap myconfigmap3 --from-env-file&#x3D;env.txt configmap&#x2F;myconfigmap3 created[root@master ~]# kubectl get configmaps NAME DATA AGEmyconfigmap1 2 16mmyconfigmap2 2 5m18smyconfigmap3 2 8m56s 4、通过yaml配置文件 12345678910111213141516[root@master ~]# vim configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: myconfigmap4data: username: adam age: \"18\"[root@master ~]# kubectl apply -f configmap.yaml configmap/myconfigmap4 created[root@master ~]# kubectl get configmaps NAME DATA AGEmyconfigmap1 2 16mmyconfigmap2 2 5m18smyconfigmap3 2 8m56smyconfigmap4 2 4m8s ¶使用configmap： 和secret一样，有两种方法 第一种方法是： 以volumes挂载的方式引用资源 1234567891011121314151617181920212223[root@master ~]# vim v-pod.yamlapiVersion: v1kind: Podmetadata: name: pod1spec: containers: - name: pod1 image: busybox args: - bin/sh - -c - sleep 300000 volumeMounts: - name: cmp-test mountPath: \"/etc/cmp-test\" readOnly: true volumes: - name: cmp-test configMap: name: myconfigmap1[root@master ~]# kubectl apply -f v-pod.yaml pod/pod1 created 第二种方式： 以环境变量的方式引用资源 123456789101112131415161718192021222324252627282930[root@master ~]# vim e-pod.yaml apiVersion: v1kind: Podmetadata: name: pod2spec: containers: - name: pod2 image: busybox args: - bin/sh - -c - sleep 300000 env: - name: CONFIGMAP_NAME valueFrom: configMapKeyRef: name: myconfigmap2 key: username - name: CONFIGMAP_AGE valueFrom: configMapKeyRef: name: myconfigmap2 key: age[root@master ~]# kubectl apply -f e-pod.yaml pod/pod2 created[root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGEpod1 1/1 Running 0 5m34spod2 1/1 Running 0 48s 如果现在将confgimap资源内保存的数据进行更新，使用此数据的应用内，数据是否也会更新 123456789[root@master ~]# kubectl edit configmaps myconfigmap1data: age: \"18\" username: root[root@master ~]# kubectl exec -it pod1 /bin/sh/ # cd /etc/cmp-test//etc/cmp-test # cat username root//这里会跟着更新，如果操作过快，它会反应不过来，你就话看不到改变，稍微等一下就行了 那么，以环境变量的方式引用的数据，是否会实时更新？ 1234567891011121314151617181920212223242526[root@master ~]# kubectl exec -it pod2 /bin/sh/ # echo $CONFIGMAP_AGE18/ # echo $CONFIGMAP_NAMEadam/ # exit[root@master ~]# kubectl edit configmaps myconfigmap2data: age: | 18 username: | root[root@master ~]# kubectl describe configmaps myconfigmap2Data====age:----18username:----root[root@master ~]# kubectl exec -it pod2 /bin/sh/ # echo $CONFIGMAP_NAMEadam//和secret一样，是不会更新的 ¶小结 ¶Secret： 用于存放一些敏感信息，比如数据库的用户名密码、密钥等，以密文的方式保存 创建Secret资源对象的四种方式： –from-literal（文字的）：需要保存什么内容直接写出来，一次只能保存一条 –from-file（文件）：把需要保存的内容写到文件里面，通过–from-file指定这个文件。一次只能保存一条 –from-env-file（环境变量）：把想要保存的内容都写入一个文件里面，通过–from-env-file指定 通过yaml配置文件：在data字段写入要保存的内容，注意是以密文的格式写入（使用base64的方式加密就行） 引用Secret资源的两种方法： Volumes挂载的方式： 环境变量的方式： ¶ConfigMap： 和Secret一样，拥有大多数共同的特性，但是区别是，configMap保存的是一些不太重要的信息，它保存的数据是以明文的方式存放的，使用describe来查看是，能看到真正的信息 创建ConfigMap资源对象的四种方式和引用ConfigMap的两种方式一摸一样 –from-literal（文字的） –from-file（文件） –from-env-file（环境变量） 通过yaml配置文件 Volumes挂载的方式： 环境变量的方式： 如果引用secret、CongigMap数据的应用，要求会随着secret、ConfigMap资源对象内保存的数据的更新而实时更新，那么应该使用volumes挂载的方式引用资源。因为用环境变量的方式引用不会实时更新数据","categories":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]},{"title":"StatefulSet","slug":"StatefulSet","date":"2020-02-11T16:00:00.000Z","updated":"2020-02-14T03:25:48.428Z","comments":true,"path":"StatefulSet.html","link":"","permalink":"https://pdxblog.top/StatefulSet.html","excerpt":"","text":"¶StatefulSet RC、RS、Deployment、DS（DaemonSet）这些Pod控制器都是面向无状态的服务，它们所管理的Pod的IP、名字、启停顺序等都是随机的 这些Pod控制器都有一个相同点 ​ template（模板）：根据模板创建出来的Pod，它们的状态都是一摸一样的（除了名称、IP、域名之外） ​ 可以理解为：任何一个Pod都可以被删除，然后用新生成的Pod进行替换 StatefulSet： 顾名思义：有状态的集合，管理所有有状态的服务，比如MySQL、MongoDB集群等 它之前的名字是：PetSet Pet：宠物 把之前按无状态的服务比喻为牛、羊等牲畜。把有状态的服务比喻为：宠物 StatefulSet本质上是Deployment的一种变体，在v1.9版本中已成为GA版本，它为了解决有状态服务的问题，它所管理的Pod拥有固定的Pod名称，启停顺序，在StatefulSet中，Pod名字称为网络标识(hostname)，还必须要用到共享存储 有状态的服务：后端生成的每一个Pod都具有自己的唯一性，不可随意被删除 需要记录前一次或者多次通信中的相关事件，以作为下一次通信的分类标准。比如：mysql等数据库服务。（Pod的名称不能随意变化，数据持久化的目录也是不一样的，每一个Pod都有自己独有的数据持久化存储目录） 一个小实例： 12345678910111213141516171819202122232425262728293031323334353637383940[root@master ~]# vim statefulset.yamlapiVersion: v1kind: Servicemetadata: name: headless-svc labels: app: headless-svcspec: ports: - port: 80 selector: app: headless-pod clusterIP: None---apiVersion: apps/v1kind: StatefulSetmetadata: name: statefulset-testspec: serviceName: headless-svc replicas: 3 selector: matchLabels: app: headless-pod template: metadata: labels: app: headless-pod spec: containers: - name: myhttpd image: httpd ports: - containerPort: 80[root@master ~]# kubectl apply -f statefulset.yaml service/headless-svc createdstatefulset.apps/statefulset-test created[root@master ~]# kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEheadless-svc ClusterIP None &lt;none&gt; 80/TCP 4m Deployment控制的pod的名称由来： ​ Deployment+RS+随机字符串（Pod的名称），没有顺序的额，可以被随意替代 StategulSet的三个组成部分： 1、headless-svc：无头服务。因为没有IP地址，所以它不具备负载均衡的功能了 作用：为后端的每一个Pod去命名 因为statefulset要求Pod的名称是有顺序的，每一个Pod都不能被随意取代，也就是说即使Pod重建之后，名称依然不变 12345[root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGEstatefulset-test-0 1/1 Running 0 23mstatefulset-test-1 1/1 Running 0 22mstatefulset-test-2 1/1 Running 0 22m 1234567[root@master ~]# kubectl delete pod statefulset-test-0[root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGEstatefulset-test-0 0/1 ContainerCreating 0 6sstatefulset-test-1 1/1 Running 0 25mstatefulset-test-2 1/1 Running 0 25m//Pod重建之后名称没有发生变化 2、statefulset：定义具体的应用 3、volumeClaimTeplates：自动创建PVC，为后端的Pod提供专有的存储 存储卷申请模板，创建PVC，指定pvc名称大小，将自动创建pvc，且pvc必须由存储类供应 为什么需要 headless service 无头服务？ 在用Deployment时，每一个Pod名称是没有顺序的，是随机字符串，因此是Pod名称是无序的，但是在statefulset中要求必须是有序 ，每一个pod不能被随意取代，pod重建后pod名称还是一样的。而pod IP是变化的，所以是以Pod名称来识别。pod名称是pod唯一性的标识符，必须持久稳定有效。这时候要用到无头服务，它可以给每个Pod一个唯一的名称 。 为什么需要volumeClaimTemplate？ 对于有状态的副本集都会用到持久存储，对于分布式系统来讲，它的最大特点是数据是不一样的，所以各个节点不能使用同一存储卷，每个节点有自已的专用存储，但是如果在Deployment中的Pod template里定义的存储卷，是所有副本集共用一个存储卷，数据是相同的，因为是基于模板来的 ，而statefulset中每个Pod都要自已的专有存储卷，所以statefulset的存储卷就不能再用Pod模板来创建了，于是statefulSet使用volumeClaimTemplate，称为卷申请模板，它会为每个Pod生成不同的pvc，并绑定pv， 从而实现各pod有专用存储。这就是为什么要用volumeClaimTemplate的原因 每一个pod—&gt;对应一个pvc----&gt;每一个pvc对应一个pv ​ storageclass：自动创建PV ​ 需要解决：自动创建PVC-----&gt;volumeClaimTeplates 一、创建StorageClass资源对象 ​ 1、基于NFS服务，创建NFS服务 123[root@master ~]# showmount -eExport list for master:/nfsdata * ​ 2、创建rbac权限 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@master ~]# vim rbac-rolebind.yamlapiVersion: v1kind: ServiceAccountmetadata: name: nfs-provisioner---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: nfs-provisioner-runnerrules: - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"watch\", \"create\", \"update\", \"patch\"] - apiGroups: [\"\"] resources: [\"services\", \"endpoints\"] verbs: [\"get\",\"create\",\"list\", \"watch\",\"update\"] - apiGroups: [\"extensions\"] resources: [\"podsecuritypolicies\"] resourceNames: [\"nfs-provisioner\"] verbs: [\"use\"]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: run-nfs-provisionersubjects: - kind: ServiceAccount name: nfs-provisioner namespace: default //这个字段必须要写，不然会报错roleRef: kind: ClusterRole name: nfs-provisioner-runner apiGroup: rbac.authorization.k8s.io[root@master ~]# kubectl apply -f rbac-rolebind.yaml serviceaccount/nfs-provisioner unchangedclusterrole.rbac.authorization.k8s.io/nfs-provisioner-runner unchangedclusterrolebinding.rbac.authorization.k8s.io/run-nfs-provisioner created ​ 3、创建Deployment资源对象，用Pod代替真正的NFS服务 1234567891011121314151617181920212223242526272829303132333435363738[root@master ~]# vim nfs-deployment.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nfs-client-provisionerspec: replicas: 1 strategy: type: Recreate template: metadata: labels: app: nfs-client-provisioner spec: serviceAccount: nfs-provisioner containers: - name: nfs-client-provisioner image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: bdqn - name: NFS_SERVER value: 192.168.1.70 - name: NFS_PATH value: /nfsdata volumes: - name: nfs-client-root nfs: server: 192.168.1.70 path: /nfsdata[root@master ~]# kubectl apply -f nfs-deployment.yaml deployment.extensions/nfs-client-provisioner created[root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGEnfs-client-provisioner-f6cb6688b-5zn8d 1/1 Running 0 7s ​ 4、创建storaclass 123456789101112[root@master ~]# vim test-storageclass.yamlapiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: sc-nfsprovisioner: bdqnreclaimPolicy: Retain[root@master ~]# kubectl apply -f test-storageclass.yaml storageclass.storage.k8s.io/sc-nfs created[root@master ~]# kubectl get scNAME PROVISIONER AGEsc-nfs bdqn 10s 二、解决自动创建PVC 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[root@master ~]# vim statefulset.yamlapiVersion: v1kind: Servicemetadata: name: headless-svc labels: app: headless-svcspec: ports: - port: 80 name: myweb selector: app: headless-pod clusterIP: None---apiVersion: apps/v1kind: StatefulSetmetadata: name: statefulset-testspec: serviceName: headless-svc replicas: 3 selector: matchLabels: app: headless-pod template: metadata: labels: app: headless-pod spec: containers: - image: httpd name: myhttpd ports: - containerPort: 80 name: httpd volumeMounts: - mountPath: /mnt name: test volumeClaimTemplates: //自动的创建PVC - metadata: name: test annotations: //这是指定storageclass volume.beta.kubernetes.io/storage-class: sc-nfs spec: accessModes: - ReadWriteOnce resources: requests: storage: 100Mi[root@master ~]# kubectl apply -f statefulset.yaml service/headless-svc createdstatefulset.apps/statefulset-test created[root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGEnfs-client-provisioner-f6cb6688b-5zn8d 1/1 Running 0 13mstatefulset-test-0 1/1 Running 0 23sstatefulset-test-1 1/1 Running 0 16sstatefulset-test-2 1/1 Running 0 9s 注意： ​ 如果生成的Pod，第一个出现了问题，后面的都不会生成 根据volumeClaimTemplates自动创建的PVC： 12345[root@master ~]# kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEtest-statefulset-test-0 Bound pvc-3a105a9d-5892-4080-a993-20fd2540cd3e 100Mi RWO sc-nfs 46mtest-statefulset-test-1 Bound pvc-123bf53d-a72b-4bfa-a901-bb98efcda056 100Mi RWO sc-nfs 45mtest-statefulset-test-2 Bound pvc-8529c668-5b38-4024-93af-b18fa238b0ba 100Mi RWO sc-nfs 45m 如果集群中没有StorageClass的动态供应PVC的机制，也可以提前手动创建多个PV、PVC，手动创建的PVC名称必须符合之后创建的StatefulSet命名规则：(volumeClaimTemplates.name)-(pod_name) Statefulset名称为statefulset-test 三个Pod副本: statefulset-test-0，statefulset-test-1，statefulset-test-2 volumeClaimTemplates名称为：test 那么自动创建出来的PVC名称为test-statefulset-test-[0-2]，为每个Pod创建一个PVC 规律总结： 匹配Pod name(网络标识)的模式为：$(statefulset名称)-$(序号)，比如上面的示例：statefulset-test-0，statefulset-test-1，statefulset-test-2。 StatefulSet为每个Pod副本创建了一个DNS域名，这个域名的格式为： $(podname).(headless server name)，也就意味着服务间是通过Pod域名来通信而非Pod IP，因为当Pod所在Node发生故障时，Pod会被飘移到其它Node上，Pod IP会发生变化，但是Pod域名不会有变化。 StatefulSet使用Headless服务来控制Pod的域名，这个域名的FQDN为：$(service name).$(namespace).svc.cluster.local，其中，“cluster.local”指的是集群的域名。 根据volumeClaimTemplates，为每个Pod创建一个pvc，pvc的命名规则匹配模式：(volumeClaimTemplates.name)-(pod_name)，比如上面的volumeMounts.name=test， Pod name=statefulset-test-[0-2]，因此创建出来的PVC是test-statefulset-test-0，test-statefulset-test-1，test-statefulset-test-2 删除Pod不会删除其pvc，手动删除pvc将自动释放pv。 关于Cluster Domain、headless service名称、StatefulSet 名称如何影响StatefulSet的Pod的 StatefulSet的启停顺序： 有序部署：部署StatefulSet时，如果有多个Pod副本，它们会被顺序地创建（从0到N-1）并且，在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态。 有序删除：当Pod被删除时，它们被终止的顺序是从N-1到0。 有序扩展：当对Pod执行扩展操作时，与部署一样，它前面的Pod必须都处于Running和Ready状态 StatefulSet Pod管理策略： 在v1.7以后，通过允许修改Pod排序策略，同时通过.spec.podManagementPolicy字段确保其身份的唯一性。 OrderedReady：上述的启停顺序，默认设置。 Parallel：告诉StatefulSet控制器并行启动或终止所有Pod，并且在启动或终止另一个Pod之前不等待前一个Pod变为Running and Ready或完全终止 StatefulSet使用场景： 稳定的持久化存储，即Pod重新调度后还是能访问到相同的持久化数据，基于PVC来实现 稳定的网络标志，即Pod重新调度后其PodName和HostName不变，基于Headless Service（即没有Cluster IP的Service）来实现 有序部署，有序扩展，即Pod是有顺序的，在部署或者扩展的时候要依据定义的顺序依次依次进行（即从0到N-1，在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态），基于init containers来实现 有序收缩，有序删除（即从N-1到0） 更新策略： 在Kubernetes 1.7及更高版本中，通过.spec.updateStrategy字段允许配置或禁用Pod、labels、source request/limits、annotations自动滚动更新功能。 **OnDelete：**通过.spec.updateStrategy.type 字段设置为OnDelete，StatefulSet控制器不会自动更新StatefulSet中的Pod。用户必须手动删除Pod，以使控制器创建新的Pod。 **RollingUpdate：**通过.spec.updateStrategy.type 字段设置为RollingUpdate，实现了Pod的自动滚动更新，如果.spec.updateStrategy未指定，则此为默认策略。 StatefulSet控制器将删除并重新创建StatefulSet中的每个Pod。它将以Pod终止（从最大序数到最小序数）的顺序进行，一次更新每个Pod。在更新下一个Pod之前，必须等待这个Pod Running and Ready。 **Partitions：**通过指定 .spec.updateStrategy.rollingUpdate.partition 来对 RollingUpdate 更新策略进行分区，如果指定了分区，则当 StatefulSet 的 .spec.template 更新时，具有大于或等于分区序数的所有 Pod 将被更新。 具有小于分区的序数的所有 Pod 将不会被更新，即使删除它们也将被重新创建。如果 StatefulSet 的 .spec.updateStrategy.rollingUpdate.partition 大于其 .spec.replicas，则其 .spec.template 的更新将不会传播到 Pod。在大多数情况下，不需要使用分区 StatefulSet注意事项： 还在beta状态，需要kubernetes v1.5版本以上才支持 所有Pod的Volume必须使用PersistentVolume或者是管理员事先创建好 为了保证数据安全，删除StatefulSet时不会删除Volume StatefulSet需要一个Headless Service来定义DNS domain，需要在StatefulSet之前创建好 目前StatefulSet还没有feature complete，比如更新操作还需要手动patch 更多可以参考：https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/ 进入容器，验证持久化是否成功 123456789101112[root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGEnfs-client-provisioner-f6cb6688b-5zn8d 1/1 Running 0 30mstatefulset-test-0 1/1 Running 0 17mstatefulset-test-1 1/1 Running 0 16mstatefulset-test-2 1/1 Running 0 16m[root@master ~]# kubectl exec -it statefulset-test-0 /bin/sh# cd /mnt# touch testfile# exit[root@master ~]# ls /nfsdata/default-test-statefulset-test-0-pvc-3a105a9d-5892-4080-a993-20fd2540cd3e/testfile ¶小结 Deployment、RC、RS、DS： 这些Pod控制器都是面向无状态的服务，他们管理的Pod的IP、名字、启停顺序等都是随机的 这些根据模板创建出来的Pod，特们的状态都是一摸一样的（除了名称、IP、域名之外） 任何一个Pod都可以被删除，然后用因生成的Pod进项替换 StatefulSet： 顾名思义：有状态的集合，管理所有的有状态服务，比如MySQL集群等 后端生成的每一个Pod都具有自己的唯一性，不可被随意删除 需要记录前一次或者多次通信中的相关事件，以作为下一次通信的分类标准 Pod的名称不能随意变化，数据持久化的目录也是不一样的，每一个Pod又都自己独有的数据持久化存储目录 扩容、缩容：在此过程中，Pod的生成或删除操作也是有顺序性的 12345678[root@master ~]# kubectl get pod -n zhbNAME READY STATUS RESTARTS AGEnfs-client-provisioner-f6cb6688b-x2zls 1/1 Running 1 42hstatefulset-test-0 1/1 Running 1 42hstatefulset-test-1 1/1 Running 1 42hstatefulset-test-2 1/1 Running 1 42hstatefulset-test-3 1/1 Running 0 76sstatefulset-test-4 1/1 Running 0 66s 升级操作： 1[root@master ~]# kubectl explain sts.spec.updateStrategy.rollingUpdate.partition partition：如果partition后面的值等于N，N+的都会更新，默认值为0（所有都会更新） 如果N等于2，那么它会从statefulset-test-2开始更新，以此类推 statefulset-test-0 statefulset-test-1 statefulset-test-2 statefulset-test-3 statefulset-test-4","categories":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]},{"title":"k8s的存储类","slug":"k8s的存储类","date":"2020-02-10T16:00:00.000Z","updated":"2020-02-12T07:04:51.200Z","comments":true,"path":"k8s的存储类.html","link":"","permalink":"https://pdxblog.top/k8s%E7%9A%84%E5%AD%98%E5%82%A8%E7%B1%BB.html","excerpt":"","text":"¶k8s存储类 如果，k8s集群中，有很多类似的PV，PVC在去向PV申请空间的时候，不仅会考虑名称以及访问控制模式，还会考虑你申请空间的大小，会分配给你最合适大小的PV 运行一个web服务，采用Deployment资源，基于nginx镜像。数据持久化目录为nginx服务的主访问目录：/usr/share/nginx/html 创建一个PVC，与上述资源进行关联 ​ 先创建两个PV：web-pv1（1G），web-pv2（2G） 123456789101112131415161718192021[root@master ~]# vim web1.yamlapiVersion: v1kind: PersistentVolumemetadata: name: web-pv1spec: capacity: storage: 1Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle storageClassName: nfs nfs: path: /nfsdata/web1 server: 192.168.1.70[root@master ~]# mkdir /nfsdata/web1[root@master ~]# kubectl apply -f web1.yaml persistentvolume/web-pv1 created[root@master ~]# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEweb-pv1 1Gi RWO Recycle Available nfs 6s 1234567891011121314151617181920[root@master ~]# vim web2.yamlapiVersion: v1kind: PersistentVolumemetadata: name: web-pv2spec: capacity: storage: 2Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle storageClassName: nfs nfs: path: /nfsdata/web2 server: 192.168.1.70[root@master ~]# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEweb-pv1 1Gi RWO Recycle Available nfs 97sweb-pv2 2Gi RWO Recycle Available nfs 6s[root@master ~]# mkdir /nfsdata/web2 123456789101112131415161718192021[root@master ~]# vim web.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: test-webspec: template: metadata: labels: app: nginx spec: containers: - image: nginx name: nginx volumeMounts: - name: test-web mountPath: /usr/share/nginx/html volumes: - name: test-web persistentVolumeClaim: claimName: web-pvc 123456789101112131415161718192021222324[root@master ~]# vim web-pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: web-pvcspec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi storageClassName: nfs[root@master ~]# kubectl apply -f web-pvc.yaml[root@master ~]# kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEweb-pvc Bound web-pv1 1Gi RWO nfs 6s[root@master ~]# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEweb-pv1 1Gi RWO Recycle Bound default&#x2F;web-pvc nfs 9m8sweb-pv2 2Gi RWO Recycle Available nfs 7m37s[root@master ~]# kubectl apply -f web.yaml[root@master ~]# kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-web-67989b6d78-2b774 1&#x2F;1 Running 0 2m1s 10.244.2.5 node02 &lt;none&gt; &lt;none&gt; 如果名称和访问模式都一样，它会考虑空间大小进行分配，分配比较接近的PV进行关联 12345678[root@master ~]# kubectl exec -it test-web-67989b6d78-2b774 /bin/bashroot@test-web-67989b6d78-2b774:/# cd /usr/share/nginx/html/root@test-web-67989b6d78-2b774:/usr/share/nginx/html# echo 12345 &gt; index.htmlroot@test-web-67989b6d78-2b774:/usr/share/nginx/html# exitexitcommand terminated with exit code 127[root@master ~]# curl 10.244.2.512345 很多的服务，很多的资源对象 ​ 如果要去创建服务，做数据持久化，需要预先知道可用PV有哪些？ ​ 如果为了这个服务去提前创建PV，那么我们还需要知道，这个服务大概需要多大的空间？ Storage Class（存储类）：它可以动态的自动的创建所需要的 PV PV是运维人员来创建的，开发操作PVC，可是大规模集群中可能会有很多PV，如果这些PV都需要运维手动来处理这也是一件很繁琐的事情，所以就有了动态供给概念，也就是Dynamic Provisioning。而我们上面的创建的PV都是静态供给方式，也就是Static Provisioning。而动态供给的关键就是StorageClass，它的作用就是创建PV模板。 创建StorageClass里面需要定义PV属性比如存储类型、大小等；另外创建这种PV需要用到存储插件。最终效果是，用户提交PVC，里面指定存储类型，如果符合我们定义的StorageClass，则会为其自动创建PV并进行绑定 存储类（Storage class）是k8s资源类型的一种，它是有管理员为管理PV更加方便创建的一个逻辑组，可以按照存储系统的性能高低，或者综合服务质量，备份策略等分类。不过k8s本身不知道类别到底是什么，它这是作为一个描述 Provisioner（供给方、提供者）： 及提供了存储资源的存储系统。k8s内建有多重供给方，这些供给方的名字都以“kubernetes.io”为前缀。并且还可以自定义 Parmeters（参数）： 存储类使用参数描述要关联到的存储卷，注意不同的供给方参数也不同 ReclaimPolicy： PV的回收策略，可用值有Delete(默认)和Retain 基于StorageClass的动态存储供应整体过程如下图所示： 1）集群管理员预先创建存储类（StorageClass）； 2）用户创建使用存储类的持久化存储声明(PVC：PersistentVolumeClaim)； 3）存储持久化声明通知系统，它需要一个持久化存储(PV: PersistentVolume)； 4）系统读取存储类的信息； 5）系统基于存储类的信息，在后台自动创建PVC需要的PV； 6）用户创建一个使用PVC的Pod； 7）Pod中的应用通过PVC进行数据的持久化； 8）而PVC使用PV进行数据的最终持久化处理。 更多可以参考：https://www.kubernetes.org.cn/4078.html 1）确定基于NFS服务来做的sc，NFS服务需要开启 123[root@master ~]# showmount -eExport list for master:/nfsdata * 2）需要RBAC权限 RBAC： rbac是k8s的API安全策略，是基于用户的访问权限 规定了谁可以有什么样的权限 为了给SC资源操作k8s集群的权限 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@master ~]# vim rbac-rolebind.yamlkind: NamespaceapiVersion: v1metadata: name: bdqn-test---apiVersion: v1kind: ServiceAccountmetadata: name: nfs-provisioner namespace: bdqn-test---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: nfs-provisioner-runner namespace: bdqn-testrules: - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"watch\", \"create\", \"update\", \"patch\"] - apiGroups: [\"\"] resources: [\"services\", \"endpoints\"] verbs: [\"get\",\"create\",\"list\", \"watch\",\"update\"] - apiGroups: [\"extensions\"] resources: [\"podsecuritypolicies\"] resourceNames: [\"nfs-provisioner\"] verbs: [\"use\"]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: run-nfs-provisionersubjects: - kind: ServiceAccount name: nfs-provisioner namespace: bdqn-testroleRef: kind: ClusterRole name: nfs-provisioner-runner apiGroup: rbac.authorization.k8s.io[root@master ~]# kubectl apply -f rbac-rilebind.yaml namespace/bdqn-test createdserviceaccount/nfs-provisioner createdclusterrole.rbac.authorization.k8s.io/nfs-provisioner-runner createdclusterrolebinding.rbac.authorization.k8s.io/run-nfs-provisioner created 3）nfs-deployment. 作用：其实它是NFS的客户端，但是它通过K8S的内置的NFS驱动挂载远端的NFS服务器到本地目录；然后将自身作为storage provider，关联storage class 123456789101112131415161718192021222324252627282930313233343536[root@master ~]# vim nfs-deployment.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nfs-client-provisioner namespace: bdqn-testspec: replicas: 1 strategy: type: Recreate template: metadata: labels: app: nfs-client-provisioner spec: serviceAccount: nfs-provisioner containers: - name: nfs-client-provisioner image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME //提供者的名称 value: bdqn-test - name: NFS_SERVER //nfs服务器地址 value: 192.168.1.70 - name: NFS_PATH value: /nfsdata volumes: - name: nfs-client-root nfs: server: 192.168.1.70 path: /nfsdata[root@master ~]# kubectl apply -f nfs-deployment.yaml deployment.extensions/nfs-client-provisioner created 4）创建storageclass 12345678910[root@master ~]# vim test-storageclass.yamlapiVersion: storage.k8s.io&#x2F;v1kind: StorageClassmetadata: name: sc-nfs namespace: bdqn-test &#x2F;&#x2F;属于哪个名称空间provisioner: bdqn-test &#x2F;&#x2F;供给着，和nfs-deployment的名称要一样：value: bdqn-testreclaimPolicy: Retain[root@master ~]# kubectl apply -f test-storageclass.yaml storageclass.storage.k8s.io&#x2F;sc-nfs created provisioner: bdqn-test //通过preovisioner字段关联到上述Deployment 5）创建PVC 12345678910111213141516171819[root@master ~]# vim test-pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: test-claim namespace: bdqn-testspec: storageClassName: sc-nfs accessModes: - ReadWriteMany resources: requests: storage: 20Mi[root@master ~]# kubectl apply -f test-pvc.yaml persistentvolumeclaim/test-claim created[root@master ~]# kubectl get pvc -n bdqn-test NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEtest-claim Bound pvc-0c606810-9f93-441b-bc6b-391d7813dcab 20Mi RWX sc-nfs 2m15s 它会为我们自动生成一个pv 12345[root@master ~]# ls /nfsdata/bdqn-test-test-claim-pvc-0c606810-9f93-441b-bc6b-391d7813dcab[root@master ~]# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEpvc-0c606810-9f93-441b-bc6b-391d7813dcab 20Mi RWX Delete Bound bdqn-test/test-claim sc-nfs 4m24s 6）创建Pod测试 12345678910111213141516171819202122232425262728[root@master ~]# vim test-pod.yamlkind: PodapiVersion: v1metadata: name: test-pod namespace: bdqn-testspec: containers: - name: test-pod image: busybox args: - /bin/sh - -c - sleep 30000 volumeMounts: - name: nfs-pvc mountPath: /test restartPolicy: OnFailure volumes: - name: nfs-pvc persistentVolumeClaim: claimName: test-claim[root@master ~]# kubectl apply -f test-pod.yaml pod/test-pod created[root@master ~]# kubectl get pod -n bdqn-test NAME READY STATUS RESTARTS AGEnfs-client-provisioner-57f49c99c7-lhd8n 1/1 Running 0 27mtest-pod 1/1 Running 0 32s 1234567[root@master ~]# kubectl exec -it test-pod -n bdqn-test /bin/sh/ # cd /test/test # touch test-file/test # echo 123456 &gt; test-file /test # exit[root@master ~]# cat /nfsdata/bdqn-test-test-claim-pvc-0c606810-9f93-441b-bc6b-391d7813dcab/test-file 123456 1234567[root@master ~]# kubectl exec -it -n bdqn-test nfs-client-provisioner-57f49c99c7-lhd8n /bin/sh/ # ls /persistentvolumes / # cd /persistentvolumes//persistentvolumes # lsbdqn-test-test-claim-pvc-0c606810-9f93-441b-bc6b-391d7813dcab#这个目录和/nfsdata下面的目录一样","categories":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]},{"title":"k8s数据持久化","slug":"k8s数据持久化","date":"2020-02-10T08:53:18.320Z","updated":"2020-02-14T03:50:17.919Z","comments":true,"path":"k8s数据持久化.html","link":"","permalink":"https://pdxblog.top/k8s%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96.html","excerpt":"","text":"¶k8s数据持久化 Docker容器是有生命周期的，因此数据卷可以实现数据持久化 数据卷主要解决的问题： 数据持久性：当我们写入数据时，文件都是暂时性的存在，当容器崩溃后，host就会将这个容器杀死，然后重新从镜像创建容器，数据就会丢失 数据共享：在同一个Pod中运行容器，会存在共享文件的需求 ¶Volume： **emptyDir（空目录）：**使用情况比较少，一般只做临时使用，类似Docker数据 持久化的：docker manager volume，该数据卷初始分配时，是一个空目录，同一个Pod中的容器可以对该目录有执行读写操作，并且共享数据 ​ 使用场景：在同一个Pod里，不同的容器，共享数据卷 ​ 如果容器被删除，数据仍然存在，如果Pod被删除，数据也会被删除 使用实例： 123456789101112131415161718192021222324252627282930313233343536[root@master ~]# vim emptyDir.yamlapiVersion: v1kind: Podmetadata: name: producer-consumerspec: containers: - image: busybox name: producer volumeMounts: - mountPath: /producer_dir //容器内的路径 name: shared-volume //指定本地的目录名 args: - /bin/sh - -c - echo \"hello k8s\" &gt; /producer_dir/hello; sleep 30000 - image: busybox name: consumer volumeMounts: - mountPath: /consumer_dir name: shared-volume args: - /bin/sh - -c - cat /consumer_dir/hello; sleep 30000 volumes: - name: shared-volume //这里的名字必须与上面的Pod的mountPath的name相对应 emptyDir: &#123;&#125; //定义数据持久化类型，即表示空目录[root@master ~]# kubectl apply -f emptyDir.yaml[root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGE producer-consumer 2/2 Running 0 14s[root@master ~]# kubectl logs producer-consumer consumer hello k8s 使用inspect查看挂载的目录在哪（查看Mount字段） 123456789101112131415161718192021222324252627282930313233[root@master ~]# kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESproducer-consumer 2/2 Running 0 69s 10.244.1.2 node01 &lt;none&gt; &lt;none&gt;//可以看到容器运行在node01上，在node01上找到这个容器并查看并查看详细信息[root@node01 ~]# docker psCONTAINER ID IMAGEf117beb235cf busybox13c7a18109a1 busybox[root@node01 ~]# docker inspect 13c7a18109a1 \"Mounts\": [ &#123; \"Type\": \"bind\", \"Source\": \"/var/lib/kubelet/pods/5225f542-0859-4a6a-8d99-1f23b9781807/volumes/kubernetes.io~empty-dir/shared-volume\", \"Destination\": \"/producer_dir\", //容器内的挂载目录 \"Mode\": \"\", \"RW\": true, \"Propagation\": \"rprivate\"//再查看另一个容器[root@node01 ~]# docker inspect f117beb235cf \"Mounts\": [ &#123; \"Type\": \"bind\", \"Source\": \"/var/lib/kubelet/pods/5225f542-0859-4a6a-8d99-1f23b9781807/volumes/kubernetes.io~empty-dir/shared-volume\", \"Destination\": \"/consumer_dir\", //容器内的挂载目录 \"Mode\": \"\", \"RW\": true, \"Propagation\": \"rprivate\"//可以看到两个容器使用的同一个挂载目录[root@node01 ~]# cd /var/lib/kubelet/pods/5225f542-0859-4a6a-8d99-1f23b9781807/volumes/kubernetes.io~empty-dir/shared-volume[root@node01 shared-volume]# lshello[root@node01 shared-volume]# cat hello hello k8s 将容器删除，验证目录是否存在 1234567[root@node01 ~]# docker rm -f 13c7a18109a1 13c7a18109a1[root@node01 ~]# docker psCONTAINER ID IMAGEa809717b1aa5 busyboxf117beb235cf busybox//它会重新生成一个新的容器，来达到我们用户所期望的状态，所以这个目录还是存在的 删除Pod 1234[root@master ~]# kubectl delete pod producer-consumer[root@master ~]# ls /var/lib/kubelet/pods/5225f542-0859-4a6a-8d99-1f23b9781807/volumes/kubernetes.io~empty-dir/shared-volumels: 无法访问/var/lib/kubelet/pods/5225f542-0859-4a6a-8d99-1f23b9781807/volumes/kubernetes.io~empty-dir/shared-volume: 没有那个文件或目录//Pod删除后数据也会被删除 **hostPath Volume（使用场景也比较少）：**类似Docker数据持久化的：bind mount 将Pod所在节点的文件系统上某一个文件或目录挂载进容器内 ​ 如果Pod被删除，数据会保留，相比较emptyDir会好一点，不过，一旦host崩溃，hostPath也无法访问 docker或者k8s集群本身的存储会采用hostPath这种方式 k8s集群中会有很多pod，如果都是用hostPath Volume的话管理起来很不方便，所以就用到了PV Persistent Volume | PV（持久卷）提前做好的，数据持久化的数据存放目录 是集群中的一块存储空间，由集群管理员管理或者由Storage class（存储类）自动管理，PV和pod、deployment、Service一样，都是一个资源对象 PersistentVolume（PV）是集群中已由管理员配置的一段网络存储。 集群中的资源就像一个节点是一个集群资源。 PV是诸如卷之类的卷插件，但是具有独立于使用PV的任何单个pod的生命周期。 该API对象捕获存储的实现细节，即NFS，iSCSI或云提供商特定的存储系统 Psesistent Volume Claim | PVC（持久卷使用声明|申请） PVC代表用户使用存储的请求，应用申请PV持久化空间的一个申请、声明。K8s集群可能会有多个PV，你需要不停的为不同的应用创建多个PV 它类似于pod。Pod消耗节点资源，PVC消耗存储资源。 pod可以请求特定级别的资源（CPU和内存）。 权限要求可以请求特定的大小和访问模式 更多可以参考：https://www.kubernetes.org.cn/pvpvcstorageclass 基于NFS服务来做的PV 12345678910[root@master ~]# yum -y install nfs-utils (需要节点全部下载，会报挂载类型错误)[root@master ~]# yum -y install rpcbind[root@master ~]# mkdir &#x2F;nfsdata[root@master ~]# vim &#x2F;etc&#x2F;exports&#x2F;nfsdata *(rw,sync,no_root_squash)[root@master ~]# systemctl start rpcbind[root@master ~]# systemctl start nfs-server[root@master ~]# showmount -eExport list for master:&#x2F;nfsdata * 1.创建PV（实际的存储目录） 2.创建PVC 3.创建pod 创建PV资源对象： 12345678910111213141516171819[root@master ~]# vim nfs-pv.yamlapiVersion: v1kind: PersistentVolumemetadata: name: test-pvspec: capacity: //PV容量的大小 storage: 1Gi accessModes: //PV支持的访问模式 - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle //PV的存储空间的回收策略是什么 storageClassName: nfs nfs: path: /nfsdata/pv1 server: 192.168.1.70[root@master ~]# kubectl apply -f nfs-pv.yaml[root@master ~]# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEtest-pv 1Gi RWO Recycle Available nfs 9m30s accessModes: （PV支持的访问模式） ​ - ReadWriteOnce：能以读-写的方式mount到单个节点 ​ - ReadWriteMany：能以读-写的方式mount到多个节点 ​ - ReadOnlyMany：能以只读的方式mount到多个节点 persistentVolumeReclaimPolicy：（PV的存储空间的回收策略是什么） ​ Recycle：自动清除数据 ​ Retain：需要管理员手动回收 ​ Delete：云存储专用。直接删除数据 PV和PVC相互的关联：通过的是storageClassName &amp;&amp; accessModes 创建PVC 12345678910111213141516[root@master ~]# vim nfs-pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: test-pvcspec: accessModes: //访问模式 - ReadWriteOnce resources: requests: storage: 1Gi //申请的容量大小 storageClassName: nfs //向哪个PV申请[root@master ~]# kubectl apply -f nfs-pvc.yaml[root@master ~]# kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEtest-pvc Bound test-pv 1Gi RWO nfs 14s ¶PV的应用： 创建一个Pod资源： 123456789101112131415161718192021[root@master ~]# vim pod.yamlkind: PodapiVersion: v1metadata: name: test-podspec: containers: - name: pod1 image: busybox args: - /bin/sh - -c - sleep 30000 volumeMounts: - mountPath: \"/mydata\" name: mydata volumes: - name: mydata persistentVolumeClaim: claimName: test-pvc[root@master ~]# kubectl apply -f pod.yaml 之前创建PV的时候指定的挂载目录是/nfsdata/pv1，我们并没有创建pv1这个目录，所以这个pod是运行不成功的。 以下是排错方法： kubectl describe kubectl logs /var/log/messages 查看该节点的kubelet的日志 123//使用kubectl describe[root@master ~]# kubectl describe pod test-podmount.nfs: mounting 192.168.1.70:/nfsdata/pv1 failed, reason given by server: No such file or directory //提示没有文件或目录 创建目录，再查看pod状态： 123[root@master ~]# mkdir /nfsdata/pv1NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-pod 1/1 Running 0 12m 10.244.1.3 node01 &lt;none&gt; &lt;none&gt; 验证是否应用成功： 123456[root@master ~]# kubectl exec test-pod touch /mydata/hello[root@master ~]# ls /nfsdata/pv1/hello[root@master ~]# echo 123 &gt; /nfsdata/pv1/hello [root@master ~]# kubectl exec test-pod cat /mydata/hello123 删除Pod，验证回收策略（Recycle）： 12345678[root@master ~]# kubectl delete pod test-pod[root@master ~]# kubectl delete pvc test-pvc[root@master ~]# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEtest-pv 1Gi RWO Recycle Available nfs 42h[root@master ~]# ls &#x2F;nfsdata&#x2F;pv1&#x2F;[root@master ~]#&#x2F;&#x2F;验证成功，数据已经回收 通常情况下不会设置为自动删除，不然就和emptyDir就差不多了 删除pv，修改回收策略： 之前是先创建PV—&gt;PVC—&gt;Pod，现在调整一下，先创建PV—&gt;---Pod—&gt;PVC 12345678910111213141516171819202122[root@master ~]# vim nfs-pv.yaml persistentVolumeReclaimPolicy: Retain[root@master ~]# kubectl apply -f nfs-pv.yaml [root@master ~]# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEtest-pv 1Gi RWO Retain Available nfs 7s[root@master ~]# kubectl apply -f pod.yaml [root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGEtest-pod 0&#x2F;1 Pending 0 5s &#x2F;&#x2F;Pending正在被调度[root@master ~]# kubectl describe pod test-podEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 41s (x2 over 41s) default-scheduler persistentvolumeclaim &quot;test-pvc&quot; not found&#x2F;&#x2F;没有发现对应的pvc创建pvc[root@master ~]# kubectl apply -f nfs-pvc.yaml[root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGEtest-pod 1&#x2F;1 Running 0 114s 验证Retain（管理员手动删除）回收策略： 1234567891011[root@master ~]# kubectl exec test-pod touch /mydata/k8s[root@master ~]# ls /nfsdata/pv1/k8s[root@master ~]# kubectl delete pod test-pod [root@master ~]# kubectl delete pvc test-pvc[root@master ~]# ls /nfsdata/pv1/k8s//可以看到并没有回收[root@master ~]# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEtest-pv 1Gi RWO Retain Available nfs 6s mysql对数据持久化的应用： //这里就不再创建PV，PVC了，用之前的就行 1234[root@master ~]# kubectl apply -f nfs-pvc.yaml [root@master ~]# kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEtest-pvc Bound test-pv 1Gi RWO nfs 7s 创建Deploment资源对象，mysql容器 123456789101112131415161718192021222324252627282930[root@master ~]# vim mysql.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: test-mysqlspec: selector: matchLabels: //基于等值的标签 app: mysql template: metadata: labels: app: mysql spec: containers: - image: mysql:5.6 name: mysql env: - name: MYSQL_ROOT_PASSWORD value: 123.com volumeMounts: - name: mysql-storage mountPath: /var/lib/mysql volumes: - name: mysql-storage persistentVolumeClaim: claimName: test-pvc[root@master ~]# kubectl get deployments.NAME READY UP-TO-DATE AVAILABLE AGEtest-mysql 1/1 1 1 61s 进入容器创建数据，验证是否应用PV： 123456789101112131415161718[root@master ~]# kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-mysql-569f8df4db-fnnxc 1/1 Running 0 32m 10.244.1.5 node01 &lt;none&gt; &lt;none&gt;[root@master ~]# kubectl exec -it test-mysql-569f8df4db-fnnxc -- mysql -u root -p123.commysql&gt; create database yun33; //创建数据库mysql&gt; use yun33; //选择使用数据路Database changedmysql&gt; create table my_id( id int(4)); 创建表mysql&gt; insert my_id values(9527); //在表中插入数据mysql&gt; select * from my_id; //查看表中所有数据+------+| id |+------+| 9527 |+------+1 row in set (0.00 sec)[root@master ~]# ls /nfsdata/pv1/auto.cnf ibdata1 ib_logfile0 ib_logfile1 k8s mysql performance_schema yun33 关闭node01节点，模拟节点宕机： 1234567891011121314151617[root@master ~]# kubectl get nodes NAME STATUS ROLES AGE VERSIONmaster Ready master 36d v1.15.0node01 NotReady &lt;none&gt; 36d v1.15.0node02 Ready &lt;none&gt; 36d v1.15.0[root@master ~]# kubectl get pod -o wide -wNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-mysql-569f8df4db-fnnxc 1/1 Running 0 36m 10.244.1.5 node01 &lt;none&gt; &lt;none&gt;test-mysql-569f8df4db-fnnxc 1/1 Terminating 0 38m 10.244.1.5 node01 &lt;none&gt; &lt;none&gt;test-mysql-569f8df4db-2m5rd 0/1 Pending 0 0s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;test-mysql-569f8df4db-2m5rd 0/1 Pending 0 0s &lt;none&gt; node02 &lt;none&gt; &lt;none&gt;test-mysql-569f8df4db-2m5rd 0/1 ContainerCreating 0 0s &lt;none&gt; node02 &lt;none&gt; &lt;none&gt;test-mysql-569f8df4db-2m5rd 1/1 Running 0 2s 10.244.2.4 node02 &lt;none&gt; &lt;none&gt;[root@master ~]# kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-mysql-569f8df4db-2m5rd 1/1 Running 0 20s 10.244.2.4 node02 &lt;none&gt; &lt;none&gt;test-mysql-569f8df4db-fnnxc 1/1 Terminating 0 38m 10.244.1.5 node01 &lt;none&gt; &lt;none&gt; 验证：在node02上新生成的pod，它内部是否有我们创建的数据 12345678910111213141516171819202122232425262728293031323334[root@master ~]# kubectl exec -it test-mysql-569f8df4db-2m5rd -- mysql -u root -p123.commysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || yun33 |+--------------------+4 rows in set (0.01 sec)mysql&gt; use yun33;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; show tables;+-----------------+| Tables_in_yun33 |+-----------------+| my_id |+-----------------+1 row in set (0.01 sec)mysql&gt; select * from my_id;+------+| id |+------+| 9527 |+------+1 row in set (0.01 sec)[root@master ~]# ls /nfsdata/pv1/auto.cnf ibdata1 ib_logfile0 ib_logfile1 k8s mysql performance_schema yun33 Pod不断的重启： ​ 1.swap，没有关闭。导致集群运行不正常 ​ 2.内存不足，运行服务也会重启 ¶小结 负责把PVC绑定到PV的是一个持久化存储卷控制循环，这个控制器也是kube-manager-controller的一部分运行在master上。而真正把目录挂载到容器上的操作是在POD所在主机上发生的，所以通过kubelet来完成。而且创建PV以及PVC的绑定是在POD被调度到某一节点之后进行的，完成这些操作，POD就可以运行了。下面梳理一下挂载一个PV的过程： 用户提交一个包含PVC的POD 调度器把根据各种调度算法把该POD分配到某个节点，比如node01 Node01上的kubelet等待Volume Manager准备存储设备 PV控制器调用存储插件创建PV并与PVC进行绑定 Attach/Detach Controller或Volume Manager通过存储插件实现设备的attach。（这一步是针对块设备存储） Volume Manager等待存储设备变为可用后，挂载该设备到/var/lib/kubelet/pods//volumes/kubernetes.io~/目录上 Kubelet被告知卷已经准备好，开始启动POD，通过映射方式挂载到容器中","categories":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]},{"title":"Docker swarm","slug":"Docker swarm","date":"2020-01-24T16:00:00.000Z","updated":"2020-02-02T09:31:18.463Z","comments":true,"path":"Docker swarm.html","link":"","permalink":"https://pdxblog.top/Docker%20swarm.html","excerpt":"","text":"Docker swarm docker swarm集群：三剑客之一 docker01 192.168.1.70 node1 docker02 192.168.1.50 node2 docker03 192.168.1.40 node3 关闭防火墙、禁用linux、3台dockerhost区别主机名，时间同步 1234[root@localhost ~]# setenforce 0[root@localhost ~]# systemctl stop firewalld[root@localhost ~]# hostnamectl set-hostname node1[root@localhost ~]# su - docker版本必须是：v1.12版本开始 Swarm： 作用docker engin（引擎）的多个主机组成的集群 node： 每一个docker engin都是一个node（节点），分为manager和worker manager node： 负责执行编排和集群管理的工作，保持并维护swarm处于期望的状态，swarm可以有多个manager node，他们会自动协调并选举出一个Leader执行编排任务，但相反不能没有manager node worker node： 接受并执行由manager node派发的任务，并且默认manager node也是一个worker node，不过可以将它设置为manager-noly node，让他只负责编排和管理工作 service： 用来定义worker上执行的命令 1）初始化集群 12345678[root@node1 ~]# docker swarm init --advertise-addr 192.168.1.70Swarm initialized: current node (g26pbaqiozkn99qw9ngtgncke) is now a manager.To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-3fp7qnihbzzy8u0esfjmmdfncdud4yh628e7bey5tu8fo3cl5p-4x021jwoh1bryxpwqd4bsj8xd 192.168.1.70:2377To add a manager to this swarm, run &#39;docker swarm join-token manager&#39; and follow the instructions. –advertise-addr：指定与其他Node通信的地址 上边返回的结果告诉我们：初始化成功，并且，如果想要添加work节点运行下面的命令： 1docker swarm join --token SWMTKN-1-3fp7qnihbzzy8u0esfjmmdfncdud4yh628e7bey5tu8fo3cl5p-4x021jwoh1bryxpwqd4bsj8xd 192.168.1.70:2377 PS：这里注意，token只有24小时的有效期 如果想要添加manager节点：运行下边的命令： 1docker swarm join-token manager 当两个节点加入成功之后，我们可以执行docker node ls查看节点详情 12345[root@node1 ~]# docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSIONg26pbaqiozkn99qw9ngtgncke * node1 Ready Active Leader 18.09.0w11nz7pzgmhq6wn5b51g6b8ao node2 Ready Active 18.09.0zqi7od9q0v7zo2tkabnseuqdf node3 Ready Active 18.09.0 基本操作命令： docker swarm leave：申请离开一个集群，之后查看节点状态会变成down然后通过manager node将其删除 docker node rm xxx：删除某个节点 docker swarm join-token {manager|worker}：生成令牌，可以是manager身份或worker身份 docker node demote（降级）：将swarm节点的manager降级为work docker node promote（升级）：将swarm节点的work升级为manager 2）部署docker swarm集群网络 overlay：覆盖型网络 1[root@node1 ~]# docker network create -d overlay --attachable docker attacheable：这个参数必须要加，否则不能用于容器 在创建网络的时候，我们并没有部署一个存储 服务，比如consul，那是因为docker swarm自带存储 3）部署一个图形化webUI界面 12[root@node1 ~]# docker run -d -p 8080:8080 -e HOST&#x3D;192.168.1.70 -e PORT&#x3D;8080 \\&gt; -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock --name viswalizer dockersamples&#x2F;visualizer 然后通过浏览器验证：192.168.1.70:8080 如果访问网页访问不到，需要开启路由转发： 12[root@node1 ~]# echo net.ipv4.ip_forward &#x3D; 1 &gt;&gt; &#x2F;etc&#x2F;sysctl.conf [root@node1 ~]# sysctl -p 4）创建service（服务） 1[root@node1 ~]# docker service create --replicas 1 --network docker --name web1 -p 80:80 nginx PS： 如果node2或node3宕机，这些服务会自动转到节点中没有宕机的host上，并继续运行 –replicas：副本数量 大概可以理解为以个副本等于一个容器 查看service： docker service ls 查看service信息： docker service ps xxx 删除server： docker service rm xxx 设置manager node不参加工作 1[root@node1 ~]# docker node update node1 --availability drain 5)搭建私有仓库 过程：略，详情请查看看https://blog.csdn.net/weixin_45636702/article/details/104002017 6）自定义镜像 要求：基于httpd镜像，更改访问界面内容。镜像tag版本为v1，对应主机页面内容为111，2222，3333 v1，v2，v3目录下的操作一样 12345678910[root@node01 ~]# mkdir &#123;v1,v2,v3&#125;[root@node01 ~]# cd v1[root@node01 v1]# vim index.html[root@node01 v1]# cat index.html111111111111111111111111111.................[root@node01 v1]# vim Dockerfile[root@node01 v1]# cat Dockerfile FROM httpdADD index.html &#x2F;usr&#x2F;local&#x2F;apache2&#x2F;htdocs&#x2F;index.html 7）发布一个服务，基于上述镜像 要求：副本数量为3个，服务的名称为：bdqn 1[root@node01 ~]# docker service create --replicas 3 --name bdqn -p 80:80 192.168.1.70:5000&#x2F;httpd:v1 默认的ingress网络，包括创建的自定义overlay网络，为后端真正为用户提供服务的container，提供了一个统一的入口 随机映射的端口范围：30000-32767 8）服务的扩容与缩容 1[root@node01 ~]# docker service scale bdqn&#x3D;6 扩容与缩容可以直接通过scale进行设置副本数量 9）服务的升级与回滚 1[root@node01 ~]# docker service update --image 192.168.1.70:5000&#x2F;httpd:v2 bdqn //平滑的更新 1[root@node01 ~]# docker service update --image 192.168.1.70:5000&#x2F;httpd:v3 --update-parallelism 2 --update-delay 1m bdqn PS： 默认情况下，swarm一次只更新一个副本，并且两个副本之间没有等待时间，我们可以通过 –update-parallelisnm：设置并更新的副本数量 –update-delay：指定滚动更新时间间隔 //回滚操作 1[root@node01 ~]# docker service rollback bdqn PS： docker swarm的回滚操作，默认只能回滚到上一次的操作状态，并不能连续回滚操作","categories":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/tags/Docker/"}]},{"title":"Docker架构+Docker镜像分层+Dockerfile","slug":"Docker架构+Docker镜像分层+Dockerfile","date":"2020-01-24T16:00:00.000Z","updated":"2020-01-25T13:07:32.224Z","comments":true,"path":"Docker架构+Docker镜像分层+Dockerfile.html","link":"","permalink":"https://pdxblog.top/Docker%E6%9E%B6%E6%9E%84+Docker%E9%95%9C%E5%83%8F%E5%88%86%E5%B1%82+Dockerfile.html","excerpt":"","text":"¶Docker架构： Docker架构总结： Docker是属于C/S架构，用户是使用 Docker Client 与 Docker Daemon 建立通信，并发送请求。请求接收后，Docker server通过http协议与路由，找到相应的 Handler 来执行请求 Docker Engine 是 Docker 架构中的运行引擎，同时也 Docker 运行的核心模块。Docker Engine 执行 Docker 内部的一系列工作，每一项工作都是以一个 Job 的形式的存在 Job 的运行过程中，当需要容器镜像时，则从 Docker Registry 中下载镜像，并通过镜像管理驱动 Graphdriver 将下载镜像以 Graph 的形式存储 当需要为 Docker 创建网络环境时，通过网络管理驱动 Networkdriver 创建并配置 Docker容器网络环境 当需要限制 Docker 容器运行资源或执行用户指令等操作时，则通过 Execdriver 来完成 Libcontainer 是一项独立的容器管理包，Networkdriver 以及 Execdriver 都是通过 Libcontainer 来实现具体对容器进行的操作 ¶Docker镜像分层： Docker的最小镜像： 1[root@localhost ~]# docker pull hello-world 123FROM scratchCORP hello&#x2F;CMD [&quot;&#x2F;hello&quot;] Dockerfile的组成： 1）FROM：scratch（抓、挠） 2）COPY：hello/ 3）CMD：[&quot;/hello&quot;] base镜像(基础镜像)： Centos:7镜像的dockerfile 1234567891011FROM scratch &#x2F;&#x2F;从零开始构建ADD centos-7-x86 64-docker.tar.xz &#x2F;LABEL org. label-schema. schema-version&#x3D;&quot;1.0&quot;\\org. label-schema.namem&quot;centos Base Image&quot;\\org. label-schema.vendore&quot;Centos&quot;\\org. label-schema.Ticenses&quot;GPLv2&quot; \\org. labe1-schema.build-date&quot;20190305CMD [&quot;&#x2F;bin&#x2F;bash&quot;] 1[root@localhost test]# docker build -t centos7-vim-net-tools:12-11 . Dockerfile镜像分层总结： 镜像是容器的基石，容器是镜像运行后的实例，当镜像运行为容器之后，对镜像的所有数据仅有只读权限，如果需要对镜像源文件进行修改或删除操作时，此时是在容器层（可写层）进行的，用到了COW（copy on write）写时复制机制 Docker镜像的缓存特性 创建一个新的Dockerfile文件 12345FROM centos:7RUN yum -y install vimRUN yum -y install net-toolsRUN yum -y install wgetCMD [&quot;&#x2F;bin&#x2F;bash&quot;] 1[root@localhost ~]# docker build -t new-centos . 1）如果在相同层，有用到相同的镜像，可以不必再去下载，可以直接使用缓存 创建一个新的Dockefile文件 12345FROM centos:7RUN yum -y install vimRUN yum -y install wgetRUN yum -y install net-toolsCMD [&quot;&#x2F;bin&#x2F;bash&quot;] 1[root@localhost test1]# docker build -t centos-new . 2）即使镜像层里的操作一样，也必须是在同一层才可以使用dockerfile的缓存特性 如果制作镜像过程中，不想使用缓存可以加–no-cache选项 3）如果前面的曾发生改变，即使后边的层操作和顺序一样，也不能使用缓存特性 Dockerfile常用指令： 1）FROM：构建镜像基于哪个镜像 例如：FROM:centos:7 2）MAINTAINER：镜像维护者姓名或邮箱 例如：MAINTAINER admin 3）RUN：构建镜像时运行的shell命令 例如： RUN [“yum”,“install”,“httpd”] RUN yum -y install httpd 4）CMD：运行容器时执行的shell命令 例如： CMD [&quot;/bin/bash&quot;] 5）EXPOSE：声明容器的服务端口 例如：EXPOSE 80 443 6）ENV：设置容器环境变量 例如： ENV MYSQL_ROOT_PASSWORD 123.com 7）ADD：拷贝文件或目录到镜像，如果时URL或压缩包会自动下载或解压 ADD &lt;源文件&gt;… &lt;目标目录&gt; ADD [“源文件”…“目标目录”] 8）COPY：拷贝文件或目录到镜像容器内，跟ADD相似，但不具备自动下载或解压功能 9）ENTRYPOINT：运行容器时执行的shell命令 例如： ENTRYPOINT [&quot;/bin/bash&quot;,&quot;-c&quot;,“command”] ENTRYPOINT /bin/bash -c ‘command’ 10）VOLUME：指定容器挂在点到宿主机自动生成的目录或其他容器 例如： VOLUME [&quot;/va/lib/mysql&quot;] 11）USER：为RUN、CMD、和ENTRYPOINT执行命令指定运行用户 12）WORKDIR：为RUN、CMD、ENTRYPOINT、COPY和ADD设置工作目录，意思为切换目录 例如： WORKDIR：/var/lib/mysql 13）HEALTHCHECK：健康检查 14）ARG：构建时指定的一些参数 例如： FROM centos:7 ARG user USER $user 注意： 1、RUN在building时运行，可以写多条 2、CMD和ENTRYPOINT在运行container时，只能写一条，如果写多条，最后一条生效 3、CMD在run时可以被COMMAND覆盖，ENTRYPOINT不会被不会被COMMAND覆盖，但可以指定–entrypoint覆盖 4、如果在Dockerfile里需要往镜像内导入文件，则此文件必须在dockerfile所在目录或子目录下 小实验： 写一个dockerfile，基于cenyos:7镜像，部署安装NGINX服务 1234567891011121314151617[root@localhost ~]# mkdir web[root@localhost ~]# mv nginx-1.14.0.tar.gz web&#x2F;[root@localhost ~]# cd web&#x2F;[root@localhost web]# vim DockerfileFROM centos:7RUN yum -y install gcc pcre pcre-devel openssl openssl-devel zlib zlib-develCOPY nginx-1.14.0.tar.gz &#x2F;RUN tar -zxf nginx-1.14.0.tar.gz -C &#x2F;usr&#x2F;srcRUN useradd -M -s &#x2F;sbin&#x2F;nologin nginxWORKDIR &#x2F;usr&#x2F;src&#x2F;nginx-1.14.0RUN .&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx --user&#x3D;nginx --group&#x3D;nginxRUN make &amp;&amp; make installRUN ln -s &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;* &#x2F;usr&#x2F;local&#x2F;sbinRUN nginx -tRUN nginxEXPOSE 80[root@localhost web]# docker build -t test-web . &#x2F;&#x2F;如果Dockerfile在其他路径需要加-f参数来指定Dockerfile文件路径 //如果想要保证容器运行之后，nginx服务就直接开启，不必手动开启，我们可以在命令最后加上：nginx -g &quot;daemon off;&quot;选项 1[root@localhost web]# docker run -itd --name testweb_2 test-web:latest nginx -g &quot;daemon off;&quot; //查看容器的IP： 1[root@localhost web]# docker inspect testweb_2","categories":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/tags/Docker/"}]},{"title":"Docker的基本操作命令","slug":"Docker的基本操作命令","date":"2020-01-24T16:00:00.000Z","updated":"2020-01-25T13:07:32.240Z","comments":true,"path":"Docker的基本操作命令.html","link":"","permalink":"https://pdxblog.top/Docker%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4.html","excerpt":"","text":"¶Docker的基本操作命令： //查找镜像： 1[root@localhost ~]# docker search mysql &#x2F;&#x2F;默认在docker hub公共仓库进行查找 //拉取镜像，下载镜像: 1[root@localhost ~]# docker pull busybox //导出镜像到本地： 1[root@localhost ~]# docker save -o busybox.tar busybox:latest （docker save &gt; busybox.tar busybox:latest） //查看本地镜像： 1[root@localhost ~]# docker images （docker image ls） PS：虽然我们查看到镜像标签位latest（最新的），但并不表示它一定是最新的，而且镜像如果没有写标签，默认是以latest为标签 //删除镜像： 1[root@localhost ~]# docker rmi busybox:latest //根据本地镜像包导入镜像： 1[root@localhost ~]# docker load -i busybox.tar （docker load &lt; busybox.tar ） //查看容器–正在运行的： 1[root@localhost ~]# docker ps //查看所有的容器： 1[root@localhost ~]# docker ps -a //删除容器： 1[root@localhost ~]# docker rm centos [CONTAINER ID&#x2F;容器名称] //停止容器运行： 1[root@localhost ~]# docker stop centos //启动容器: 1[root@localhost ~]# docker start centos PS:开启容器后记得去验证一下容器是否开启 //强制删除容器： 1[root@localhost ~]# docker rm centos -f //强制删除所有容器（生产环境严禁使用）： 1[root@localhost ~]# docker ps -a -q | xargs docker rm -f ---------------------------------------------------------------------------------------------- 123[root@localhost ~]# docker ps -a -q | xargs docker start -f &#x2F;&#x2F;开启所有容器[root@localhost ~]# docker ps -a -q | xargs docker stop -f &#x2F;&#x2F;关闭所有容器 //重启一个容器： 1[root@localhost ~]# docker restart test2 //运行一个容器： 1[root@localhost ~]# docker run -it --name test1 centos:7 -i：交互 -t：伪终端 -d（daemon）：后台运行 –name：给容器命名 –restart=always：始终保持运行（随着docker开启而运行） 1[root@localhost ~]# docker create -it --name test3 centos:7 &#x2F;&#x2F;不常用 //进入一个容器： 123[root@localhost ~]# docker exec -it test2 &#x2F;bin&#x2F;bash[root@localhost ~]# docker attach test2 区别： exec进入的方式需要添加-i，-t选项，后面还需要给容器一个shell环境，但attach就不需要这么麻烦 exec进入的方式：如果exit退出，容器仍然保持运行 attach：如果执行exit退出，容器会被关闭，如果想要保持容器不被关闭，可以使用键盘：ctrl+p ctrl+q可以实现 本质上区别： exec进入的方法，会产生新的进程 attach进入的方法，不会产生新的进程 Docker的基本操作逻辑： 小实验： 基于centos:7镜像运行一个容器，并且在这个容器内部署nginx服务 1）下载镜像： 1[root@localhost ~]# docker pull centos:7 2）运行容器： 1[root@localhost ~]# docker run -itd --name webapp --restart&#x3D;always centos:7 3）进入容器，开始部署nginx服务：//将nginx包导入到容器内： 1[root@localhost ~]# docker cp nginx-1.14.0.tar.gz 12345678910111213[root@localhost ~]# docker exec -it webapp &#x2F;bin&#x2F;bash[root@01b870908942 ~]# tar zxf nginx-1.14.0.tar.gz [root@01b870908942 ~]# cd nginx-1.14.0[root@01b870908942 nginx-1.14.0]# yum -y install gcc pcre pcre-devel openssl openssl-devevl zlib zlib-devel[root@01b870908942 nginx-1.14.0]# useradd -s &#x2F;sbin&#x2F;nologin nginx[root@01b870908942 nginx-1.14.0]# .&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx --user&#x3D;nginx --group&#x3D;nginx[root@01b870908942 nginx-1.14.0]# make &amp;&amp; make install[root@01b870908942 nginx-1.14.0]# ln -s &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;* &#x2F;usr&#x2F;local&#x2F;sbin&#x2F;[root@01b870908942 nginx-1.14.0]# nginx[root@01b870908942 nginx-1.14.0]# cd &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;html&#x2F;[root@01b870908942 html]# echo This is a resrweb in container &gt; index.html[root@01b870908942 html]# curl 127.0.0.1This is a resrweb in container //把容器制作成镜像：（可移植性） 1[root@localhost ~]# docker commit webapp myweb:12-10","categories":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/tags/Docker/"}]},{"title":"Docker的监控","slug":"Docker的监控","date":"2020-01-24T16:00:00.000Z","updated":"2020-01-25T13:07:32.256Z","comments":true,"path":"Docker的监控.html","link":"","permalink":"https://pdxblog.top/Docker%E7%9A%84%E7%9B%91%E6%8E%A7.html","excerpt":"","text":"¶Docker的监控 docker自带的监控命令 docker top / stats / logs sysdig 12345678910[root@localhost ~]# docker load &lt; sysdig.tar[root@localhost ~]# docker load &lt; scope.1.12.tar[root@localhost ~]# docker run -it --rm --name sysdig \\&gt; --privileged&#x3D;true \\&gt; --volume&#x3D;&#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;host&#x2F;var&#x2F;run&#x2F;docker.sock \\&gt; --volume&#x3D;&#x2F;dev:&#x2F;host&#x2F;dev \\&gt; --volume&#x3D;&#x2F;proc:&#x2F;host&#x2F;proc:ro \\&gt; --volume&#x3D;&#x2F;boot:&#x2F;host&#x2F;boot:ro \\&gt; --volume&#x3D;&#x2F;lib&#x2F;modules:&#x2F;host&#x2F;lib&#x2F;modules:ro \\&gt; --volume&#x3D;&#x2F;usr:&#x2F;host&#x2F;usr:ro sysdig&#x2F;sysdig //下载失败后可以运行下边的命令，重新下载 1root@2fefbfde3db5:&#x2F;# sysdig-probe-loader //下载成功之后，可以运行sysdig命令 1root@2fefbfde3db5:&#x2F;# csysdig ¶scope 123[root@localhost ~]# curl -L git.io&#x2F;scope -o &#x2F;usr&#x2F;local&#x2F;bin&#x2F;scope[root@localhost ~]# chmod a+x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;scope[root@localhost ~]# scope launch //访问本机的4040端口 //监控两台dockerhost docker01 192.168.1.70 docker02 192.168.1.50 //docker02上也需要同样的操作 123[root@docker02 ~]# curl -L git.io&#x2F;scope -o &#x2F;usr&#x2F;local&#x2F;bin&#x2F;scope[root@docker02 ~]# chmod a+x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;scope[root@docker02 ~]# docker load &lt; scope.1.12.tar 12[root@docker01 ~]# scope launch 192.168.1.70 192.168.1.50[root@docker02 ~]# scope launch 192.168.1.50 192.168.1.70","categories":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/tags/Docker/"}]},{"title":"Docker的底层原理","slug":"Docker的底层原理","date":"2020-01-24T16:00:00.000Z","updated":"2020-01-25T13:07:32.240Z","comments":true,"path":"Docker的底层原理.html","link":"","permalink":"https://pdxblog.top/Docker%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86.html","excerpt":"","text":"¶Docker底层原理 如果虚拟机内服务对内核版本有要求，这个服务就不太适合用docker来实现了 Busybox：欺骗层 解耦：解除耦合、解除冲突 耦合：冲突现象 run-----&gt;Centos系统（nginx、web） 对于docker host来说这个系统仅仅是一个进程 Namespace（名称空间）： 用来隔离容器 1234[root@localhost ns]# pwd&#x2F;proc&#x2F;2971&#x2F;ns[root@localhost ns]# lsipc mnt net pid user uts ipc：共享内存、消息列队 mnt：挂载点、文件系统 net：网络栈 pid：进程编号 user：用户、组 uts：主机名、域名 //namespace六项隔离，实现了容器与宿主机、容器与容器之间的隔离 Cgroup（控制组）： 资源的限制 12[root@d9d679199f74 cgroup]# pwd&#x2F;sys&#x2F;fs&#x2F;cgroup 1[root@localhost cpu]# cat tasks PS：task这个文件内的数字，记录的是进程编号。PID 四大功能： 1）资源限制：cgroup可以对进程组使用的资源总额进行限制 2）优先级分配：通过分配的cpu时间片数量以及硬盘IO带宽大小，实际上相当于控制了进程运行的优先级别 3）资源统计：cgroup可以统计西系统资源使用量，比如cpu使用时间，内存使用量等，用于按量计费。同时还支持挂起功能，也就是说用过cgroup把所有的资源限制起来，对资源都不能使用，注意并不算是说我们的程序不能使用了，只是不能使用资源，处于挂起等待状态 4）进程控制：可以对进程组执行挂起、恢复等操作 内存限额： 容器内存包括两个部分：物理内存和swap 可以通过参数控制容器内存的使用量： -m或者–memory：设置内存的使用限额 –memory-swap：设置内存+swap的使用限额 举个例子： 如果运行一个容器，并且限制该容器最多使用200M内存和100M的swap 123[root@localhost ~]# docker run -it -m 200M --memory-swap 300M centos:7[root@5bc0e71faba3 memory]# pwd&#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;memory //内存使用限制 12[root@5bc0e71faba3 memory]# cat memory.limit_in_bytes 209715200（字节） //内存+swap限制 12[root@5bc0e71faba3 memory]# cat memory.memsw.limit_in_bytes314572800（字节） 对比一个没有限制的容器，我们会发现，如果运行容器之后不限制内存的话，意味着没有限制 CPU使用： 通过-c或者–cpu-shares设置容器使用cpu的权重，如果 不设置默认为1024 举个例子： //没有限制：1024 1234[root@localhost ~]# docker run -it --name containerA centos:7[root@e2d88b8f8b87 &#x2F;]# cd &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu[root@e2d88b8f8b87 cpu]# cat cpu.shares 1024 //限制CPU使用权重为512： 1234[root@localhost ~]# docker run -it --name containerB -c 512 centos:7[root@f8165e07c8d7 &#x2F;]# cd &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu[root@f8165e07c8d7 cpu]# cat cpu.shares 512 容器的Block IO（磁盘的读写）： docker中可以通过设置权重，限制bps和iops的方式控制容器读写磁盘的IO bps：每秒的读写的数据量（byte per second） iops：每秒IO的次数 （io per second） 默认情况下，所有容器都能够平等的读写磁盘，也可以通过–blkio-weight参数改变容器的blockIO的优先级 –device-read-bps：显示读取某个设备的bps –device-write-bps：显示写入某个设备的bps –device-read-iops：显示读取某个设备的iops –device-write-iops：显示写入某个设备的iops //限制testA这个容器，写入/dev/sda这块磁盘的bps为30MB 1[root@localhost ~]# docker run -it --name testA --device-write-bps &#x2F;dev&#x2F;sda:30MB centos:7 //从/dev/zero输入，然后输出到test.out文件中，每次大小为1M，总共为800次，oflg=direct用来指定directIO方式写文件，这样才会使–device-write-bps生效 1[root@0e659ca3e85d &#x2F;]# time dd if&#x3D;&#x2F;dev&#x2F;zero of&#x3D;test.out bs&#x3D;1M count&#x3D;800 oflag&#x3D;direct","categories":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/tags/Docker/"}]},{"title":"Docker的私有仓库","slug":"Docker的私有仓库","date":"2020-01-24T16:00:00.000Z","updated":"2020-01-25T13:07:32.256Z","comments":true,"path":"Docker的私有仓库.html","link":"","permalink":"https://pdxblog.top/Docker%E7%9A%84%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93.html","excerpt":"","text":"¶Registry 用docker容器运行registry私有仓库 下载registry镜像： 1[root@localhost ~]# docker pull registry:2 &#x2F;&#x2F;2版本是使用go语言编写的，而registry是使用python写的 //运行私有仓库： 1[root@localhost ~]# docker run -itd --name registry --restart&#x3D;always -p 5000:5000 -v &#x2F;registry:&#x2F;var&#x2F;lib&#x2F;registry registry:2 -p：端口映射（宿主机端口：容器暴露的端口） -v：挂载目录（宿主机的目录：容器内的目录） 镜像重命名： 1[root@localhost ~]# docker tag test-web:latest 192.168.1.70:5000&#x2F;test 上传镜像到私有仓库： 123456[root@localhost ~]# vim &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;docker.service修改：指定私有仓库地址ExecStart&#x3D;&#x2F;usr&#x2F;bin&#x2F;dockerd --insecure-registry 192.168.1.70:5000[root@localhost ~]# systemctl daemon-reload [root@localhost ~]# systemctl restart docker[root@localhost ~]# docker push 192.168.1.70:5000&#x2F;test:latest 这里注意，既然是私有仓库，肯定是要考虑多台DockerHost共用的情况，如果有其他的DockerHost想要使用私有仓库，仅需要修改docker的配置文件，指定私有仓库的IP和端口即可。当然别忘了，更改过配置文件之后，daemon-reload ,restart docker服务 ¶企业级私有仓库镜像Harbor 下载一个docker-compse工具 //从GitHub上下载方法： 12[root@docker01 ~]# curl -L https:&#x2F;&#x2F;github.com&#x2F;docker&#x2F;compose&#x2F;releases&#x2F;download&#x2F;1.25.0&#x2F;docker-compose-&#96;uname -s&#96;-&#96;uname -m&#96; -o &#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker-compose[root@docker01 ~]# chmod +x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker-compose 12[root@docker01 ~]# tar zxf docker-compose.tar.gz -C &#x2F;usr&#x2F;local&#x2F;bin[root@docker01 ~]# chmod +x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker-compose //下载依赖包 1[root@docker01 ~]# yum -y install yum-utils device-mapper-persistent-data lvm2 //导入harbo离线安装包，并解压到/usr/local/下 1[root@docker01 ~]# tar zxf harbor-offline-installer-v1.7.4.tgz -C &#x2F;usr&#x2F;local&#x2F; //安装harbor 1234[root@docker01 ~]# cd &#x2F;usr&#x2F;local&#x2F;harbor&#x2F;[root@docker01 harbor]# vim harbor.cfghostname &#x3D; 192.168.1.70[root@docker01 harbor]# .&#x2F;install.sh //浏览器访问：192.168.1.70 用户名：admin 密码：Harbor12345 //修改docker配置文件，连接Harbor私有仓库 1234[root@docker01 ~]# vim &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;docker.serviceExecStart&#x3D;&#x2F;usr&#x2F;bin&#x2F;dockerd --insecure-registry 192.168.1.70[root@docker01 ~]# systemctl daemon-reload [root@docker01 ~]# systemctl restart docker //创建私有仓库 //登录仓库上传镜像 123[root@docker01 harbor]# docker login -u admin -p Harbor12345 192.168.1.70[root@docker01 harbor]# docker tag centos:7 192.168.1.70&#x2F;bdqn&#x2F;centos:7[root@docker01 harbor]# docker push 192.168.1.70&#x2F;bdqn&#x2F;centos:7 //从私有仓库下载镜像 1[root@docker03 ~]# docker pull 192.168.1.70&#x2F;bdqn&#x2F;centos:7","categories":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/tags/Docker/"}]},{"title":"Docker部署LNMP环境","slug":"Docker部署LNMP环境","date":"2020-01-24T16:00:00.000Z","updated":"2020-01-25T13:07:32.271Z","comments":true,"path":"Docker部署LNMP环境.html","link":"","permalink":"https://pdxblog.top/Docker%E9%83%A8%E7%BD%B2LNMP%E7%8E%AF%E5%A2%83.html","excerpt":"","text":"¶Docker部署LNMP环境 172.16.10.0/24 Nginx：172.16.10.10 Mysql：172.16.10.20 PHP：172.16.10.30 网站的访问主目录：/wwwroot Nginx的配置文件：/docker 123456789101112[root@localhost ~]# docker run -itd --name test nginx:latest[root@localhost ~]# mkdir &#x2F;wwwroot[root@localhost ~]# mkdir &#x2F;docker[root@localhost ~]# docker cp test:&#x2F;etc&#x2F;nginx &#x2F;docker&#x2F;[root@localhost ~]# ls &#x2F;docker&#x2F;nginx[root@localhost ~]# docker cp test:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html &#x2F;wwwroot&#x2F;[root@localhost ~]# ls &#x2F;wwwroot&#x2F;html[root@localhost ~]# vim &#x2F;wwwroot&#x2F;html&#x2F;index.html[root@localhost ~]# cat &#x2F;wwwroot&#x2F;html&#x2F;index.html hello LNMP! 1）创建一个自定义网络 1[root@localhost ~]# docker network create -d bridge --subnet 172.16.10.0&#x2F;24 --gateway 172.16.10.1 lnmp 2）运行nginx容器 1[root@localhost ~]# docker run -itd --name nginx -v &#x2F;docker&#x2F;nginx&#x2F;:&#x2F;etc&#x2F;nginx -v &#x2F;wwwroot&#x2F;html&#x2F;:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html -p 80:80 --network lnmp --ip 172.16.10.10 nginx:latest 3）运行mysql容器 123456789101112131415[root@localhost ~]# docker run --name mysql -e MYSQL_ROOT_PASSWORD&#x3D;123.com -d -p 3306:3306 --network lnmp --ip 172.16.10.20 mysql:5.7[root@localhost ~]# yum -y install mysql[root@localhost ~]# mysql -u root -p123.com -h 127.0.0.1 -P 3306MySQL [(none)]&gt; create database name;MySQL [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || name || performance_schema || sys |+--------------------+5 rows in set (0.00 sec) 4）运行php容器 1[root@localhost ~]# docker run -itd --name phpfpm -p 9000:9000 -v &#x2F;wwwroot&#x2F;html&#x2F;:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html --network lnmp --ip 172.16.10.30 php:7.2-fpm //添加php测试页面： 123456[root@localhost html]# pwd&#x2F;wwwroot&#x2F;html[root@localhost html]# cat test.php &lt;?phpphpinfo();?&gt; 5）修改nginx配置文件，nginx和php连接 1234567891011121314[root@localhost ~]# cd &#x2F;docker&#x2F;nginx&#x2F;conf.d&#x2F;[root@localhost conf.d]# vim default.conf location &#x2F; &#123; root &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html; index index.html index.htm index.php; &#x2F;&#x2F;添加php解析&#x2F;&#x2F;打开此模块，并更改相应信息 location ~ \\.php$ &#123; root &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html; fastcgi_pass 172.16.10.30:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; //重启nginx 1[root@localhost conf.d]# docker restart nginx //到此，去浏览器验证，nginx服务和php服务界面 说明nginx和php的来连接，没有问题，接下来是php和mysql的连接，在这我们使用一个phpMyAdmin的数据库管理工具 1234[root@localhost html]# pwd&#x2F;wwwroot&#x2F;html[root@localhost html]# unzip phpMyAdmin-4.9.1-all-languages.zip[root@localhost html]# mv phpMyAdmin-4.9.1-all-languages phpmyadmin //更改nginx的配置文件 123456789101112131415161718[root@localhost ~]# cd &#x2F;docker&#x2F;nginx&#x2F;conf.d&#x2F;[root@localhost conf.d]# pwd&#x2F;docker&#x2F;nginx&#x2F;conf.d[root@localhost conf.d]# vim default.conf&#x2F;&#x2F;在27行添加 location &#x2F;phpmyadmin &#123; root &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html; index index.html index.htm index.php; &#125;&#x2F;&#x2F;在43行添加 location ~ &#x2F;phpmyadmin&#x2F;(?&lt;after_ali&gt;(.*)\\.(php|php5)?$) &#123; root &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html; fastcgi_pass 172.16.10.30:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; //重启nginx 1[root@localhost conf.d]# docker restart nginx //验证php主界面 //需要我们对php镜像做出更改，添加php和mysql连接的模块 写一个Docker 123456789FROM php:7.2-fpmRUN apt-get update &amp;&amp; apt-get install -y \\ libfreetype6-dev \\ libjpeg62-turbo-dev \\ libpng-dev \\ &amp;&amp; docker-php-ext-install -j$(nproc) iconv \\ &amp;&amp; docker-php-ext-configure gd --with-freetype-dir&#x3D;&#x2F;usr&#x2F;include&#x2F; --with-jpeg-dir&#x3D;&#x2F;usr&#x2F;include&#x2F; \\ &amp;&amp; docker-php-ext-install -j$(nproc) gd \\ &amp;&amp; docker-php-ext-install mysqli pdo pdo_mysql 1[root@localhost ~]# docker build -t phpmysql . //删除之前的php容器，并用我们新制作的php镜像重新运行 123[root@localhost ~]# docker stop phpfpm [root@localhost ~]# docker rm phpfpm [root@localhost ~]# docker run -itd --name phpfpm -p 9000:9000 -v &#x2F;wwwroot&#x2F;html&#x2F;:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html --network lnmp --ip 172.16.10.30 phpmysql:latest //修改phpmyadmin的配置文件，指定连接的数据库的IP，然后重启php容器 1234567[root@localhost ~]# cd &#x2F;wwwroot&#x2F;html&#x2F;phpmyadmin&#x2F;[root@localhost phpmyadmin]# pwd&#x2F;wwwroot&#x2F;html&#x2F;phpmyadmin[root@localhost phpmyadmin]# cp config.sample.inc.php config.inc.php[root@localhost phpmyadmin]# vim config.inc.php$cfg[&#39;Servers&#39;][$i][&#39;host&#39;] &#x3D; &#39;172.16.10.20&#39;; &#x2F;&#x2F;修改，指定数据库的IP地址[root@localhost ~]# docker restart phpfpm 用户名：root 密码：123.com //登录成功之后会看到我们之前创建的数据库","categories":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/tags/Docker/"}]},{"title":"KVM简介","slug":"KVM简介","date":"2020-01-24T16:00:00.000Z","updated":"2020-01-25T13:07:32.318Z","comments":true,"path":"KVM简介.html","link":"","permalink":"https://pdxblog.top/KVM%E7%AE%80%E4%BB%8B.html","excerpt":"","text":"KVM简介： 什么是云计算： 云计算:配置各种资源的方式 云计算的分类： 基础即服务Lass 平台即服务Pass 软件即服务Sass 如果按照不同的部署方式：公有云、私有云、混合云 KVM介绍：虚拟化的不同的方式 实现虚拟化的技术： 基于二进制翻译的全虚拟化：（会报错） 解决思路： 捕捉报错----翻译—模拟（会增加服务器的开销） 半虚拟化（Xen）：更改内核，只能用到Linux系统上 全虚拟化：KVM、VMware //所依赖的硬件全部准备好就行 KVM的概念： 基于内核的虚拟机（Kernel-Based VIrtul mathine） 打开KVM的方式： virt-manager 应用程序–系统工具–虚拟系统管理器 命令创建虚拟主机域： 1234[root@localhost iso]# virt-install --os-type&#x3D;linux --os-variant centos7.0--name test01 --ram 1024 --vcpus 1 --disk&#x3D;&#x2F;kvm-vm&#x2F;centos.raw,format&#x3D;raw,size&#x3D;10--location &#x2F;iso&#x2F;CentOS-7-x86_64-DVD-1611.iso --network network&#x3D;default --graphics vnc,listen&#x3D;0.0.0.0 --noautoconsole（不会占用终端） vnc连接KVM虚拟机默认的端口为：5900","categories":[{"name":"KVM","slug":"KVM","permalink":"https://pdxblog.top/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://pdxblog.top/tags/KVM/"}]},{"title":"KVM磁盘格式","slug":"KVM磁盘格式","date":"2020-01-24T16:00:00.000Z","updated":"2020-01-25T13:07:32.318Z","comments":true,"path":"KVM磁盘格式.html","link":"","permalink":"https://pdxblog.top/KVM%E7%A3%81%E7%9B%98%E6%A0%BC%E5%BC%8F.html","excerpt":"","text":"磁盘格式： RAW：（裸格式） //占用空间较大，性能较好，但不支持虚拟机快照功能 QCOW2：（copy on write） //占用空间较小，支持快照，性能比RAW稍差一些 创建磁盘：（默认是裸格式） 1[root@kvm disk]# qemu-img create 1234.raw 5G 查看磁盘信息： 1[root@kvm disk]# qemu-img info 1234.raw 创建指定格式磁盘： 1[root@kvm disk]# qemu-img create -f qcow2 bdqn.qcow2 5G 转换磁盘格式： qemu-img convert [-f fmt] [-O output_fmt] filename output_filename 1[root@kvm kvm-vm]# qemu-img convert -f raw -O qcow2 centos.raw centos.qcow2 //转换之后原来的磁盘还在 拍摄快照： 1[root@kvm ~]# virsh snapshot-create test01 查看快照信息： 1234[root@kvm ~]# virsh snapshot-list test01 名称 生成时间 状态------------------------------------------------------------ 1575254957 2019-12-02 10:49:17 +0800 running 时间戳：1970年1月1号（计算机C语言诞生了，Linux系统诞生了） 32位系统：68年之后你的系统就不能使用了 64位系统：使用时间没有限制 根据快照恢复系统： 1[root@kvm ~]# virsh snapshot-revert test01 1575254957 //拍摄的快照是占用磁盘空间的","categories":[{"name":"KVM","slug":"KVM","permalink":"https://pdxblog.top/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://pdxblog.top/tags/KVM/"}]},{"title":"KVM基本操作命令","slug":"KVM基本操作命令","date":"2020-01-24T16:00:00.000Z","updated":"2020-01-25T13:07:32.334Z","comments":true,"path":"KVM基本操作命令.html","link":"","permalink":"https://pdxblog.top/KVM%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4.html","excerpt":"","text":"基于操作命令 1）查看虚拟机列表： 12[root@kvm ~]# virsh list &#x2F;&#x2F;查看正在运行的虚拟机[root@kvm ~]# virsh list --all &#x2F;&#x2F;查看所有虚拟机 ¶//开机的虚拟机才有ID号，而且会随时变化 Id 名称 状态 test01 关闭 2）查看虚拟机的详细信息： 1234567891011121314[root@kvm ~]# virsh dominfo test01 &#x2F;&#x2F;dom全称domain，域的意思Id: -名称： test01UUID: 8ba94166-08dd-4805-962b-c99ed56869bcOS 类型： hvm状态： 关闭CPU： 1最大内存： 1048576 KiB使用的内存： 1048576 KiB持久（peisistent）： 是 &#x2F;&#x2F;数据的持久化自动启动（autostart）： 禁用 &#x2F;&#x2F;是否开机自启管理的保存： 否安全性模式： none安全性 DOI： 0 3）虚拟机域的开关机： 123[root@kvm ~]# virsh start test01 &#x2F;&#x2F;开机[root@kvm ~]# virsh shutdown test01 &#x2F;&#x2F;关机（shutdown：温柔的关机）[root@kvm ~]# virsh shutdown 2 &#x2F;&#x2F;2为ID号 //关机后再开机ID号也会变化 1[root@kvm ~]# virsh destroy test01 &#x2F;&#x2F;强制关机，类似于拔电源 4）导出配置： 1[root@kvm ~]# virsh dumpxml test01 &gt; test01.xml &#x2F;&#x2F;dump备份的意思 vmnet0：桥接 //好处：外网能够访问你的虚拟机 vmnet1：主机 vmnet8：NAT //缺点：外网访问不了你的虚拟机，好处：可以自己随意指定IP 一个完成的KVM域，生成之后会有两个文件： 1）磁盘文件：在部署之处已经指定 //用来记录它的信息 2）xml配置文件，默认在/etc/libvirt/qemu //qemu模拟硬件，类型为raw 5）删除虚拟机： //删除之前保证虚拟机是关闭状态 1[root@kvm ~]# virsh undefine test01 &#x2F;&#x2F;undefine取消定义 //xml配置文件也会被删除，但是磁盘文件不会被影响 6）根据配置文件恢复虚拟机： 1[root@kvm ~]# virsh define test01.xml &#x2F;&#x2F;define：定义 7）修改配置文件： 1[root@kvm qemu]# virsh edit test01 edit：自带语法检查功能（y：是、n：不、i：忽略、f：强制） vim：不会提示你语法错误 8）虚拟机重命名（7.2版本之前的不支持这条命令） 1[root@kvm ~]# virsh domrename test01 test1 &#x2F;&#x2F;重命名前关闭虚拟机 9）查看虚拟机对应的vnc端口 12[root@localhost ~]# virsh vncdisplay test01:0 :0等于5900 :1=5901 :2=5902 10)挂起虚拟机 12[root@localhost ~]# virsh suspend test01[root@localhost ~]# virsh resume test01 &#x2F;&#x2F;恢复挂起的虚拟机 11）开机自启 12[root@localhost ~]# virsh autostart test01[root@localhost autostart]# virsh autostart --disable test01 &#x2F;&#x2F;取消开机自启 12）console登录KVM域 //在KVM域里添加 1234grubby --update-kernel&#x3D;ALL --args&#x3D;&quot;console&#x3D;ttyS0&quot;rebootvirsh console test01 &#x2F;&#x2F;使用xshell连接kvm退出 ctrl+]","categories":[{"name":"KVM","slug":"KVM","permalink":"https://pdxblog.top/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://pdxblog.top/tags/KVM/"}]},{"title":"KVM网络","slug":"KVM网络","date":"2020-01-24T16:00:00.000Z","updated":"2020-01-25T13:07:32.318Z","comments":true,"path":"KVM网络.html","link":"","permalink":"https://pdxblog.top/KVM%E7%BD%91%E7%BB%9C.html","excerpt":"","text":"NAT模式： KVM默认的网络方式，如果想要应用这种模式，防火墙需要打开，因为需要用到iptables规则 //打开防火墙添加规则，打开5900端口 12345[root@localhost ~]# firewall-cmd --add-port&#x3D;5900&#x2F;tcp --permanent success[root@localhost ~]# firewall-cmd --reloadsuccess[root@localhost ~]# firewall-cmd --list-all //添加路由转发： 123[root@localhost ~]# echo net.ipv4.ip_forward &#x3D; 1 &gt;&gt; &#x2F;etc&#x2F;sysctl.conf [root@localhost ~]# sysctl -pnet.ipv4.ip_forward &#x3D; 1 总结： nat模式支持主机与虚拟机的互访，也支持虚拟机访问互联网，但不支持外网访问虚拟机域 桥接网络： 1）创建虚拟桥接网卡br0 1234[root@localhost ~]# systemctl stop NetworkManager[root@localhost ~]# virsh iface-bridge ens33 br0 &#x2F;&#x2F;提示失败不用理会使用附加设备 br0 生成桥接 ens33 失败已启动桥接接口 br0 //查看配置文件会看到，ens33桥接到了br0 12345678[root@localhost network-scripts]# cat ifcfg-ens33DEVICE&#x3D;ens33ONBOOT&#x3D;yesBRIDGE&#x3D;&quot;br0&quot;[root@localhost network-scripts]# brctl showbridge name bridge id STP enabled interfacesbr0 8000.000c2901f11f yes ens33virbr0 8000.525400dc381b yes virbr0-nic 2）修改kvm虚拟机域的xml配置文件： 123&lt;interface type&#x3D;&#39;bridge&#39;&gt;&lt;mac address&#x3D;&#39;52:54:00:f8:a1:c9&#39;&#x2F;&gt;&lt;source bridge&#x3D;&#39;br0&#39;&#x2F;&gt; 3）开启虚拟机，配置IP，验证是否能够联通外网: 1[root@localhost ~]# vi &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth //IP和br0的IP要在同一网段","categories":[{"name":"KVM","slug":"KVM","permalink":"https://pdxblog.top/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://pdxblog.top/tags/KVM/"}]},{"title":"ReplicaSet、DaemonSet","slug":"ReplicaSet、DaemonSet","date":"2020-01-24T16:00:00.000Z","updated":"2020-01-25T13:07:32.303Z","comments":true,"path":"ReplicaSet、DaemonSet.html","link":"","permalink":"https://pdxblog.top/ReplicaSet%E3%80%81DaemonSet.html","excerpt":"","text":"¶ReplicaSet RC：ReplicationoController（老一代的Pod控制器） RS：ReplicaSet（新一代的Pod控制器） 用于确保由其管理的控制的Pod对象副本，能够满足用户期望，多则删除，少则通过模板创建 deployment、rs、rc 特点： 确保Pod资源对象的数量精准 确保Pod健康运行 弹性伸缩 同样，它也可以通过yaml或json格式的资源清单来创建，其中spec字段一般嵌套一下字段 replicas：期望的Pod对象副本数量 selector：当前控制器匹配Pod对象副本的标签 template：Pod副本的模板 与RC相比而言，RS不仅支持基于等值的标签选择器，而且还支持集合的标签选择器 标签：解决同类型的资源对象越来越多，为了更好的管理，按照标签分组 常用标签分类： release（版本）：stable（稳定版）、canary（金丝雀）、beta（测试版） environment（环境变量）：dev（开发）、qa（测试）、production（生产） application（应用）：ui、as（application software应用软件）、pc、sc tier（架构层级）：frontend（前端）、backend（后端）、cache（缓存） partition（分区）：customerA（客户A）、customoerB（客户B） track（品控级别）：daily（每天）、weekly（每周） 标签要做到：见名知意 //通过–show-labels显示资源对象的标签 1[root@master ~]# kubectl get pod --show-labels //通过-l选项查看仅含有包含某个标签的资源 1[root@master ~]# kubectl get pod -l env //通过-L显示某个键对应的值 1[root@master ~]# kubectl get pod -L env //给Pod资源添加标签 1[root@master ~]# kubectl label pod label app&#x3D;pc //删除标签 1[root@master ~]# kubectl label pod label app- //修改标签 1[root@master ~]# kubectl label pod label env&#x3D;dev --overwrite 如果标签有多个，标签选择器选择其中一个，也可以关联成功，相反，如果选择器有多个，那标签必须完全满足条件，才可以关联成功 标签选择器：标签的查询过滤条件 基于等值关系的（equality-based）：&quot;=&quot;，&quot;==&quot;，&quot;!=&quot; =&quot; 前面两个都是相等，最后是不等 基于集合关系（set-based）：in、notin、exists三种 例子： 123456selector: matchLables: app: nginx metchExpressions: - &#123;key: name,operator: In,values: [zhangsan,lisi]&#125; - &#123;key: age,operator: Exists,values:&#125; matchLabels：指定键值对来表示的标签选择器 matchExpressions：基于表达式来指定的标签选择器，选择器列表间为&quot;逻辑与&quot;关系；使用In或者Notin操作时，其values不强制要求为非控的字符串，而使用Exists或DosNotExist时，其values必须为空 使用标签选择器的逻辑： 同时指定的多个选择器之间的逻辑关系为&quot;与&quot;操作 使用空值的标签选择器意味着每个资源对象都将被选择中 空的标签选择器无法选中任何资源 ¶DaemonSet 它也是一种Pod控制器 使用场景：如果必须将Pod运行再固定的某个或某几个节点，且要优先其他Pod的启动，通常情况下，默认会每个节点都会运行，并且只能运行一个Pod，这种情况推荐使用DaemonSet资源对象 监控程序： 日志收集程序： 运行一个web服务，在每一个节点都运行一个Pod 1234567891011121314[root@master ~]# vim daemonset.yamlkind: DaemonSetapiVersion: extensions&#x2F;v1beta1metadata: name: test-dsspec: template: metadata: labels: name: test-ns spec: containers: - name: test-ns image: httpd:v1 RC、RS、Deployment、DaemonSet，Pod控制器。statfulSet（有状态）、Ingress。Pod RBAC：基于用户的认证授权机制","categories":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]},{"title":"虚拟机的迁移","slug":"虚拟机的迁移","date":"2020-01-24T16:00:00.000Z","updated":"2020-01-25T13:07:32.334Z","comments":true,"path":"虚拟机的迁移.html","link":"","permalink":"https://pdxblog.top/%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E8%BF%81%E7%A7%BB.html","excerpt":"","text":"虚拟机的迁移： 冷迁移（静态迁移）： //服务器需要关闭 kvm01：192.168.1.100 kvm02：192.168.1.200 两台机器防火墙全部关闭，禁用selinux 12[root@localhost ~]# lsmod | grep kvm &#x2F;&#x2F;查看是否支持kvm[root@localhost ~]# systemctl status libvirtd &#x2F;&#x2F;查看libvirtd服务是否正常 //迁移和克隆差不多，都是需要对磁盘文件和xml配置文件进行操作 123[root@kvm01 ~]# scp &#x2F;etc&#x2F;libvirt&#x2F;qemu&#x2F;test01.xml root@192.168.1.200:&#x2F;etc&#x2F;libvirt&#x2F;qemu [root@kvm01 ~]# scp &#x2F;kvm-vm&#x2F;centos.raw root@192.168.1.200:&#x2F;kvm-vm&#x2F;[root@kvm02 ~]# virsh define &#x2F;etc&#x2F;libvirt&#x2F;qemu&#x2F;test01.xml 热迁移（动态迁移）： 删除所有的KVM虚拟机 kvm01：192.168.1.100 kvm02：192.168.1.200 NFS：192.168.1.129 1）在NFS服务器上面操作： 123456789[root@NFS ~]# yum -y install nfs-utils[root@NFS ~]# mkdir &#x2F;kvmshare &#x2F;&#x2F;创建共享文件夹[root@NFS ~]# vim &#x2F;etc&#x2F;exports &#x2F;&#x2F;编辑共享文件夹权限[root@NFS ~]# cat &#x2F;etc&#x2F;exports&#x2F;kvmshare *(rw,sync,no_root_squash)[root@NFS ~]# systemctl start rpcbind &#x2F;&#x2F;远程传输控制协议[root@NFS ~]# systemctl enable rpcbind[root@NFS ~]# systemctl start nfs-server[root@NFS ~]# systemctl enable nfs-server //确保两台KVM服务器能看到 12[root@kvm01 ~]# showmount -e 192.168.1.129[root@kvm02 ~]# showmount -e 192.168.1.129 2）KVM01上基于NFS服务创建虚拟机 添加新的存储池： 名称：nfsshare 类型：netfs 目标路径：/opt/nfsshare（本机挂在的目录，目录默认没有，但会自己创建） 主机名:192.168.1.129（nfs-server IP address） 源路径：/kvmshare（nfs-server上的共享目录） 验证nfs服务是否正常： 123[root@kvm01 ~]# touch &#x2F;opt&#x2F;nfsshare&#x2F;test[root@NFS ~]# ls &#x2F;kvmshare&#x2F;test 创建存储卷： 名称：centos7 最大容量：10G //存储池和存储卷完成之后，直接创建虚拟机，并最小化安装 选择之前的创建的iso镜像以及刚才创建的存储池和存储卷 配置虚拟机使用bridge桥接网络，使其能够ping通外网，并且在这里我们执行一个ping百度的命令，并让他保持一直是ping着的状态，用来模拟迁移到kvm02上服务不中断： 12345678[root@kvm01 ~]# virsh destroy centos7.0[root@kvm01 ~]# systemctl stop NetworkManager[root@kvm01 ~]# virsh iface-bridge ens33 br0[root@kvm01 ~]# virsh edit centos7.0&lt;interface type&#x3D;&#39;bridge&#39;&gt;&lt;mac address&#x3D;&#39;52:54:00:12:80:97&#39;&#x2F;&gt;&lt;source bridge&#x3D;&#39;br0&#39;&#x2F;&gt;[root@kvm01 ~]# virsh start centos7.0 配置IP为DHCP自动获取 在KVM02上操作，创建存储池： 名称：nfsshare 类型：netfs 目标路径：/opt/nfsshare（本机挂在的目录，目录默认没有，但会自己创建） 主机名:192.168.1.129（nfs-server IP address） 源路径：/kvmshare（nfs-server上的共享目录） 创建完之后会看到之前在KVM01上创建的test文件和centos.qcow2的存储卷 在KVM01上连接KVM02： 右上角—文件—添加连接—连接到远程主机—方法：ssh—用户名：root----主机名：192.168.1.200（KVM02的IP） 会提示安装openssh-askpass，直接在KVM01和KVm02上安装： 12[root@kvm01 ~]# yum -y install openssh-askpass[root@kvm02 ~]# yum -y install openssh-askpass //因为KVM01使用的是bridge br0网卡，所以我们需要在KVM02上创建同样的网卡br0，用来支持虚拟机 12[root@kvm02 ~]# systemctl stop NetworkManager[root@kvm02 ~]# virsh iface-bridge ens33 br0 接下来直接在virt-manager管理器中迁移就可以了，迁移完成之后，保证我么的ping命令是不中断的，就表示实验完成了 右键centos7.0—迁移—地址：192.168.1.200（KVM02的IP）—高级选项----勾选允许不可靠----迁移 如果出现错误解决办法： 把KVM01和KVM02上挂载的目录给一个777的权限，保证双方root用户有权限调用目录 12[root@kvm01 ~]# chmod 777 &#x2F;opt&#x2F;[root@kvm02 ~]# chmod 777 &#x2F;opt&#x2F; 迁移完成后在KVM02上面查看ping命令是否中断","categories":[{"name":"KVM","slug":"KVM","permalink":"https://pdxblog.top/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://pdxblog.top/tags/KVM/"}]},{"title":"虚拟机的克隆","slug":"虚拟机的克隆","date":"2020-01-24T16:00:00.000Z","updated":"2020-01-25T13:07:32.318Z","comments":true,"path":"虚拟机的克隆.html","link":"","permalink":"https://pdxblog.top/%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%85%8B%E9%9A%86.html","excerpt":"","text":"克隆： 克隆的两种方式： 1、手动克隆（完整克隆）： test01----------&gt;test02：（将test01克隆为test02） 1）复制xml配置文件： 1234[root@localhost ~]# cd &#x2F;etc&#x2F;libvirt&#x2F;qemu&#x2F;[root@localhost qemu]# cp test01.xml test02.xml或者[root@kvm ~]# virsh dumpxml test01 &gt; test02.xml 2）复制磁盘文件： 12[root@localhost qemu]# cd &#x2F;kvm-vm&#x2F;[root@localhost kvm-vm]# cp centos.raw test02.raw 3）修改配置文件并重新生成一个虚拟机： 12[root@localhost kvm-vm]# cd &#x2F;etc&#x2F;libvirt&#x2F;qemu&#x2F;[root@localhost qemu]# vim test02.xml a:name字段 b:删除UUID c:删除mac address d:修改磁盘路径以及名称 1[root@localhost qemu]# virsh define test02.xml 链接克隆： //做一个链接的磁盘，然后第二个新的虚拟机更改xml配置文件，磁盘信息指定新的链接磁盘 1[root@localhost kvm-vm]# qemu-img create -f qcow2 -b centos.raw test02.qcow2 自动克隆（完整克隆）: 1[root@localhost ~]# virt-clone --auto-clone -o test02 -n test03 //-o:表示克隆谁，-n：指定名称","categories":[{"name":"KVM","slug":"KVM","permalink":"https://pdxblog.top/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://pdxblog.top/tags/KVM/"}]},{"title":"Deployment","slug":"Deployment","date":"2020-01-23T16:00:00.000Z","updated":"2020-01-25T13:00:44.044Z","comments":true,"path":"Deployment.html","link":"","permalink":"https://pdxblog.top/Deployment.html","excerpt":"","text":"¶Deployment 12345678910111213141516apiVersion: extensions&#x2F;v1beta1kind: Deploymentmetadata: name: test-webspec: replicas: 4 template: metadata: labels: app: web spec: containers: - name: test-web image: 192.168.1.70:5000&#x2F;httpd:v1 ports: - containerPort: 80 PS：注意，在Deployment资源对象中，可以添加Port字段，但此字段仅供用户查看，并不实际生效 ¶service 12345678910111213kind: ServiceapiVersion: v1metadata: name: web-svcspec: type: NodePort selector: app: web ports: - protocol: TCP port: 80 &#x2F;&#x2F;clusterIP的端口 targetPort: 80 &#x2F;&#x2F;Pod的端口 nodePort: 30123 SNAT：Source NAT（源地址转换） DNAT：Destination NAT（目标地址转换） MASQ：动态的源地址转换 service实现的负载均衡：默认使用的是iptables规则 第二种方案：IPVS ¶回滚到指定版本 准备三个版本所使用的私有镜像，来模拟每次升级到不同的镜像 Deployment1.yaml 1234567891011121314151617[root@master ~]# vim deployment1.yamlapiVersion: extensions&#x2F;v1beta1kind: Deploymentmetadata: name: test-webspec: revisionHistoryLimit: 10 replicas: 3 template: metadata: labels: app: web spec: containers: - name: test-web image: 192.168.1.70:5000&#x2F;httpd:v1 ports: Deployment2.yaml 123456789101112131415161718[root@master ~]# vim deployment2.yamlapiVersion: extensions&#x2F;v1beta1kind: Deploymentmetadata: name: test-webspec: revisionHistoryLimit: 10 replicas: 3 template: metadata: labels: app: web spec: containers: - name: test-web image: 192.168.1.70:5000&#x2F;httpd:v2 ports: - containerPort: 80 Deployment3.yaml 123456789101112131415161718[root@master ~]# vim deployment3.yamlapiVersion: extensions&#x2F;v1beta1kind: Deploymentmetadata: name: test-webspec: revisionHistoryLimit: 10 replicas: 3 template: metadata: labels: app: web spec: containers: - name: test-web image: 192.168.1.70:5000&#x2F;httpd:v3 ports: - containerPort: 80 此处3个yaml文件，指定不同版本的镜像 //运行一个服务，并记录一个版本信息 1[root@master ~]# kubectl apply -f deployment1.yaml --record //查看有哪些版本信息 1[root@master ~]# kubectl rollout history deployment test-web //运行并升级Deployment资源，并记录版本信息 12[root@master ~]# kubectl apply -f deployment2.yaml --record[root@master ~]# kubectl apply -f deployment3.yaml --record //此时可以运行一个关联的Service资源去验证升级是否成功 123[root@master ~]# kubectl apply -f web-svc.yaml[root@master ~]# curl 10.96.179.50&lt;h1&gt;zhb | test-web | httpd | v3&lt;h1&gt; //回滚到指定版本 ¶用label控制Pod的位置 //添加节点你标签 12[root@master ~]# kubectl label nodes node02 disk&#x3D;ssd[root@master ~]# kubectl get nodes --show-labels | grep node02 12345678910111213141516171819apiVersion: extensions&#x2F;v1beta1kind: Deploymentmetadata: name: test-webspec: revisionHistoryLimit: 10 &#x2F;&#x2F;版本历史限制 replicas: 3 template: metadata: labels: app: web spec: containers: - name: test-web image: 192.168.1.70:5000&#x2F;httpd:v1 ports: - containerPort: 80 nodeSelector: &#x2F;&#x2F;添加节点选择器 disk: ssd &#x2F;&#x2F;和标签内容一致 12345[root@master ~]# kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-web-d58c9f847-bhswj 1&#x2F;1 Running 0 28s 10.244.2.14 node02 &lt;none&gt; &lt;none&gt;test-web-d58c9f847-k58nj 1&#x2F;1 Running 0 28s 10.244.2.13 node02 &lt;none&gt; &lt;none&gt;test-web-d58c9f847-vt7r5 1&#x2F;1 Running 0 28s 10.244.2.15 node02 &lt;none&gt; &lt;none&gt; //删除节点标签 1[root@master ~]# kubectl label nodes node02 disk-","categories":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]},{"title":"Docker三剑客之docker-compose+wordpress的博客搭建","slug":"Docker三剑客之docker-compose+wordpress的博客搭建","date":"2020-01-23T16:00:00.000Z","updated":"2020-02-03T02:45:12.557Z","comments":true,"path":"Docker三剑客之docker-compose+wordpress的博客搭建.html","link":"","permalink":"https://pdxblog.top/Docker%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bdocker-compose+wordpress%E7%9A%84%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA.html","excerpt":"","text":"Docker三剑客： docker machine：自动化部署多台dockerHost docker-compose：它可以同时控制多个容器 docker swarm：从单个的服务向集群的形式发展 为什么要做集群： 高可用、高性能、高并发：防止单点故障 ¶Docker三剑客之docker-compose docker容器的编排工具： 解决相互有依赖关系的多个容器的管理 //验证已有docker-compose命令 12[root@localhost ~]# docker-compose -vdocker-compose version 1.25.0, build 0a186604 docker-compose的配置文件实例 通过识别一个docker-compose.yml的配置文件，去管理容器 //设置tab键的空格数量 123[root@localhost ~]# vim .vimrcset tabstop&#x3D;2[root@localhost ~]# source .vimrc 12345678910111213[root@localhost ~]# mkdir compose_test[root@localhost ~]# cd compose_test&#x2F;[root@localhost compose_test]# vim docker-compose.ymlversion: &quot;3&quot;services: nginx: container_name: web-nginx image: nginx restart: always ports: - 90:80 volumes: - .&#x2F;webserver:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html 第一个部分：version：指定格式的版本 第二部分：services：定义服务，（想要运行什么样的容器） //运行docker-compose规定的容器： PS：在执行这条命令的当前目录下，也需要有一个docker-compose.yml的配置文件，并且通常只有一个 12345[root@localhost compose_test]# docker-compose up -d[root@localhost compose_test]# cd webserver&#x2F;[root@localhost webserver]# echo 123456 &gt; index.html[root@localhost webserver]# curl 127.0.0.1:90123456 //停止运行 1[root@localhost compose_test]# docker-compose stop //重启 1[root@localhost compose_test]# docker-compose restart //如果在当前目录没有docker-compose.yml这个文件，可以通过-f来指定docker-compose.yml文件位置 1[root@localhost ~]# docker-compose -f compose_test&#x2F;docker-compose.yml start 并且，在运行container的过程中，还可以支持Dockerfile 1234567891011121314151617181920212223[root@localhost compose_test]# vim Dockerfile[root@localhost compose_test]# cat Dockerfile FROM nginxADD webserver &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;htm[root@localhost compose_test]# vim docker-compose.ymlversion: &quot;3&quot;services: nginx: build: . container_name: web-nginx image: new-nginx:v1.0 restart: always ports: - 90:80[root@localhost compose_test]# docker-compose stop[root@localhost compose_test]# docker-compose rm[root@localhost compose_test]# docker-compose up -d[root@localhost compose_test]# curl 127.0.0.1:90123456[root@localhost compose_test]# cd webserver&#x2F;[root@localhost webserver]# echo 654321 &gt; index.html [root@localhost webserver]# curl 127.0.0.1:90123456 ¶搭建wordpress的博客 12345678910111213141516171819202122232425[root@localhost ~]# mkdir wordpress[root@localhost ~]# docker load &lt; wordpress.tar[root@localhost ~]# cd wordpress&#x2F;[root@localhost wordpress]# vim docker-compose.ymlversion: &quot;3.1&quot;services: wordpress: image: wordpress restart: always ports: - 8080:80 environment: WORDPRESS_DB_HOST: db WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: 123.com WORDPRESS_DB_NAME: wordpress db: image: mysql:5.7 restart: always environment: MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: 123.com MYSQL_ROOT_PASSWORD: 123.com[root@localhost wordpress]# docker-compose up -d //浏览器访问本机的8080端口：（192.168.1.70:8080）","categories":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/tags/Docker/"}]},{"title":"Docker实现服务发现","slug":"Docker实现服务发现","date":"2020-01-23T16:00:00.000Z","updated":"2020-01-25T13:07:32.209Z","comments":true,"path":"Docker实现服务发现.html","link":"","permalink":"https://pdxblog.top/Docker%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0.html","excerpt":"","text":"¶Docker实现服务发现 ¶Docker + Consul + registrator实现服务发现 Consul：分布式、高可用的，服务发现和配置的工具，数据中心 Registrator：负责收集dockerhost上，容器服务的信息，并且发送给consul Consul-template：根据编辑好的模板生成新的nginx配置文件，并且负责加载nginx配置文件 实验环境 docker01 192.168.1.70 docker02 192.168.1.60 docker03 192.168.1.50 关闭防火墙和selinux，并修改主机名 1234[root@localhost ~]# systemctl stop firewalld[root@localhost ~]# setenforce 0[root@localhost ~]# hostnamectl set-hostname docker01[root@localhost ~]# su - 1）docker01上，启动consul服务 123[root@docker01 ~]# unzip consul_1.5.1_linux_amd64.zip[root@docker01 ~]# mv consul &#x2F;usr&#x2F;local&#x2F;bin&#x2F;[root@docker01 ~]# chmod +x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;consul //以二进制的方式部署consul，并启动，身份为leader 12345[root@docker01 ~]# consul agent -server -bootstrap \\&gt; -ui -data-dir&#x3D;&#x2F;var&#x2F;lib&#x2F;consul-data \\&gt; -bind&#x3D;192.168.1.70 \\&gt; -client&#x3D;0.0.0.0 \\&gt; -node&#x3D;master //这时这个命令会占用终端，可以使用nohup命令让它保持后台运行 1[root@docker01 ~]# nohup consul agent -server -bootstrap -ui -data-dir&#x3D;&#x2F;var&#x2F;lib&#x2F;consul-data -bind&#x3D;192.168.1.70 -client&#x3D;0.0.0.0 -node&#x3D;master &amp; PS: -bootstrap：加入这个选项时，一般都在server单节点的时候用，自选举为leader -ui：开启内部web界面 -data-dir：key/volume数据存储位置 -bind：指定开启服务的IP -client：指定访问的客户端 -node：只当集群内通信使用的名称，默认是用主机名命名的 PS：开启的端口 8300：集群节点 8301：集群内部的访问 8302：跨数据中心的通信 8500：web ui界面 8600：使用dns协议查看节点信息的端口 //查看conusl的信息 12[root@docker01 ~]# consul infoleader_addr &#x3D; 192.168.1.70:8300 &#x2F;&#x2F;这个对我们比较有用，其他的都是一些它的算法 //查看集群内成员的信息 123[root@docker01 ~]# consul membersNode Address Status Type Build Protocol DC Segmentmaster 192.168.1.70:8301 alive server 1.5.1 2 dc1 &lt;all&gt; 2）docker02、docker03，加入consul集群 这里我们采用容器的方式去运行consul服务 //docker02 12[root@docker02 ~]# docker load &lt; myprogrium-consul.tar[root@docker02 ~]# docker run -d --name consul -p 8301:8301 -p 8301:8301&#x2F;udp -p 8500:8500 -p 8600:8600 -p 8600:8600&#x2F;udp --restart always progrium&#x2F;consul:latest -join 192.168.1.70 -advertise 192.168.1.60 -client 0.0.0.0 -node&#x3D;node01 //docker03 12[root@docker03 ~]# docker load &lt; myprogrium-consul.tar[root@docker03 ~]# docker run -d --name consul -p 8301:8301 -p 8301:8301&#x2F;udp -p 8500:8500 -p 8600:8600 -p 8600:8600&#x2F;udp --restart always progrium&#x2F;consul:latest -join 192.168.1.70 -advertise 192.168.1.50 -client 0.0.0.0 -node&#x3D;node02 //在docker01上就能看到加入的信息 12342019&#x2F;12&#x2F;26 09:50:25 [INFO] serf: EventMemberJoin: node01 192.168.1.602019&#x2F;12&#x2F;26 09:50:25 [INFO] consul: member &#39;node01&#39; joined, marking health alive2019&#x2F;12&#x2F;26 09:53:06 [INFO] serf: EventMemberJoin: node02 192.168.1.502019&#x2F;12&#x2F;26 09:53:06 [INFO] consul: member &#39;node02&#39; joined, marking health alive 12345[root@docker01 ~]# consul membersNode Address Status Type Build Protocol DC Segmentmaster 192.168.1.70:8301 alive server 1.5.1 2 dc1 &lt;all&gt;node01 192.168.1.60:8301 alive client 0.5.2 2 dc1 &lt;default&gt;node02 192.168.1.50:8301 alive client 0.5.2 2 dc1 &lt;default&gt; //浏览器访问consul服务，验证集群信息 192.168.1.70:8500 3)下载部署consul-template //在docker01上导入consul-template_0.19.5_linux_amd64.zip 123[root@docker01 ~]# unzip consul-template_0.19.5_linux_amd64.zip[root@docker01 ~]# mv consul-template &#x2F;usr&#x2F;local&#x2F;bin&#x2F;[root@docker01 ~]# chmod +x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;consul-template 4）docker02、docker03上部署registrator服务 registrator是一个能自动发现docker container提供的服务，并在后端服务注册中心注册服务或取消服务的工具，后端注册中心支持consul、etcd、skydns2、zookeeper等 //docker02 1234567[root@docker02 ~]# docker load &lt; myregistrator.tar[root@docker02 ~]# docker run -d \\&gt; --name registrator \\&gt; -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;tmp&#x2F;docker.sock \\&gt; --restart always \\&gt; gliderlabs&#x2F;registrator \\&gt; consul:&#x2F;&#x2F;192.168.1.60:8500 //运行一个nginx容器 123[root@docker02 ~]# docker run -d -P --name test nginx:latestb0665dcbd6c5 nginx:latest &quot;nginx -g &#39;daemon of…&quot; 10 seconds ago Up 9 seconds 0.0.0.0:32768-&gt;80&#x2F;tcp &#x2F;&#x2F;映射的端口为32768 //回到浏览器 //docker03 1234567[root@docker03 ~]# docker load &lt; myregistrator.tar[root@docker02 ~]# docker run -d \\&gt; --name registrator \\&gt; -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;tmp&#x2F;docker.sock \\&gt; --restart always \\&gt; gliderlabs&#x2F;registrator \\&gt; consul:&#x2F;&#x2F;192.168.1.50:8500 5）docker01部署一个nginx服务 //依赖环境 [root@docker01 ~]# yum -y install zlib-devel openssl-devel pcre-devel 1234567891011121314[root@docker01 ~]# useradd -M -s &#x2F;sbin&#x2F;nologin nginx[root@docker01 ~]# tar zxf nginx-1.14.0.tar.gz [root@docker01 ~]# cd nginx-1.14.0&#x2F;[root@docker01 nginx-1.14.0]# .&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx \\&gt; --user&#x3D;nginx --group&#x3D;nginx \\&gt; --with-http_stub_status_module \\&gt; --with-http_realip_module \\&gt; --with-pcre --with-http_ssl_module[root@docker01 nginx-1.14.0]# make &amp;&amp; make install[root@docker01 nginx-1.14.0]# ln -s &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;* &#x2F;usr&#x2F;local&#x2F;sbin&#x2F;[root@docker01 nginx-1.14.0]# nginx -tnginx: the configuration file &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.conf syntax is oknginx: configuration file &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.conf test is successful[root@docker01 nginx-1.14.0]# nginx PS： 这里nginx作为反向代理，代理后端docker02、docker03上nignx的容器服务，所以我们先去docker02、docker03上部署一些服务，为了方便等会看到负载的效果，所以我们运行完成容器之后，做一个主界面内容的区分 docker02：web01 web02 docker03：web03 web04 //docker02 12345678910111213141516[root@docker02 ~]# docker run -itd --name web01 -P nginx:latest [root@docker02 ~]# docker exec -it web01 &#x2F;bin&#x2F;bashroot@dac0cc15f3fe:&#x2F;# cd &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;root@dac0cc15f3fe:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html# echo &quot;This web caontainer in dockek02-web01&quot; &gt; index.html root@dac0cc15f3fe:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html# cat index.html This web caontainer in dockek02-web01[root@docker02 ~]# docker run -itd --name web02 -P nginx:latest [root@docker02 ~]# docker exec -it web02 &#x2F;bin&#x2F;bashroot@26d622553e5e:&#x2F;# cd &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;root@26d622553e5e:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html# echo &quot;This web caontainer in dockek02-web02&quot; &gt; index.html root@26d622553e5e:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html# cat index.html This web caontainer in dockek02-web02[root@docker02 ~]# curl 127.0.0.1:32769This web caontainer in dockek02-web01[root@docker02 ~]# curl 127.0.0.1:32770This web caontainer in dockek02-web02 //docker03 12345678910111213141516[root@docker03 ~]# docker run -itd --name web03 -P nginx:latest [root@docker03 ~]# docker exec -it web03 &#x2F;bin&#x2F;bashroot@a10f25a91edf:&#x2F;# cd &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;root@a10f25a91edf:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html# echo &quot;This web caontainer in dockek03-web03&quot; &gt; index.html root@a10f25a91edf:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html# cat index.html This web caontainer in dockek03-web03[root@docker03 ~]# docker run -itd --name web04 -P nginx:latest [root@docker03 ~]# docker exec -it web04 &#x2F;bin&#x2F;bashroot@6d30a445c9b8:&#x2F;# cd &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;root@6d30a445c9b8:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html# echo &quot;his web caontainer in dockek03-web04&quot; &gt; index.html root@6d30a445c9b8:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html# cat index.html This web caontainer in dockek03-web04[root@docker03 ~]# curl 127.0.0.1:32768This web caontainer in dockek03-web03[root@docker03 ~]# curl 127.0.0.1:32769This web caontainer in dockek03-web04 更改nginx的配置文件 12345678910111213141516171819202122232425[root@docker01 ~]# cd &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;[root@docker01 nginx]# mkdir consul[root@docker01 nginx]# cd consul&#x2F;[root@docker01 consul]# pwd&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;consul[root@docker01 consul]# vim nginx.ctmpl[root@docker01 consul]# cat nginx.ctmpl upstream httpd_backend &#123; &#123;&#123;range service &quot;nginx&quot;&#125;&#125; server &#123;&#123; .Address &#125;&#125;:&#123;&#123; .Port &#125;&#125;; &#123;&#123; end &#125;&#125;&#125;server &#123; listen 8000; server_name localhost; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;http_backend; &#125;&#125;[root@docker01 ~]# vim &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.conf&#x2F;&#x2F;在文件最后，也就是倒数第二行添加：include &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;consul&#x2F;*.conf;&#x2F;&#x2F;使nginx的主配置文件能够识别到新产生的配置文件[root@docker01 ~]# nginx -s reload //使用consul-template命令，根据模板生产的配置文件，并重新加载nginx的配置文件 1[root@docker01 consul]# consul-template -consul-addr 192.168.1.70:8500 -template &quot;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;consul&#x2F;nginx.ctmpl:&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;consul&#x2F;vhost.conf:&#x2F;usr&#x2F;local&#x2F;sbin&#x2F;nginx -s reload&quot; //这时这个命令会占用终端，可以使用nohup命令让它保持后台运行 1[root@docker01 consul]# nohup consul-template -consul-addr 192.168.1.70:8500 -template &quot;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;consul&#x2F;nginx.ctmpl:&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;consul&#x2F;vhost.conf:&#x2F;usr&#x2F;local&#x2F;sbin&#x2F;nginx -s reload&quot; &amp; //此时，应该能够看到，新生产的vhost.conf配置文件已经生效，访问本机的8000端口可以得到不同容器提供的服务 12345678910111213141516171819202122232425[root@docker01 ~]# cd &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;consul&#x2F;[root@docker01 consul]# lsnginx.ctmpl vhost.conf[root@docker01 consul]# cat vhost.confupstream httpd_backend &#123; server 192.168.1.60:32768; server 192.168.1.60:32769; server 192.168.1.60:32770; server 192.168.1.50:32768; server 192.168.1.50:32769; &#125;server &#123; listen 8000; server_name localhost; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;httpd_backend; &#125;&#125; 12345678[root@docker01 consul]# curl localhost:8000This web caontainer in dockek02-web01[root@docker01 consul]# curl localhost:8000This web caontainer in dockek02-web02[root@docker01 consul]# curl localhost:8000This web caontainer in dockek03-web03[root@docker01 consul]# curl localhost:8000This web caontainer in dockek03-web04 当然，这时不管是添加新的nginx的web容器，或是删除，生产的配置文件都会时时更新，这是我们在运行consul-template这条命令最后添加：/usr/local/sbin/nginx -s reload它的作用 //删除之前的test容器，查看vhost文件 123456789101112[root@docker02 ~]# docker rm -f test[root@docker01 consul]# cat vhost.conf upstream httpd_backend &#123; server 192.168.1.60:32769; server 192.168.1.60:32770; server 192.168.1.50:32768; server 192.168.1.50:32769;&#125; //在运行一个web05，查看vhost文件的变化 12345678910111213[root@docker02 ~]# docker run -itd --name web05 -P nginx:latest upstream httpd_backend &#123; server 192.168.1.60:32769; server 192.168.1.60:32770; server 192.168.1.60:32771; server 192.168.1.50:32768; server 192.168.1.50:32769;&#125; 1、docker01主机上以二进制包的方式部署consul服务并后台运行，其身份为leader 2、docker02、docker03以容器的方式运行consul服务，并加入到docker01的consul群集中 3、在主机docker02、docker03上后台运行registrator容器，使其自动发现docker容器提供的服务，并发送给consul 4、在docker01上部署Nginx，提供反向代理服务，docker02、docker03主机上基于Nginx镜像，各运行两个web容器，提供不同的网页文件，以便测试效果 5、在docker01上安装consul-template命令，将收集到的信息（registrator收集到容器的信息）写入template模板中，并且最终写入Nginx的配置文件中 6、至此，实现客户端通过访问Nginx反向代理服务器（docker01），获得docker02、docker03服务器上运行的Nginx容器提供的网页文件 Consul：分布式、高可用的，服务发现和配置的工具，数据中心 Registrator：负责收集dockerhost上，容器服务的信息，并且发送给consul registrator是一个能自动发现docker container提供的服务，并在后端服务注册中心注册服务或取消服务的工具，后端注册中心支持consul、etcd、skydns2、zookeeper等 Consul-template：根据编辑好的模板生成新的nginx配置文件，并且负责加载nginx配置文件","categories":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/tags/Docker/"}]},{"title":"Docker数据持久化","slug":"Docker数据持久化","date":"2020-01-23T16:00:00.000Z","updated":"2020-01-25T13:07:32.224Z","comments":true,"path":"Docker数据持久化.html","link":"","permalink":"https://pdxblog.top/Docker%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96.html","excerpt":"","text":"¶Docker数据持久化 为什么要做数据持久化： 因为Docker容器本身就是一个进程，可能会因为某些原因，或某些错误导致进程被杀死，这样数据就会丢失。 Docker容器是有生命周期的，生命周期结束，进程也会被杀死，数据就会丢失，因此需要做数据持久化，保证数据不会丢失 ¶Storage Driver 数据存储 Centos7版本的Docker，Storage Driver为：Overlay2； backing filesystem：xfs ¶Data Volume ¶Bind mount 持久化存储：本质上是DockerHost文件系统中的目录或文件，能够直接被Mount到容器的文件系统中，在运行容器时，可以通过-v实现 特点： Data Volume是目录或文件，不能是没有格式化的磁盘（块设备） 容器可以读写volume中的数据 volume数据可以永久保存，即使用它的容器已经被销毁 小实验： 运行一个nginx服务，做数据持久化 12345678910[root@docker01 ~]# mkdir html[root@docker01 ~]# cd html&#x2F;[root@docker01 html]# echo &quot;This is a testfile in dockerHost.&quot; &gt; index.html[root@docker01 html]# cat index.html This is a testfile in dockerHost.[root@docker01 ~]# docker run -itd --name testweb -v &#x2F;root&#x2F;html&#x2F;:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html nginx:latest[root@docker01 ~]# docker inspect testweb&quot;Gateway&quot;: &quot;172.17.0.1&quot;,[root@docker01 ~]# curl 172.17.0.2This is a testfile in dockerHost. PS:DockerHost上需要挂在的源文件或目录，必须是已经存在的，否则，当做一个目录挂在到容器中 默认挂载到容器内的文件，容器是有读写权限，可以在运行容器时-v后边加&quot;:ro&quot;限制容器的写入权限 并且还可以挂在单独文件到容器内部，一般它的使用场景是：如果不想对整个目录进行覆盖，而只希望添加某个文件，就可以使用挂载单个文件 ¶Docker Manager Volume 1[root@docker01 ~]# docker run -itd --name t2 -P -v &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html nginx:latest 删除容器的操作，默认不会对dockerHost上的文件操作，如果想要在删除容器时把源文件也删除，可以在删除容器时添加-v选型（一般不推荐使用这种方式，因为文件有可能被其他容器使用） ¶容器与容器的数据共享： volume container：给其他容器提供volume存储卷的容器，并且可以提供bind mount，也可以提供docker manager volume //创建一个vc_data容器： 123[root@docker01 ~]# docker create --name vc_data \\&gt; -v ~&#x2F;html:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html \\&gt; -v &#x2F;other&#x2F;useful&#x2F;tools busybox ¶容器的跨主机数据共享 docker01 dcoker02 docker03 httpd httpd nfs 要求： docker01和docker02的主目录是一样的 //docker03的操作： 1234567891011121314151617[root@docker03 ~]#yum -y install nfs-utils[root@docker03 ~]# mkdir &#x2F;datashare[root@docker03 ~]# vim &#x2F;etc&#x2F;exports[root@docker03 ~]# cat &#x2F;etc&#x2F;exports&#x2F;datashare *(rw,sync,no_root_squash)[root@docker03 ~]# systemctl start rpcbind[root@docker03 ~]# systemctl enable rpcbind[root@docker03 ~]# systemctl start nfs-server[root@docker03 ~]# systemctl enable nfs-server[root@docker03 ~]# vim &#x2F;datashare&#x2F;index.html[root@docker03 ~]# cat &#x2F;datashare&#x2F;index.html &lt;div id&#x3D;&quot;datetime&quot;&gt; &lt;script&gt; setInterval(&quot;document.getElementById(&#39;datetime&#39;).innerHTML&#x3D;new Date().toLocaleString();&quot;, 1000); &lt;&#x2F;script&gt;&lt;&#x2F;div&gt;bdqn-webshare //验证 123456[root@docker01 ~]# showmount -e 192.168.1.60Export list for 192.168.1.60:&#x2F;datashare *[root@docker02 ~]# showmount -e 192.168.1.60Export list for 192.168.1.60:&#x2F;datashare * //docker01的操作 12345678910[root@docker01 ~]# mkdir &#x2F;htdocs[root@docker01 ~]# mount -t nfs 192.168.1.60:&#x2F;datashare &#x2F;htdocs&#x2F;&#x2F;&#x2F;-t：指定类型（type）[root@docker01 ~]# cat &#x2F;htdocs&#x2F;index.html &lt;div id&#x3D;&quot;datetime&quot;&gt; &lt;script&gt; setInterval(&quot;document.getElementById(&#39;datetime&#39;).innerHTML&#x3D;new Date().toLocaleString();&quot;, 1000); &lt;&#x2F;script&gt;&lt;&#x2F;div&gt;bdqn-webshare //docker02的操作 123456789[root@docker02 ~]# mkdir &#x2F;htdocs[root@docker02 ~]# mount -t nfs 192.168.1.60:&#x2F;datashare &#x2F;htdocs&#x2F;[root@docker02 ~]# cat &#x2F;htdocs&#x2F;index.html &lt;div id&#x3D;&quot;datetime&quot;&gt; &lt;script&gt; setInterval(&quot;document.getElementById(&#39;datetime&#39;).innerHTML&#x3D;new Date().toLocaleString();&quot;, 1000); &lt;&#x2F;script&gt;&lt;&#x2F;div&gt;bdqn-webshare 这里先不考虑将代码写入镜像，先以这种方式，分别在docker01和docker02部署httpd服务 //docker01 12[root@docker01 ~]# docker run -itd --name bdqn-web1 -P -v &#x2F;htdocs&#x2F;:&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;htdocs httpd:latestPS：查看端口映射0.0.0.0:32778-&gt;80&#x2F;tcp bdqn-web1 //docker02 12[root@docker02 ~]# docker run -itd --name bdqn-web2 -P -v &#x2F;htdocs&#x2F;:&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;htdocs httpd:latestPS：查看端口映射0.0.0.0:32768-&gt;80&#x2F;tcp bdqn-web2 此时用浏览器访问，两个web服务的主界面是一样的，但如果NFS服务器上源文件丢失，则两个web服务都会异常 想办法将源数据写入镜像内，在基于镜像做一个vc_data容器，这里因为没有接触到docker-compose和docker swarm等docker编排工具，所以我们在docker01和docker02上手动创建镜像 123456789101112[root@docker01 ~]# cd &#x2F;htdocs&#x2F;[root@docker01 htdocs]# vim Dockerfile[root@docker01 htdocs]# cat Dockerfile FROM busyboxADD index.html &#x2F;usr&#x2F;local&#x2F;apache2&#x2F;htdocs&#x2F;index.htmlVOLUME &#x2F;usr&#x2F;local&#x2F;apache2&#x2F;htdocs[root@docker01 htdocs]# docker build -t back_data .[root@docker01 htdocs]# docker create --name back_container1 back_data:latest [root@docker01 htdocs]# docker run -itd --name web3 -P --volumes-from back_container1 httpd:latest [root@docker01 htdocs]# pwd&#x2F;htdocs[root@docker01 htdocs]# docker save &gt; back_data.tar back_data:latest //docker02上操作： 123456[root@docker02 ~]# cd &#x2F;htdocs&#x2F;[root@docker02 htdocs]# lsback_data.tar Dockerfile index.html[root@docker02 htdocs]# docker load &lt; back_data.tar [root@docker02 htdocs]# docker create --name back_container2 back_data:latest[root@docker02 htdocs]# docker run -itd --name web4 -P --volumes-from back_container2 httpd:latest 测试： 1[root@docker01 htdocs]# rm -rf index.html 通过浏览器访问，一开始运行的web1和web2容器，无法访问了。web3和web4还是可以访问的。 但是数据无法同步了","categories":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/tags/Docker/"}]},{"title":"Docker跨主机网络方案之MacVlan","slug":"Docker跨主机网络方案之MacVlan","date":"2020-01-23T16:00:00.000Z","updated":"2020-01-25T13:07:32.271Z","comments":true,"path":"Docker跨主机网络方案之MacVlan.html","link":"","permalink":"https://pdxblog.top/Docker%E8%B7%A8%E4%B8%BB%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%96%B9%E6%A1%88%E4%B9%8BMacVlan.html","excerpt":"","text":"¶Docker跨主机网络方案之MacVlan 实验环境： docker01 192.168.1.70 docker02 192.168.1.50 关闭防火墙和禁用selinux，更该主机名： 1234567[root@localhost ~]# systemctl stop firewalld[root@localhost ~]# systemctl disable firewalld[root@localhost ~]# setenforce 0[root@localhost ~]# systemctl daemon-reload [root@localhost ~]# systemctl restart docker[root@localhost ~]# hostnamectl set-hostname docker01[root@localhost ~]# su - macvlan的单网络通信 1）打开网卡的混杂模式 //需要在docker01和docker02上都进行操作 12[root@docker01 ~]# ip link set ens33 promisc on[root@docker01 ~]# ip link show ens33 2）在docker01上创建macvlan网络 1234在这里插入代码片[root@docker01 ~]# docker network create -d macvlan --subnet 172.22.16.0&#x2F;24 --gateway 172.22.16.1 -o parent&#x3D;ens33 mac_net1[root@docker01 ~]# docker network lsNETWORK ID NAME DRIVER SCOPEe6860af70e90 mac_net1 macvlan local PS:-o parent=绑定在哪张网卡之上 3）基于创建的macvlan网络运行一个容器 1[root@docker01 ~]# docker run -itd --name bbox1 --ip 172.22.16.10 --network mac_net1 busybox 4）在docker02上创建macvlan网络，注意与docker01上的macvlan网络一摸一样 1[root@docker02 ~]# docker network create -d macvlan --subnet 172.22.16.0&#x2F;24 --gateway 172.22.16.1 -o parent&#x3D;ens33 mac_net1 5）在docker02上，基于创建的macvlan网络运行一个容器，验证与docker01上容器的通信 1[root@docker02 ~]# docker run -itd --name bbox2 --network mac_net1 --ip 172.22.16.20 busybox macvlan的多网络通信 1）docker01和docker02验证内核模块8021q封装 macvlan需要解决的问题：基于真实的ens33网卡，生产新的虚拟网卡 123[root@docker01 ~]# modinfo 8021q&#x2F;&#x2F;如果内核模块没有开启，运行下边命令导入一下[root@docker01 ~]# modprobe 8021q 2）基于ens33创建虚拟网卡 //修改ens33网卡配置文件： 1234[root@docker01 ~]# cd &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;[root@docker01 network-scripts]# vim ifcfg-ens33&#x2F;&#x2F;修改：BOOTPROTO&#x3D;manual &#x2F;&#x2F;手动模式 //手动添加虚拟网卡配置文件 123456789101112[root@docker01 network-scripts]# cp -p ifcfg-ens33 ifcfg-ens33.10&#x2F;&#x2F;PS：-p 保留源文件或目录的属性[root@docker01 network-scripts]# vim ifcfg-ens33.10BOOTPROTO&#x3D;noneIPADDR&#x3D;192.168.10.10PREFIX&#x3D;24GATEWAY&#x3D;192.168.10.1NAME&#x3D;ens33.10DEVICE&#x3D;ens33.10ONBOOT&#x3D;yesVLAN&#x3D;yes&#x2F;&#x2F;PS：这里注意，IP要和ens33网段做一个区分，保证网关和网段IP的一致性，设备名称和配置文件的一致性，并且打开VLAN支持模式 //创建第二个虚拟网卡配置文件 12345678910[root@docker01 network-scripts]# cp -p ifcfg-ens33.10 ifcfg-ens33.20[root@docker01 network-scripts]# vim ifcfg-ens33.20BOOTPROTO&#x3D;noneIPADDR&#x3D;192.168.20.20PREFIX&#x3D;24GATEWAY&#x3D;192.168.20.1NAME&#x3D;ens33.20DEVICE&#x3D;ens33.20ONBOOT&#x3D;yesVLAN&#x3D;yes 3）docker01上的操作，启用创建的虚拟网卡 12[root@docker01 network-scripts]# ifup ifcfg-ens33.10[root@docker01 network-scripts]# ifup ifcfg-ens33.20 4)基于虚拟网卡，创建macvlan网络 12[root@docker01 ~]# docker network create -d macvlan --subnet 172.16.10.0&#x2F;24 --gateway 172.16.10.1 -o parent&#x3D;ens33.10 mac_net10[root@docker01 ~]# docker network create -d macvlan --subnet 172.16.20.0&#x2F;24 --gateway 172.16.20.1 -o parent&#x3D;ens33.20 mac_net20 5)基于创建的虚拟网卡，创建macvlan网络 12[root@docker02 ~]# docker network create -d macvlan --subnet 172.16.10.0&#x2F;24 --gateway 172.16.10.1 -o parent&#x3D;ens33.10 mac_net10[root@docker02 ~]# docker network create -d macvlan --subnet 172.16.20.0&#x2F;24 --gateway 172.16.20.1 -o parent&#x3D;ens33.20 mac_net20 6)docker02上也创建虚拟网卡，并启用 1234567891011121314151617181920212223[root@docker01 ~]# scp &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-ens33.10 &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-ens33.20 root@192.168.1.50:&#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;[root@docker02 network-scripts]# vim ifcfg-ens33BOOTPROTO&#x3D;manual[root@docker02 network-scripts]# vim ifcfg-ens33.10BOOTPROTO&#x3D;noneIPADDR&#x3D;192.168.10.11PREFIX&#x3D;24GATEWAY&#x3D;192.168.10.1NAME&#x3D;ens33.10DEVICE&#x3D;ens33.10ONBOOT&#x3D;yesVLAN&#x3D;yes[root@docker02 network-scripts]# vim ifcfg-ens33.20BOOTPROTO&#x3D;noneIPADDR&#x3D;192.168.20.21PREFIX&#x3D;24GATEWAY&#x3D;192.168.20.1NAME&#x3D;ens33.20DEVICE&#x3D;ens33.20ONBOOT&#x3D;yesVLAN&#x3D;yes[root@docker02 network-scripts]# ifup ifcfg-ens33.10 [root@docker02 network-scripts]# ifup ifcfg-ens33.20 7)基于macvlan网络创建容器，并指定IP地址，不过这里要注意，运行的同期与网络对应的网段相符合，还需要注意IP地址的唯一性 123456&#x2F;&#x2F;docker01[root@docker01 ~]# docker run -itd --name bbox10 --network mac_net10 --ip 172.16.10.10 192.168.1.70:5000&#x2F;busybox:v1 [root@docker01 ~]# docker run -itd --name bbox20 --network mac_net20 --ip 172.16.20.20 192.168.1.70:5000&#x2F;busybox:v1&#x2F;&#x2F;docker02[root@docker02 ~]# docker run -itd --name bbox11 --network mac_net10 --ip 172.16.10.11 192.168.1.70:5000&#x2F;busybox:v1[root@docker02 ~]# docker run -itd --name bbox21 --network mac_net20 --ip 172.16.20.21 192.168.1.70:5000&#x2F;busybox:v1 8)将VMware虚拟机的网络改为桥接 9)进入容器测试通信 在docker01上进入容器bbox10和docker02上的bbox11进行通信 在docker01上进入容器bbox20和docker02上的bbox21进行通信 12345678910[root@docker01 ~]# docker exec -it bbox10 &#x2F;bin&#x2F;sh&#x2F; # ping 172.16.10.11PING 172.16.10.11 (172.16.10.11): 56 data bytes64 bytes from 172.16.10.11: seq&#x3D;0 ttl&#x3D;64 time&#x3D;0.668 ms64 bytes from 172.16.10.11: seq&#x3D;1 ttl&#x3D;64 time&#x3D;0.335 ms[root@docker01 ~]# docker exec -it bbox20 &#x2F;bin&#x2F;sh&#x2F; # ping 172.16.20.21PING 172.16.20.21 (172.16.20.21): 56 data bytes64 bytes from 172.16.20.21: seq&#x3D;0 ttl&#x3D;64 time&#x3D;0.584 ms64 bytes from 172.16.20.21: seq&#x3D;1 ttl&#x3D;64 time&#x3D;0.365 ms","categories":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/tags/Docker/"}]},{"title":"Docker网络","slug":"Docker网络","date":"2020-01-23T16:00:00.000Z","updated":"2020-01-25T13:07:32.256Z","comments":true,"path":"Docker网络.html","link":"","permalink":"https://pdxblog.top/Docker%E7%BD%91%E7%BB%9C.html","excerpt":"","text":"¶Docker网络： ¶原生网络 12345[root@localhost ~]# docker network lsNETWORK ID NAME DRIVER SCOPEfcc280741b01 bridge bridge local9c09e5a698dc host host local03411a6d716c none null local None：什么都没有的网络 12[root@localhost ~]# docker run -itd --name none --network none busybox:latest[root@localhost ~]# docker exec -it none /bin/sh PS：用到None网络的容器，会发现它只有一个LoopBack回环的网络，没有Mac地址、IP等信息，意味着它不能跟外界通信，是被隔离起来的网络 使用场景： 隔离意味着安全，所以，此网络可以运行一些关于安全方面的验证码、校验码等服务 Bridge：桥接网络 1234[root@localhost ~]# brctl showbridge name bridge id STP enabled interfacesdocker0 8000.02428e69e324 no virbr0 8000.525400547d41 yes virbr0-nic docker0：在我们安装docker这个服务的时候，默认就会生产一张docker0的网卡，一般默认IP为172.17.0.1/16 12[root@localhost ~]# docker run -itd --name test1 busybox:latest [root@localhost ~]# docker exec -it test1 /bin/sh 容器默认使用的网络是docker0网络，docker0此时相当于一个路由器，基于此网络的容器，网段都是和docker0一致的 ¶自定义网络 自带了一个ContainerDNSserver功能（域名解析） bridge //创建一个bridge网络： 1[root@localhost ~]# docker network create -d bridge my_net //创建两个容器，应用自定义网络（my_net）： 12[root@localhost ~]# docker run -itd --name test3 --network my_net busybox:latest[root@localhost ~]# docker run -itd --name test4 --network my_net busybox:latest PS：自定义网络优点，它可以通过容器的名称通信 12[root@localhost ~]# docker exec -it test3 &#x2F;bin&#x2F;sh&#x2F; # ping test4 //创建一个自定义网络，并且指定网关和网段 1[root@localhost ~]# docker network create -d bridge --subnet 172.20.16.0&#x2F;24 --gateway 172.20.16.1 my_net2 //创建两个容器，应用自定义网络(my_net2)，并指定IP 12[root@localhost ~]# docker run -itd --name test5 --network my_net2 --ip 172.20.16.6 busybox:latest[root@localhost ~]# docker run -itd --name test6 --network my_net2 --ip 172.20.16.8 busybox:latest PS：如果想要给容器指定IP地址，那么自定义网络的时候，必须指定网关gateway和subnet网段选项 //实现不同网段之间的通信，在容器里再添加一块网卡： 1[root@localhost ~]# docker network connect my_net2 test4 ¶让外网能够访问容器的端口映射方法： 1）手动指定端口映射关系： 1[root@localhost ~]# docker run -itd --name web1 -p 90:80 nginx:latest 2）从宿主机随机映射端口到容器： 1[root@localhost ~]# docker run -itd --name web2 -p 80 nginx:latest 3)从宿主机随机映射端口到容器，容器内所有暴露的端口，都会一一映射 1[root@localhost ~]# docker run -itd --name web4 -P nginx:latest ¶join容器：container（共享网络协议栈） 容器和容器之间 12[root@localhost ~]# docker run -itd --name web5 busybox:latest[root@localhost ~]# docker run -itd --name web6 --network container:web5 busybox:latest 123[root@localhost ~]# docker exec -it web6 &#x2F;bin&#x2F;sh&#x2F; # echo 123456 &gt; &#x2F;tmp&#x2F;index.html&#x2F; # httpd -h &#x2F;tmp&#x2F; 123[root@localhost ~]# docker exec -it web5 &#x2F;bin&#x2F;sh&#x2F; # wget -O - -q 127.0.0.1123456 //这时会发现，两个容器的IP地址一样 PS：这种方法的使用场景： 由于这种网络的特殊特性，一般在运行同一个服务，并且合格服务需要做监控，已经日志收集、或者网络监控的时候，可以选择这种网络 docker的跨主机网络解决方案 overlay（覆盖）的解决方案： 实验环境： docker01：192.168.1.70 docker02：192.168.1.60 docker03：192.168.1.50 暂时不考录防火墙和selinux安全问题 将3台dockerhost防火墙和selinux全部关闭，并分别更改主机名称 12345[root@localhost ~]# hostnamectl set-hostname docker01[root@localhost ~]# su -[root@docker01 ~]# systemctl stop firewalld[root@docker01 ~]# setenforce 0[root@docker01 ~]# systemctl disable firewalld 在docker01上操作： //运行consul服务：（数据中心–分布式的） 123[root@docker01 ~]# docker load &lt; myprogrium-consul.tar[root@docker01 ~]# docker run -d -p 8500:8500 -h consul --name consul \\ &gt; --restart always progrium&#x2F;consul -server -bootstrap PS:容器产生之后我们可以通过浏览器访问consul服务，验证consul服务是否正常，访问dockerHost加映射端口 修改docker02和docker03的docker配置文件： //将IP和端口的映射关系，写入consul 123[root@docker02 ~]# vim &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;docker.service修改：ExecStart&#x3D;&#x2F;usr&#x2F;bin&#x2F;dockerd -H unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;docker.sock -H tcp:&#x2F;&#x2F;0.0.0.0:2376 --cluster-store&#x3D;consul:&#x2F;&#x2F;192.168.1.70:8500 --cluster-advertise&#x3D;ens33:2376 PS:返回浏览器consul服务界面，找到KEY/VALUE----&gt;Docker----&gt;NODES，会看到刚刚加入的docker02和docker03的信息 在docker02上创建一个自定义网络： 1234[root@docker02 ~]# docker network create -d overlay ov_net1[root@docker02 ~]# docker network lsNETWORK ID NAME DRIVER SCOPEfe92a0eff6a4 ov_net1 overlay global 在docker02上创建网络，我们可以看到它的SCOPE定义的时global（全局），意味着加入到consul这个服务的docker服务，都可以看到我们自定义的网络 同理如果是用此网络创建的容器，会有两张网卡，默认这张网卡是10.0.0.0网段，如果想要docker01也可以看到这个网络，那么也只需在docker01的docker配置文件添加相应内容即可 同理，因为是自定义网络，符合自定义网络的特性，可以直接通过docker容器的名称互相通信，当然也可以在自定义网络的时候，指定它的网段，那么使用此网络的容器也可以指定IP地址","categories":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/tags/Docker/"}]},{"title":"Kubernetes集群部署","slug":"Kubernetes集群部署","date":"2020-01-23T16:00:00.000Z","updated":"2020-02-03T02:44:38.847Z","comments":true,"path":"Kubernetes集群部署.html","link":"","permalink":"https://pdxblog.top/Kubernetes%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2.html","excerpt":"","text":"生产级别的容器编排系统 Kubernetes 是用于自动部署，扩展和管理容器化应用程序的开源系统 k8s 最基本的硬件要求 CPU:双核 Mem：2G 3台dockerhost时间必须同步 Kubeadm工具自动部署k8s集群 //给3台docker命名，禁用swap交换分区 12345678910111213[root@localhost ~]# hostnamectl set-hostname master[root@localhost ~]# su -[root@localhost ~]# hostnamectl set-hostname node01[root@localhost ~]# su -[root@localhost ~]# hostnamectl set-hostname node02[root@localhost ~]# su -[root@master ~]# swapoff -a &#x2F;&#x2F;临时禁用[root@master ~]# free total used free shared buff&#x2F;cache availableMem: 1867292 335448 908540 9256 623304 1290100Swap: 0 0 0&#x2F;&#x2F;永久禁用[root@master ~]# vim &#x2F;etc&#x2F;fstab &#x2F;&#x2F;注释掉swap那一行 //禁用selinux，防火墙，并关闭开机自启（三台都需要） 12345[root@master ~]# vim &#x2F;etc&#x2F;selinux&#x2F;configSELINUX&#x3D;disabled[root@master ~]# setenforce 0[root@master ~]# systemctl stop firewalld[root@master ~]# systemctl disable firewalld //编写hosts文件，设置域名解析 12345678[root@master ~]# vim &#x2F;etc&#x2F;hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.1.70 master192.168.1.50 node01192.168.1.40 node02[root@master ~]# scp &#x2F;etc&#x2F;hosts root@192.168.1.50:&#x2F;etc[root@master ~]# scp &#x2F;etc&#x2F;hosts root@192.168.1.40:&#x2F;etc //设置免密登录 123[root@master ~]# ssh-keygen -t rsa[root@master ~]# ssh-copy-id node01[root@master ~]# ssh-copy-id node02 //打开iptables的桥接功能，开启路由转发 1234567891011121314151617181920212223[root@master ~]# vim &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.confnet.bridge.bridge-nf-call-iptables &#x3D; 1net.bridge.bridge-nf-call-ip6tables &#x3D; 1[root@master ~]# echo net.ipv4.ip_forward &#x3D; 1 &gt;&gt; &#x2F;etc&#x2F;sysctl.conf [root@master ~]# sysctl -pnet.ipv4.ip_forward &#x3D; 1[root@master ~]# sysctl -p &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf &#x2F;&#x2F;如果这条命令不成功则需要添加一个模块[root@master ~]# modprobe br_netfilternet.bridge.bridge-nf-call-iptables &#x3D; 1net.bridge.bridge-nf-call-ip6tables &#x3D; 1[root@master ~]# scp &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf node01:&#x2F;etc&#x2F;sysctl.d [root@master ~]# scp &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf node02:&#x2F;etc&#x2F;sysctl.d [root@master ~]# scp &#x2F;etc&#x2F;sysctl.conf node02:&#x2F;etc&#x2F; [root@master ~]# scp &#x2F;etc&#x2F;sysctl.conf node01:&#x2F;etc&#x2F;[root@node01 ~]# sysctl -pnet.ipv4.ip_forward &#x3D; 1[root@node01 ~]# sysctl -p &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf net.bridge.bridge-nf-call-iptables &#x3D; 1net.bridge.bridge-nf-call-ip6tables &#x3D; 1[root@node02 ~]# sysctl -pnet.ipv4.ip_forward &#x3D; 1[root@node02 ~]# sysctl -p &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf net.bridge.bridge-nf-call-iptables &#x3D; 1net.bridge.bridge-nf-call-ip6tables &#x3D; 1 //获取yum源 123456789101112[root@master ~]# cat &lt;&lt;EOF &gt; &#x2F;etc&#x2F;yum.repos.d&#x2F;kubernetes.repo&gt; [kubernetes]&gt; name&#x3D;Kubernetes&gt; baseurl&#x3D;https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;yum&#x2F;repos&#x2F;kubernetes-el7-x86_64&#x2F;&gt; enabled&#x3D;1&gt; gpgcheck&#x3D;1&gt; repo_gpgcheck&#x3D;1&gt; gpgkey&#x3D;https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;yum&#x2F;doc&#x2F;yum-key.gpg https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;yum&#x2F;doc&#x2F;rpm-package-key.gpg&gt; EOF[root@master ~]# yum repolist[root@master ~]# yum makecache&#x2F;&#x2F;三台都需要这个yum源（node01，node02步骤省略） //安装以下三个组件 kubectl：k8s客户端 kubeadm：自动化快速部署k8s集群工具 kubelet：客户端代理 1234[root@master ~]# yum -y install kubeadm-1.15.0-0 kubelet-1.15.0-0 kubectl-1.15.0-0&#x2F;&#x2F;node01、node02不需要安装kubectl[root@node01 ~]# yum -y install kubeadm-1.15.0-0 kubelet-1.15.0-0[root@node02 ~]# yum -y install kubeadm-1.15.0-0 kubelet-1.15.0-0 //加入开机自启（三台全部加入开机自启） 1[root@master ~]# systemctl enable kubelet //导入镜像 1234567891011121314[root@master ~]# mkdir images[root@master ~]# cd images&#x2F;[root@master images]# lscoredns-1-3-1.tar kube-apiserver-1-15.tar kube-proxy-1-15.tar myflannel-11-0.taretcd-3-3-10.tar kube-controller-1-15.tar kube-scheduler-1-15.tar pause-3-1.tar[root@master ~]# cat &gt; images.sh &lt;&lt;EOF&gt; #!&#x2F;bin&#x2F;bash&gt; for i in &#x2F;root&#x2F;images&#x2F;*&gt; do&gt; docker load &lt; $i&gt; done&gt; EOF[root@master ~]# chmod +x images.sh[root@master ~]# sh images.sh //初始化k8s集群 1234[root@master ~]# kubeadm init --kubernetes-version&#x3D;v1.15.0 \\&gt; --pod-network-cidr&#x3D;10.244.0.0&#x2F;16 \\&gt; --service-cidr&#x3D;10.96.0.0&#x2F;12 \\&gt; --ignore-preflight-errors&#x3D;Swap //如果初始化失败，需要重置k8s集群 1[root@master ~]# kubeadm reset //初始化完成后的操作 123[root@master ~]# mkdir -p $HOME&#x2F;.kube[root@master ~]# cp -i &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf $HOME&#x2F;.kube&#x2F;config[root@master ~]# chown $(id -u):$(id -g) $HOME&#x2F;.kube&#x2F;config //查看节点信息情况 123[root@master ~]# kubectl get nodeNAME STATUS ROLES AGE VERSIONmaster NotReady master 10m v1.15.0 //部署flannel网络，（k8s版本必须是1.7版本以上） 1[root@master ~]# kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;coreos&#x2F;flannel&#x2F;master&#x2F;Documentation&#x2F;kube-flannel.yml PS：这里执行不成功的话可能是网络的问题 //在node01、node02上提前导入镜像（不然在加入集群的时候，它会自动下载镜像） 12345[root@node02 ~]# mkdir images[root@node02 ~]# cd images&#x2F;[root@node02 images]# lskube-proxy-1-15.tar myflannel-11-0.tar pause-3-1.tardocker load &lt; kube-proxy-1-15.tar &amp;&amp; docker load &lt; myflannel-11-0.tar &amp;&amp; docker load &lt; pause-3-1.tar //node01、node02加入集群 1234567kubeadm join 192.168.1.70:6443 --token x85ks8.4x5qrhw87zct1vti \\ --discovery-token-ca-cert-hash sha256:227c69c29f16521a7dccb52104710b8cdd449aa0f7cb787affb62514fc8cc9eb[root@master ~]# kubectl get nodeNAME STATUS ROLES AGE VERSIONmaster Ready master 25m v1.15.0node01 Ready &lt;none&gt; 82s v1.15.0node02 Ready &lt;none&gt; 76s v1.15.0 //确保是running的状态 1234567891011121314[root@master ~]# kubectl get pod --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEkube-system coredns-5c98db65d4-fr894 1&#x2F;1 Running 0 28mkube-system coredns-5c98db65d4-qkqh5 1&#x2F;1 Running 0 28mkube-system etcd-master 1&#x2F;1 Running 0 27mkube-system kube-apiserver-master 1&#x2F;1 Running 0 27mkube-system kube-controller-manager-master 1&#x2F;1 Running 0 27mkube-system kube-flannel-ds-amd64-rjnns 1&#x2F;1 Running 0 4m44skube-system kube-flannel-ds-amd64-tpkh5 1&#x2F;1 Running 0 4m50skube-system kube-flannel-ds-amd64-x425t 1&#x2F;1 Running 0 13mkube-system kube-proxy-4qsj2 1&#x2F;1 Running 0 4m44skube-system kube-proxy-gngnx 1&#x2F;1 Running 0 28mkube-system kube-proxy-shkw9 1&#x2F;1 Running 0 4m50skube-system kube-scheduler-master 1&#x2F;1 Running 0 27m //设置tab键的距离 123[root@master ~]# vim .vimrcset tabstop&#x3D;2[root@master ~]# source .vimrc //将kubectl命令加入tab自动补全 123[root@master ~]# source &#x2F;usr&#x2F;share&#x2F;bash-completion&#x2F;bash_completion [root@master ~]# source &lt;(kubectl completion bash)[root@master ~]# echo &quot; source &lt;(kubectl completion bash)&quot; &gt;&gt; ~&#x2F;.bashrc","categories":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]},{"title":"Pod资源对象+健康检查","slug":"Pod资源对象+健康检查","date":"2020-01-23T16:00:00.000Z","updated":"2020-03-09T01:24:28.655Z","comments":true,"path":"Pod资源对象+健康检查.html","link":"","permalink":"https://pdxblog.top/Pod%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1+%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5.html","excerpt":"","text":"¶Deployment、Service、Pod是k8s最核心的3个资源对象 Deployment： 最常见的无状态的控制器，支持应用的扩容缩容、滚动更新等操作 Service： 为弹性变动且存在生命周期的Pod对象提供了一个固定的访问接口，用户服务发现和服务访问 Pod： 是运行容器以及调度的最小单位，同一个Pod可以同时运行多个容器，这些容器共享NET、UTS、IPC，除此之外还有USER、PID、MOUNT ReplicationController：（rc） 用于确保每个Pod副本在任意时刻都能满足目标数量，简单点来说，它用于保证每个容器或容器组总是运行并且可以访问：老一代无状态的Pod控制器 ReplicaSet：（rs） 新一代无状态的Pod应用控制器，它与rc的不同之处在于支持的标签选择器不同，rc只支持等值选择器，rs还额外支持基于集合的选择器 StatefulSet： 用于管理有状态的持久化应用，如database服务程序，它与Deployment不同之处在于，它会为每一个Pod创建一个独有的持久性标识符，并确保每个Pod之间的顺序性 DamonSet： 确保每一个节点都运行了某个Pod的一个副本，新增的节点一样会被添加此类Pod，在节点移除时Pod会被收回 Job： 用于管理运行完成后即可终止的银应用，例如批量处理作业任务 volume: PV PVC ConfigMap: Secret： Role： ClusterRole： ClusterRoleBinding： Service account： Helm： ¶Namespace：名称空间 默认的名称空间：Default //查看名称空间 123456[root@master ~]# kubectl get nsNAME STATUS AGEdefault Active 6d22hkube-node-lease Active 6d22hkube-public Active 6d22hkube-system Active 6d22h //查看名称空间详细信息 1[root@master ~]# kubectl describe ns default //创建名称空间 1[root@master ~]# kubectl create ns bdqn //使用yaml创建名称空间 123456[root@master ~]# vim test-ns.yamlapiVersion: v1kind: Namespacemetadata: name: test[root@master ~]# kubectl apply -f test-ns.yaml PS： namespace资源对象仅用于资源对象的隔离，并不能隔绝不同名称空间的Pod之间的通信，那是网络策略资源的功能 //删除名称空间： 12[root@master ~]# kubectl delete ns test[root@master ~]# kubectl delete -f test-ns.yaml //查看指定名称空间的资源可以使用–namespace或者-n选项 12[root@master ~]# kubectl get pod --namespace&#x3D;bdqn [root@master ~]# kubectl get pod -n bdqn ¶Pod //通过yaml文件手动创建pod 12345678910111213141516[root@master ~]# vim pod.yamlkind: PodapiVersion: v1metadata: name: test-pod namespace: bdqn &#x2F;&#x2F;指定名称空间spec: containers: - name: test-app image: httpd:v1[root@master ~]# kubectl apply -f pod.yaml[root@master ~]# kubectl get pod -n bdqnNAME READY STATUS RESTARTS AGEtest-pod 1&#x2F;1 Running 0 19s&#x2F;&#x2F;删除[root@master ~]# kubectl delete pod -n bdqn test-pod ¶Pod中镜像获取策略： Always： 镜像标签为“lastest”或镜像不存在时，总是从指定的仓库中获取镜像 ifNotPresent： 仅当本地镜像不存在时从目标仓库中下载 Never： 禁止从仓库下载镜像，即只是用本地镜像 123456789101112131415kind: PodapiVersion: v1metadata: name: test-pod namespace: bdqn labels: app: test-webspec: containers: - name: test-app image: httpd:v1 imagePullPolicy: IfNotPresent &#x2F;&#x2F;指定镜像获取策略 ports: - protocol: TCP containerPort: 90 &#x2F;&#x2F;手动创建的Pod，指定容器暴露的端口也不会生效 PS： 对于标签为“latest”或者这标签不存在，其默认镜像下载策略为“Always”,而对于其他标签的镜像，默认策略为“ifNotPresent” ¶容器的重启策略 Always： 但凡Pod对象终止就将其重启，此为默认设定 OnFailure： 仅在Pod对象出现错误时才将其重启 Never： 从不重启 PS：对于标签为“latest”或者不存在的时候，其默认镜像下载策略为“Always”，而对于其他标签的镜像，默认策略为“IfNotPresent” ¶Pod的默认健康检查 12345678910111213141516171819202122[root@master ~]# vim healcheck.yamlapiVersion: v1kind: Podmetadata: labels: test: healcheck name: healcheckspec: restartPolicy: OnFailure containers: - name: healthcheck image: busybox args: &#x2F;&#x2F;由镜像运行成容器的时候去做的事情 - &#x2F;bin&#x2F;sh - -c - sleep 20; exit 1[root@master ~]# vim healcheck.yaml[root@master ~]# kubectl get pod -w &#x2F;&#x2F;实时查看它的状态[root@master ~]# kubectl get podNAME READY STATUS RESTARTS AGEhealthcheck 0&#x2F;1 Error 5 8m44s&#x2F;&#x2F;可以看到每过20s就会重启一次 ¶LivenessProbe（活跃度探测） 1234567891011121314151617181920212223[root@master ~]# vim liveness.yamlkind: PodapiVersion: v1metadata: name: liveness labels: test: livenessspec: restartPolicy: OnFailure containers: - name: liveness image: busybox args: &#x2F;&#x2F;由镜像运行成容器的时候去做的事情 - &#x2F;bin&#x2F;sh - -c - touch &#x2F;tmp&#x2F;test; sleep 60; rm -rf &#x2F;tmp&#x2F;test; sleep 300 livenessProbe: &#x2F;&#x2F;活跃度探测 exec: command: - cat - &#x2F;tmp&#x2F;test initialDelaySeconds: 10 &#x2F;&#x2F;pod运行10秒后开始探测 periodSeconds: 5 &#x2F;&#x2F;每5秒探测一次 PS: Liveness活跃度探测，根据某个文件是否存在，来确认某个服务是否正常运行，如果存在则正常，否则，它会根据你设置的Pod的重启策略操作Pod ¶Readiness（敏捷探测、就绪性探测） 1234567891011121314151617181920212223[root@master ~]# vim readiness.yaml kind: PodapiVersion: v1metadata: name: readiness labels: test: readinessspec: restartPolicy: OnFailure containers: - name: readiness image: busybox args: - &#x2F;bin&#x2F;sh - -c - touch &#x2F;tmp&#x2F;test; sleep 60; rm -rf &#x2F;tmp&#x2F;test; sleep 300 readinessProbe: exec: command: - cat - &#x2F;tmp&#x2F;test initialDelaySeconds: 10 periodSeconds: 5 PS：总结liveness和readiness探测 1）leveness和readiness是两种健康检查机制，如果不特意配置，k8s两种探测采取相同的默认行为，即通过判断容器启动进程的返回是否为零，来判断探测是否成功 2）两种探测配置方法完全一样，不同之处在于探测失败后的行为： liveness探测是根据Pod重启策略操作容器，大多数是重启容器 readinesss则是将容器设置为不可用，不接收Service转发的请求 3）两种探测方法可以独立存在，也可以同时使用，用liveness判断容器是否需要实现自愈；用readiness判断容器是否已经准备好对外提供服务 ¶监控检测应用 在scale（扩容、缩容）中的应用 123456789101112131415161718192021222324252627282930313233343536373839404142[root@master ~]# vim hcscal.yamlkind: DeploymentapiVersion: extensions&#x2F;v1beta1metadata: name: webspec: replicas: 3 template: metadata: labels: run: web spec: containers: - name: web image: httpd ports: - containerPort: 80 readinessProbe: httpGet: scheme: HTTP path: &#x2F;healthy port: 80 initialDelaySeconds: 10 periodSeconds: 5---kind: ServiceapiVersion: v1metadata: name: web-svcspec: type: NodePort selector: run: web ports: - protocol: TCP port: 90 targetPort: 80 nodePort: 30321[root@master ~]# kubectl exec web-69d659f974-ktqbz touch &#x2F;usr&#x2F;local&#x2F;apache2&#x2F;htdocs&#x2F;healthy[root@master ~]# kubectl describe svcEndpoints: 10.244.1.4:80 ¶在更新过程中的使用 1234567891011121314151617181920212223242526[root@master ~]# vim app.v1.yamlkind: DeploymentapiVersion: extensions&#x2F;v1beta1metadata: name: appspec: replicas: 10 template: metadata: labels: run: app spec: containers: - name: app image: busybox args: - &#x2F;bin&#x2F;sh - -c - sleep 10; touch &#x2F;tmp&#x2F;healthy; sleep 3000 readinessProbe: exec: command: - cat - &#x2F;tmp&#x2F;healthy initialDelaySeconds: 10 periodSeconds: 5 //第一次升级 12345678[root@master ~]# kubectl apply -f app.v1.yaml --record[root@master ~]# cp app.v1.yaml app.v2.yaml [root@master ~]# vim app.v2.yaml&#x2F;&#x2F;修改 args: - &#x2F;bin&#x2F;sh - -c - sleep 3000 //第二次升级 123456789101112131415161718192021[root@master ~]# cp app.v1.yaml app.v3.yaml [root@master ~]# vim app.v3.yaml&#x2F;&#x2F;删除探测机制kind: DeploymentapiVersion: extensions&#x2F;v1beta1metadata: name: appspec: replicas: 10 template: metadata: labels: run: app spec: containers: - name: app image: busybox args: - &#x2F;bin&#x2F;sh - -c - sleep 3000 maxSurge：此参数控制滚动更新过程中，副本总数超过预期数的值，可以是整数，也可以是百分比，默认为1 maxUnavilable：不可用Pod的值，默认为1","categories":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]},{"title":"Prometheus（普罗米修斯）","slug":"Prometheus（普罗米修斯）","date":"2020-01-23T16:00:00.000Z","updated":"2020-01-25T13:07:32.287Z","comments":true,"path":"Prometheus（普罗米修斯）.html","link":"","permalink":"https://pdxblog.top/Prometheus%EF%BC%88%E6%99%AE%E7%BD%97%E7%B1%B3%E4%BF%AE%E6%96%AF%EF%BC%89.html","excerpt":"","text":"¶Prometheus（普罗米修斯） 是一个系统和服务的监控平台。它可以自定义时间间隔从已配置的目标收集指标，评估规则表达式，显示结果，并在发现某些情况时触发警报 与其他监视系统相比，Prometheus的主要区别特征是： 一个多维数据模型（时间序列由指标名称定义和设置键/值尺寸） 一个灵活的查询语言来利用这一维度 不依赖于分布式存储；单服务器节点是自治的 时间序列收集通过HTTP 上的拉模型进行 通过中间网关支持推送时间序列 通过服务发现或静态配置发现目标 多种图形和仪表板支持模式 支持分层和水平联合 实验环境： docker01 192.168.1.70 NodeEXporter cAdvisor+Prometheus server+gragana docker02 192.168.1.60 NodeEXporter cAdvisor docker03 192.168.1.50 NodeEXporter cAdvisor 123456[root@localhost ~]# hostnamectl set-hostname docker1[root@localhost ~]# su -[root@localhost ~]# hostnamectl set-hostname docker2[root@localhost ~]# su -[root@localhost ~]# hostnamectl set-hostname docker3[root@localhost ~]# su - 全部关闭防火墙，禁用selinux 123[root@docker01 ~]# systemctl stop firewalld[root@docker01 ~]# systemctl disable firewalld[root@docker01 ~]# setenforce 0 需要部署的组件 Prometheus server（9090）：普罗米修斯的主机服务器 NodeEXporter（9100）：负责收集host硬件信息和操作系统信息 //谷歌开发的监控软件。收集数据，不太直观。有历史保留，方便后期做优化 cAdvisor（8080）：负责收集host上运行的容器信息 Grafana（3000）：负责展示普罗米修斯监控界面 //类似于kibana的图形界面，提供可视化web页面 1）三个节点，全部部署node-exporter和cadvisor //分别在三个节点上导入镜像 1[root@docker01 ~]# docker load &lt; node-exporter.tar &amp;&amp; docker load &lt; mycadvisor.tar //部署node-exporter，收集硬件和系统信息（三台都需要部署） 12345[root@docker01 ~]# docker run -d -p 9100:9100 -v &#x2F;proc:&#x2F;host&#x2F;proc \\&gt; -v &#x2F;sys:&#x2F;host&#x2F;sys -v &#x2F;:&#x2F;rootfs --net&#x3D;host \\&gt; prom&#x2F;node-exporter --path.procfs &#x2F;host&#x2F;proc \\&gt; --path.sysfs &#x2F;host&#x2F;sys \\&gt; --collector.filesystem.ignored-mount-points &quot;^&#x2F;(sys|proc|dev|host|etc)($|&#x2F;)&quot; PS：注意这里使用了–net=host，这样prometheus server可以直接与node-exporter通信 验证，打开浏览器验证结果（192.168.1.70:9100） //部署安装cAdvisor，收集节点容器信息（三台都需要部署） 1234[root@docker01 ~]# docker run -v &#x2F;:&#x2F;rootfs:ro -v &#x2F;var&#x2F;run:&#x2F;var&#x2F;run&#x2F;:rw \\&gt; -v &#x2F;sys:&#x2F;sys:ro -v &#x2F;var&#x2F;lib&#x2F;docker:&#x2F;var&#x2F;lib&#x2F;docker:ro \\&gt; -p 8080:8080 --detach&#x3D;true --name&#x3D;cadvisor \\&gt; --net&#x3D;host google&#x2F;cadvisor 打开浏览器验证（192.168.1.70:8080） 2）在docker01上部署prometheus server服务 在部署prometheus之前，我们需要对它的配置文件进行修改，所以我们先运行一个容器，将其配置文件拷贝出来 123456789[root@docker01 ~]# docker load &lt; prometheus.tar[root@docker01 ~]# docker run -d -p 9090:9090 --name prometheus --net&#x3D;host prom&#x2F;prometheus[root@docker01 ~]# docker exec -it prometheus &#x2F;bin&#x2F;sh&#x2F;prometheus $ cd &#x2F;etc&#x2F;prometheus&#x2F;&#x2F;etc&#x2F;prometheus $ lsconsole_libraries consoles prometheus.yml[root@docker01 ~]# docker cp prometheus:&#x2F;etc&#x2F;prometheus&#x2F;prometheus.yml .&#x2F;[root@docker01 ~]# vim prometheus.yml- targets: [&#39;localhost:9090&#39;,&#39;localhost:8080&#39;,&#39;localhost:9100&#39;,&#39;192.168.1.60:8080&#39;,&#39;192.168.1.60:9100&#39;,&#39;192.168.1.50:8080&#39;,&#39;192.168.1.50:9100&#39;] PS：这里制定了prometheus的监控项，包括它也会监控自己收集到的数据 1[root@docker01 ~]# docker rm -f prometheus //重新运行容器： 1[root@docker01 ~]# docker run -d -p 9090:9090 --name prometheus --net&#x3D;host -v &#x2F;root&#x2F;prometheus.yml:&#x2F;etc&#x2F;prometheus&#x2F;prometheus.yml prom&#x2F;prometheus //浏览器访问：192.168.1.70:9090 PS:这里能够看到我们各个监控项 3）在docker01上部署grafana服务，用来展示prometheus收集到的数据 1234[root@docker01 ~]# docker load &lt; grafana.tar[root@docker01 ~]# mkdir grafana-storage[root@docker01 ~]# chmod 777 -R grafana-storage&#x2F;[root@docker01 ~]# docker run -d -p 3000:3000 --name grafana -v &#x2F;root&#x2F;grafana-storage:&#x2F;var&#x2F;lib&#x2F;grafana -e &quot;GF_SECURITY_ADMIN_PASSWORD&#x3D;123.com&quot; grafana&#x2F;grafana 浏览器访问：192.168.1.70:3000 用户名：admin 密码：123.com //创建数据源 PS：看到这这提示，说明prometheus和grafana服务是正常连接的 此时，虽然grafana收集到了数据，但怎么显示它，仍然是个问题，grafana支持自定义显示信息，不过要自定义起来非常麻烦，不过好在，grafana官方为我们提供了一些模板，来供我们使用 Grafana官网：https://grafana.com //可以根据自己的喜好选择模板 选中一款模板后，然后，我们又两种方式可以套用这个模板 第一种方式：通过JSON文件使用模板 下载完成之后，回到grangana控制台 第二种方式： 可以直接通过模板的ID号 ¶配置AlertManager AlertManager：用来接收prometheus发送的报警信息，并且执行设置好的报警方式、报警内容 AlertManager.yml配置文件： global：全部配置，包括报警解决后的超时时间、SMTP相关配置、各种渠道通知的API地址等新消息 route：用来设置报警的分发策略 receivers：配置告警消息接收者信息 inhibit_rules：抑制规则配置，当存在于另一组匹配的报警时，抑制规则将禁用一组匹配的警报 //运行一个容器获取配置文件并进行配置 12345678910111213141516171819202122232425262728[root@docker01 ~]# docker run -d --name alertmanager -p 9093：993 prom&#x2F;alertmanager:latest[root@docker01 ~]# docker cp alertmanager:&#x2F;etc&#x2F;alertmanager&#x2F;alertmanager .&#x2F;[root@docker01 ~]# cat alertmanager.yml global: resolve_timeout: 5m smtp_from: &#39;2960824193@qq.com&#39; smtp_smarthost: &#39;smtp.qq.com:465&#39; smtp_auth_username: &#39;2960824193@qq.com&#39; smtp_auth_password: &#39;aseydtzejqfqdhai&#39; smtp_require_tls: false smtp_hello: &#39;qq.com&#39;route: group_by: [&#39;alertname&#39;] group_wait: 5s group_interval: 5s repeat_interval: 5m receiver: &#39;email&#39;receivers:- name: &#39;email&#39; email_configs: - to: &#39;2960824193@qq.com&#39; send_resolved: trueinhibit_rules: - source_match: severity: &#39;critical&#39; target_match: severity: &#39;warning&#39; equal: [&#39;alertname&#39;, &#39;dev&#39;, &#39;instance&#39;] //删除容器并重新运行 12[root@docker01 ~]# docker rm -f alertmanager[root@docker01 ~]# docker run -d --name alertmanager -p 9093:9093 -v &#x2F;root&#x2F;alertmanager.yml:&#x2F;etc&#x2F;alertmanager&#x2F;alertmanager.yml prom&#x2F;alertmanager:latest //浏览器访问：192.168.1.70:9093 Prometheus配置alertmanager报警规则 1234567891011121314151617181920212223[root@docker01 ~]# mkdir -p prometheus&#x2F;rules[root@docker01 ~]# cd prometheus&#x2F;rules&#x2F;[root@docker01 rules]# lsnode-up.rules[root@docker01 rules]# cat node-up.rules groups:- name: node-up rules: - alert: node-up expr: up&#123;job&#x3D;&quot;prometheus&quot;&#125; &#x3D;&#x3D; 0 &#x2F;&#x2F;这个job要和prometheus里的job名称一样 for: 15s labels: severity: 1 team: node annotations: summary: &quot;&#123;&#123; $labels.instance &#125;&#125; 已停止运行超过 15s！&quot;-----------------------------------------------------------------------------------------------&#x2F;etc&#x2F;prometheus $ cat prometheus.yml.......- job_name: &#39;prometheus&#39;&#x2F;&#x2F;监控的内容是： - targets: [&#39;localhost:9090&#39;,&#39;localhost:8080&#39;,&#39;localhost:9100&#39;,&#39;192.168.1.60:9100&#39;,&#39;192.168.1.60:8080&#39;,&#39;192.168.1.50:9100&#39;,&#39;192.168.1.50:8080&#39;]....... //编辑prometheus的配置文件 12345678910[root@docker01 ~]# vim prometheus.yml# Alertmanager configurationalerting: alertmanagers: - static_configs: - targets: - 192.168.1.70:9093 &#x2F;&#x2F;目标为alertmanager容器rule_files: - &quot;&#x2F;usr&#x2F;local&#x2F;prometheus&#x2F;rules&#x2F;*.rules&quot; &#x2F;&#x2F;路径是容器内的路径 //删除prometheus容器，重新挂载配置文件 12[root@docker01 ~]# docker rm -f prometheus[root@docker01 ~]# docker run -d -p 9090:9090 --name prometheus --net&#x3D;host -v &#x2F;root&#x2F;prometheus.yml:&#x2F;etc&#x2F;prometheus&#x2F;prometheus.yml -v &#x2F;root&#x2F;prometheus&#x2F;rules&#x2F;node-up.rules:&#x2F;usr&#x2F;local&#x2F;prometheus&#x2F;rules&#x2F;node-up.rules prom&#x2F;prometheus //浏览器访问：192.168.1.70:9090 //随便关闭一个容器进行测试 AlertManager配置自定义邮件模板 1234567891011121314151617[root@docker01 ~]# mkdir prometheus&#x2F;alertmanager-tmpl[root@docker01 ~]# cd prometheus&#x2F;alertmanager-tmpl&#x2F;[root@docker01 alertmanager.tmpl]# cat email.tmpl &#123;&#123; define &quot;email.from&quot; &#125;&#125;2960824193@qq.com&#123;&#123; end &#125;&#125; &#x2F;&#x2F;哪个邮箱来发送信息&#123;&#123; define &quot;email.to&quot; &#125;&#125;2960824193@qq.com&#123;&#123; end &#125;&#125; &#x2F;&#x2F;发送到哪个邮箱&#123;&#123; define &quot;email.to.html&quot; &#125;&#125;&#123;&#123; range .Alerts &#125;&#125;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;start&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&lt;br&gt;告警程序: prometheus_alert&lt;br&gt;告警级别: &#123;&#123; .Labels.severity &#125;&#125; 级&lt;br&gt;告警类型: &#123;&#123; .Labels.alertname &#125;&#125;&lt;br&gt;故障主机: &#123;&#123; .Labels.instance &#125;&#125;&lt;br&gt;告警主题: &#123;&#123; .Annotations.summary &#125;&#125;&lt;br&gt;触发时间: &#123;&#123; .StartsAt.Format &quot;2019-08-04 16:58:15&quot; &#125;&#125; &lt;br&gt;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;end&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&lt;br&gt;&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125; //修改altermanager的配置文件 1234567[root@docker01 ~]# vim alertmanager.yml&#x2F;&#x2F;在第九行添加templates: - &#39;&#x2F;etc&#x2F;alertmanager-tmpl&#x2F;*.tmpl&#39; &#x2F;&#x2F;容器内的路径&#x2F;&#x2F;修改第20行，和第21行： - to: &#39;&#123;&#123; template &quot;email.to&quot; &#125;&#125;&#39; &#x2F;&#x2F;必须和email.tmpl中的&#123;&#123; define “email.to”&#125;&#125; 2960824193@qq.com&#123;&#123;end&#125;&#125;对应 html: &#39;&#123;&#123; template &quot;email.to.html&quot; . &#125;&#125;&#39; &#x2F;&#x2F;必须和email.tml中的&#123;&#123; define &quot;email.to.html&quot; &#125;&#125;名字对应 //删除alertmanager容器，重新运行并挂载 12[root@docker01 ~]# docker rm -f alertmanager[root@docker01 ~]# docker run -d --name alertmanager -p 9093:9093 -v &#x2F;root&#x2F;alertmanager.yml:&#x2F;etc&#x2F;alertmanager&#x2F;alertmanager.yml -v &#x2F;root&#x2F;prometheus&#x2F;alertmanager-tmpl&#x2F;:&#x2F;etc&#x2F;altermanager-tmpl prom&#x2F;alertmanager:latest //停止容器测试","categories":[{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/categories/Docker/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]},{"title":"k8s架构、基本概念","slug":"k8s架构、基本概念","date":"2020-01-23T16:00:00.000Z","updated":"2020-01-25T13:07:32.303Z","comments":true,"path":"k8s架构、基本概念.html","link":"","permalink":"https://pdxblog.top/k8s%E6%9E%B6%E6%9E%84%E3%80%81%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html","excerpt":"","text":"¶k8s总架构： ¶Master节点： （默认不参加工作） kubectl：k8s是命令端，用来发送客户端的操作指令 ¶k8s的原生组件：（部署k8s比必不可少的组件） API server：是k8s集群的前端接口，各种客户端工具以及k8s的其他组件可以通过它管理k8s集群的各种资源，它提供了HTTP/HTTPS RESTful API，即k8s API Scheduler：负责决定将Pod放在哪个Node上运行，在调度时，会充分考虑集群内的拓扑结构，当前各个节点的负载情况，以及对高可用、性能、数据和亲和性需求 Controller Manager：负责管理集群的各种资源，保证资源处于预期的状态，它由多种Controller组成，包括Replication Controller、Endpoints Controller、Namespace Controller、Serviceaccounts Controller等等 Etcd：负责保存k8s集群的配置信息和各种资源的状态信息，当数据发生变化时，etcd会快速的通知k8s相关组件。第三方组件，意味着它有可替换方案，比如：Consul、zookeeper Pod：k8s集群的最小组成单位，一个Pod内，可以运行一个或多个容器，大多数情况下，一个Pod内只有一个Container容器 Flannel：是k8s集群网络解决方案，可以保证Pod的跨主机通信。第三方解决方案，也有替换方案 ¶Node节点： kubelet：它是Node的agent（代理），当Scheduler确定某个Node上运行Pod之后，会将Pod的具体配置信息发送给该节点的kubelet，kubelet会根据这些信息创建和运行容器，并向Master报告运行状态 kube-proxy：负责将访问service的TCP/UDP数据流转发到后端容器，如果有多个副本，kube-pory会实现负载均衡 运行一个例子： //创建一个deployment资源对象。Pod控制器 1[root@master ~]# kubectl run test-web --image&#x3D;httpd --replicas&#x3D;2 分析各个组件的作用以及架构流程： kubectl发送部署请求到API server API server通知Controller Manager创建一个Deployment资源 Scheduler执行调度任务，将两个副本Pod分发到node01和node02上 node1和node02上的kubelet在各个节点上创建并运行Pod 补充： 应用的配置和当前的状态信息报错在etcd中，执行kubectl get pod时API server会从etc中读取这 些数据 flannel会为每个Pod分配一个IP，但此时没有创建Service资源，目前kube-pory还没有参与进来","categories":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]},{"title":"创建资源的两种方式","slug":"创建资源的两种方式","date":"2020-01-23T16:00:00.000Z","updated":"2020-01-25T13:07:32.303Z","comments":true,"path":"创建资源的两种方式.html","link":"","permalink":"https://pdxblog.top/%E5%88%9B%E5%BB%BA%E8%B5%84%E6%BA%90%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F.html","excerpt":"","text":"¶创建资源的两种方式 ¶用命令行的方式创建： //创建Pod控制器，deployments 1[root@master ~]# kubectl run web --image&#x3D;nginx --replicas&#x3D;5 //查看控制器情况 1[root@master ~]# kubectl get deployments. //查看资源详细信息 1[root@master ~]# kubectl describe deployments. web PS：查看某种资源对象，没有指名称空间，默认是在default名称空间，可以加上-n选项，查看指定名称空间 1[root@master ~]# kubectl get pod -n&#x3D;kube-system 注意：直接运行创建的Deployment资源对象，是经常使用的一个控制器类型，除了deployment，还有rc，rs等Pod控制器，Deployment是一个高级的Pod控制器 //创建Service资源类型 1[root@master ~]# kubectl expose deployment web --name&#x3D;web-svc --port&#x3D;80 --type&#x3D;NodePort PS：如果想要外网能够访问服务，可以暴露deployment资源，得到service资源，但svc资源的类型必须为NodePoet 映射端口范围：30000-32767 服务的扩容与缩容： 1[root@master ~]# kubectl scale deployment web --replicas&#x3D;8 //通过修改yuml文件进行扩容与缩容 1[root@master ~]# kubectl edit deployments. web 服务的升级与回滚: 1[root@master ~]# kubectl set image deployment web web&#x3D;nginx:1.15 //通过修改配置文件进行升级 1[root@master ~]# kubectl edit deployments. web //回滚 1[root@master ~]# kubectl rollout undo deployment web ¶配置清单（yml、yaml）： 常见yaml文件写法，以及字段的作用： 五个一级字段： apiVersion: api版本信息 kind: 资源对象的类别 metadata: 元数据。名称字段必须写 spec: 用户期望的状态 status: 资源现在处于什么样的状态 Deployment 12345678910111213141516[root@master ~]# vim web.yamlkind: DeploymentapiVersion: extensions&#x2F;v1beta1metadata: name: webspec: replicas: 2 template: metadata: labels: app: web_server spec: containers: - name: nginx image: nginx[root@master ~]# kubectl apply -f web.yaml service 123456789101112kind: ServiceapiVersion: v1metadata: name: web-svcspec: selector: &#x2F;&#x2F;标签选择器，和Deployment里的标签要一样 app: web_server ports: - protocol: TCP port: 80 targetPort: 80[root@master ~]# kubectl apply -f web-svc.yml 使用相同的标签和标签选择器，使两个资源对象相互关联 PS：（本质的意义：提供一个统一的接口） 创建的Service资源对象，默认的type为ClusterIP,意味着集群内任何节点都可以访问，它的作用是为后端真正提供服务的Pod提供一个统一的访问接口,如果想要外网访问服务，应该把type改为NodePort 12345678910111213kind: ServiceapiVersion: v1metadata: name: web-svcspec: type: NodePort &#x2F;&#x2F;指定类型，让外网来访问 selector: app: web_server ports: - protocol: TCP port: 80 targetPort: 80 nodePort: 30033 &#x2F;&#x2F;指定集群映射端口，范围是30000-32767","categories":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"}]}],"categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/categories/MySQL/"},{"name":"架构","slug":"架构","permalink":"https://pdxblog.top/categories/%E6%9E%B6%E6%9E%84/"},{"name":"Python一些列练习题","slug":"Python一些列练习题","permalink":"https://pdxblog.top/categories/Python%E4%B8%80%E4%BA%9B%E5%88%97%E7%BB%83%E4%B9%A0%E9%A2%98/"},{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/categories/Python/"},{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/categories/k8s/"},{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/categories/Docker/"},{"name":"KVM","slug":"KVM","permalink":"https://pdxblog.top/categories/KVM/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://pdxblog.top/tags/MySQL/"},{"name":"架构","slug":"架构","permalink":"https://pdxblog.top/tags/%E6%9E%B6%E6%9E%84/"},{"name":"Python一系列练习题","slug":"Python一系列练习题","permalink":"https://pdxblog.top/tags/Python%E4%B8%80%E7%B3%BB%E5%88%97%E7%BB%83%E4%B9%A0%E9%A2%98/"},{"name":"Python","slug":"Python","permalink":"https://pdxblog.top/tags/Python/"},{"name":"k8s","slug":"k8s","permalink":"https://pdxblog.top/tags/k8s/"},{"name":"Docker","slug":"Docker","permalink":"https://pdxblog.top/tags/Docker/"},{"name":"KVM","slug":"KVM","permalink":"https://pdxblog.top/tags/KVM/"}]}